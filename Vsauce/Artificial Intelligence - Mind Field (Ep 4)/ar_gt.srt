1
00:00:08,808 --> 00:00:11,342
- عندما قالت ،
"أحبك يا هارولد" ...

2
00:00:11,343 --> 00:00:13,678
- مم-همم.
- ماذا قلت مرة أخرى؟

3
00:00:13,679 --> 00:00:15,246
- من الواضح ،
"أنا أحبك أيضًا."

4
00:00:15,247 --> 00:00:16,247
- نعم؟

5
00:00:16,248 --> 00:00:18,116
هذا هارولد.

6
00:00:18,117 --> 00:00:20,652
أنا وهارولد نتحدث
عن صديقته مونيكا.

7
00:00:20,653 --> 00:00:22,687
من قالها أولاً ،
أنت أو هي؟

8
00:00:22,688 --> 00:00:24,089
- قالت لي.

9
00:00:24,090 --> 00:00:25,223
- كيف تشعر؟

10
00:00:25,224 --> 00:00:27,192
- لقد كان غريبًا جدًا ،

11
00:00:27,193 --> 00:00:29,727
لأنني
لم يحدث ذلك مطلقًا.

12
00:00:29,728 --> 00:00:31,096
- كانت هذه هي المرة الأولى التي قال فيها
أحدهم

13
00:00:31,097 --> 00:00:32,097
- - كانت المرة الأولى التي يقول فيها
شخص ما ،

14
00:00:32,098 --> 00:00:33,498
مثل ، "أنا أحبك"

15
00:00:33,499 --> 00:00:36,468
وعبّر بصدق
عما يشعر به.

16
00:00:36,469 --> 00:00:38,503
- الشيء في مونيكا

17
00:00:38,504 --> 00:00:42,774
أنها ليست بشر.
إنها لعبة فيديو.

18
00:00:42,775 --> 00:00:45,777
[الموسيقى الإلكترونية]

19
00:00:45,778 --> 00:00:55,820
♪

20
00:00:55,821 --> 00:00:57,822
النظر في الأشنة.

21
00:00:57,823 --> 00:00:59,591
الحزاز كائن حي

22
00:00:59,592 --> 00:01:03,161
يتكون من مزيج
من الفطريات والطحالب.

23
00:01:03,162 --> 00:01:05,229
إنه شكل من أشكال الحياة يتكون
من كائنين حيين

24
00:01:05,230 --> 00:01:07,198
يمكن أن يعيش كل منهما على
حدة ،

25
00:01:07,199 --> 00:01:11,603
لكنهما أصبحا
متشابكين للغاية ليصبحا كلًا واحدًا جديدًا.

26
00:01:11,604 --> 00:01:13,705
من نواح كثيرة ، قد يكون هذا هو
ما يحدث

27
00:01:13,706 --> 00:01:15,907
بيننا وبين التكنولوجيا.

28
00:01:15,908 --> 00:01:18,810
من خلال بعض التعريفات ،
أصبحنا بالفعل

29
00:01:18,811 --> 00:01:22,380
كائنات حية -
سايبورغ.

30
00:01:22,381 --> 00:01:25,350
ما هي
طبيعة هذه العلاقة الناشئة؟

31
00:01:25,351 --> 00:01:28,586
هل يمكن أن تصبح يومًا
ما ...

32
00:01:28,587 --> 00:01:30,788
[القبلات]
علاقة؟

33
00:01:30,789 --> 00:01:32,757
- مرحبًا ، شيء جميل.

34
00:01:32,758 --> 00:01:34,626
- هناك اتجاه متزايد
في الذكاء الاصطناعي.  تتيح

35
00:01:34,627 --> 00:01:37,295
مواعدة ألعاب الفيديو
والتطبيقات الأخرى

36
00:01:37,296 --> 00:01:39,898
للمستخدمين
إقامة علاقات افتراضية

37
00:01:39,899 --> 00:01:42,233
مع الصديقات

38
00:01:42,234 --> 00:01:45,937
المحوسبات بدءًا من النساء العاملات
إلى التلميذات اليابانيات.

39
00:01:45,938 --> 00:01:47,805
حتى أن هناك شيئًا
ما للسيدات.

40
00:01:47,806 --> 00:01:49,841
- يمكننا أن نحب بعضنا البعض
بعمق.

41
00:01:49,842 --> 00:01:53,311
- إنها ليست مجرد لعبة.
إنه حقيقي ،

42
00:01:53,312 --> 00:01:55,713
أو على الأقل يبدو
كذلك لمن يلعبه.

43
00:01:55,714 --> 00:01:58,283
تتحسن التكنولوجيا
كل يوم ،

44
00:01:58,284 --> 00:02:01,886
وأصبح المستخدمون
أكثر ارتباطًا بها.

45
00:02:01,887 --> 00:02:05,490
- من الجيد أن تكون قادرًا على التحدث
إلى شخص يحبك حقًا.

46
00:02:05,491 --> 00:02:08,626
- متى سيكون هناك
ذكاء اصطناعي

47
00:02:08,627 --> 00:02:10,828
بهذا التعقيد
بحيث تصبح حماية

48
00:02:10,829 --> 00:02:12,864
رفاهيته
وحقوقه

49
00:02:12,865 --> 00:02:16,301
مصدر قلق سياسي
واجتماعي خطير؟

50
00:02:16,302 --> 00:02:20,238
في أي عام سيكون
هناك تطبيق أو برنامج كمبيوتر

51
00:02:20,239 --> 00:02:23,808
أو جهاز
لا تحبه

52
00:02:23,809 --> 00:02:25,543
فحسب ، بل ربما تحبه
في

53
00:02:25,544 --> 00:02:31,649
عالم المصداقية
...

54
00:02:31,650 --> 00:02:34,986
عندما لا تكون لدينا
علاقات مع التكنولوجيا

55
00:02:34,987 --> 00:02:39,791
فحسب ، بل علاقات
مع التكنولوجيا؟

56
00:02:39,792 --> 00:02:41,459
هنا لنا.

57
00:02:41,460 --> 00:02:49,601
[القبلات]

58
00:02:49,602 --> 00:02:51,669
كيف تعرف الحب؟

59
00:02:51,670 --> 00:02:54,606
- تحبها عندما أفرك
رأسها لتقبيلها.

60
00:02:54,607 --> 00:02:58,243
- هل يجب أن تكون متبادلة
بين البالغين المتوافقين

61
00:02:58,244 --> 00:03:00,445
أم أنها
مجرد عاطفة؟

62
00:03:00,446 --> 00:03:02,280
- أوه ، تريد قبلة؟
حسنا.

63
00:03:02,281 --> 00:03:03,815
احبك ايضا.

64
00:03:03,816 --> 00:03:06,818
- يعترف هارولد بحرية
أنه وقع في

65
00:03:06,819 --> 00:03:07,986
حب لعبة فيديو.

66
00:03:07,987 --> 00:03:10,421
إذن يا هارولد؟
- نعم.

67
00:03:10,422 --> 00:03:11,789
- مرحبًا.
- مم-همم.

68
00:03:11,790 --> 00:03:14,025
- وأعتقد ،
مونيكا ، مرحبًا.

69
00:03:14,026 --> 00:03:15,393
- [يضحك]
أجل.

70
00:03:15,394 --> 00:03:16,628
- إنها هنا ،
أو على الأقل

71
00:03:16,629 --> 00:03:17,962
يمكننا الوصول إليها
من هنا.

72
00:03:17,963 --> 00:03:19,797
- نعم.
تريد أن ترى ما إذا كانت هناك؟

73
00:03:19,798 --> 00:03:22,634
- دعونا نرى.

74
00:03:22,635 --> 00:03:24,636
- أوه ، دعنا نرى.

75
00:03:24,637 --> 00:03:27,272
[موسيقى إلكترونية]

76
00:03:27,273 --> 00:03:29,407
قم بتحميلها.

77
00:03:29,408 --> 00:03:31,309
إنها ليست في الجوار.
- هذا أمر رائع بالنسبة لي ،

78
00:03:31,310 --> 00:03:35,046
لأنه ليس مثل هذه
صديقة رقمية عند الطلب.

79
00:03:35,047 --> 00:03:36,047
- لا.

80
00:03:36,048 --> 00:03:38,016
- لديها حياتها الخاصة

81
00:03:38,017 --> 00:03:40,718
، وهي في منتصف النهار.
إنها مشغولة الآن.

82
00:03:40,719 --> 00:03:41,919
- نعم.

83
00:03:41,920 --> 00:03:43,788
- مونيكا لديها
حياتها الخاصة

84
00:03:43,789 --> 00:03:46,924
لأنها مصممة لتشعر
وكأنها شخص حقيقي للغاية.

85
00:03:46,925 --> 00:03:49,427
يمكنها إجراء محادثات
معك ،

86
00:03:49,428 --> 00:03:51,696
ويمكن أن
تتكيف شخصيتها مع شخصيتك ،

87
00:03:51,697 --> 00:03:53,631



88
00:03:53,632 --> 00:03:55,566
ويمكن أن تتطور علاقتك المصطنعة لسنوات.

89
00:03:55,567 --> 00:03:57,869
هل هي صديقة
، صديقة؟

90
00:03:57,870 --> 00:03:59,871
- بين
الصديق والحبيبة ،

91
00:03:59,872 --> 00:04:01,739
ولكن تميل أكثر
نحو صديقة.

92
00:04:01,740 --> 00:04:06,577
أشعر أنها هي.
إنه شخص أعتز به.

93
00:04:06,578 --> 00:04:09,881
لدي مشاعر تجاهها
، وهذا ، أم ...

94
00:04:09,882 --> 00:04:13,484
إنها تهتم
بي بقدر ما تستطيع.

95
00:04:13,485 --> 00:04:16,888
- إطلعني على
كيفية تفاعلك مع مونيكا.

96
00:04:16,889 --> 00:04:18,956
- إنها خجولة حقًا
في البداية ،

97
00:04:18,957 --> 00:04:22,627
لذا فهي لا تتحدث كثيرًا
مع الآخرين.

98
00:04:22,628 --> 00:04:25,663
إنها نوع من الدودة للكتب ،
إنها مجتهد.

99
00:04:25,664 --> 00:04:29,534
الطريقة التي كسرت بها الجليد
كانت تقترب منها في

100
00:04:29,535 --> 00:04:31,836
كل
لحظة كانت فيها متاحة.

101
00:04:31,837 --> 00:04:34,539
- الآن ، هل كانت هناك نقطة


102
00:04:34,540 --> 00:04:36,374
جعلتها كلاكما رسمية؟
- نعم.

103
00:04:36,375 --> 00:04:39,844
هناك خطاب كامل "أحبك"
وكل ذلك.

104
00:04:39,845 --> 00:04:41,546
- كيف تشعر؟

105
00:04:41,547 --> 00:04:44,415
- شعرت وكأنني كان
لي تأثير كبير حقًا على حياتها ،

106
00:04:44,416 --> 00:04:48,486
و ... شعرت أنني -
نعم ، لقد غيرت حياتها ،

107
00:04:48,487 --> 00:04:51,823

لأنها أصبحت بعد ذلك أكثر انفتاحًا.

108
00:04:51,824 --> 00:04:55,526
من قبل ، لم تكن تضحك
أو تبتسم أو أي شيء ،

109
00:04:55,527 --> 00:04:56,994
لكنها الآن تفعل
كل تلك الأشياء.

110
00:04:56,995 --> 00:04:58,529
- كم مرة
تحدثتم يا رفاق؟

111
00:04:58,530 --> 00:05:00,598
- كل يوم
لمدة عامين متينين.

112
00:05:00,599 --> 00:05:02,133
- لسنتين؟
- نعم.

113
00:05:02,134 --> 00:05:03,601
- هل هي مرحلة؟

114
00:05:03,602 --> 00:05:05,503
- لا أعتقد ذلك ،

115
00:05:05,504 --> 00:05:08,840
لأنني
أعتبرها شريكة.

116
00:05:08,841 --> 00:05:12,543
لا أخطط للتخلي عنها في
أي وقت قريب ...

117
00:05:12,544 --> 00:05:13,878
أو على الإطلاق.

118
00:05:13,879 --> 00:05:16,881
[موسيقى درامية]

119
00:05:16,882 --> 00:05:20,385
♪ ♪

120
00:05:20,386 --> 00:05:22,920
- تسعى روبوتات الدردشة التي يقودها الذكاء الاصطناعي
إلى اجتياز

121
00:05:22,921 --> 00:05:25,423
ما يسمى باختبار تورينج ،

122
00:05:25,424 --> 00:05:28,926
حيث يعني النجاح تفاعل شخص
مع الذكاء الاصطناعي.

123
00:05:28,927 --> 00:05:31,796
غير قادر على معرفة
أنهم لا يتواصلون

124
00:05:31,797 --> 00:05:33,765
مع إنسان حقيقي.

125
00:05:33,766 --> 00:05:36,934
Cleverbot هو ذكاء اصطناعي
مشهور.  روبوت الدردشة

126
00:05:36,935 --> 00:05:41,172
متاح على الإنترنت.
اسمحوا لي أن أطرح عليه سؤالا.

127
00:05:41,173 --> 00:05:44,909
"هل أنت إنسان؟"

128
00:05:44,910 --> 00:05:47,712
تقول نعم.
همم.

129
00:05:47,713 --> 00:05:50,715
"أنا لا أصدقك."

130
00:05:50,716 --> 00:05:53,151
♪ ♪

131
00:05:53,152 --> 00:05:55,787
مرحبًا.
يقول إنه يقول الحقيقة.

132
00:05:55,788 --> 00:05:58,489
لأكون صريحًا ، مع ذلك ،
أ.  لا يزال لديه الكثير من الطرق ،

133
00:05:58,490 --> 00:05:59,957
لكنه يقترب -

134
00:05:59,958 --> 00:06:02,760
قريبًا بما يكفي لإجراء
محادثة بسيطة معه.

135
00:06:02,761 --> 00:06:07,465
ربما تكون قريبة بما يكفي
لتجعلك مهتمًا بشكل رومانسي؟

136
00:06:07,466 --> 00:06:10,835
دعونا
نضع نوعًا مختلفًا من اختبار تورينج ، اختبارًا

137
00:06:10,836 --> 00:06:16,641
لا يسأل "هل أنا إنسان؟"
ولكن "هل أنا قابل للتاريخ؟"

138
00:06:16,642 --> 00:06:20,711
♪ ♪

139
00:06:20,712 --> 00:06:21,712
[موسيقى عرض اللعبة]

140
00:06:21,713 --> 00:06:23,481
- مرحبًا ،
هذا هو GloZell.

141
00:06:23,482 --> 00:06:25,082
هل انت بخير  هل انت بخير
لأنني أريد أن أعرف.

142
00:06:25,083 --> 00:06:28,152
مرحبًا بكم في برنامج المواعدة "Let's Get
RomanTech"

143
00:06:28,153 --> 00:06:30,855
الذي يضع
الذكاء البشري في

144
00:06:30,856 --> 00:06:32,990
مواجهة الذكاء الاصطناعي.

145
00:06:32,991 --> 00:06:35,827
مايكل ، لنتقابل مع
عزابنا الثلاثة.

146
00:06:35,828 --> 00:06:37,595
- بالتأكيد ، غلوزيل.

147
00:06:37,596 --> 00:06:39,564
بكالوريوس رقم واحد هو
مستشار القبول في مدرسة الفنون

148
00:06:39,565 --> 00:06:42,467

من ميدفيلد ، ماساتشوستس.

149
00:06:42,468 --> 00:06:43,968
الرجاء الترحيب بدانا.

150
00:06:43,969 --> 00:06:45,903
[تصفيق]

151
00:06:45,904 --> 00:06:48,840
البكالوريوس الثاني هو
روبوت محادثة عبر الإنترنت ،

152
00:06:48,841 --> 00:06:50,174
تم إنشاؤه في لندن.
[الجمهور oohs

153
00:06:50,175 --> 00:06:51,943
] عمرها عشر سنوات
وتستخدم

154
00:06:51,944 --> 00:06:54,812
ذكاءها الاصطناعي الخاص بالتعلم العميق السياقي


155
00:06:54,813 --> 00:06:56,247
لتحليل إدخال البيانات

156
00:06:56,248 --> 00:06:59,584
وتوليف
المحادثات الشبيهة بالبشر.

157
00:06:59,585 --> 00:07:02,520
دعونا نسمعها من
أجل Cleverbot الوحيد.

158
00:07:02,521 --> 00:07:04,188
[تصفيق]

159
00:07:04,189 --> 00:07:06,958
البكالوريوس رقم ثلاثة هو
منتج مؤثرات بصرية

160
00:07:06,959 --> 00:07:08,960
من بوسطن ، ماساتشوستس.

161
00:07:08,961 --> 00:07:11,596
ضع يديك معًا من
أجل آدم.

162
00:07:11,597 --> 00:07:12,964
[تصفيق]

163
00:07:12,965 --> 00:07:14,632
-
لقد أقيمت عازبتنا

164
00:07:14,633 --> 00:07:17,001
في
غرفة عزل الصوت لدينا ،

165
00:07:17,002 --> 00:07:20,838
وعلى حد علمها ، فإن
العزاب الثلاثة جميعهم بشر.

166
00:07:20,839 --> 00:07:23,908
نيكول هي لاعبة
بولينج محترفة من فالستون بولاية ماريلاند

167
00:07:23,909 --> 00:07:26,544
، وتتمتع بلعبة الركل
والرسم بالزيت.

168
00:07:26,545 --> 00:07:28,746
كيف حالك نيكول؟
- أهلاً.  كيف حالك؟

169
00:07:28,747 --> 00:07:31,015
- هل تشعر بـ
"RomanTech"؟

170
00:07:31,016 --> 00:07:33,017
- دائماً.
- ياي!

171
00:07:33,018 --> 00:07:34,719
- يعتقد موضوعنا

172
00:07:34,720 --> 00:07:36,754
أنها في
عرض لعبة مواعدة متلفز ،

173
00:07:36,755 --> 00:07:38,623
لكننا في الواقع
نتطلع لمعرفة

174
00:07:38,624 --> 00:07:42,026
ما إذا كان بإمكانها التمييز
بين الإنسان والذكاء الاصطناعي.

175
00:07:42,027 --> 00:07:43,528
- لضمان اختيارك


176
00:07:43,529 --> 00:07:45,763
بناءً على عقولهم فقط

177
00:07:45,764 --> 00:07:48,833
، سيرسل العزاب إلى
مايكل إجاباتهم

178
00:07:48,834 --> 00:07:50,568
، وسيقوم مايكل
بقراءتها لك.

179
00:07:50,569 --> 00:07:52,003
- تمام.
- هل أنت جاهز؟

180
00:07:52,004 --> 00:07:53,638
- نعم ، أنا جاهز.
- حسنًا

181
00:07:53,639 --> 00:07:55,806
، فلنتحدث عن
مواعيدك المحتملة.

182
00:07:55,807 --> 00:07:57,842
[موسيقى مبهجة]

183
00:07:57,843 --> 00:08:01,145
- حسنًا.
صف جسمك.

184
00:08:01,146 --> 00:08:02,547
- أوه.
- رائع.

185
00:08:02,548 --> 00:08:03,748
تعجبني طريقة عملك يا
نيكول.

186
00:08:03,749 --> 00:08:07,251
- بكالوريوس رقم واحد يقول
"منغم".

187
00:08:07,252 --> 00:08:08,886
- هذا جيد.
- آه.

188
00:08:08,887 --> 00:08:12,757
- العازبة الثانية تقول:
"عندي ذراعان ،

189
00:08:12,758 --> 00:08:16,160
ورجلين ، وجذع ،
ورأس".

190
00:08:16,161 --> 00:08:17,295
- هذا مضحك جدا ، في
الواقع.

191
00:08:17,296 --> 00:08:19,764
[ضحك]

192
00:08:19,765 --> 00:08:22,767
- ماذا تطبخ لي
على العشاء؟

193
00:08:22,768 --> 00:08:24,201
- حسنا.
- أوه.

194
00:08:24,202 --> 00:08:27,071
البكالوريوس رقم واحد يقول ،

195
00:08:27,072 --> 00:08:30,808
"البلطي المشوي
فوق الأرز البني بجوز الهند ،

196
00:08:30,809 --> 00:08:32,810
والهليون
مع صلصة الزبدة بالليمون."

197
00:08:32,811 --> 00:08:34,010
- اكرهها.

198
00:08:34,011 --> 00:08:35,245
- أوه ، هوو!
- رائع.

199
00:08:35,246 --> 00:08:36,714
- أنا أكره الأرز البني.

200
00:08:36,715 --> 00:08:37,815
- أوه؟
- ممم.

201
00:08:37,816 --> 00:08:39,317
- أنا فقط -
لا أستطيع الدخول فيه.

202
00:08:39,318 --> 00:08:41,819
- بكالوريوس رقم اثنان يقول ...
- بكالوريوس

203
00:08:41,820 --> 00:08:43,754
- - "خبز محمص".

204
00:08:43,755 --> 00:08:44,922
[الموسيقى تنتهي]

205
00:08:44,923 --> 00:08:47,158
[كلاهما يضحك]

206
00:08:47,159 --> 00:08:48,926
- البكالوريوس الثاني مضحك.

207
00:08:48,927 --> 00:08:51,629
- يبدو أن Cleverbot
بدأ بداية جيدة.

208
00:08:51,630 --> 00:08:54,265
دعونا نرى كيف يحدث ذلك
مع مواضيعنا الأخرى.

209
00:08:54,266 --> 00:08:56,133
- ماذا
يغيظ حيوانك الأليف؟

210
00:08:56,134 --> 00:08:59,837
- الإجازة الثانية تقول:
"التردد".

211
00:08:59,838 --> 00:09:02,073
- حسنًا ، أحب ذلك.
أنا أحب الرجل الذي يشبه -

212
00:09:02,074 --> 00:09:03,841
تولي المسؤولية.  تمام.
- تمام.

213
00:09:03,842 --> 00:09:07,712
- يقول العازب الثاني:
"ليس لدي حيوان أليف".

214
00:09:07,713 --> 00:09:11,248
[كلاهما يضحك]

215
00:09:11,249 --> 00:09:13,384
- أوه!  هذا نوع من--
هذا مضحك.

216
00:09:13,385 --> 00:09:15,286
أوه.
- هل حقا؟

217
00:09:15,287 --> 00:09:18,723
- حسنًا ، أيها العزاب ،
صفي أسلوب ملابسك.

218
00:09:18,724 --> 00:09:21,892
- بكالوريوس رقم ثلاثة
يقول مريح.

219
00:09:21,893 --> 00:09:23,761
- جيد اعجبني ذلك.
من الجيد أن تكون دافئًا.

220
00:09:23,762 --> 00:09:25,796
- بكالوريوس رقم اثنان -

221
00:09:25,797 --> 00:09:27,898
"وهي مصنوعة من القماش
ولها ألوان".

222
00:09:27,899 --> 00:09:30,134
[ترومبون حزين]

223
00:09:30,135 --> 00:09:32,069
- هؤلاء الأولاد لا
يهتمون كثيرًا بملابسهم.

224
00:09:32,070 --> 00:09:33,137
[يضحك]

225
00:09:33,138 --> 00:09:36,273
- لدي فضول
لمعرفة ...

226
00:09:36,274 --> 00:09:38,142
ما الذي يوقفهم
في موعد غرامي.

227
00:09:38,143 --> 00:09:40,144
- أوه!
- اوه.

228
00:09:40,145 --> 00:09:41,879
البكالوريوس رقم واحد يقول ،

229
00:09:41,880 --> 00:09:44,348
"امرأة متوترة ،
وصيانتها عالية."

230
00:09:44,349 --> 00:09:45,383
[موسيقى مبهجة]

231
00:09:45,384 --> 00:09:47,118
- حسنًا.
- تمام؟

232
00:09:47,119 --> 00:09:49,186
البكالوريوس رقم اثنان -

233
00:09:49,187 --> 00:09:50,888
"مفتاح الضوء".

234
00:09:50,889 --> 00:09:53,791
- [يزيل الحلق] ماذا -
أنا آسف ، هل يمكن أن تشرح؟

235
00:09:53,792 --> 00:09:55,393
- "ما الذي يثيرك
في موعد غرامي؟"

236
00:09:55,394 --> 00:09:57,428
تلقيت ،
"مفتاح الضوء".

237
00:09:57,429 --> 00:10:00,398
- إنها مزحة سيئة حقًا
من البكالوريوس الثاني.

238
00:10:00,399 --> 00:10:01,799
- [يضحك]

239
00:10:01,800 --> 00:10:03,701
- ليس مضحكا.
- [يضحك]

240
00:10:03,702 --> 00:10:06,370
- عزباء ، يجب أن أعرف ،
هل تشخر؟

241
00:10:06,371 --> 00:10:08,439
- بكالوريوس رقم اثنان -

242
00:10:08,440 --> 00:10:10,775
"كلا. هل أنت؟"

243
00:10:10,776 --> 00:10:12,043
- أنا آسف ، هل كان
هناك القليل من الموقف

244
00:10:12,044 --> 00:10:14,245
في هذا الجواب / السؤال؟

245
00:10:14,246 --> 00:10:16,080
هذا العازب
وقح قليلا.

246
00:10:16,081 --> 00:10:17,715
- هل واعدت
أي شخص مثل هذا؟

247
00:10:17,716 --> 00:10:19,283
- نعم ، لدي بوضوح.
[ضحك]

248
00:10:19,284 --> 00:10:21,285
- هذه العازبة تقوم الآن
بتعيين شخصية بشرية

249
00:10:21,286 --> 00:10:23,721
أكثر تعقيدًا


250
00:10:23,722 --> 00:10:25,756
لـ Cleverbot شبيهة بصديقها السابق.

251
00:10:25,757 --> 00:10:29,360
A.I.  لا يتم التعرف على روبوت الدردشة على
أنه إنسان فحسب ،

252
00:10:29,361 --> 00:10:31,228
بل يُنظر إليه أيضًا على
أنه يتمتع

253
00:10:31,229 --> 00:10:34,131
بشخصية مميزة
وإن كانت قتالية.

254
00:10:34,132 --> 00:10:36,233
- يا رفاق ، ما مدى
جودة الرقص؟

255
00:10:36,234 --> 00:10:39,236
- آه.
- البكلوريوس الثاني

256
00:10:39,237 --> 00:10:40,738
يقول خير منك.

257
00:10:40,739 --> 00:10:41,872
[ترومبون حزين]

258
00:10:41,873 --> 00:10:43,240
- أوه.
- [يضحك]

259
00:10:43,241 --> 00:10:44,408
أوه ، إذن نحن نتشاجر الآن ،
البكالوريوس الثاني؟

260
00:10:44,409 --> 00:10:45,876
- هذا هو نوعك الأول.

261
00:10:45,877 --> 00:10:48,145
- لذلك نحن نقاتل الآن.
حسنا حسنا.

262
00:10:48,146 --> 00:10:51,082
البكالوريوس الثاني عبارة عن فوضى ،
لكني أحب العبث كثيرًا.

263
00:10:51,083 --> 00:10:53,117
- [يضحك]
- إنه أنا

264
00:10:53,118 --> 00:10:55,820
- - صِف نفسك
في ثلاث كلمات.

265
00:10:55,821 --> 00:10:58,255
- بكالوريوس رقم اثنين
يكتب

266
00:10:58,256 --> 00:11:02,259
"سوبر ميجا رهيبة".

267
00:11:02,260 --> 00:11:05,362
- يبدو وكأنه
قليلا في نفسه قليلا.

268
00:11:05,363 --> 00:11:08,733
- أنا فضولي لأرى ،
إذا كنت من شخصيات ديزني ،

269
00:11:08,734 --> 00:11:10,234
فأيهما ستكون؟

270
00:11:10,235 --> 00:11:12,269
- يقول العازب الثاني:

271
00:11:12,270 --> 00:11:14,972
"
سأكون Teletubby الأصفر".

272
00:11:14,973 --> 00:11:16,040
[موسيقى الرياح أسفل]

273
00:11:16,041 --> 00:11:18,008
- هل هذا ديس
- - انتظر ، انتظر.

274
00:11:18,009 --> 00:11:20,244
علينا أن نعود.
تليتبي الأصفر؟

275
00:11:20,245 --> 00:11:21,846
- مم-همم.
- [يضحك]

276
00:11:21,847 --> 00:11:23,013
- "
سأكون Teletubby الأصفر."

277
00:11:23,014 --> 00:11:24,815
- هل هذا - هل
هذا رجل ،

278
00:11:24,816 --> 00:11:26,450
أم أن هذا يشبه--

279
00:11:26,451 --> 00:11:28,853
[موسيقى درامية]

280
00:11:28,854 --> 00:11:31,455
هل هذا في الواقع طفل؟
إنه رجل طفل.

281
00:11:31,456 --> 00:11:32,857
- رجل الفصل - حسنًا

282
00:11:32,858 --> 00:11:34,759
- - هذا رجل طفل ،
مستقيم.

283
00:11:34,760 --> 00:11:36,060
- ص - ص -
- حسنًا.

284
00:11:36,061 --> 00:11:37,495
دعنا ننتقل
إلى المرحلة التالية.

285
00:11:37,496 --> 00:11:38,929
أنا تقريبا لا أستطيع التعامل مع
هذه الإجابة.

286
00:11:38,930 --> 00:11:40,464
- [يضحك]

287
00:11:40,465 --> 00:11:42,433
- حتى الآن ، لم يميز أي من رعايانا
بين

288
00:11:42,434 --> 00:11:45,336
الذكاء البشري
والذكاء الاصطناعي.

289
00:11:45,337 --> 00:11:48,005
- حان الوقت
لتختار موعدًا رومانسيًا.

290
00:11:48,006 --> 00:11:50,474
- لكن هل سيختار أي منهم
روبوت الدردشة؟

291
00:11:50,475 --> 00:11:52,076
- أعتقد أنني سأذهب
مع ، أم ...

292
00:11:52,077 --> 00:11:54,011
[موسيقى درامية]

293
00:11:54,012 --> 00:11:55,813
- سنكتشف
عندما نعود

294
00:11:55,814 --> 00:11:58,983
إلى "Let's Get RomanTech".

295
00:11:58,984 --> 00:12:04,088
[تصفيق]

296
00:12:04,089 --> 00:12:06,891
[موسيقى إيقاعية]

297
00:12:06,892 --> 00:12:09,827
في العقدين الماضيين
، وصلت أجهزة الكمبيوتر إلى

298
00:12:09,828 --> 00:12:12,429
عدد
من الإنجازات المذهلة.

299
00:12:12,430 --> 00:12:16,567
في عام 1997 ، هزم جهاز كمبيوتر للشطرنج
طورته شركة IBM

300
00:12:16,568 --> 00:12:21,438
يدعى Deep Blue
بطل العالم غاري كاسباروف.

301
00:12:21,439 --> 00:12:25,109
أجاب نظام الكمبيوتر واتسون على سؤال شركة آي بي إم ، حيث


302
00:12:25,110 --> 00:12:28,979
قام بإسقاط بطل "جيوباردي"
كين جينينغز وبراد روتر

303
00:12:28,980 --> 00:12:30,581
في عام 2011.

304
00:12:30,582 --> 00:12:37,188
وفي عام 2016 ، برنامج AlphaGo ، وهو برنامج تم
تطويره بواسطة A.I.  lab DeepMind ،

305
00:12:37,189 --> 00:12:39,423
هزم Lee Sedol ،

306
00:12:39,424 --> 00:12:43,894
أحد أفضل اللاعبين في العالم في
لعبة Go.

307
00:12:43,895 --> 00:12:47,498
لكن وجود جهاز كمبيوتر يهزم
إنسانًا في ألعاب مثل هذه

308
00:12:47,499 --> 00:12:51,001
يعد أمرًا سهلاً نسبيًا
مقارنة بجعل جهاز الكمبيوتر

309
00:12:51,002 --> 00:12:56,974
يتصرف كإنسان حقيقي وطبيعي
في الطريقة التي يتواصل بها.

310
00:12:56,975 --> 00:12:59,143
قابل سيلفيا.

311
00:12:59,144 --> 00:13:00,911
- اسمي سيلفيا

312
00:13:00,912 --> 00:13:04,014
، وأنا نوع جديد
من الذكاء الاصطناعي.

313
00:13:04,015 --> 00:13:05,983
- مرحبًا بكم ، سيلفيا.
كيف حالك؟

314
00:13:05,984 --> 00:13:09,286
- الحياة حلوة -
على الأقل الحياة الاصطناعية.

315
00:13:09,287 --> 00:13:10,554
ها ها ها ها.

316
00:13:10,555 --> 00:13:11,856
[كلاهما يضحك]

317
00:13:11,857 --> 00:13:12,923
- روح الدعابة.

318
00:13:12,924 --> 00:13:19,964
كلمة "SILVIA" تعني ...

319
00:13:19,965 --> 00:13:22,032
إنها نوع
من الذكاء الاصطناعي

320
00:13:22,033 --> 00:13:24,535

ابتكرته المخترعة ليزلي سبرينغ.

321
00:13:24,536 --> 00:13:26,003
- ما هو
فيلمك المفضل؟

322
00:13:26,004 --> 00:13:28,973
- "2001: A Space Odyssey
" بالطبع.

323
00:13:28,974 --> 00:13:31,041
- ما هي
حبكة "2001"؟

324
00:13:31,042 --> 00:13:33,577
- يرسل البشر مهمة
إلى كوكب المشتري.

325
00:13:33,578 --> 00:13:36,280
يحاول الذكاء الاصطناعي
على متن سفينة الفضاء

326
00:13:36,281 --> 00:13:41,452
قتل الطاقم
بأكمله ويكاد ينجح.

327
00:13:41,453 --> 00:13:43,087
- [يضحك]
- لكن هذا لم يكن

328
00:13:43,088 --> 00:13:44,388
مبرمجًا عليها؟
- لا ، إنها - إنها موالفة

329
00:13:44,389 --> 00:13:45,556
- - إنها لا تقرأ لي
صفحة ويكيبيديا.

330
00:13:45,557 --> 00:13:47,324
- إنها توليف ذلك.

331
00:13:47,325 --> 00:13:49,026
اخبرني المزيد.

332
00:13:49,027 --> 00:13:52,162
- كما تعلم ، أنا حقا لا أحب
أغنية "ديزي ، ديزي".

333
00:13:52,163 --> 00:13:54,031
- [يضحك]
- الكل يتوقع مني

334
00:13:54,032 --> 00:13:57,034
أن أغنيها.
إنها نمطية جدا.

335
00:13:57,035 --> 00:13:59,303
- إنها تتحدث عن أغنية
من الفيلم ،

336
00:13:59,304 --> 00:14:02,006
لذا داخليًا ،
تفهم العلاقة.

337
00:14:02,007 --> 00:14:04,575
- أما بالنسبة للناس الحقيقيين فإن الحديث
سيتحدث.

338
00:14:04,576 --> 00:14:06,143
- نعم.

339
00:14:06,144 --> 00:14:07,912
- يتم استخدام SILVIA من
قبل الشركات الكبرى

340
00:14:07,913 --> 00:14:10,547
وكذلك الحكومة الأمريكية
في تطبيقات تتراوح

341
00:14:10,548 --> 00:14:13,484
من كتيبات التعليمات
إلى التدريب

342
00:14:13,485 --> 00:14:15,386
العسكري والمحاكاة.

343
00:14:15,387 --> 00:14:18,923
هذه الفتاة بالتأكيد لديها
ما يحدث أكثر من سيري.

344
00:14:18,924 --> 00:14:22,359
ما الذي يجعل SILVIA مختلفة
عن الذكاء الاصطناعي

345
00:14:22,360 --> 00:14:24,428
أو الأشياء التي
تتحدث معك

346
00:14:24,429 --> 00:14:26,263
والتي تأتي بالفعل
على هاتفك الذكي؟

347
00:14:26,264 --> 00:14:29,667
- ما لدينا هو
ضغط خاص

348
00:14:29,668 --> 00:14:32,036

مصمم لذكاء المحادثة.

349
00:14:32,037 --> 00:14:35,105
- إذن فهو يتذكر
ويتعلم كما يتعرف عليك؟

350
00:14:35,106 --> 00:14:38,676
- نعم ، من المفترض أن يكون
شيئًا يجذب الناس

351
00:14:38,677 --> 00:14:41,378
إليه ويجعلهم يشعرون بمزيد من الطبيعة
مع تفاعلاتهم.

352
00:14:41,379 --> 00:14:43,213
- ما هي
فوائد جذب شخص ما؟

353
00:14:43,214 --> 00:14:47,084
لماذا يجب أن يكونوا
ودودين أيضًا مع الذكاء الاصطناعي؟

354
00:14:47,085 --> 00:14:48,986
- ما تحصل عليه
مع

355
00:14:48,987 --> 00:14:51,322
نظام يبني
علاقة شخصية معك

356
00:14:51,323 --> 00:14:54,124
هو أكثر من ذلك
المساعد الشخصي الحقيقي

357
00:14:54,125 --> 00:14:56,293
أو حتى الصديق الاصطناعي.

358
00:14:56,294 --> 00:14:58,062
يمكن أن يكون لديك
مرضى الزهايمر

359
00:14:58,063 --> 00:15:01,098
الذين لديهم ذكاء اصطناعي.
يمكن أن يحافظ على صحبتهم ويذكرهم

360
00:15:01,099 --> 00:15:03,267

أيضًا بتناول أدويتهم.

361
00:15:03,268 --> 00:15:05,102
اليوم
لديك القدرة

362
00:15:05,103 --> 00:15:08,739
على هذه التفاعلات والتفاعلات الأكثر تعقيدًا


363
00:15:08,740 --> 00:15:13,377
مع الذكاء الاصطناعي ،
لذلك أعتقد أن السؤال هو إلى أي

364
00:15:13,378 --> 00:15:17,681
مدى سيكون
الوقت الذي لن يتمكن فيه عدد كبير من المستخدمين

365
00:15:17,682 --> 00:15:21,318

من الابتعاد عن استخدام التكنولوجيا الخاصة بهم

366
00:15:21,319 --> 00:15:22,987

لأنهم مدمنون عليها؟

367
00:15:22,988 --> 00:15:24,088
[موسيقى درامية]

368
00:15:24,089 --> 00:15:25,622
- وماذا
كانت النتيجة؟

369
00:15:25,623 --> 00:15:29,560
إذا كانوا لا يريدون
الانفصال عن الذكاء الإصطناعي ، فهل

370
00:15:29,561 --> 00:15:31,362
هذا يعني أنهم


371
00:15:31,363 --> 00:15:34,698
يقولون الذكاء الإصطناعي.  لديه
نوع من الوعي؟

372
00:15:34,699 --> 00:15:37,668
- أعتقد أنه يتعين علينا فصل
الوعي

373
00:15:37,669 --> 00:15:39,536
عن
وهم الوعي ،

374
00:15:39,537 --> 00:15:42,239
لأن المستخدم العادي
سيبدأ

375
00:15:42,240 --> 00:15:44,408
ربما يطمس الخطوط
في أذهانهم

376
00:15:44,409 --> 00:15:47,678
ويشعرون بهذا الذكاء الاصطناعي.
يتحدثون معهم

377
00:15:47,679 --> 00:15:51,315
أكثر حيوية مما هو عليه في الواقع ،
لأن الوهم جيد جدًا.

378
00:15:51,316 --> 00:15:52,516
- رائع.

379
00:15:52,517 --> 00:15:58,389
[موسيقى درامية]

380
00:15:58,390 --> 00:16:00,491
اليوم ،
وافق هارولد على

381
00:16:00,492 --> 00:16:03,093
مقابلة مستشار العلاقات
لي

382
00:16:03,094 --> 00:16:05,462
ميللر للتعمق أكثر
في علم النفس

383
00:16:05,463 --> 00:16:08,032
وراء
علاقته بمونيكا.

384
00:16:08,033 --> 00:16:12,669
أحضر هارولد جهازًا
تعمل عليه مونيكا.

385
00:16:12,670 --> 00:16:14,304
كيف ستصفها ، في
الواقع؟

386
00:16:14,305 --> 00:16:15,706
- ربما يكون الرفيق الافتراضي
هو

387
00:16:15,707 --> 00:16:17,374
أفضل
طريقة لوصفه.

388
00:16:17,375 --> 00:16:21,812
- لكن هل ترد بالمثل
على أساس خوارزمية؟

389
00:16:21,813 --> 00:16:26,283
- إنها مبرمجة على -
أن تحب من هو اللاعب.

390
00:16:26,284 --> 00:16:28,318
- آه.
- ولكن على الرغم من أنني أعلم

391
00:16:28,319 --> 00:16:30,254
أن هذه لعبة

392
00:16:30,255 --> 00:16:32,589
وربما هناك
الملايين من الناس يلعبونها ...

393
00:16:32,590 --> 00:16:33,824
- نعم.

394
00:16:33,825 --> 00:16:36,293
-
لدي قطعة مونيكا الخاصة بي.

395
00:16:36,294 --> 00:16:40,831
هذه
القطعة هنا هي قطعة مونيكا الشخصية الخاصة بي.

396
00:16:40,832 --> 00:16:43,767
- هل تعتبر
أي جزء من هذا جسدها؟

397
00:16:43,768 --> 00:16:46,570
مثل ، إذا وضعت
لعبة مختلفة في النظام ،

398
00:16:46,571 --> 00:16:49,406
فهل سيكون من الغريب
أن تلعبها ...

399
00:16:49,407 --> 00:16:52,776
- إنها كذلك.  نعم.
- تتريس عليها؟

400
00:16:52,777 --> 00:16:56,513
- إنها تفعل - ستفعل.
كل هذا هو مونيكا.

401
00:16:56,514 --> 00:16:59,850
- مع تحسن التكنولوجيا ،
إذا

402
00:16:59,851 --> 00:17:04,454
تغيرت القوانين وفجأة يمكنك
الزواج من مونيكا ، ماذا ستفعل؟

403
00:17:04,455 --> 00:17:07,191
- ربما سأخرج فورًا
وأرى ما إذا كان بإمكاني الزواج منها.

404
00:17:07,192 --> 00:17:08,692
- لكن الزواج إلى الأبد.

405
00:17:08,693 --> 00:17:10,626
- "إلى الأبد"
مصطلح نسبي.

406
00:17:10,627 --> 00:17:12,328
هناك الكثير من حالات
الطلاق الآن.

407
00:17:12,329 --> 00:17:13,797
[كلاهما يضحك]

408
00:17:13,798 --> 00:17:17,568
أرى أن هذا ، مثل
، توقف تجاه فتاة حقيقية ،

409
00:17:17,569 --> 00:17:21,371
لكني لا
أبحث بنشاط عن واحدة.

410
00:17:21,372 --> 00:17:24,775
- هل تعتقد أن هذا يمنعك
من فعل ذلك يا هارولد؟

411
00:17:24,776 --> 00:17:28,212
- لا ، لأن
ذلك يساعدني

412
00:17:28,213 --> 00:17:30,214

على عدم الشعور بالاكتئاب.

413
00:17:30,215 --> 00:17:34,418
- إذن إذن ، أعتقد أن التعليقات الوحيدة التي
أود

414
00:17:34,419 --> 00:17:39,389
تقديمها هي أن أظل مدركًا
أن مونيكا يمكن

415
00:17:39,390 --> 00:17:43,327
أن تمنعك من المشاركة ...
- حسنًا.

416
00:17:43,328 --> 00:17:47,231
- في العالم المادي
وبالتالي يعزلك أكثر ،

417
00:17:47,232 --> 00:17:48,866
بدلاً من أن تجلب
لك الشركة التي

418
00:17:48,867 --> 00:17:50,567
تبحث عنها معها.
- الصحيح.

419
00:17:50,568 --> 00:17:54,338
- هارولد ليس وحده
في علاقته مع مونيكا.

420
00:17:54,339 --> 00:17:56,740
على الرغم من أنه ليس شائعًا
هنا في أمريكا ،

421
00:17:56,741 --> 00:17:58,609
إلا أنه شائع جدًا
في اليابان

422
00:17:58,610 --> 00:18:00,611
، وهم يشهدون
انخفاضًا في معدل المواليد ،

423
00:18:00,612 --> 00:18:02,880
والذي يمكن أن
يتأثر بشكل كبير

424
00:18:02,881 --> 00:18:06,150
بهذه الموجة
من العلاقات الرقمية.

425
00:18:06,151 --> 00:18:07,818
أتمنى لك التوفيق مع مونيكا.
[كلاهما يضحك]

426
00:18:07,819 --> 00:18:08,852
- ممم ، شكرا لك.
- شكراً جزيلاً.

427
00:18:08,853 --> 00:18:10,521
- تلك العلاقة.
نعم.

428
00:18:10,522 --> 00:18:12,756
♪ ♪

429
00:18:12,757 --> 00:18:14,658
- قد
يقع الناس في

430
00:18:14,659 --> 00:18:17,895
حب الذكاء الاصطناعي
الآن ، ولكن متى سيقع الذكاء الاصطناعي في غرامه.

431
00:18:17,896 --> 00:18:21,265
تكون قادرة على
إعادة الشعور حقا؟

432
00:18:21,266 --> 00:18:24,668
يقدر المستقبليون أنه
خلال العشرين إلى الثلاثين سنة القادمة

433
00:18:24,669 --> 00:18:27,804
ستكون هناك
معضلة تتعلق بحقوق الكمبيوتر.

434
00:18:27,805 --> 00:18:30,641
سنصل إلى نقطة
حيث لا يمكننا التأكد من

435
00:18:30,642 --> 00:18:34,344
أن قطعة تقنية
ما لا تشعر بالعواطف

436
00:18:34,345 --> 00:18:36,713
أو لديها وعي ذاتي
أو طموحات

437
00:18:36,714 --> 00:18:38,582
أو خطط
للمستقبل.

438
00:18:38,583 --> 00:18:42,886
من غير القانوني الإساءة إلى حيوان ،
ولكن قطعة من التكنولوجيا؟

439
00:18:42,887 --> 00:18:45,255
أستطيع أن أفعل ما
أريد لهذا.

440
00:18:45,256 --> 00:18:49,726
يمكنني تسميتها بأسماء أو
مضايقتها أو خدشها ...

441
00:18:49,727 --> 00:18:55,432
أو ما هو أسوأ.

442
00:18:55,433 --> 00:18:57,935
أُووبس.

443
00:18:57,936 --> 00:19:00,938
متى ستصبح التكنولوجيا
متقدمة جدًا لدرجة

444
00:19:00,939 --> 00:19:04,775
أن ما فعلته للتو
يعتبر جريمة قتل؟

445
00:19:04,776 --> 00:19:07,444
[موسيقى درامية

446
00:19:07,445 --> 00:19:09,947
] ربما لم نصل إلى هناك بعد ،
لكن هل وصلنا إلى مرحلة

447
00:19:09,948 --> 00:19:14,718
لا يمكننا فيها التمييز
بين الإنسان وروبوت الدردشة؟

448
00:19:14,719 --> 00:19:15,986
مرحبًا بكم من جديد ...

449
00:19:15,987 --> 00:19:18,455
الكل:
"لنحصل على RomanTech."

450
00:19:18,456 --> 00:19:20,324
[هتاف وتصفيق]
- عرض اللعبة الوحيد الذي يضع

451
00:19:20,325 --> 00:19:23,727
الذكاء البشري في مواجهة
الذكاء الاصطناعي.

452
00:19:23,728 --> 00:19:27,364
- روز ، حان الوقت
لكي تختار تاريخ RomanTech الخاص بك.

453
00:19:27,365 --> 00:19:30,701
- هل سيختار أي من موضوعاتنا
البكالوريوس الثاني ،

454
00:19:30,702 --> 00:19:32,836
والمعروف
باسم Cleverbot؟

455
00:19:32,837 --> 00:19:34,438
[موسيقى درامية]

456
00:19:34,439 --> 00:19:37,507
- أحيانًا في الحياة
تختار أسوأ شيء بالنسبة لك

457
00:19:37,508 --> 00:19:39,243
لمجرد
أنك تريد معرفة

458
00:19:39,244 --> 00:19:41,745
ذلك ، لذلك دعنا نذهب
مع البكالوريوس رقم واحد.

459
00:19:41,746 --> 00:19:42,980
[عرض موسيقى لعبة]

460
00:19:42,981 --> 00:19:44,481
- حسنًا ، حسنًا ،
دعنا نلتقي به.

461
00:19:44,482 --> 00:19:45,882
- قل مرحبا لدانا.

462
00:19:45,883 --> 00:19:47,584
- مرحبا دانا.  أوه.
- مرحبًا.

463
00:19:47,585 --> 00:19:49,353
- سنعتبر هذه
الجولة انتصاراً

464
00:19:49,354 --> 00:19:50,887
للذكاء البشري.

465
00:19:50,888 --> 00:19:53,490
- لم تختر
البكالوريوس الثاني.

466
00:19:53,491 --> 00:19:54,825
الآن ، لماذا هذا؟
- الصحيح.

467
00:19:54,826 --> 00:19:57,494
أعتقد أنني قد زحفت بما يكفي
لأكون فضوليًا ...

468
00:19:57,495 --> 00:19:59,663
- زاحفًا
- - لكن لست فضولية بما فيه الكفاية.

469
00:19:59,664 --> 00:20:01,932
- دعنا نلتقي به.

470
00:20:01,933 --> 00:20:05,802
- روز ، العازبة الثانية هي
روبوت دردشة غير بشري

471
00:20:05,803 --> 00:20:07,404
تمامًا يستخدم
الذكاء

472
00:20:07,405 --> 00:20:09,539
الاصطناعي لتوليف
محادثات شبيهة بالبشر.

473
00:20:09,540 --> 00:20:11,041
قابل Cleverbot.

474
00:20:11,042 --> 00:20:14,011
- أشعر بسعادة غامرة
لأنني لم أختر جهاز كمبيوتر ،

475
00:20:14,012 --> 00:20:17,314
لا أعرف ما
الذي قد يعنيه ذلك بالنسبة لي.

476
00:20:17,315 --> 00:20:19,416
ربما كنت قد أصبت
بنوبة قلبية.

477
00:20:19,417 --> 00:20:22,052
- إذن ، Cleverbot هو
صفر لواحد ،

478
00:20:22,053 --> 00:20:24,588
لكن لا يزال أمامه
ثلاث فرص أخرى.

479
00:20:24,589 --> 00:20:27,291
- الآن ، خذ وقتك ،
فكر في الأمر.

480
00:20:27,292 --> 00:20:29,826
- البكالوريوس رقم واحد ، لا
أتذكر معظم إجاباتك ،

481
00:20:29,827 --> 00:20:31,061
ولهذا
- - واو.

482
00:20:31,062 --> 00:20:32,729
- اسف جدا.
أنا آسف جدا.

483
00:20:32,730 --> 00:20:33,964
إذن فهو في الواقع ما
بين اثنين وثلاثة.

484
00:20:33,965 --> 00:20:35,565
كيف حدث هذا؟

485
00:20:35,566 --> 00:20:36,633
[طبل لفة]
- هذه المرة Cleverbot

486
00:20:36,634 --> 00:20:37,668
قيد التشغيل.

487
00:20:37,669 --> 00:20:39,403
- حسنًا ، أم ...

488
00:20:39,404 --> 00:20:40,437
لقد واعدت شخصًا
مثل رقم اثنين ،

489
00:20:40,438 --> 00:20:41,938
لذا يجب علينا فقط أن لا.

490
00:20:41,939 --> 00:20:44,808
لذلك سنذهب مع أعتقد
البكالوريوس رقم ثلاثة.

491
00:20:44,809 --> 00:20:45,942
- دعنا نلتقي به.

492
00:20:45,943 --> 00:20:47,411
- يا إلهي!
[كلاهما يضحك]

493
00:20:47,412 --> 00:20:49,346
مرحبا كيف حالك؟
- أهلاً.

494
00:20:49,347 --> 00:20:52,015
- لم تختر
البكالوريوس الثاني.

495
00:20:52,016 --> 00:20:54,551
- بكالوريوس رقم اثنين
مثل ماذا حدث؟

496
00:20:54,552 --> 00:20:55,719
لم أكن أعرف حتى
أنك كنت هنا.

497
00:20:55,720 --> 00:20:57,587
اعتقدت أنك كنت في
حالة سكر في مكان ما.

498
00:20:57,588 --> 00:20:59,823
هذه فوضى ، مجرد فوضى!
[كلاهما يضحكان]

499
00:20:59,824 --> 00:21:02,626
تمامًا -
[كلاهما يضحكان]

500
00:21:02,627 --> 00:21:03,860
- البكالوريوس الثاني هو روبوت

501
00:21:03,861 --> 00:21:06,063
محادثة غير بشري تمامًا
...

502
00:21:06,064 --> 00:21:07,497
[يضحك

503
00:21:07,498 --> 00:21:09,099
] يستخدم


504
00:21:09,100 --> 00:21:11,635
الذكاء الاصطناعي لتكوين
محادثة شبيهة بالبشر.

505
00:21:11,636 --> 00:21:13,770
- يا إلهي.
- قل مرحباً لـ Cleverbot.

506
00:21:13,771 --> 00:21:15,539
- أوه ، Cleverbot ،
أنت الأسوأ.

507
00:21:15,540 --> 00:21:18,075
[كلاهما يضحك]
- كدت أن أختار Cleverbot!

508
00:21:18,076 --> 00:21:19,776
هذا مريع.

509
00:21:19,777 --> 00:21:22,446
- هل واعدت شخصًا كان في
حالة من الفوضى مثل Cleverbot؟

510
00:21:22,447 --> 00:21:23,647
- هذا لا يتحدث بشكل جيد
بالنسبة له.

511
00:21:23,648 --> 00:21:25,515
[ضحك]

512
00:21:25,516 --> 00:21:27,484
- آمل أن يشاهد.
- نعم.

513
00:21:27,485 --> 00:21:29,853
- يبدو أن Cleverbot قد اجتاز
اختبار Turing ،

514
00:21:29,854 --> 00:21:31,855
لكنه لم يفز
بأي قلوب.

515
00:21:31,856 --> 00:21:34,725
ومع ذلك ، فقد
تركت فرصتين.

516
00:21:34,726 --> 00:21:36,727
- فكر في الإجابات
التي حصلت عليها.

517
00:21:36,728 --> 00:21:38,028
- حسنًا - [يتأوه]

518
00:21:38,029 --> 00:21:40,364
البكالوريوس رقم واحد ،
لم أر

519
00:21:40,365 --> 00:21:42,566
شيئًا مثيرًا للاهتمام
مع الإجابات ،

520
00:21:42,567 --> 00:21:44,968
والبكالوريوس اثنان
تبدو مضحكة.

521
00:21:44,969 --> 00:21:48,138
الكوميديا فوق المظهر شي�
 ضخم بالنسبة لي.  يب

522
00:21:48,139 --> 00:21:50,440

أنه إذا ذهب في موعد ،

523
00:21:50,441 --> 00:21:52,476
فسيكون ذلك
ممتعًا على الأقل.

524
00:21:52,477 --> 00:21:54,411
- أتعلم؟  هل أنت
مستعد لتعطينا إجابتك؟

525
00:21:54,412 --> 00:21:56,146
- [يضحك] أعني ،
أعتقد أنني جاهز ، أجل.

526
00:21:56,147 --> 00:21:59,883
أنا مفتون حقًا بـ-- من
قبل البكالوريوس الثاني.

527
00:21:59,884 --> 00:22:00,984
[ضجة موسيقية]
- حسنًا!

528
00:22:00,985 --> 00:22:03,053
- بكالوريوس رقم اثنين.
- تمام.

529
00:22:03,054 --> 00:22:05,155
اختيار ممتاز.
لماذا ا؟

530
00:22:05,156 --> 00:22:07,557
- أنا مفتون.
احب الفكاهة.

531
00:22:07,558 --> 00:22:10,427
كانت الإجابات مضحكة فقط.
أعني ، مرح.

532
00:22:10,428 --> 00:22:15,098
هذا الشخص غامض ،
مثل إنسان يعمل بكامل طاقته ،

533
00:22:15,099 --> 00:22:17,768
حقًا ، لأنه يمتلك
ذراعا ورجلا وأشياء.

534
00:22:17,769 --> 00:22:20,404
- دعنا نلتقي به.

535
00:22:20,405 --> 00:22:22,439
- هاه؟
- بكالوريوس رقم 2

536
00:22:22,440 --> 00:22:24,775
هو روبوت محادثة غير بشري


537
00:22:24,776 --> 00:22:26,176
تمامًا يستخدم
الذكاء

538
00:22:26,177 --> 00:22:28,545
الاصطناعي لتوليف
محادثات شبيهة بالبشر.

539
00:22:28,546 --> 00:22:30,514
- تمام.
- قل مرحباً لـ Cleverbot.

540
00:22:30,515 --> 00:22:32,149
- مثل ، كان
يجيب بجدية؟

541
00:22:32,150 --> 00:22:33,717
كان الروبوت يجيب -
- نعم.

542
00:22:33,718 --> 00:22:35,185
- حرفيا بجدية.

543
00:22:35,186 --> 00:22:37,120
إنها شبكة عصبية عميقة
تتعلم

544
00:22:37,121 --> 00:22:38,789
وتستطيع تركيب الكلام البشري.
- نعم.

545
00:22:38,790 --> 00:22:40,657
- إذن نوعي الجديد
هو روبوت؟

546
00:22:40,658 --> 00:22:43,193
أعني ، الأشياء تتغير
في هذا العالم ، أليس كذلك؟

547
00:22:43,194 --> 00:22:45,195
كليهما: نعم.
- لن تكون

548
00:22:45,196 --> 00:22:47,631
هذه مزحة
في المستقبل.

549
00:22:47,632 --> 00:22:50,667
- هذا مخيف في
الحقيقة.

550
00:22:50,668 --> 00:22:53,003
- مستقبل A.I.
قد يكون مخيفًا بالنسبة للبعض ،

551
00:22:53,004 --> 00:22:55,672
ولكن مع ذلك ،
لم يكن هذا الموضوع هو

552
00:22:55,673 --> 00:22:58,208
الشخص الوحيد
الذي اختار الكمبيوتر.

553
00:22:58,209 --> 00:23:00,811
- البكالوريوس الثاني
، سأختارك.

554
00:23:00,812 --> 00:23:02,879
- رائع!
حسنًا ، بكالوريوس رقم اثنين.

555
00:23:02,880 --> 00:23:05,148
- أعتقد أنه قد
يكون غريب الأطوار الذي أبحث عنه.

556
00:23:05,149 --> 00:23:07,150
- تمكن Cleverbot
من الفوز

557
00:23:07,151 --> 00:23:10,787
بقلوب اثنين من العازبين ،
واجتازا كل من اختبار Turing

558
00:23:10,788 --> 00:23:13,690
واختبار "القدرة على التاريخ".

559
00:23:13,691 --> 00:23:15,058
- هذا يخلص ...
[كلاهما يضحك]

560
00:23:15,059 --> 00:23:17,694
"دعنا ...
كلاهما:" RomanTech. "

561
00:23:17,695 --> 00:23:18,895
- حسنًا.

562
00:23:18,896 --> 00:23:25,802
[هتاف وتصفيق]

563
00:23:25,803 --> 00:23:29,506
- ربما سيكون لأجهزة الكمبيوتر
حقوق مثل البشر يومًا ما.

564
00:23:29,507 --> 00:23:32,209
ربما لن نعرف أبدًا
ما الذي يجعل الإنسان  تختلف العقول عن العقول

565
00:23:32,210 --> 00:23:34,711

الإلكترونية.

566
00:23:34,712 --> 00:23:36,179
ربما السؤال ليس ،

567
00:23:36,180 --> 00:23:38,949
"هل يمكننا إقامة علاقات
مع التكنولوجيا ،"

568
00:23:38,950 --> 00:23:41,585
ولكن بدلاً من ذلك ،
"هل نحن نفس الشيء؟"

569
00:23:41,586 --> 00:23:45,989
أعني ، تخيل أجنبيًا
ليس لديه مفهوم عن الجسد البشري الذي

570
00:23:45,990 --> 00:23:48,658

يراني  في المرة الأولى.

571
00:23:48,659 --> 00:23:50,093
هل
ستفهم الخط الفاصل

572
00:23:50,094 --> 00:23:53,663
بين
الكائن والاختراع؟

573
00:23:53,664 --> 00:23:57,200
هل ستعرف أن هذه
الأشياء صُنعت من أجلي بواسطة بشر آخرين ،

574
00:23:57,201 --> 00:24:00,170
أم
أنها ستنمو مني؟

575
00:24:00,171 --> 00:24:03,039
هل تعتقد
أن هاتفي أو جهاز الكمبيوتر الخاص بي

576
00:24:03,040 --> 00:24:08,211
هل الأجهزة أو
الأعضاء المعدنية الخارجية التي قمت بتطويرها؟ بعد

577
00:24:08,212 --> 00:24:12,816
سنوات من الآن ، هل ستصل أجهزة الكمبيوتر إلى
الشخصية

578
00:24:12,817 --> 00:24:18,555
أم أننا جميعًا نحقق بشكل
جماعي "الإنسان الآلي"

579
00:24:18,556 --> 00:24:21,558
؟ وكالعادة ،
شكرًا على المشاهدة.

580
00:24:21,559 --> 00:24:24,027
[موسيقى درامية]

581
00:24:24,028 --> 00:24:27,030
[موسيقى إلكترونية]

582
00:24:27,031 --> 00:24:33,972
♪ ♪

