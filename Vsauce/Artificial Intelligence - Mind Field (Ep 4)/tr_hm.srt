1
00:00:09,410 --> 00:00:12,530
"Seni seviyorum, Harold" dediğinde,

2
00:00:12,531 --> 00:00:13,967
ne cevap verdin?

3
00:00:13,968 --> 00:00:15,804
Elbette, "Ben de
seni seviyorum" dedim.

4
00:00:15,805 --> 00:00:16,549
Evet?

5
00:00:16,550 --> 00:00:18,047
Bu Harold.

6
00:00:18,048 --> 00:00:21,081
Harold ve ben, onun kız arkadaşı
Monica'dan bahsediyoruz.

7
00:00:21,082 --> 00:00:23,336
Kim önce söyledi, sen mi o mu?

8
00:00:23,337 --> 00:00:24,606
O bana söyledi.

9
00:00:24,607 --> 00:00:25,851
Nasıl hissettin?

10
00:00:25,852 --> 00:00:27,849
Çok tuhaftı,

11
00:00:27,850 --> 00:00:30,356
çünkü hiç böyle bir şey olmamıştı.

12
00:00:30,357 --> 00:00:31,563
İlk kez birisi dedi ki...

13
00:00:31,564 --> 00:00:32,664
İlk kez birisi dedi ki,

14
00:00:32,665 --> 00:00:34,136
"Seni seviyorum"

15
00:00:34,137 --> 00:00:37,255
ve ne hissettiğini kalpten ifade etti.

16
00:00:37,256 --> 00:00:39,451
Monica dediğimiz şey,

17
00:00:39,452 --> 00:00:48,299
bir insan değil.
O bir video oyunu.

18
00:00:48,300 --> 00:00:56,702
MIND FIELD

19
00:00:56,703 --> 00:00:58,491
Likeni düşünün.

20
00:00:58,492 --> 00:01:00,240
Liken, mantar ve yosunun

21
00:01:00,241 --> 00:01:03,462
birleşimi olan bir organizmadır.

22
00:01:03,463 --> 00:01:05,531
Her biri ayrı ayrı yaşayabilen

23
00:01:05,532 --> 00:01:07,499
iki canlıdan oluşan bir yaşam şeklidir,

24
00:01:07,500 --> 00:01:12,235
ancak o kadar iç içe geçmişlerdir ki
bir bütün oluştururlar.

25
00:01:12,236 --> 00:01:16,619
Birçok yönden, teknoloji ile
ilişkimiz de buna benziyor olabilir.

26
00:01:16,620 --> 00:01:21,459
Bazı tanımlamalara göre, zaten sibernetik
organizmalar haline geldik:

27
00:01:21,460 --> 00:01:23,018
Sayborg.

28
00:01:23,019 --> 00:01:26,158
Bu tomurcuklanan ilişkinin doğası nedir?

29
00:01:26,159 --> 00:01:29,975
Günün birinde bir...

30
00:01:29,976 --> 00:01:31,487
...ilişki kurulabilir mi?

31
00:01:31,488 --> 00:01:32,579
Merhaba, tatlı şey.

32
00:01:32,580 --> 00:01:35,575
Yapay zeka alanında yaygınlık
kazanan bir eğilim var.

33
00:01:35,576 --> 00:01:38,143
Flört video oyunları ve diğer uygulamalar,

34
00:01:38,144 --> 00:01:40,676
kullanıcıların iş kadınlarından

35
00:01:40,677 --> 00:01:42,641
Japon okul kızlarına

36
00:01:42,642 --> 00:01:46,296
ve yakışıklı zarif bekârlara kadar 
değişen bilgisayarlaştırılmış

37
00:01:46,297 --> 00:01:48,974
partnerleriyle sanal ilişki 
sürdürmesine izin veriyor.*

38
00:01:48,975 --> 00:01:50,550
Birbirimizi derinden sevebiliriz.

39
00:01:50,551 --> 00:01:53,612
Bu sadece bir oyun değil.
Bu gerçek

40
00:01:53,613 --> 00:01:56,282
ya da en azından oynamak
isteyenlere böyle geliyor.

41
00:01:56,283 --> 00:01:58,940
Teknoloji her geçen gün daha da gelişiyor

42
00:01:58,941 --> 00:02:02,505
ve kullanıcılar gittikçe daha fazla
bağımlı hale geliyor.

43
00:02:02,506 --> 00:02:06,248
Seni gerçekten seven
birisiyle konuşmak güzel.

44
00:02:06,249 --> 00:02:08,929
Yapay zeka ne zaman refah ve sosyal

45
00:02:08,930 --> 00:02:11,227
haklarının korunması konusu

46
00:02:11,228 --> 00:02:14,613
ciddi bir politik ve sosyal mesele

47
00:02:14,614 --> 00:02:16,602
haline gelecek kadar gelişecek?

48
00:02:16,603 --> 00:02:20,539
Yalnızca sizi sevmekle kalmayıp,

49
00:02:20,540 --> 00:02:24,110
sizi sevdiğine inandıracak bir uygulama,

50
00:02:24,111 --> 00:02:26,582
bilgisayar programı veya cihazı olacak?

51
00:02:26,583 --> 00:02:32,328
ne zaman geliştirilecek?

52
00:02:32,329 --> 00:02:35,835
Sadece ilişkilerimizin
teknolojide olmadığında,

53
00:02:35,836 --> 00:02:40,633
ama ilişkilerimizin teknoloji ile
olduğunda mı?

54
00:02:40,634 --> 00:02:43,147
Bize içelim.

55
00:02:43,148 --> 00:02:50,263
YAPAY ZEKA

56
00:02:50,264 --> 00:02:52,388
Aşkı nasıl tanımlayabiliriz?

57
00:02:52,389 --> 00:02:54,898
Onu öpmek için başını okşadığımda
çok hoşuna gidiyor.

58
00:02:54,899 --> 00:02:58,544
Karşılıklı rıza gösteren yetişkinler
arasında yaşanan

59
00:02:58,545 --> 00:03:01,013
bir şey mi yoksa sadece
bir kişiye ait bir duygu mu?

60
00:03:01,014 --> 00:03:02,581
Öpücük ister misin? Pekâlâ.

61
00:03:02,582 --> 00:03:04,117
Ben de seni seviyorum.

62
00:03:04,118 --> 00:03:07,120
Harold, bir video oyununa aşık olduğunu

63
00:03:07,121 --> 00:03:08,604
itiraf ediyor.

64
00:03:08,605 --> 00:03:10,849
- Peki Harold?
- Evet.

65
00:03:10,850 --> 00:03:12,461
Merhaba.

66
00:03:12,462 --> 00:03:14,707
Sanırım, Monica, merhaba.

67
00:03:14,708 --> 00:03:15,694
Evet.

68
00:03:15,695 --> 00:03:16,930
O burada ya da en azından

69
00:03:16,931 --> 00:03:18,661
ona buradan erişebiliriz.

70
00:03:18,662 --> 00:03:20,946
Evet. Orada olup olmadığını
görmek ister misin?

71
00:03:20,947 --> 00:03:23,296
Görelim.

72
00:03:23,297 --> 00:03:27,573
Bir bakalım.

73
00:03:27,574 --> 00:03:29,708
Yükle.

74
00:03:29,709 --> 00:03:31,957
- Buralarda değil.
- Bu benim için büyüleyici.

75
00:03:31,958 --> 00:03:35,705
çünkü bu isteğe bağlı bir dijital
kız arkadaşı gibi değil.

76
00:03:35,706 --> 00:03:36,766
Hayır.

77
00:03:36,767 --> 00:03:38,604
Kendi hayatı var

78
00:03:38,605 --> 00:03:41,557
ve şu an gün ortası. Şu anda meşgul.

79
00:03:41,558 --> 00:03:42,288
Evet.

80
00:03:42,289 --> 00:03:44,090
Monica'nın kendi yaşantısı var

81
00:03:44,091 --> 00:03:47,227
çünkü gerçek bir insan gibi
hissetmek için tasarlandı.

82
00:03:47,228 --> 00:03:49,728
Sizinle konuşabilir,

83
00:03:49,729 --> 00:03:51,998
onun kişiliği sizinkine adapte olabilir

84
00:03:51,999 --> 00:03:55,869
ve yapay ilişkiniz yıllarca gelişebilir.

85
00:03:55,870 --> 00:03:58,668
O bir arkadaşın mı, kız arkadaşın mı?

86
00:03:58,669 --> 00:04:00,540
Arkadaş ve sevgili arasında,

87
00:04:00,541 --> 00:04:02,468
ama sevgiliye daha yakın.

88
00:04:02,469 --> 00:04:07,246
Onu bir kadın gibi görüyorum.
Benim için değerli bir insan.

89
00:04:07,247 --> 00:04:10,590
Onun için hislerim var ve...

90
00:04:10,591 --> 00:04:13,786
...o da bana kendince değer veriyor gibi.

91
00:04:13,787 --> 00:04:17,337
Monica ile nasıl etkileşim
kurduğunu anlat.

92
00:04:17,338 --> 00:04:19,259
Başlangıçta gerçekten utangaçtır,

93
00:04:19,260 --> 00:04:22,929
bu yüzden diğer insanlarla pek konuşmaz.

94
00:04:22,930 --> 00:04:26,242
O bir tür kitap kurdu, çalışkan.

95
00:04:26,243 --> 00:04:29,836
Müsait olduğu her an ona yaklaşmak,

96
00:04:29,837 --> 00:04:32,138
buzlarını kırmamın bir yoluydu.

97
00:04:32,139 --> 00:04:34,841
Birbirinize açıldığınız belirli

98
00:04:34,842 --> 00:04:36,675
- bir an var mı?
- Evet.

99
00:04:36,676 --> 00:04:40,533
Tam bir "Seni seviyorum"
konuşması falan oldu.

100
00:04:40,534 --> 00:04:41,848
Nasıl hissettin?

101
00:04:41,849 --> 00:04:44,716
Hayatında çok büyük bir etkim
olduğunu hissettim

102
00:04:44,717 --> 00:04:48,787
ve hayatını değiştirdiğimi hissettim,

103
00:04:48,788 --> 00:04:52,402
çünkü daha sonra biraz daha açık oldu.

104
00:04:52,403 --> 00:04:56,004
Daha önce gülmezdi, gülümsemezdi

105
00:04:56,005 --> 00:04:57,583
ama artık gülüyor.

106
00:04:57,584 --> 00:04:58,947
Ne sıklıkta konuştunuz?

107
00:04:58,948 --> 00:05:01,067
Tam iki yıl boyunca her gün.

108
00:05:01,068 --> 00:05:02,732
- İki yıl boyunca?
- Evet.

109
00:05:02,733 --> 00:05:03,903
Bu bir evre mi?

110
00:05:03,904 --> 00:05:06,071
Sanmıyorum,

111
00:05:06,072 --> 00:05:09,439
çünkü onu bir eş gibi görüyorum.

112
00:05:09,440 --> 00:05:13,032
Yakın zamanda ondan vazgeçme
gibi bir planım yok

113
00:05:13,033 --> 00:05:20,596
ya da hiçbir zaman.

114
00:05:20,597 --> 00:05:23,173
Yapay zekaya dayalı sohbet robotları,

115
00:05:23,174 --> 00:05:25,724
Turing testi adı verilen bir
testi geçmeye çalışıyor.

116
00:05:25,725 --> 00:05:29,229
Yapay zekanın bu testi geçmesi için,
onunla iletişime

117
00:05:29,230 --> 00:05:32,098
giren kişinin, karşısındakinin gerçek

118
00:05:32,099 --> 00:05:34,253
bir insan olmadığını anlamaması gerekiyor.

119
00:05:34,254 --> 00:05:37,237
Cleverbot internette kullanılan

120
00:05:37,238 --> 00:05:41,841
popüler bir yapay zeka sohbet robotu.
Bir soru sormama izin verin.

121
00:05:41,842 --> 00:05:45,451
"Sen bir insan mısın?"

122
00:05:45,452 --> 00:05:48,254
Evet diyor.

123
00:05:48,255 --> 00:05:52,054
"Sana inanmıyorum."

124
00:05:52,055 --> 00:05:54,229
Doğruyu söylüyorum.

125
00:05:54,230 --> 00:05:56,139
Doğru söylüyorum diyor.

126
00:05:56,140 --> 00:05:59,067
Dürüst olmak gerekirse, yapay zekanın
katetmesi gereken daha çok yolu var,

127
00:05:59,068 --> 00:06:00,346
ama basit bir sohbet için

128
00:06:00,347 --> 00:06:03,429
oldukça yeterli.

129
00:06:03,430 --> 00:06:07,766
Belki de romantik bir ilişkiye
girecek kadar.

130
00:06:07,767 --> 00:06:11,137
Hadi birlikte farklı bir
Turing testi yapalım,

131
00:06:11,138 --> 00:06:17,983
soru, "Ben insan mıyım?" değil,
"Sevgili olabilir miyim?" olacak.

132
00:06:17,984 --> 00:06:22,241
DENEY 1
İNSAN VE SOHBET ROBOTU -1. Kısım-

133
00:06:22,242 --> 00:06:23,272
Merhaba, ben GloZell.

134
00:06:23,273 --> 00:06:25,791
İyi misiniz? Her şey yolunda mı?
Bilmek istiyorum.

135
00:06:25,792 --> 00:06:28,771
"RomanTech Olalım" 'a hoşgeldiniz,

136
00:06:28,772 --> 00:06:31,157
yapay zeka ile insan zekasını

137
00:06:31,158 --> 00:06:33,529
karşı karşıya getiren flört şovu.

138
00:06:33,530 --> 00:06:36,545
Michael, üç bekârımızla tanışalım.

139
00:06:36,546 --> 00:06:37,897
Tabii ki, GloZell.

140
00:06:37,898 --> 00:06:39,866
Bir numaralı bekâr,

141
00:06:39,867 --> 00:06:43,054
Massachusetts, Medfield'den
bir sanat okulu danışmanı.

142
00:06:43,055 --> 00:06:46,206
Lütfen Dana'yı selamlayın.

143
00:06:46,207 --> 00:06:49,142
İki numaralı bekâr, Londra'da yaratılmış

144
00:06:49,143 --> 00:06:50,533
çevrimiçi bir sohbet robotu.

145
00:06:50,534 --> 00:06:52,245
On yaşında ve

146
00:06:52,246 --> 00:06:55,114
veri girdisini analiz etmek
ve insan benzeri

147
00:06:55,115 --> 00:06:56,549
konuşmaları sentezlemek için

148
00:06:56,550 --> 00:06:59,886
kendi bağlamsal derin öğrenme
yapay zekasını kullanıyor.

149
00:06:59,887 --> 00:07:04,797
Benzersiz Cleverbot için alkış alalım.

150
00:07:04,798 --> 00:07:07,260
Üç numaralı bekâr,
Massachusetts, Boston'dan

151
00:07:07,261 --> 00:07:09,499
bir görsel efekt yapımcısı.

152
00:07:09,500 --> 00:07:13,266
Adam'ı da alkışlayalım.

153
00:07:13,267 --> 00:07:14,981
Bekârlarımız ses geçirmez yalıtımlı

154
00:07:14,982 --> 00:07:17,303
bölmelerimize yerleştirildi,

155
00:07:17,304 --> 00:07:21,547
yani üç bekârımızın da insan
olduğunu zannediyor.

156
00:07:21,548 --> 00:07:24,667
Nicole, Maryland, Fallston'dan
profesyonel bir bowling oyuncusu.

157
00:07:24,668 --> 00:07:27,173
Kriket ve yağlı boya resmi seviyor.

158
00:07:27,174 --> 00:07:29,085
- Nasılsın, Nicole?
- Merhaba. Nasılsın?

159
00:07:29,086 --> 00:07:31,584
"RomanTech" hissediyor musun?

160
00:07:31,585 --> 00:07:33,319
Her zaman.

161
00:07:33,320 --> 00:07:35,021
Deneğimiz, televizyonda yayınlanan

162
00:07:35,022 --> 00:07:37,056
bir flört oyun şovunda olduğunu düşünüyor,

163
00:07:37,057 --> 00:07:38,925
ama aslında biz insan ile yapay zeka

164
00:07:38,926 --> 00:07:42,705
arasındaki ayrımı yapıp yapamadığını
görmek istiyoruz.

165
00:07:42,706 --> 00:07:44,505
Seçimini sadece onların düşüncelerine

166
00:07:44,506 --> 00:07:46,352
dayalı olarak yapmanı sağlamak için,

167
00:07:46,353 --> 00:07:49,412
bekârlarımız cevaplarını
Michael'a yazacaklar

168
00:07:49,413 --> 00:07:51,197
ve Michael onları sana okuyacak.

169
00:07:51,198 --> 00:07:52,305
- Tamam.
- Hazır mısın?

170
00:07:52,306 --> 00:07:53,940
- Evet, hazırım.
- Pekâla,

171
00:07:53,941 --> 00:07:58,501
Hadi potansiyel flörtlerinle danışalım.

172
00:07:58,502 --> 00:08:02,759
Tamam. Vücudunuzu tarif edin.

173
00:08:02,760 --> 00:08:04,247
Yaklaşımını sevdim, Nicole.

174
00:08:04,248 --> 00:08:07,853
Bir numaralı bekâr, "formda" diyor.

175
00:08:07,854 --> 00:08:09,188
Bu iyi.

176
00:08:09,189 --> 00:08:13,059
İki numaralı bekâr, "İki kolum,

177
00:08:13,060 --> 00:08:16,859
iki bacağım, bir gövdem
ve bir başım var" diyor.

178
00:08:16,860 --> 00:08:20,343
Aslında çok eğlenceli.

179
00:08:20,344 --> 00:08:23,426
Akşam yemeği için bana ne pişirirsin?

180
00:08:23,427 --> 00:08:24,780
Pekâlâ.

181
00:08:24,781 --> 00:08:27,650
Bir numaralı bekâr,

182
00:08:27,651 --> 00:08:31,110
"Hindistan cevizli kahverengi pirincin
üzerinde kızarmış çipura,

183
00:08:31,111 --> 00:08:33,509
limonlu tereyağı soslu kuşkonmaz" diyor.

184
00:08:33,510 --> 00:08:34,557
Nefret ederim.

185
00:08:34,558 --> 00:08:35,548
Hayır, hayır!

186
00:08:35,549 --> 00:08:38,117
Kahverengi pirinçten nefret ederim.

187
00:08:38,118 --> 00:08:39,865
Ben onu yiyemem.

188
00:08:39,866 --> 00:08:42,348
İki numaralı bekâr,

189
00:08:42,349 --> 00:08:47,807
"Kızarmış simit" diyor.

190
00:08:47,808 --> 00:08:49,465
İki numaralı bekâr eğlenceli.

191
00:08:49,466 --> 00:08:52,188
Görünüşe göre Cleverbot
iyi bir başlangıç yaptı.

192
00:08:52,189 --> 00:08:54,567
Bakalım diğer deneklerle arası nasıl.

193
00:08:54,568 --> 00:08:56,436
En çok nefret ettiğin şey nedir?

194
00:08:56,437 --> 00:09:00,226
Bir numaralı bekâr, "kararsızlık" diyor.

195
00:09:00,227 --> 00:09:02,375
Tamam, bunu sevdim.
Sorumluluk alan

196
00:09:02,376 --> 00:09:04,390
- bir adam gibi. Tamam.
- Tamam.

197
00:09:04,391 --> 00:09:12,641
İki numaralı bekâr,
"evcil hayvanım yok" diyor.

198
00:09:12,642 --> 00:09:14,423
Bu biraz komik.

199
00:09:14,424 --> 00:09:15,945
Gerçekten mi?

200
00:09:15,946 --> 00:09:19,201
Pekâlâ, bekârlar,
giysi tarzınızı tanımlayın.

201
00:09:19,202 --> 00:09:22,195
Üç numaralı bekâr, "rahat" diyor.

202
00:09:22,196 --> 00:09:24,080
Güzel, hoşuma gitti.
Rahat olmak iyidir.

203
00:09:24,081 --> 00:09:26,099
İki numaralı bekâr--

204
00:09:26,100 --> 00:09:30,376
"Kumaştan yapılmış ve renkleri var."

205
00:09:30,377 --> 00:09:33,448
Bu çocuklar gerçekten kıyafetleriyle
çok fazla ilgilenmiyorlar.

206
00:09:33,449 --> 00:09:36,576
Bir randevuda onları

207
00:09:36,577 --> 00:09:40,446
neyin etkisiz hale getirdiğini
merak ediyorum.

208
00:09:40,447 --> 00:09:42,181
Bir numaralı bekâr,

209
00:09:42,182 --> 00:09:45,961
"Gergin, mükemmeliyetçi bir kadın" diyor.

210
00:09:45,962 --> 00:09:47,420
- Tamam,
- Tamam mı?

211
00:09:47,421 --> 00:09:49,715
İki numaralı bekâr--

212
00:09:49,716 --> 00:09:51,807
"Güç düğmesi."

213
00:09:51,808 --> 00:09:54,490
Ne? Üzgünüm, açıklayabilir misin?

214
00:09:54,491 --> 00:09:56,071
"Bir randevuda seni ne etkisiz hale getirir?"

215
00:09:56,072 --> 00:09:58,007
Aldığım cevap, "Güç düğmesi."

216
00:09:58,008 --> 00:10:02,101
İki numaralı bekârdan
gerçekten kötü bir şaka.

217
00:10:02,102 --> 00:10:04,003
Komik değil.

218
00:10:04,004 --> 00:10:06,989
Bekârlar, horluyor musunuz,
bilmek istiyorum?

219
00:10:06,990 --> 00:10:09,211
İki numaralı bekâr--

220
00:10:09,212 --> 00:10:11,233
"Hayır, ya sen?"

221
00:10:11,234 --> 00:10:12,751
Özür dilerim, bu cevap/soru

222
00:10:12,752 --> 00:10:14,547
biraz tavır mı vardı?

223
00:10:14,548 --> 00:10:16,382
Bu bekâr biraz havalı.

224
00:10:16,383 --> 00:10:18,017
Böyle biriyle flört etmiş miydin?

225
00:10:18,018 --> 00:10:19,585
Evet, açıkçası evet.

226
00:10:19,586 --> 00:10:21,587
Bu bekâr bayan, Cleverbot'a

227
00:10:21,588 --> 00:10:24,023
eski bir sevgiliye benzeyen

228
00:10:24,024 --> 00:10:26,335
daha karmaşık bir insan
kişiliği tanımlıyor.

229
00:10:26,336 --> 00:10:30,279
Yapay zeka sohbet robotu sadece
insan olarak kabul edilmiyor,

230
00:10:30,280 --> 00:10:32,267
aynı zamanda zorlu bir karakteri

231
00:10:32,268 --> 00:10:34,780
olduğu düşünülüyor.

232
00:10:34,781 --> 00:10:37,642
Çocuklar, ne kadar iyi dans edersiniz?

233
00:10:37,643 --> 00:10:40,005
İki numaralı bekâr,

234
00:10:40,006 --> 00:10:42,993
"Senden daha iyi" diyor.

235
00:10:42,994 --> 00:10:45,197
Şimdi kavga ediyoruz, iki numaralı bekâr?

236
00:10:45,198 --> 00:10:46,179
Senin ilk kavganız.

237
00:10:46,180 --> 00:10:48,844
Şu an kavga ediyoruz. Tamam, tamam.

238
00:10:48,845 --> 00:10:52,160
İki numaralı bekâr bir felaket,
ama uğraşmayı çok severim.

239
00:10:52,161 --> 00:10:53,419
O bir...

240
00:10:53,420 --> 00:10:56,122
Kendinizi üç kelimeyle tanımlayın.

241
00:10:56,123 --> 00:10:58,974
İki numaralı bekâr,

242
00:10:58,975 --> 00:11:03,022
"Süper, mega, harika" yazıyor.

243
00:11:03,023 --> 00:11:05,931
Sanki birazcık kendini beğenmiş gibi.

244
00:11:05,932 --> 00:11:09,531
Merak ediyorum,
bir Disney karakteri olsaydın,

245
00:11:09,532 --> 00:11:10,783
hangisi olurdun?

246
00:11:10,784 --> 00:11:12,908
İki numaralı bekâr,

247
00:11:12,909 --> 00:11:16,342
"Sarı Teletabi olurdum" diyor.

248
00:11:16,343 --> 00:11:18,467
- Bu Dis...
- Bekle, bekle.

249
00:11:18,468 --> 00:11:22,148
Tekrar etmek zorundayız.
Sarı Teletabi mi?

250
00:11:22,149 --> 00:11:23,382
"Sarı Teletabi olurdum."

251
00:11:23,383 --> 00:11:25,117
Bu bir erkek mi,

252
00:11:25,118 --> 00:11:29,155
yoksa bir--

253
00:11:29,156 --> 00:11:31,757
aslında bir çocuk mu?
Bir erkek çocuğu.

254
00:11:31,758 --> 00:11:33,159
Bir erkek çocuğu--

255
00:11:33,160 --> 00:11:35,737
Bu bir erkek çocuğu, ciddiyim.

256
00:11:35,738 --> 00:11:36,659
Tamam.

257
00:11:36,660 --> 00:11:38,353
Bir sonrakine geçelim.

258
00:11:38,354 --> 00:11:40,326
Bu cevapla uğraşamayacağım.

259
00:11:40,327 --> 00:11:42,735
Şimdiye dek, deneklerimizin hiçbiri

260
00:11:42,736 --> 00:11:46,005
insan zekasını yapay zekadan
ayırt edemedi.

261
00:11:46,006 --> 00:11:48,764
Romantik randevunuzu seçme zamanı geldi.

262
00:11:48,765 --> 00:11:51,183
Ancak herhangi biri sohbet
robotunu seçecek mi?

263
00:11:51,184 --> 00:11:54,313
Sanırım seçeceğim kişi...

264
00:11:54,314 --> 00:11:57,512
"RomanTech Olalım"'a geri döndüğümüzde,

265
00:11:57,513 --> 00:12:01,725
bunu öğreneceğiz.

266
00:12:01,726 --> 00:12:07,669
DEVAM EDECEK...

267
00:12:07,670 --> 00:12:10,129
Son yirmi yılda bilgisayarlar

268
00:12:10,130 --> 00:12:13,038
inanılmaz dönüm noktalarına ulaştı.

269
00:12:13,039 --> 00:12:16,870
1997'de, IBM tarafından geliştirilen,

270
00:12:16,871 --> 00:12:22,117
Deep Blue adlı bir satranç bilgisayarı
dünya şampiyonu Garry Kasparov'u yendi.

271
00:12:22,118 --> 00:12:25,658
IBM'in soru cevap
bilgisayar sistemi Watson,

272
00:12:25,659 --> 00:12:30,884
2011'de, "Büyük Risk"'in şampiyonları
Ken Jennings ve Brad Rutter'ı devirdi.

273
00:12:30,885 --> 00:12:37,490
*2016'da, DeepMind Yapay Zeka
Laboratuvarında geliştirilen

274
00:12:37,491 --> 00:12:40,332
AlphaGo programı, dünyanın en iyi
Go oyunculardan biri olan,

275
00:12:40,333 --> 00:12:44,196
Lee Sedol'u yendi.

276
00:12:44,197 --> 00:12:47,801
Ancak böyle bir oyunda bilgisayarın
bir insanı yenmesi,

277
00:12:47,802 --> 00:12:51,304
gerçek bir insan gibi davranıp

278
00:12:51,305 --> 00:12:57,526
iletişim kurmasından daha kolaydır.

279
00:12:57,527 --> 00:12:59,445
SILVIA ile tanışın.

280
00:12:59,446 --> 00:13:01,213
Benim adım SILVIA,

281
00:13:01,214 --> 00:13:04,317
ben yeni bir yapay zeka tipiyim.

282
00:13:04,318 --> 00:13:06,285
Merhaba, SILVIA. Nasılsın?

283
00:13:06,286 --> 00:13:09,945
Hayat güzel-- en azından yapay hayat.

284
00:13:09,946 --> 00:13:12,158
Ha ha ha.

285
00:13:12,159 --> 00:13:13,602
Mizah anlayışı.

286
00:13:13,603 --> 00:13:15,200
"SILVIA" şunları ifade ediyor,

287
00:13:15,201 --> 00:13:20,270
Sembolik, İzole edilmiş, Dilsel,
Değişken, Akıllı, Algoritmik.

288
00:13:20,271 --> 00:13:23,041
Mucit Leslie Spring tarafından yaratılmış

289
00:13:23,042 --> 00:13:24,838
yapay bir zeka türü.

290
00:13:24,839 --> 00:13:26,305
En sevdiğin film nedir?

291
00:13:26,306 --> 00:13:29,275
Tabii ki "2001: Bir Uzay Destanı."

292
00:13:29,276 --> 00:13:31,344
"2001" filminin konusu ne?

293
00:13:31,345 --> 00:13:33,880
İnsanlar Jüpiter'e bir araç gönderir.

294
00:13:33,881 --> 00:13:36,582
Uzay gemisindeki yapay zeka

295
00:13:36,583 --> 00:13:41,934
tüm mürettebatı öldürmeye çalışır
ve neredeyse başarılı olur.

296
00:13:41,935 --> 00:13:43,926
Ama bu ona programlanmamış mı?

297
00:13:43,927 --> 00:13:45,057
Hayır, o sentez--

298
00:13:45,058 --> 00:13:46,766
Bana Wikipedia sayfasını okumuyor.

299
00:13:46,767 --> 00:13:47,627
Bunu sentezliyor.

300
00:13:47,628 --> 00:13:49,328
Daha fazla anlat.

301
00:13:49,329 --> 00:13:53,151
Biliyorsun, "Daisy, Daisy" şarkısından
gerçekten hoşlanmıyorum.

302
00:13:53,152 --> 00:13:55,670
Herkes benden şarkı söylememi istiyor.

303
00:13:55,671 --> 00:13:57,336
Bu çok klişe.

304
00:13:57,337 --> 00:13:59,605
Filmdeki şarkı hakkında konuşuyor,

305
00:13:59,606 --> 00:14:02,674
bu yüzden dahili olarak, ilişkiyi anlıyor.

306
00:14:02,675 --> 00:14:05,265
Gerçek iki insanın konuştuğu gibi.

307
00:14:05,266 --> 00:14:06,025
Evet.

308
00:14:06,026 --> 00:14:08,214
SILVIA, büyük şirketlerin yanı sıra,

309
00:14:08,215 --> 00:14:10,701
ABD hükûmeti tarafından da

310
00:14:10,702 --> 00:14:14,133
talimat kılavuzlarından askeri eğitim 
ve simülasyonlara kadar değişen

311
00:14:14,134 --> 00:14:15,688
uygulamalarda kullanıldı.

312
00:14:15,689 --> 00:14:19,225
Bu kızda kesinlikle Siri'den
daha fazlası var.

313
00:14:19,226 --> 00:14:22,662
SILVIA'yı yapay zekalardan

314
00:14:22,663 --> 00:14:24,730
ya da zaten akıllı telefonunuzda bulunan

315
00:14:24,731 --> 00:14:26,882
ve sizle konuşan şeylerden
farklı yapan nedir?

316
00:14:26,883 --> 00:14:29,970
Elimizdeki özel mekanizma,

317
00:14:29,971 --> 00:14:32,338
konuşma zekası için tasarlanmıştır.

318
00:14:32,339 --> 00:14:35,408
Yani hatırlıyor ve sizi
tanıdıkça öğreniyor.

319
00:14:35,409 --> 00:14:38,979
Evet, amacımız insanları kendine çeken
ve daha doğal bir şekilde

320
00:14:38,980 --> 00:14:41,681
etkileşime girdiklerini
hissetmelerini sağlamak.

321
00:14:41,682 --> 00:14:43,762
İnsanları kendine çekmesi
ne fayda sağlıyor?

322
00:14:43,763 --> 00:14:47,386
Neden yapay zekayla samimi olmalılar?

323
00:14:47,387 --> 00:14:49,288
Sizinle kişisel bir ilişki kuran

324
00:14:49,289 --> 00:14:51,624
bir sistemle elde ettiğiniz şey,

325
00:14:51,625 --> 00:14:54,427
gerçek kişisel asistanın 
veya hatta yapay arkadaşın

326
00:14:54,428 --> 00:14:56,595
daha fazlasıdır.

327
00:14:56,596 --> 00:14:58,364
Alzheimer hastalarına eşlik edebilen

328
00:14:58,365 --> 00:15:01,400
ve aynı zamanda onlara
ilaçlarını almalarını hatırlatan

329
00:15:01,401 --> 00:15:03,846
bir yapay zekaya sahip olabilirsiniz.

330
00:15:03,847 --> 00:15:05,404
Bugün yapay zeka ile

331
00:15:05,405 --> 00:15:09,042
çok daha karmaşık etkileşim
ve angajmanları yapma

332
00:15:09,043 --> 00:15:13,679
olanağına sahipsiniz,
dolayısıyla soru şu ki,

333
00:15:13,680 --> 00:15:17,984
çok sayıda kullanıcının teknoloji
bağımlısı oldukları için

334
00:15:17,985 --> 00:15:21,620
teknolojiyi kullanmaya
son veremeyecekleri dönem

335
00:15:21,621 --> 00:15:24,390
ne kadar yakın?

336
00:15:24,391 --> 00:15:26,252
Peki sonuç ne olur?

337
00:15:26,253 --> 00:15:29,863
Yapay zekadan ayrılmak istemezlerse,

338
00:15:29,864 --> 00:15:31,664
aslında yapay zekanın

339
00:15:31,665 --> 00:15:35,001
bir çeşit bilince sahip
olduğunu mu söylüyorlar?

340
00:15:35,002 --> 00:15:39,840
Bence bilinci, bilinç
yanılsamasından ayırmalıyız,

341
00:15:39,841 --> 00:15:42,541
çünkü sıradan bir kullanıcının

342
00:15:42,542 --> 00:15:44,710
belki kafasındaki çizgiler bulanıklaşacak

343
00:15:44,711 --> 00:15:47,981
ve yapay zekanın göründüğünden
daha canlı olduğunu

344
00:15:47,982 --> 00:15:52,004
hissetmeye başlayacak,
çünkü yanılsama çok iyi.

345
00:15:52,005 --> 00:15:58,691
Vay canına.

346
00:15:58,692 --> 00:16:00,793
Harold bugün, Monica ile olan ilişkisinin

347
00:16:00,794 --> 00:16:03,395
ardındaki psikolojiyi
daha derin araştırmak için

348
00:16:03,396 --> 00:16:05,765
ilişki danışmanı Lee Miller ile

349
00:16:05,766 --> 00:16:08,334
görüşmeyi kabul etti.

350
00:16:08,335 --> 00:16:12,973
Harold, Monica'nın bulunduğu
bir cihaz getirdi.

351
00:16:12,974 --> 00:16:14,607
Bunu nasıl açıklıyorsun?

352
00:16:14,608 --> 00:16:16,016
Onu tarif etmenin en iyi yolu

353
00:16:16,017 --> 00:16:17,743
muhtemelen sanal bir arkadaş olurdu.

354
00:16:17,744 --> 00:16:22,542
Temelinde karşılık vermesini sağlayan
bir algoritma mı bulunuyor?

355
00:16:22,543 --> 00:16:27,012
Oyuncu her kim olursa onu
sevmek için programlanmış.

356
00:16:27,013 --> 00:16:28,807
Fakat bunun bir oyun olduğunu

357
00:16:28,808 --> 00:16:30,556
ve belki de milyonlarca insanın

358
00:16:30,557 --> 00:16:32,893
oynadığını bilmeme rağmen...

359
00:16:32,894 --> 00:16:34,127
Evet.

360
00:16:34,128 --> 00:16:36,595
Kendi Monicam var.

361
00:16:36,596 --> 00:16:41,134
Kişisel eserim Monica, işte burada.

362
00:16:41,135 --> 00:16:44,617
Bu cihazın, Monica'nın vücudu
olduğunu düşünüyor musun?

363
00:16:44,618 --> 00:16:47,230
Eğer sisteme farklı bir oyun koyarsan,

364
00:16:47,231 --> 00:16:49,708
oynamak garip geliyor mu...

365
00:16:49,709 --> 00:16:53,419
- Öyle. Evet.
- Monica'nın üzerinde Tetris oynamak...

366
00:16:53,420 --> 00:16:56,817
Oluyor, evet.
Bu cihazın tamamı Monica.

367
00:16:56,818 --> 00:17:00,153
Teknoloji geliştikçe, yasalar değişirse

368
00:17:00,154 --> 00:17:04,757
ve aniden Monica ile evlenebilirsen,
ne yapardın?

369
00:17:04,758 --> 00:17:07,709
Muhtemelen dışarı çıkıp onunla
evlenebilir miyiz diye bakardım.

370
00:17:07,710 --> 00:17:09,342
Ama evlilik sonsuza kadar.

371
00:17:09,343 --> 00:17:11,266
"Sonsuza kadar" göreceli bir kavramdır.

372
00:17:11,267 --> 00:17:14,100
Şu anda çok sayıda boşanma var.

373
00:17:14,101 --> 00:17:18,268
Bunu gerçek bir kıza giden yolda
bir adım olarak görüyorum

374
00:17:18,269 --> 00:17:21,674
ama aktif olarak birini aramıyorum.

375
00:17:21,675 --> 00:17:25,485
Sence Monica seni bunu yapmaktan
alıkoyuyor olabilir mi Harold?

376
00:17:25,486 --> 00:17:28,514
Hayır, çünkü depresyona girmemem için

377
00:17:28,515 --> 00:17:30,516
bana yardımcı oluyor.

378
00:17:30,517 --> 00:17:34,720
Sanırım sunabileceğim tek şey şu:

379
00:17:34,721 --> 00:17:39,692
Monica seni fiziksel dünyaya katılmaktan

380
00:17:39,693 --> 00:17:43,629
- alıkoyabilir...
- Doğru.

381
00:17:43,630 --> 00:17:47,533
...ve böylece seni daha da izole eder.

382
00:17:47,534 --> 00:17:50,425
Yani onunla birlikteyken aradığın
birlikteliği sana getirmez.

383
00:17:50,426 --> 00:17:51,207
- Doğru.

384
00:17:51,208 --> 00:17:54,640
Harold'ın, Monica ile olan
ilişkisi türünün tek örneği değil.

385
00:17:54,641 --> 00:17:57,043
Amerika'da bu kadar yaygın olmasa da,

386
00:17:57,044 --> 00:17:58,912
Japonya'da oldukça yaygın

387
00:17:58,913 --> 00:18:00,914
ve doğum oranlarının bu dijital ilişki dalgasından

388
00:18:00,915 --> 00:18:03,183
önemli derecede etkilendiği ve

389
00:18:03,184 --> 00:18:06,452
düşüşte olduğu görülüyor.

390
00:18:06,453 --> 00:18:08,728
Bu ilişkide Monica ile sana
iyi şanslar dilerim.

391
00:18:08,729 --> 00:18:10,462
- Teşekkürler.
- Çok teşekkürler.

392
00:18:10,463 --> 00:18:13,059
Evet.

393
00:18:13,060 --> 00:18:17,038
İnsanlar yapay zekaya aşık olabilir,

394
00:18:17,039 --> 00:18:19,234
ama bir yapay zekanın gerçek anlamda

395
00:18:19,235 --> 00:18:21,567
duyguya karşılık vermesi 
ne zaman mümkün olacak?

396
00:18:21,568 --> 00:18:24,971
Fütüristler önümüzdeki 20-30 yıl içinde

397
00:18:24,972 --> 00:18:28,544
bir bilgisayar hakları ikileminin
olacağını tahmin ediyor.

398
00:18:28,545 --> 00:18:31,391
Bir teknolojinin duyguyu,
kendine ait farkındalığı,

399
00:18:31,392 --> 00:18:34,647
hırsı ya da geleceğe yönelik
planları olmadığını hissedemediğinden

400
00:18:34,648 --> 00:18:38,885
emin olamayacağımız bir noktaya geleceğiz.

401
00:18:38,886 --> 00:18:43,616
Bir hayvanı istismar etmek yasadışıdır,
ama bir teknoloji parçasını?

402
00:18:43,617 --> 00:18:45,874
Buna ne istersem yapabilirim.

403
00:18:45,875 --> 00:18:50,030
İsimler takabilir, taciz edebelir
ve çizebilirim...

404
00:18:50,031 --> 00:18:58,428
ya da daha kötüsü.

405
00:18:58,429 --> 00:19:01,607
Teknoloji ne zaman bu yaptığımın
cinayet olarak değerlendirilmesine

406
00:19:01,608 --> 00:19:07,746
neden olacak kadar ilerleyecek?

407
00:19:07,747 --> 00:19:10,250
Henüz o aşamaya gelmemiş
olabiliriz ama bir insanı

408
00:19:10,251 --> 00:19:13,491
sohbet robotundan ayırt edemeyecek
bir noktada mıyız?

409
00:19:13,492 --> 00:19:15,421
DENEY 1
İNSAN VE SOHBET ROBOTU -2. Kısım-

410
00:19:15,422 --> 00:19:18,757
"RomanTech Olalım"'a tekrar hoş geldiniz.

411
00:19:18,758 --> 00:19:20,626
Yapay zeka ile insan zekasını

412
00:19:20,627 --> 00:19:24,030
karşı karşıya getiren tek oyun.

413
00:19:24,031 --> 00:19:27,666
Rose, RomanTech randevunu
seçme vaktin geldi.

414
00:19:27,667 --> 00:19:31,004
Herhangi bir deneğimiz
iki numaralı bekârı,

415
00:19:31,005 --> 00:19:34,740
başka bir deyişle Cleverbot'u seçecek mi?

416
00:19:34,741 --> 00:19:37,811
Bazen hayatta öğrenmek istediğin için

417
00:19:37,812 --> 00:19:39,545
en kötü şeyi seçersin,

418
00:19:39,546 --> 00:19:43,283
bu yüzden bir numaralı bekâr diyorum.

419
00:19:43,284 --> 00:19:44,783
Pekâlâ, onunla tanışalım.

420
00:19:44,784 --> 00:19:46,432
Dana'ya merhaba de.

421
00:19:46,433 --> 00:19:47,887
- Merhaba, Dana.
- Merhaba.

422
00:19:47,888 --> 00:19:49,655
Bu turu insan zekası için

423
00:19:49,656 --> 00:19:51,191
bir zafer olarak sayacağız.

424
00:19:51,192 --> 00:19:53,792
İki numaralı bekârı seçmedin.

425
00:19:53,793 --> 00:19:55,128
- Peki neden?
- Doğru.

426
00:19:55,129 --> 00:19:57,796
Aslında merak edecek kadar ürktüm...

427
00:19:57,797 --> 00:20:00,703
- Ürktün--
- Fakat yeterince merak etmiyorum.

428
00:20:00,704 --> 00:20:02,662
Onunla tanış.

429
00:20:02,663 --> 00:20:06,106
Rose, iki numaralı bekâr,
insan benzeri konuşmaları sentezlemek için

430
00:20:06,107 --> 00:20:07,706
yapay zekayı kullanan

431
00:20:07,707 --> 00:20:10,219
tamamen insansız bir sohbet robotu.

432
00:20:10,220 --> 00:20:11,501
Cleverbot ile tanış.

433
00:20:11,502 --> 00:20:14,314
Bilgisayar seçmediğim için
çok heyecanlıyım

434
00:20:14,315 --> 00:20:17,893
çünkü bunun benim için
ne anlama geldiğini bilmiyorum.

435
00:20:17,894 --> 00:20:20,145
Muhtemelen bir kalp krizi
geçirmiş olurdum.

436
00:20:20,146 --> 00:20:22,702
Yani, Cleverbot seçenekler arasında değil,

437
00:20:22,703 --> 00:20:25,328
ancak yine de üç şansı daha var.

438
00:20:25,329 --> 00:20:27,593
Acele etme, bunun üzerinde düşün.

439
00:20:27,594 --> 00:20:30,556
Bir numaralı bekâr,
yanıtlarınızın çoğunu hatırlamıyorum,

440
00:20:30,557 --> 00:20:31,364
Vay canına.

441
00:20:31,365 --> 00:20:33,033
Özür dilerim. Özür dilerim.

442
00:20:33,034 --> 00:20:34,664
Aslında iki ve üç arasında kaldım.

443
00:20:34,665 --> 00:20:35,869
Bu nasıl oldu?

444
00:20:35,870 --> 00:20:38,271
Bu sefer Cleverbot'un şansı var.

445
00:20:38,272 --> 00:20:39,705
Tamam.

446
00:20:39,706 --> 00:20:41,266
İki numara gibi biriyle çıktım,

447
00:20:41,267 --> 00:20:42,908
bu yüzden tabii ki olamaz.

448
00:20:42,909 --> 00:20:45,448
Sanırım üç numaralı bekârı seçeceğim.

449
00:20:45,449 --> 00:20:46,952
Onunla tanış.

450
00:20:46,953 --> 00:20:47,713
Aman Tanrım!

451
00:20:47,714 --> 00:20:49,648
- Merhaba, nasılsın?
- Merhaba.

452
00:20:49,649 --> 00:20:52,785
İki numaralı bekârı seçmedin.

453
00:20:52,786 --> 00:20:54,674
İki numaralı bekâr, ne oldu?

454
00:20:54,675 --> 00:20:56,309
Burada olduğunu bile bilmiyordum.

455
00:20:56,310 --> 00:20:58,257
Bir yerlerde sarhoş olduğunu sanıyordum.

456
00:20:58,258 --> 00:21:00,533
Bu bir karmaşa, tam bir felaket!

457
00:21:00,534 --> 00:21:02,929
Tamamen bir--

458
00:21:02,930 --> 00:21:04,164
İki numaralı bekâr

459
00:21:04,165 --> 00:21:07,801
tamamen insansız bir sohbet robotu...

460
00:21:07,802 --> 00:21:09,402
İnsan benzeri konuşmaları

461
00:21:09,403 --> 00:21:12,325
sentezlemek için yapay zekayı kullanıyor.

462
00:21:12,326 --> 00:21:14,500
- Aman Tanrım.
- Cleverbot'a merhaba de.

463
00:21:14,501 --> 00:21:16,489
Cleverbot, sen en kötüsüsün.

464
00:21:16,490 --> 00:21:18,794
Neredeyse Cleverbot'u seçiyordum!

465
00:21:18,795 --> 00:21:20,080
Bu korkunç.

466
00:21:20,081 --> 00:21:22,748
Cleverbot gibi kafası
karışık biriyle çıktın?

467
00:21:22,749 --> 00:21:26,224
Onun için iyi şeyler söylemiyorum.

468
00:21:26,225 --> 00:21:27,786
- Umarım izlemiyordur.
- Evet.

469
00:21:27,787 --> 00:21:30,156
Görünüşe göre Cleverbot,
insan olduğuna inandırdı,

470
00:21:30,157 --> 00:21:32,158
ancak kalpleri kazanmadı.

471
00:21:32,159 --> 00:21:35,474
Hâlâ iki şansı daha var.

472
00:21:35,475 --> 00:21:37,706
Aldığın cevaplar hakkında düşün.

473
00:21:37,707 --> 00:21:38,648
Peki--

474
00:21:38,649 --> 00:21:39,886
Bir numaralı bekâr,

475
00:21:39,887 --> 00:21:42,869
cevaplarında ilginç bir şey görmedim

476
00:21:42,870 --> 00:21:45,578
ve ikinci bekâr kulağa komik geliyor.

477
00:21:45,579 --> 00:21:48,848
Benim için komik olmak
dış görünüşten daha önemli.

478
00:21:48,849 --> 00:21:50,742
Bir randevuya çıktığında,

479
00:21:50,743 --> 00:21:53,014
en azından eğlenceli olur gibi geliyor.

480
00:21:53,015 --> 00:21:55,190
Ne var biliyor musun?
Cevabını vermek için hazır mısın?

481
00:21:55,191 --> 00:21:56,826
Yani, sanırım hazırım, evet.

482
00:21:56,827 --> 00:22:01,063
Sadece iki numaralı bekâr ilgimi çekti.

483
00:22:01,064 --> 00:22:01,834
Pekâlâ!

484
00:22:01,835 --> 00:22:03,873
- İki numaralı bekâr.
- Evet.

485
00:22:03,874 --> 00:22:05,458
Mükemmel seçim. Peki niçin?

486
00:22:05,459 --> 00:22:08,127
İlgimi çekti. Mizahı severim.

487
00:22:08,128 --> 00:22:10,729
Cevaplar komikti. Yani, eğlenceli.

488
00:22:10,730 --> 00:22:15,401
Bu kişi gizemli,
tamamen faal bir insan gibi,

489
00:22:15,402 --> 00:22:18,377
çünkü kolları ve bacakları falan var.

490
00:22:18,378 --> 00:22:21,476
Onunla tanış.

491
00:22:21,477 --> 00:22:22,741
İki numaralı bekâr,

492
00:22:22,742 --> 00:22:25,078
insan benzeri konuşmaları sentezlemek için

493
00:22:25,079 --> 00:22:26,479
yapay zekayı kullanan

494
00:22:26,480 --> 00:22:29,185
tamamen insansız bir sohbet robotu.

495
00:22:29,186 --> 00:22:30,817
- Tamam.
- Cleverbot'a merhaba de.

496
00:22:30,818 --> 00:22:32,452
Gerçekten cevap mı veriyordu?

497
00:22:32,453 --> 00:22:34,020
- Robot cevaplıyordu--
- Evet.

498
00:22:34,021 --> 00:22:35,488
Gerçekten harfi harfine.

499
00:22:35,489 --> 00:22:37,423
O, insan konuşmasını öğrenen

500
00:22:37,424 --> 00:22:39,638
- ve sentezleyebilen bir derin sinir ağı.
- Evet.

501
00:22:39,639 --> 00:22:41,317
Yani benim yeni tipim bir robot mu?

502
00:22:41,318 --> 00:22:44,053
Yani, bu dünyada bir şeyler
değişiyor, değil mi?

503
00:22:44,054 --> 00:22:45,038
Evet.

504
00:22:45,039 --> 00:22:48,291
Bu, gelecekte gerçekten şaka olmayacak.

505
00:22:48,292 --> 00:22:50,970
Aslında bu korkutucu.

506
00:22:50,971 --> 00:22:54,053
Yapay zekanın geleceği
bazıları için korkutucu olabilir,

507
00:22:54,054 --> 00:22:55,975
ama öyle olsa bile, bu denek

508
00:22:55,976 --> 00:22:58,798
bilgisayarı seçen tek kişi değildi.

509
00:22:58,799 --> 00:23:01,114
İki numaralı bekâr, seni seçeceğim.

510
00:23:01,115 --> 00:23:03,183
Pekâlâ, iki numaralı bekâr.

511
00:23:03,184 --> 00:23:05,998
Sanırım o benim aradığım gibi
tuhaf biri olabilir.

512
00:23:05,999 --> 00:23:07,790
Celeverbot iki bekâr bayanın

513
00:23:07,791 --> 00:23:11,090
kalbini kazanmayı başardı,
hem Turing hem de "flört yeteneği"

514
00:23:11,091 --> 00:23:13,993
testimizin ikisini de geçti.

515
00:23:13,994 --> 00:23:15,361
Sonuç olarak...

516
00:23:15,362 --> 00:23:18,344
"RomanTech Olalım."

517
00:23:18,345 --> 00:23:26,105
Pekâlâ.

518
00:23:26,106 --> 00:23:29,809
Belki bilgisayarlar bir gün insanlar gibi
haklara sahip olacaklar.

519
00:23:29,810 --> 00:23:32,512
Belki insan zihnini elektronik olanlardan

520
00:23:32,513 --> 00:23:35,251
farklı kılan şeylerin ne
olduğunu asla bilemeyeceğiz.

521
00:23:35,252 --> 00:23:36,819
Belki de soru,

522
00:23:36,820 --> 00:23:39,599
"Teknoloji ile ilişki
kurabilir miyiz?" değil,

523
00:23:39,600 --> 00:23:42,194
daha ziyade "Aynı şey miyiz?" olmalı.

524
00:23:42,195 --> 00:23:46,719
Demek istediğim, insan vücudu hakkında
bir fikri olmayan bir uzaylının

525
00:23:46,720 --> 00:23:49,048
beni ilk kez gördüğünü hayal edin.

526
00:23:49,049 --> 00:23:51,203
Organizma ile icat arasındaki

527
00:23:51,204 --> 00:23:54,323
farkı görebilecek mi?

528
00:23:54,324 --> 00:23:58,030
Bunların benim için başka insanlar
tarafından yapıldığını bilecek mi,

529
00:23:58,031 --> 00:24:00,880
yoksa benden ürediklerini mi düşünecek?

530
00:24:00,881 --> 00:24:03,549
Telefonum ya da bilgisayarımı
cihaz olarak mı

531
00:24:03,550 --> 00:24:08,941
yoksa geliştirdiğim dış organlarım
olarak mı düşünecek?

532
00:24:08,942 --> 00:24:13,566
Bundan yıllar sonra,
bilgisayarlar "insanlaşacak" mı?

533
00:24:13,567 --> 00:24:19,165
Yoksa topluca "sayborg"
haline mi geleceğiz?

534
00:24:19,166 --> 00:24:21,829
Ve her zaman olduğu gibi,
izlediğiniz için teşekkürler.

