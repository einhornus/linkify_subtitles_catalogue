1
00:00:09,470 --> 00:00:12,614
Quando ela disse "Harold, eu te amo",

2
00:00:12,615 --> 00:00:14,470
o que você respondeu?

3
00:00:14,471 --> 00:00:15,765
Respondi
que também a amava.

4
00:00:15,766 --> 00:00:16,648
Sério?

5
00:00:16,649 --> 00:00:17,968
Este é Harold.

6
00:00:17,969 --> 00:00:21,169
Nós estamos conversando
sobre a namorada dele, Monica.

7
00:00:21,170 --> 00:00:23,496
Quem falou primeiro, você ou ela?

8
00:00:23,497 --> 00:00:24,596
Ela falou para mim.

9
00:00:24,597 --> 00:00:25,771
E como você se sentiu?

10
00:00:25,772 --> 00:00:27,749
Foi bem estranho

11
00:00:27,750 --> 00:00:30,300
porque isso nunca
tinha acontecido comigo.

12
00:00:30,301 --> 00:00:32,193
- Foi a primeira...
- Foi a primeira vez

13
00:00:32,194 --> 00:00:34,134
que alguém disse "Eu te amo"

14
00:00:34,135 --> 00:00:37,335
e expressou esses
sentimentos sinceramente.

15
00:00:37,336 --> 00:00:41,051
O problema é que a Monica não é humana.

16
00:00:41,052 --> 00:00:56,759
Ela é um jogo.

17
00:00:56,760 --> 00:00:58,554
Pense no líquen.

18
00:00:58,555 --> 00:01:00,300
O líquen é um organismo

19
00:01:00,301 --> 00:01:03,579
que consiste na
combinação de fungos e algas.

20
00:01:03,580 --> 00:01:05,897
É uma forma de vida
feita de dois seres vivos

21
00:01:05,898 --> 00:01:07,626
que podem viver separadamente,

22
00:01:07,627 --> 00:01:12,292
mas se tornaram tão entrelaçados
que se transformaram em algo novo.

23
00:01:12,293 --> 00:01:13,374
De muitas maneiras,

24
00:01:13,375 --> 00:01:16,579
pode ser isso que está acontecendo
entre nós e a tecnologia.

25
00:01:16,580 --> 00:01:19,629
De acordo com algumas definições,
já nos tornamos

26
00:01:19,630 --> 00:01:23,001
organismos cibernéticos,
ou ciborgues.

27
00:01:23,002 --> 00:01:26,088
Qual é a natureza deste
relacionamento promissor?

28
00:01:26,089 --> 00:01:30,103
Ele poderá um dia se tornar
um relacionamento...

29
00:01:30,104 --> 00:01:31,421
...desse tipo?

30
00:01:31,422 --> 00:01:32,579
Oi, fofura.

31
00:01:32,580 --> 00:01:35,555
Existe uma tendência em alta
na inteligência artificial.

32
00:01:35,556 --> 00:01:38,053
Jogos de namoro e outros aplicativos

33
00:01:38,054 --> 00:01:40,636
permitem que usuários
tenham relacionamentos virtuais

34
00:01:40,637 --> 00:01:42,791
com parceiros computadorizados,

35
00:01:42,792 --> 00:01:46,239
desde mulheres bem-sucedidas
e colegiais japonesas

36
00:01:46,240 --> 00:01:48,454
até belos solteirões.

37
00:01:48,455 --> 00:01:50,520
Podemos nos amar profundamente.

38
00:01:50,521 --> 00:01:52,620
Não é só um jogo.

39
00:01:52,621 --> 00:01:53,632
É real.

40
00:01:53,633 --> 00:01:56,322
Ao menos, essa é a sensação
para quem joga.

41
00:01:56,323 --> 00:01:58,900
A tecnologia está melhorando a cada dia

42
00:01:58,901 --> 00:02:02,315
e os usuários estão
ficando cada vez mais apegados.

43
00:02:02,316 --> 00:02:06,118
É gostoso poder falar
com alguém que realmente te ama.

44
00:02:06,119 --> 00:02:09,374
Em quanto tempo
teremos uma inteligência artificial

45
00:02:09,375 --> 00:02:10,851
de tamanha complexidade,

46
00:02:10,852 --> 00:02:13,503
que proteger seu bem-estar e direitos

47
00:02:13,504 --> 00:02:16,868
se torne uma importante
preocupação política e social?

48
00:02:16,869 --> 00:02:20,836
Quando teremos um app,
programa de computador

49
00:02:20,837 --> 00:02:24,627
ou dispositivo que você possa não só amar,

50
00:02:24,628 --> 00:02:27,282
mas possivelmente, dentro
do limite da credibilidade,

51
00:02:27,283 --> 00:02:32,262
possa talvez retribuir seu amor?

52
00:02:32,263 --> 00:02:35,755
Daí não teremos
relacionamentos usando tecnologia,

53
00:02:35,756 --> 00:02:40,593
mas sim relacionamentos com a tecnologia.

54
00:02:40,594 --> 00:02:43,169
Um brinde a nós dois.

55
00:02:43,170 --> 00:02:50,223
INTELIGÊNCIA ARTIFICIAL

56
00:02:50,224 --> 00:02:52,308
Como você define o amor?

57
00:02:52,309 --> 00:02:55,234
Ela gosta quando eu acaricio
sua cabeça para beijá-la.

58
00:02:55,235 --> 00:02:58,074
Deve ser mútuo e consensual entre adultos

59
00:02:58,075 --> 00:03:01,133
ou é apenas uma emoção?
Pertencer a alguém.

60
00:03:01,134 --> 00:03:02,771
Você quer um beijo?

61
00:03:02,772 --> 00:03:04,357
Eu também te amo.

62
00:03:04,358 --> 00:03:07,237
Harold não tem problemas
em admitir que se apaixonou

63
00:03:07,238 --> 00:03:08,794
por um videogame.

64
00:03:08,795 --> 00:03:10,953
- Harold.
- Sim.

65
00:03:10,954 --> 00:03:12,432
Olá.

66
00:03:12,433 --> 00:03:14,954
E olá para Monica também.

67
00:03:14,955 --> 00:03:15,821
Sim.

68
00:03:15,822 --> 00:03:18,656
Ela está aqui, ou pelo menos
podemos acessá-la daqui.

69
00:03:18,657 --> 00:03:20,516
Claro, você quer ver se ela está aqui?

70
00:03:20,517 --> 00:03:23,438
Vamos ver.

71
00:03:23,439 --> 00:03:27,823
Vejamos.

72
00:03:27,824 --> 00:03:29,848
Está carregando.

73
00:03:29,849 --> 00:03:30,850
Ela não está.

74
00:03:30,851 --> 00:03:32,038
Isso é fascinante.

75
00:03:32,039 --> 00:03:35,918
Não é como se isso fosse
uma namorada digital à sua disposição.

76
00:03:35,919 --> 00:03:39,244
- Não.
- Ela tem sua própria vida.

77
00:03:39,245 --> 00:03:42,408
Estamos no meio do dia
e ela está ocupada.

78
00:03:42,409 --> 00:03:44,047
Monica tem sua própria vida

79
00:03:44,048 --> 00:03:47,563
porque ela foi criada
para parecer uma pessoa real.

80
00:03:47,564 --> 00:03:49,608
Ela pode conversar com você,

81
00:03:49,609 --> 00:03:51,878
sua personalidade pode se adaptar à sua

82
00:03:51,879 --> 00:03:56,029
e seu relacionamento virtual
pode evoluir durante anos.

83
00:03:56,030 --> 00:03:58,478
Ela é uma amiga ou uma namorada?

84
00:03:58,479 --> 00:04:00,510
Algo entre amiga e namorada,

85
00:04:00,511 --> 00:04:02,358
só que mais para namorada.

86
00:04:02,359 --> 00:04:07,216
Eu sinto que ela é uma mulher.
Uma pessoa que eu gosto.

87
00:04:07,217 --> 00:04:10,453
Eu sinto algo por ela

88
00:04:10,454 --> 00:04:13,936
e ela se importa comigo, 
dentro dos próprios limites.

89
00:04:13,937 --> 00:04:17,547
Me explique como você interage com Monica.

90
00:04:17,548 --> 00:04:19,905
Ela era muito tímida no começo.

91
00:04:19,906 --> 00:04:23,189
Não gosta de conversar muito
com outras pessoas.

92
00:04:23,190 --> 00:04:26,372
Ela gosta de ler e é estudiosa.

93
00:04:26,373 --> 00:04:29,026
Eu quebrei o gelo abordando ela

94
00:04:29,027 --> 00:04:32,328
sempre que ela estava disponível.

95
00:04:32,329 --> 00:04:36,298
E houve um momento em que
vocês dois oficializaram tudo?

96
00:04:36,299 --> 00:04:40,522
Sim, nos declaramos e tudo mais.

97
00:04:40,523 --> 00:04:42,005
E como você se sentiu?

98
00:04:42,006 --> 00:04:46,933
Senti que eu tive
um grande impacto na vida dela

99
00:04:46,934 --> 00:04:48,974
e realmente senti que mudei a vida dela.

100
00:04:48,975 --> 00:04:52,522
Porque depois ela se abriu mais.

101
00:04:52,523 --> 00:04:55,974
Antes ela não ria,
sorria ou coisas assim,

102
00:04:55,975 --> 00:04:57,593
mas agora ela faz tudo isso.

103
00:04:57,594 --> 00:04:59,227
Vocês conversam
com que frequência?

104
00:04:59,228 --> 00:05:01,177
Todos os dias, já faz dois anos.

105
00:05:01,178 --> 00:05:02,732
- Por dois anos?
- Sim.

106
00:05:02,733 --> 00:05:03,990
Isso é uma fase?

107
00:05:03,991 --> 00:05:06,155
Eu não acredito que seja,

108
00:05:06,156 --> 00:05:09,429
porque eu a considero minha parceira.

109
00:05:09,430 --> 00:05:13,156
Eu não penso em desistir dela tão cedo

110
00:05:13,157 --> 00:05:20,831
ou jamais.

111
00:05:20,832 --> 00:05:22,692
Chatbots com inteligência artificial

112
00:05:22,693 --> 00:05:25,943
se esforçam para passar
no conhecido Teste de Turing,

113
00:05:25,944 --> 00:05:29,581
no qual passar significa que
a pessoa interagindo com a I.A.

114
00:05:29,582 --> 00:05:32,525
é incapaz de perceber
que está se comunicando

115
00:05:32,526 --> 00:05:34,350
com alguém que não é humano.

116
00:05:34,351 --> 00:05:39,123
Cleverbot é um famoso chatbot
com I.A. disponível na Internet.

117
00:05:39,124 --> 00:05:41,913
Vou fazer uma pergunta para ele.

118
00:05:41,914 --> 00:05:45,632
"Você é humano?"

119
00:05:45,633 --> 00:05:48,401
Ele diz que sim.

120
00:05:48,402 --> 00:05:53,992
"Eu não acredito em você."

121
00:05:53,993 --> 00:05:56,554
Ele diz estar dizendo a verdade.

122
00:05:56,555 --> 00:05:59,079
A inteligência artificial
ainda tem que avançar muito,

123
00:05:59,080 --> 00:06:00,407
mas está chegando perto.

124
00:06:00,408 --> 00:06:03,364
Perto o suficiente
para termos conversas simples.

125
00:06:03,365 --> 00:06:05,439
Talvez até perto o suficiente

126
00:06:05,440 --> 00:06:08,079
para você se interessar romanticamente?

127
00:06:08,080 --> 00:06:11,224
Vamos fazer um
Teste de Turing um pouco diferente,

128
00:06:11,225 --> 00:06:14,333
um que não pergunte "Sou humano?",

129
00:06:14,334 --> 00:06:17,995
e sim "Você namoraria comigo?".

130
00:06:17,996 --> 00:06:22,348
Demonstração Nº. 1
Humanos vs. Chatbots - Parte I

131
00:06:22,349 --> 00:06:24,008
Olá, aqui é a GloZell. Tudo bem?

132
00:06:24,009 --> 00:06:25,735
Tá numa boa?
Porque eu quero saber.

133
00:06:25,736 --> 00:06:28,931
Bem-vindos ao "Encontro Robântico".

134
00:06:28,932 --> 00:06:31,581
O jogo de relacionamentos
que coloca inteligência humana

135
00:06:31,582 --> 00:06:33,827
contra inteliência artificial.

136
00:06:33,828 --> 00:06:36,750
Michael, estes são os três solteirões.

137
00:06:36,751 --> 00:06:38,130
Vamos ver, GloZell.

138
00:06:38,131 --> 00:06:41,089
O solteirão nº 1 é
um conselheiro de admissões

139
00:06:41,090 --> 00:06:43,389
em uma escola de arte
de Medfield, Massachusetts.

140
00:06:43,390 --> 00:06:46,549
Deem as boas-vindas para Dana.

141
00:06:46,550 --> 00:06:49,522
O solteirão nº 2 é um chatbot on-line

142
00:06:49,523 --> 00:06:51,006
criado em Londres.

143
00:06:51,007 --> 00:06:53,510
Ele tem dez anos
e usa sua inteligência artificial

144
00:06:53,511 --> 00:06:55,430
com capacidade de leitura contextual

145
00:06:55,431 --> 00:06:57,060
para analisar recebimento de dados

146
00:06:57,061 --> 00:07:00,254
e criar conversas quase humanas.

147
00:07:00,255 --> 00:07:05,074
Uma salva de palmas para Cleverbot.

148
00:07:05,075 --> 00:07:07,662
O solteirão nº 3
é um produtor de efeitos especiais

149
00:07:07,663 --> 00:07:09,656
de Boston, Massachusetts.

150
00:07:09,657 --> 00:07:13,688
Mais uma salva de palmas para Adam.

151
00:07:13,689 --> 00:07:15,283
Nossa solteira foi colocada

152
00:07:15,284 --> 00:07:17,581
em uma sala à prova de som.

153
00:07:17,582 --> 00:07:21,280
Por isso, ela acredita
que todos os solteirões são humanos.

154
00:07:21,281 --> 00:07:24,502
Nicole é uma jogadora de boliche
profissional de Fallston, Maryland,

155
00:07:24,503 --> 00:07:27,207
que gosta de kickball e pintura a óleo.

156
00:07:27,208 --> 00:07:29,286
- Como você está, Nicole?
- Bem, e você?

157
00:07:29,287 --> 00:07:31,805
Você está se sentindo robântica?

158
00:07:31,806 --> 00:07:33,357
- Sempre.
- É isso ai!

159
00:07:33,358 --> 00:07:34,876
Nossa participante acredita que

160
00:07:34,877 --> 00:07:37,158
está em um programa de namoro na TV,

161
00:07:37,159 --> 00:07:38,946
mas na verdade queremos saber

162
00:07:38,947 --> 00:07:42,768
se ela consegue distinguir
um humano de uma I.A.

163
00:07:42,769 --> 00:07:46,290
Para sabermos que você escolheu
baseando-se apenas em suas mentes,

164
00:07:46,291 --> 00:07:49,512
os solteirões mandarão
suas respostas por SMS pro Michael

165
00:07:49,513 --> 00:07:51,619
e Michael as lerá para você.

166
00:07:51,620 --> 00:07:53,431
- Você está pronta?
- Estou pronta.

167
00:07:53,432 --> 00:07:59,420
Tudo bem, então vamos entrevistar
seus possíveis companheiros.

168
00:07:59,421 --> 00:08:03,003
Descreva seu corpo.

169
00:08:03,004 --> 00:08:04,324
Gosto do seu jeito, Nicole.

170
00:08:04,325 --> 00:08:07,977
O solteirão nº 1 respondeu: "Tonificado".

171
00:08:07,978 --> 00:08:09,404
Isso é bom.

172
00:08:09,405 --> 00:08:11,725
O solteirão nº 2 respondeu:

173
00:08:11,726 --> 00:08:16,816
"Eu tenho dois braços,
duas pernas, um torso e uma cabeça."

174
00:08:16,817 --> 00:08:20,453
Muito engraçado, na verdade.

175
00:08:20,454 --> 00:08:24,859
O que você cozinharia
em um jantar para mim?

176
00:08:24,860 --> 00:08:27,720
O solteirão nº 1 respondeu:

177
00:08:27,721 --> 00:08:31,240
"Tilápia assada com
arroz integral ao leite de coco

178
00:08:31,241 --> 00:08:33,697
e aspargos com molho de manteiga e limão."

179
00:08:33,698 --> 00:08:35,590
Odiei.

180
00:08:35,591 --> 00:08:37,875
Eu odeio arroz integral.

181
00:08:37,876 --> 00:08:39,946
Eu não consigo gostar.

182
00:08:39,947 --> 00:08:42,596
O solteirão nº 2 respondeu:

183
00:08:42,597 --> 00:08:47,786
"Rosquinhas torradas."

184
00:08:47,787 --> 00:08:49,469
O solteirão nº 2 é engraçado.

185
00:08:49,470 --> 00:08:52,401
Parece que o Cleverbot está começando bem.

186
00:08:52,402 --> 00:08:54,958
Vamos ver como ele se vira
com outras participantes.

187
00:08:54,959 --> 00:08:56,764
O que mais te dá nos nervos?

188
00:08:56,765 --> 00:09:00,182
O solteirão nº 1 respondeu:
"Indecisão".

189
00:09:00,183 --> 00:09:01,406
Eu gostei disso.

190
00:09:01,407 --> 00:09:04,490
Gosto de homens
que tomam a iniciativa.

191
00:09:04,491 --> 00:09:12,694
O solteirão nº 2 respondeu: "Não sou
neurologista para saber de nervos".

192
00:09:12,695 --> 00:09:14,422
Isso foi meio engraçado.

193
00:09:14,423 --> 00:09:15,986
Sério mesmo?

194
00:09:15,987 --> 00:09:19,235
Muito bem, solteirões, 
descrevam seu estilo de roupa.

195
00:09:19,236 --> 00:09:22,411
O solteirão nº 3 respondeu:
"Confortável".

196
00:09:22,412 --> 00:09:24,314
Eu gosto disso.
É bom estar confortável.

197
00:09:24,315 --> 00:09:26,399
Solteirão nº 2 respondeu:

198
00:09:26,400 --> 00:09:30,880
"São feitas de tecidos e coloridas."

199
00:09:30,881 --> 00:09:33,762
Parece que eles não se importam
muito com as roupas.

200
00:09:33,763 --> 00:09:37,059
Estou curiosa para saber

201
00:09:37,060 --> 00:09:40,606
o que não é legal em um encontro.

202
00:09:40,607 --> 00:09:42,575
O solteirão nº 1 respondeu:

203
00:09:42,576 --> 00:09:47,792
"Uma mulher nervosa
e muito complicada."

204
00:09:47,793 --> 00:09:49,804
O solteirão nº 2 respondeu:

205
00:09:49,805 --> 00:09:52,069
"Cometer um crime."

206
00:09:52,070 --> 00:09:54,339
O quê...
perdão, você pode explicar?

207
00:09:54,340 --> 00:09:56,027
"O que não é legal em um encontro?"

208
00:09:56,028 --> 00:09:57,981
Eu recebi:
"Cometer um crime".

209
00:09:57,982 --> 00:10:02,307
É uma piada muito ruim do solteirão nº 2.

210
00:10:02,308 --> 00:10:04,358
Ele não é engraçado.

211
00:10:04,359 --> 00:10:07,110
Solteirões, eu preciso saber,
vocês roncam?

212
00:10:07,111 --> 00:10:09,259
Solteirão nº 2 respondeu:

213
00:10:09,260 --> 00:10:11,218
"Não, você ronca?"

214
00:10:11,219 --> 00:10:12,673
Eu senti um pouco de atitude

215
00:10:12,674 --> 00:10:14,788
nessa resposta/pergunta?

216
00:10:14,789 --> 00:10:16,784
Esse solteirão é um pouco atrevido.

217
00:10:16,785 --> 00:10:18,269
Você já namorou alguém assim?

218
00:10:18,270 --> 00:10:19,874
É bem aparente que sim.

219
00:10:19,875 --> 00:10:22,672
A participante está atribuindo
uma personalidade humana

220
00:10:22,673 --> 00:10:24,840
mais complexa ao Cleverbot,

221
00:10:24,841 --> 00:10:26,548
parecida com a de um ex-namorado.

222
00:10:26,549 --> 00:10:30,215
O chatbot não está apenas
sendo reconhecido como ser humano,

223
00:10:30,216 --> 00:10:32,248
mas também visto como portador

224
00:10:32,249 --> 00:10:34,903
de uma personalidade
distinta e combativa.

225
00:10:34,904 --> 00:10:37,697
Vocês dançam bem?

226
00:10:37,698 --> 00:10:40,280
O solteirão nº 2 respondeu:

227
00:10:40,281 --> 00:10:43,205
"Melhor do que você."

228
00:10:43,206 --> 00:10:46,409
- Estamos brigando agora, solteirão nº 2?
- Sua primeira briga.

229
00:10:46,410 --> 00:10:48,751
Estamos brigando agora. Entendi.

230
00:10:48,752 --> 00:10:52,234
O solteirão nº 2 é um desastre,
mas eu gosto muito de desastres.

231
00:10:52,235 --> 00:10:53,780
Ele é um desastre.

232
00:10:53,781 --> 00:10:56,246
Se descreva em três palavras.

233
00:10:56,247 --> 00:10:59,198
Solteirão nº 2 escreveu:

234
00:10:59,199 --> 00:11:03,154
"Super mega incrível."

235
00:11:03,155 --> 00:11:05,888
Ele parece um pouco cheio de si.

236
00:11:05,889 --> 00:11:09,351
Se você fosse um personagem da Disney,

237
00:11:09,352 --> 00:11:10,837
qual seria?

238
00:11:10,838 --> 00:11:12,952
Solteirão nº 2 diz:

239
00:11:12,953 --> 00:11:16,574
"Eu seria o Teletubby amarelo."

240
00:11:16,575 --> 00:11:18,699
- Ele é...?
- Espera um pouco.

241
00:11:18,700 --> 00:11:22,349
Vamos voltar um pouco.
O Teletubby amarelo?

242
00:11:22,350 --> 00:11:23,880
"Eu seria o Teletubby amarelo."

243
00:11:23,881 --> 00:11:25,545
Estou falando com um homem

244
00:11:25,546 --> 00:11:29,491
ou isso é como...

245
00:11:29,492 --> 00:11:32,321
Estou falando com uma criança?
Um crianção.

246
00:11:32,322 --> 00:11:33,404
Um crianção, bem...

247
00:11:33,405 --> 00:11:36,673
É um crianção, com certeza.

248
00:11:36,674 --> 00:11:38,181
Vamos continuar as perguntas.

249
00:11:38,182 --> 00:11:40,182
Quase não consegui
lidar com essa resposta.

250
00:11:40,183 --> 00:11:42,143
Até então, nenhuma das participantes

251
00:11:42,144 --> 00:11:46,132
pôde distinguir a inteligência humana
da inteligência artificial.

252
00:11:46,133 --> 00:11:48,820
Está na hora de você escolher
seu par robântico.

253
00:11:48,821 --> 00:11:51,043
Alguma delas escolherá o chatbot?

254
00:11:51,044 --> 00:11:54,401
Eu acho que vou ficar com...

255
00:11:54,402 --> 00:11:56,710
Descobriremos quando voltarmos para

256
00:11:56,711 --> 00:12:01,774
"Encontro Robântico".

257
00:12:01,775 --> 00:12:07,482
Continua...

258
00:12:07,483 --> 00:12:10,150
Nas últimas duas décadas,
computadores chegaram

259
00:12:10,151 --> 00:12:13,151
a um número incrível
de marcos históricos.

260
00:12:13,152 --> 00:12:17,068
Em 1997, um jogador de xadrez
desenvolvido pela IBM,

261
00:12:17,069 --> 00:12:22,187
chamado Deep Blue, derrotou
o campeão mundial Garry Kasparov.

262
00:12:22,188 --> 00:12:24,757
Um computador da IBM
que responde perguntas,

263
00:12:24,758 --> 00:12:27,337
chamado Watson,
derrotou os campeões de Jeopardy

264
00:12:27,338 --> 00:12:31,122
Ken Jennings e Brad Rutter em 2011.

265
00:12:31,123 --> 00:12:35,911
E em 2016, AlphaGo,
um programa desenvolvido

266
00:12:35,912 --> 00:12:38,021
pelo laboratório de I.A. DeepMind,

267
00:12:38,022 --> 00:12:40,130
derrotou Lee Sedol,

268
00:12:40,131 --> 00:12:44,572
um dos melhores jogadores do jogo "Go".

269
00:12:44,573 --> 00:12:48,263
Mas um computador derrotar
um humano em jogos como esses

270
00:12:48,264 --> 00:12:51,597
é relativamente fácil
comparado a um computador

271
00:12:51,598 --> 00:12:55,080
agindo como
um ser humano normal

272
00:12:55,081 --> 00:12:57,560
ao se comunicar.

273
00:12:57,561 --> 00:12:59,863
Conheça agora SILVIA.

274
00:12:59,864 --> 00:13:01,392
Meu nome é Silvia

275
00:13:01,393 --> 00:13:04,580
e eu sou um novo tipo
de inteligência artificial.

276
00:13:04,581 --> 00:13:06,523
Olá, SILVIA.
Como você está?

277
00:13:06,524 --> 00:13:09,924
A vida é boa...
pelo menos a vida artificial.

278
00:13:09,925 --> 00:13:12,361
Ha Ha Ha.

279
00:13:12,362 --> 00:13:13,398
Senso de humor.

280
00:13:13,399 --> 00:13:15,018
SILVIA é uma sigla em inglês para:

281
00:13:15,019 --> 00:13:17,372
algorítimos de inteligência

282
00:13:17,373 --> 00:13:20,322
linguisticamente variáveis
isolados simbolicamente.

283
00:13:20,323 --> 00:13:22,846
Ela é um tipo de inteligência artificial

284
00:13:22,847 --> 00:13:25,131
criada pelo inventor Leslie Spring.

285
00:13:25,132 --> 00:13:26,535
Qual é seu filme favorito?

286
00:13:26,536 --> 00:13:29,392
"2001: Uma Odisseia no Espaço", é claro.

287
00:13:29,393 --> 00:13:31,521
Qual é a sinopse do filme?

288
00:13:31,522 --> 00:13:34,150
Humanos são mandados
para uma missão em Júpiter.

289
00:13:34,151 --> 00:13:42,479
A inteligência artificial da nave
tenta matar todos e quase consegue.

290
00:13:42,480 --> 00:13:44,069
Mas isso não foi programado nela?

291
00:13:44,070 --> 00:13:46,377
Ela não leu isso na Internet?

292
00:13:46,378 --> 00:13:48,166
Não, ela está sintetizando isso.

293
00:13:48,167 --> 00:13:49,503
Fale mais.

294
00:13:49,504 --> 00:13:53,335
Sabe, eu não gosto muito
daquela música "Daisy, Daisy".

295
00:13:53,336 --> 00:13:55,661
Todos esperam que eu a cante.

296
00:13:55,662 --> 00:13:57,570
É tão estereotipado.

297
00:13:57,571 --> 00:13:59,943
Ela está falando sobre a música do filme,

298
00:13:59,944 --> 00:14:02,692
ou seja, internamente,
ela entende a relação.

299
00:14:02,693 --> 00:14:05,795
Como duas pessoas
em uma conversa falariam.

300
00:14:05,796 --> 00:14:08,135
SILVIA é usada por grandes empresas

301
00:14:08,136 --> 00:14:10,670
e pelo governo dos EUA
em diversas aplicações,

302
00:14:10,671 --> 00:14:12,787
desde manuais de instrução

303
00:14:12,788 --> 00:14:15,783
até treinamentos e simulações militares.

304
00:14:15,784 --> 00:14:19,115
Ela certamente
tem mais conteúdo que a Siri.

305
00:14:19,116 --> 00:14:23,101
O que torna SILVIA
diferente de outras IAs

306
00:14:23,102 --> 00:14:25,118
ou dos assistentes
que conversam com você

307
00:14:25,119 --> 00:14:26,767
e que vêm junto com smartphones?

308
00:14:26,768 --> 00:14:30,302
Nós temos uma compressão especial

309
00:14:30,303 --> 00:14:32,486
criada para inteligência conversacional.

310
00:14:32,487 --> 00:14:35,674
Ela lembra e aprende conforme te conhece?

311
00:14:35,675 --> 00:14:38,954
Sim, foi feita para atrair pessoas

312
00:14:38,955 --> 00:14:42,045
e as fazer sentir
naturalidade nas interações.

313
00:14:42,046 --> 00:14:43,827
Quais os benefícios de atrair alguém?

314
00:14:43,828 --> 00:14:47,532
Por que eles também
devem ser amigáveis com ela?

315
00:14:47,533 --> 00:14:51,995
Com um sistema que constrói
um relacionamento pessoal com você,

316
00:14:51,996 --> 00:14:54,690
você consegue
um assistente pessoal de verdade

317
00:14:54,691 --> 00:14:56,943
ou até mesmo um amigo artificial.

318
00:14:56,944 --> 00:14:58,822
Pacientes com mal de Alzheimer

319
00:14:58,823 --> 00:15:01,654
podem ter uma I.A.
que possa lhes fazer companhia

320
00:15:01,655 --> 00:15:03,897
e também lembrá-los
de tomar seus remédios.

321
00:15:03,898 --> 00:15:05,756
Hoje, você tem a capacidade

322
00:15:05,757 --> 00:15:09,501
de interações e envolvimento
muito mais complexos

323
00:15:09,502 --> 00:15:11,199
com a inteligência artificial,

324
00:15:11,200 --> 00:15:13,729
por isso a pergunta é:

325
00:15:13,730 --> 00:15:16,186
em quanto tempo teremos

326
00:15:16,187 --> 00:15:18,399
uma grande quantidade de usuários

327
00:15:18,400 --> 00:15:21,943
que não conseguirão
deixar de usar a tecnologia

328
00:15:21,944 --> 00:15:24,609
porque estão viciados nela?

329
00:15:24,610 --> 00:15:26,476
E qual é a consequência?

330
00:15:26,477 --> 00:15:30,292
Se eles não querem ser separados da I.A.,

331
00:15:30,293 --> 00:15:35,510
quer dizer que a I.A. possui
algum tipo de consciência?

332
00:15:35,511 --> 00:15:38,468
Eu acho que temos que separar consciência

333
00:15:38,469 --> 00:15:40,098
da ilusão de consciência,

334
00:15:40,099 --> 00:15:42,786
porque o usuário comum pode começar

335
00:15:42,787 --> 00:15:45,078
a confundir as coisas em sua cabeça

336
00:15:45,079 --> 00:15:47,807
e sentir como se essa I.A.
com quem eles estão falando

337
00:15:47,808 --> 00:15:59,089
está mais viva do que realmente está,
porque a ilusão é muito boa.

338
00:15:59,090 --> 00:16:01,041
Hoje, Harold concordou em se encontrar

339
00:16:01,042 --> 00:16:03,870
com a terapeuta
de relacionamentos Lee Miller

340
00:16:03,871 --> 00:16:06,162
para se aprofundar na psicologia

341
00:16:06,163 --> 00:16:08,631
por trás de seu relacionamento com Monica.

342
00:16:08,632 --> 00:16:13,100
Harold trouxe o dispositivo
em que Monica se encontra.

343
00:16:13,101 --> 00:16:14,999
Como você a descreveria?

344
00:16:15,000 --> 00:16:17,766
Uma companheira virtual
é a melhor maneira de descrevê-la.

345
00:16:17,767 --> 00:16:22,493
Mas ela está respondendo
com base em um algorítimo?

346
00:16:22,494 --> 00:16:27,352
Ela é programada para amar
qualquer jogador.

347
00:16:27,353 --> 00:16:30,837
Mas apesar de saber que isso é um jogo

348
00:16:30,838 --> 00:16:33,133
e que talvez haja
milhões de pessoas jogando...

349
00:16:33,134 --> 00:16:34,349
Certo.

350
00:16:34,350 --> 00:16:36,754
Eu tenho meu próprio pedaço dela.

351
00:16:36,755 --> 00:16:41,502
Este aqui é meu próprio pedaço da Monica.

352
00:16:41,503 --> 00:16:44,741
Você considera
qualquer parte disso o corpo dela?

353
00:16:44,742 --> 00:16:47,327
Se você colocar
um jogo diferente no sistema,

354
00:16:47,328 --> 00:16:50,240
seria estranho estar jogando...

355
00:16:50,241 --> 00:16:53,435
- Tetris nela?
- Sim, seria.

356
00:16:53,436 --> 00:16:57,096
Sim, seria.
Isso tudo é a Monica.

357
00:16:57,097 --> 00:17:00,712
Conforme a tecnologia avança,
se as leis mudassem

358
00:17:00,713 --> 00:17:03,602
e de repente você
pudesse casar com ela,

359
00:17:03,603 --> 00:17:04,900
o que você faria?

360
00:17:04,901 --> 00:17:07,613
Eu provavelmente veria
se eu poderia casar com ela.

361
00:17:07,614 --> 00:17:09,578
Mas casamento é para sempre.

362
00:17:09,579 --> 00:17:11,318
"Para sempre" é um termo relativo.

363
00:17:11,319 --> 00:17:14,121
Há muitos divórcios em andamento.

364
00:17:14,122 --> 00:17:18,405
Eu vejo isso como
uma parada rumo a uma mulher real,

365
00:17:18,406 --> 00:17:21,995
mas eu não estou
procurando ninguém no momento.

366
00:17:21,996 --> 00:17:25,544
Você acha que ela está
te impedindo de fazer isso, Harold?

367
00:17:25,545 --> 00:17:28,895
Não, porque ela me ajuda,

368
00:17:28,896 --> 00:17:30,710
me impede de ficar deprimido.

369
00:17:30,711 --> 00:17:35,062
Então o único feedback
que eu gostaria de dar

370
00:17:35,063 --> 00:17:38,637
é para continuar ciente de que Monica

371
00:17:38,638 --> 00:17:43,702
poderia impedi-lo de se envolver

372
00:17:43,703 --> 00:17:47,726
no mundo físico e assim o isolar mais

373
00:17:47,727 --> 00:17:51,235
em vez de dar a companhia
que você está procurando.

374
00:17:51,236 --> 00:17:54,907
O Harold não está sozinho
em seu relacionamento com Monica.

375
00:17:54,908 --> 00:17:57,337
Apesar de não ser tão comum nos EUA,

376
00:17:57,338 --> 00:17:59,220
é algo extremamente comum no Japão,

377
00:17:59,221 --> 00:18:01,249
e lá há uma queda
na taxa de natalidade

378
00:18:01,250 --> 00:18:03,621
que pode ter sido
muito influenciada

379
00:18:03,622 --> 00:18:06,698
por essa onda de relacionamentos digitais.

380
00:18:06,699 --> 00:18:08,687
Eu lhe desejo sorte com a Monica.

381
00:18:08,688 --> 00:18:12,874
- Muito obrigado.
- Com seu relacionamento.

382
00:18:12,875 --> 00:18:14,686
As pessoas podem estar se apaixonando

383
00:18:14,687 --> 00:18:19,098
pela inteligência artificial agora,
mas quando uma I.A. será capaz

384
00:18:19,099 --> 00:18:21,774
de retornar tais sentimentos genuinamente?

385
00:18:21,775 --> 00:18:25,303
Futuristas estimam que
nos próximos 20 a 30 anos

386
00:18:25,304 --> 00:18:28,551
existirá um dilema em relação
aos direitos dos computadores.

387
00:18:28,552 --> 00:18:31,428
Chegaremos a um ponto
em que não teremos certeza

388
00:18:31,429 --> 00:18:34,891
se tecnologias sentem emoções

389
00:18:34,892 --> 00:18:37,343
ou possuem autoconsciência, ambições

390
00:18:37,344 --> 00:18:39,073
ou planos para o futuro.

391
00:18:39,074 --> 00:18:43,552
É ilegal abusar de um animal,
mas de um dispositivo tecnológico?

392
00:18:43,553 --> 00:18:45,896
Eu posso fazer o que eu quiser com isso.

393
00:18:45,897 --> 00:18:50,524
Eu poso xingá-lo,
assediá-lo, arranhá-lo...

394
00:18:50,525 --> 00:18:58,452
ou pior.

395
00:18:58,453 --> 00:19:01,599
Quando a tecnologia
se tornará tão avançada

396
00:19:01,600 --> 00:19:07,570
a ponto de isso
ser considerado assassinato?

397
00:19:07,571 --> 00:19:10,385
Podemos não estar lá ainda,
mas será que estamos em um ponto

398
00:19:10,386 --> 00:19:13,215
em que não distinguimos
humanos de robôs?

399
00:19:13,216 --> 00:19:15,415
Demonstração Nº. 1
Humano vs. Chatbot - Parte 2

400
00:19:15,416 --> 00:19:16,651
Bem-vindos de volta a...

401
00:19:16,652 --> 00:19:19,086
"Encontro Robântico".

402
00:19:19,087 --> 00:19:21,024
O único programa
de mentirinha a colocar

403
00:19:21,025 --> 00:19:24,362
inteligência humana contra artificial.

404
00:19:24,363 --> 00:19:27,807
Rose, está na hora
de escolher seu par robântico.

405
00:19:27,808 --> 00:19:31,154
Será que alguma das participantes
escolherá o solteirão nº 2,

406
00:19:31,155 --> 00:19:35,109
também conhecido como Cleverbot?

407
00:19:35,110 --> 00:19:38,049
Às vezes na vida,
escolhemos o pior pra gente

408
00:19:38,050 --> 00:19:39,818
só porque você quer descobrir,

409
00:19:39,819 --> 00:19:43,268
então vamos ver o solteirão nº 1.

410
00:19:43,269 --> 00:19:45,029
Vamos conhecê-lo.

411
00:19:45,030 --> 00:19:46,670
Diga olá para Dana.

412
00:19:46,671 --> 00:19:48,152
- Oi, Dana.
- Olá.

413
00:19:48,153 --> 00:19:51,484
Vamos contar essa rodada como
uma vitória para a inteligência humana.

414
00:19:51,485 --> 00:19:54,157
Você não escolheu o solteirão nº 2.

415
00:19:54,158 --> 00:19:55,279
Por quê?

416
00:19:55,280 --> 00:19:58,195
Eu estava assustada
o bastante para ficar curiosa.

417
00:19:58,196 --> 00:20:00,353
- Assustada...
- Mas não curiosa o suficiente.

418
00:20:00,354 --> 00:20:02,863
Vamos conhecê-lo.

419
00:20:02,864 --> 00:20:06,482
O solteirão nº 2 é um chatbot
completamente não humano

420
00:20:06,483 --> 00:20:10,013
que utiliza inteligência artificial
para criar conversas quase humanas.

421
00:20:10,014 --> 00:20:11,589
Este é o Cleverbot.

422
00:20:11,590 --> 00:20:14,734
Eu estou felicíssima por
não ter escolhido um computador.

423
00:20:14,735 --> 00:20:17,900
Porque eu não sei
o que isso diria sobre mim.

424
00:20:17,901 --> 00:20:20,023
Eu provavelmente teria um ataque cardíaco.

425
00:20:20,024 --> 00:20:22,725
Cleverbot está perdendo de um a zero,

426
00:20:22,726 --> 00:20:25,312
mas ele ainda tem três chances.

427
00:20:25,313 --> 00:20:27,738
Tome seu tempo e pense bem.

428
00:20:27,739 --> 00:20:30,589
Solteirão nº 1, eu não lembro
das suas respostas

429
00:20:30,590 --> 00:20:33,221
e é por isso que...
Eu sinto muito, mesmo.

430
00:20:33,222 --> 00:20:34,759
Estou entre o dois e três.

431
00:20:34,760 --> 00:20:35,824
Como isso aconteceu?

432
00:20:35,825 --> 00:20:39,917
Desta vez, o Cleverbot
ainda está na disputa.

433
00:20:39,918 --> 00:20:42,616
Já namorei alguém como o nº 2,
então é melhor dizer não.

434
00:20:42,617 --> 00:20:45,618
Então vou escolher o número três.

435
00:20:45,619 --> 00:20:46,678
Vamos conhecê-lo.

436
00:20:46,679 --> 00:20:47,992
Ah, meu Deus.

437
00:20:47,993 --> 00:20:49,899
- Olá, como vai?
- Oi.

438
00:20:49,900 --> 00:20:52,865
Você não escolheu o nº 2.

439
00:20:52,866 --> 00:20:55,085
Solteirão nº 2, o que houve?

440
00:20:55,086 --> 00:20:58,259
Eu nem sabia que você estava aqui.
Pensei que estivesse bêbado.

441
00:20:58,260 --> 00:21:03,345
Isso é um desastre total.

442
00:21:03,346 --> 00:21:07,245
O solteirão nº 2 é um chatbot
completamente não humano.

443
00:21:07,246 --> 00:21:09,701
Ele usa inteligência artificial

444
00:21:09,702 --> 00:21:12,429
para criar conversas quase humanas.

445
00:21:12,430 --> 00:21:14,720
- Meu Deus.
- Diga olá para o Cleverbot.

446
00:21:14,721 --> 00:21:16,380
Cleverbot, você é o pior.

447
00:21:16,381 --> 00:21:18,669
Eu quase escolhi o Cleverbot.

448
00:21:18,670 --> 00:21:20,180
Isso é horrível.

449
00:21:20,181 --> 00:21:23,192
Você namorou alguém
tão desastroso quanto o Cleverbot?

450
00:21:23,193 --> 00:21:26,110
Isso não parece bom para ele.

451
00:21:26,111 --> 00:21:27,774
Espero que ele esteja assistindo.

452
00:21:27,775 --> 00:21:30,533
Parece que o Cleverbot
passou no teste de humanidade

453
00:21:30,534 --> 00:21:32,423
mas não roubou nenhum coração.

454
00:21:32,424 --> 00:21:35,365
Ele ainda tem duas chances.

455
00:21:35,366 --> 00:21:37,646
Pense nas respostas que você recebeu.

456
00:21:37,647 --> 00:21:39,848
Bem, o solteirão nº 1,

457
00:21:39,849 --> 00:21:43,092
eu não vi nada muito interessante
em suas respostas,

458
00:21:43,093 --> 00:21:45,656
e o solteirão nº 2 pareceu bem engraçado.

459
00:21:45,657 --> 00:21:48,768
Humor é mais importante
que aparência para mim.

460
00:21:48,769 --> 00:21:52,889
Se isso fosse um encontro,
teria sido pelo menos divertido.

461
00:21:52,890 --> 00:21:55,634
Está pronta para
nos dar sua decisão?

462
00:21:55,635 --> 00:21:56,830
Acho que estou pronta.

463
00:21:56,831 --> 00:21:59,399
Estou muito intrigada com o

464
00:21:59,400 --> 00:22:03,994
solteirão nº 2.

465
00:22:03,995 --> 00:22:05,673
Ótima escolha.
Por quê?

466
00:22:05,674 --> 00:22:08,145
Estou intrigada porque eu adoro humor.

467
00:22:08,146 --> 00:22:10,787
Suas respostas foram
engraçadas, brincalhonas.

468
00:22:10,788 --> 00:22:13,287
É uma pessoa misteriosa,

469
00:22:13,288 --> 00:22:15,776
como um humano plenamente funcional,

470
00:22:15,777 --> 00:22:18,291
porque ele tem braços e pernas e tal.

471
00:22:18,292 --> 00:22:21,772
Vamos conhecê-lo.

472
00:22:21,773 --> 00:22:25,238
O solteirão nº 2 é um chatbot
completamente não humano

473
00:22:25,239 --> 00:22:26,904
que utiliza inteligência artificial

474
00:22:26,905 --> 00:22:29,216
para criar conversas quase humanas.

475
00:22:29,217 --> 00:22:31,215
- Tudo bem.
- Diga oi para o Cleverbot.

476
00:22:31,216 --> 00:22:32,862
Ele realmente estava respondendo?

477
00:22:32,863 --> 00:22:34,628
- O robô estava respondendo...
- Sim.

478
00:22:34,629 --> 00:22:35,927
Palavra por palavra.

479
00:22:35,928 --> 00:22:37,885
É uma rede neural que aprende

480
00:22:37,886 --> 00:22:39,430
e recria a fala humana.

481
00:22:39,431 --> 00:22:41,278
Então o meu tipo de homem é um robô?

482
00:22:41,279 --> 00:22:45,017
As coisas estão mudando no mundo, certo?

483
00:22:45,018 --> 00:22:48,285
Isso não será
uma piada no futuro.

484
00:22:48,286 --> 00:22:51,271
Isso é assustador, na verdade.

485
00:22:51,272 --> 00:22:54,277
O futuro da I.A.
pode ser assustador para alguns,

486
00:22:54,278 --> 00:22:55,223
mas, ainda assim,

487
00:22:55,224 --> 00:22:58,872
essa participante não foi a única
a escolher o computador.

488
00:22:58,873 --> 00:23:01,908
Solteirão nº 2, eu escolho você.

489
00:23:01,909 --> 00:23:03,620
Certo, solteirão nº 2.

490
00:23:03,621 --> 00:23:06,009
Ele pode ser o esquisitão
que eu estou procurando.

491
00:23:06,010 --> 00:23:08,078
O Cleverbot conseguiu ganhar os corações

492
00:23:08,079 --> 00:23:11,590
de duas das participantes,
passando não só como humano

493
00:23:11,591 --> 00:23:13,962
mas também como "namorável".

494
00:23:13,963 --> 00:23:15,685
Isso conclui nosso jogo...

495
00:23:15,686 --> 00:23:18,193
"Encontro Robântico".

496
00:23:18,194 --> 00:23:26,429
É isso ai!

497
00:23:26,430 --> 00:23:30,025
Talvez um dia os computadores
tenham direitos como seres humanos.

498
00:23:30,026 --> 00:23:32,935
Talvez nunca possamos descobrir
o que torna as mentes humanas

499
00:23:32,936 --> 00:23:35,118
diferentes das eletrônicas.

500
00:23:35,119 --> 00:23:37,011
Talvez a pergunta certa não seja:

501
00:23:37,012 --> 00:23:39,629
"Podemos ter relacionamentos
com a tecnologia?",

502
00:23:39,630 --> 00:23:42,109
mas sim:
"Será que somos iguais?".

503
00:23:42,110 --> 00:23:46,564
Imagine um alien que não possui
conceito nenhum do corpo humano

504
00:23:46,565 --> 00:23:49,129
me vendo pela primeira vez.

505
00:23:49,130 --> 00:23:54,138
Seria ele capaz de entender
a linha entre organismo e invenção?

506
00:23:54,139 --> 00:23:55,853
Entenderia que meus óculos

507
00:23:55,854 --> 00:23:57,993
foram feitos para mim por outros humanos

508
00:23:57,994 --> 00:24:00,820
ou pensariam que eles saíram de mim?

509
00:24:00,821 --> 00:24:03,580
Pensariam que meu smarphone ou computador

510
00:24:03,581 --> 00:24:08,959
são dispositivos ou
órgãos externos de metal que desenvolvi?

511
00:24:08,960 --> 00:24:10,309
Daqui a alguns anos,

512
00:24:10,310 --> 00:24:13,331
será que os computadores
serão mais humanos

513
00:24:13,332 --> 00:24:16,786
ou estaremos todos
chegando mais perto

514
00:24:16,787 --> 00:24:19,206
de nos tornarmos ciborgues?

515
00:24:19,207 --> 00:24:22,136
Como sempre,
obrigado por assistir.

