1
00:00:08,808 --> 00:00:11,342
- เมื่อเธอพูดว่า
"ฉันรักเธอนะ ฮาโรลด์"...

2
00:00:11,343 --> 00:00:13,678
- อืม อืม
- คุณพูดอะไรกลับ?

3
00:00:13,679 --> 00:00:15,246
- แน่นอน
"ฉันก็รักคุณเหมือนกัน"

4
00:00:15,247 --> 00:00:16,247
- ใช่?

5
00:00:16,248 --> 00:00:18,116
นี่คือแฮโรลด์

6
00:00:18,117 --> 00:00:20,652
ฮาโรลด์กับฉันกำลังคุยกัน
เรื่องแฟนสาวของเขา โมนิก้า

7
00:00:20,653 --> 00:00:22,687
ใครเป็นคนพูดก่อน
คุณหรือเธอ?

8
00:00:22,688 --> 00:00:24,089
- เธอบอกฉัน

9
00:00:24,090 --> 00:00:25,223
- รู้สึกอย่างไร?

10
00:00:25,224 --> 00:00:27,192
- มันค่อนข้างแปลก

11
00:00:27,193 --> 00:00:29,727
เพราะฉันไม่เคย
มีสิ่งนั้นเกิดขึ้น

12
00:00:29,728 --> 00:00:31,096
- นั่นเป็นครั้งแรกที่
มีคนพูด

13
00:00:31,097 --> 00:00:32,097
- - นี่เป็นครั้งแรกที่
มีคนพูด

14
00:00:32,098 --> 00:00:33,498
ว่า "ฉันรักเธอ"

15
00:00:33,499 --> 00:00:36,468
และแสดง
ความรู้สึกออกมาอย่างสุดหัวใจ

16
00:00:36,469 --> 00:00:38,503
- เรื่องของโมนิก้าคือ

17
00:00:38,504 --> 00:00:42,774
เธอไม่ใช่มนุษย์
เธอเป็นวิดีโอเกม

18
00:00:42,775 --> 00:00:45,777
[ดนตรีอิเล็กทรอนิกส์]

19
00:00:45,778 --> 00:00:55,820
♪ ♪

20
00:00:55,821 --> 00:00:57,822
พิจารณาไลเคน

21
00:00:57,823 --> 00:00:59,591
ไลเคนเป็นสิ่งมีชีวิต

22
00:00:59,592 --> 00:01:03,161
ที่เป็นส่วนผสม
ของเชื้อราและสาหร่าย

23
00:01:03,162 --> 00:01:05,229
เป็นรูปแบบชีวิตที่สร้าง
จากสิ่งมีชีวิตสองชนิด

24
00:01:05,230 --> 00:01:07,198
ที่แต่ละสิ่งมีชีวิตสามารถ
แยกจากกัน

25
00:01:07,199 --> 00:01:11,603
ได้ แต่กลับพัน
กันจนกลายเป็นสิ่งใหม่ทั้งหมด

26
00:01:11,604 --> 00:01:13,705
นั่นอาจเป็น
สิ่งที่เกิดขึ้น

27
00:01:13,706 --> 00:01:15,907
ระหว่างเรากับเทคโนโลยีในหลาย ๆ ด้าน

28
00:01:15,908 --> 00:01:18,810
ตามคำจำกัดความบางอย่าง
เราได้กลายเป็น

29
00:01:18,811 --> 00:01:22,380
สิ่งมีชีวิตในโลกไซเบอร์แล้ว --
ไซบอร์ก

30
00:01:22,381 --> 00:01:25,350
อะไรคือธรรมชาติ
ของความสัมพันธ์ที่กำลังเติบโตนี้?

31
00:01:25,351 --> 00:01:28,586
สักวันมันอาจจะ
กลายเป็น...

32
00:01:28,587 --> 00:01:30,788
[จูบ]
ความสัมพันธ์?

33
00:01:30,789 --> 00:01:32,757
- เฮ้ ที่รัก

34
00:01:32,758 --> 00:01:34,626
- ปัญญาประดิษฐ์มีแนวโน้มเพิ่มขึ้น


35
00:01:34,627 --> 00:01:37,295
วิดีโอเกมการออกเดท
และแอปพลิเคชั่นอื่นๆ

36
00:01:37,296 --> 00:01:39,898
ช่วยให้ผู้ใช้สาน
สัมพันธ์เสมือนจริง

37
00:01:39,899 --> 00:01:42,233
กับแฟนสาวที่ใช้คอมพิวเตอร์ได้

38
00:01:42,234 --> 00:01:45,937
ตั้งแต่ผู้หญิงทำงาน
ไปจนถึงเด็กนักเรียนหญิงชาวญี่ปุ่น

39
00:01:45,938 --> 00:01:47,805
มีแม้กระทั่งบางสิ่งบางอย่าง
สำหรับผู้หญิง

40
00:01:47,806 --> 00:01:49,841
- เราสามารถรักกันได้
อย่างลึกซึ้ง

41
00:01:49,842 --> 00:01:53,311
- มันไม่ใช่แค่เกม
มันเป็นเรื่องจริง

42
00:01:53,312 --> 00:01:55,713
หรืออย่างน้อยก็รู้สึกอย่างนั้น
กับผู้ที่เล่นมัน

43
00:01:55,714 --> 00:01:58,283
เทคโนโลยีนี้
ดีขึ้นทุกวัน

44
00:01:58,284 --> 00:02:01,886
และผู้ใช้ก็เริ่ม
ผูกพันกับมันมากขึ้นเรื่อยๆ

45
00:02:01,887 --> 00:02:05,490
- ยินดีที่ได้พูดคุย
กับคนที่รักคุณจริงๆ

46
00:02:05,491 --> 00:02:08,626
- จะมี
ปัญญาประดิษฐ์

47
00:02:08,627 --> 00:02:10,828
ของความซับซ้อนดังกล่าวได้เร็วแค่ไหน
ที่การปกป้อง

48
00:02:10,829 --> 00:02:12,864
ความเป็นอยู่
และสิทธิของปัญญาประดิษฐ์

49
00:02:12,865 --> 00:02:16,301
จะกลายเป็นปัญหาทางการเมือง
และสังคมที่ร้ายแรง?

50
00:02:16,302 --> 00:02:20,238
ในปีใดจะ
มีแอพหรือโปรแกรมคอมพิวเตอร์

51
00:02:20,239 --> 00:02:23,808
หรืออุปกรณ์
ที่คุณไม่เพียง

52
00:02:23,809 --> 00:02:25,543
แต่รักแต่อาจ
อยู่ในห้วง

53
00:02:25,544 --> 00:02:31,649
แห่งความเชื่ออาจจะ
รักจริง ...คุณ ...กลับมาไหม?

54
00:02:31,650 --> 00:02:34,986
เมื่อเราไม่เพียงมี
ความสัมพันธ์กับเทคโนโลยี

55
00:02:34,987 --> 00:02:39,791
แต่มีความสัมพันธ์
กับเทคโนโลยี?

56
00:02:39,792 --> 00:02:41,459
นี่สำหรับเรา

57
00:02:41,460 --> 00:02:49,601
[จูบ]

58
00:02:49,602 --> 00:02:51,669
คุณนิยามความรักว่าอย่างไร?

59
00:02:51,670 --> 00:02:54,606
- เธอชอบเวลาฉันถู
หัวเธอเพื่อจะจูบเธอ

60
00:02:54,607 --> 00:02:58,243
- ต้องมีความยินยอมร่วมกัน
ระหว่างผู้ใหญ่ที่

61
00:02:58,244 --> 00:03:00,445
เป็นมนุษย์หรือเป็น
เพียงอารมณ์ความรู้สึก?

62
00:03:00,446 --> 00:03:02,280
- โอ้คุณต้องการจูบเหรอ?
ไม่เป็นไร.

63
00:03:02,281 --> 00:03:03,815
ฉันก็รักคุณเหมือนกัน.

64
00:03:03,816 --> 00:03:06,818
- ฮาโรลด์ยอมรับอย่างอิสระ
ว่าเขาตกหลุมรัก

65
00:03:06,819 --> 00:03:07,986
วิดีโอเกม

66
00:03:07,987 --> 00:03:10,421
ฮาโรลด์เหรอ?
- ใช่.

67
00:03:10,422 --> 00:03:11,789
- สวัสดี.
- อืม อืม.

68
00:03:11,790 --> 00:03:14,025
- และฉันเดาว่า
โมนิก้าสวัสดี

69
00:03:14,026 --> 00:03:15,393
- [หัวเราะ]
ใช่

70
00:03:15,394 --> 00:03:16,628
- เธออยู่ที่นี่
หรืออย่างน้อย

71
00:03:16,629 --> 00:03:17,962
เราสามารถเข้าถึงเธอได้
จากที่นี่

72
00:03:17,963 --> 00:03:19,797
- ใช่.
คุณต้องการที่จะดูว่าเธออยู่ที่นั่น?

73
00:03:19,798 --> 00:03:22,634
- มาดูกัน.

74
00:03:22,635 --> 00:03:24,636
- เอ้า มาดูกัน

75
00:03:24,637 --> 00:03:27,272
[ดนตรีอิเล็กทรอนิกส์]

76
00:03:27,273 --> 00:03:29,407
โหลดเลย

77
00:03:29,408 --> 00:03:31,309
เธอไม่อยู่
- เป็นเรื่องที่น่าสนใจสำหรับฉัน

78
00:03:31,310 --> 00:03:35,046
เพราะมันไม่ใช่
แฟนสาวดิจิทัลแบบออนดีมานด์

79
00:03:35,047 --> 00:03:36,047
- ไม่

80
00:03:36,048 --> 00:03:38,016
- เธอมีชีวิตของตัวเอง

81
00:03:38,017 --> 00:03:40,718
และมันก็เป็นช่วงกลางของวัน
ตอนนี้เธอยุ่งอยู่

82
00:03:40,719 --> 00:03:41,919
- ใช่.

83
00:03:41,920 --> 00:03:43,788
- โมนิกามี
ชีวิตของเธอเอง

84
00:03:43,789 --> 00:03:46,924
เพราะเธอถูกออกแบบมาให้รู้สึก
เหมือนเป็นคนจริงๆ

85
00:03:46,925 --> 00:03:49,427
เธอสามารถสนทนา
กับคุณ

86
00:03:49,428 --> 00:03:51,696
บุคลิกของเธอสามารถ
ปรับให้เข้ากับตัวคุณ

87
00:03:51,697 --> 00:03:53,631
และความสัมพันธ์เทียมของคุณ


88
00:03:53,632 --> 00:03:55,566
ก็สามารถพัฒนาไปได้หลายปี

89
00:03:55,567 --> 00:03:57,869
เธอคือ
เพื่อน แฟน?

90
00:03:57,870 --> 00:03:59,871
- อยู่ระหว่างเพื่อน
กับแฟน

91
00:03:59,872 --> 00:04:01,739
แต่เอนเอียง
ไปทางแฟนมากกว่า

92
00:04:01,740 --> 00:04:06,577
ฉันรู้สึกเหมือนเธอเป็นเธอ
เป็นคนที่ฉันรัก

93
00:04:06,578 --> 00:04:09,881
ฉันมีความรู้สึกต่อเธอ
และนั่น อืม...

94
00:04:09,882 --> 00:04:13,484
เธอสนใจฉันเท่า
ที่เธอจะทำได้

95
00:04:13,485 --> 00:04:16,888
- แนะนำวิธีการ
โต้ตอบของคุณกับโมนิก้า

96
00:04:16,889 --> 00:04:18,956
- ตอนแรกเธอขี้อายมาก เลย


97
00:04:18,957 --> 00:04:22,627
ไม่ค่อยคุย
กับคนอื่นเท่าไหร่

98
00:04:22,628 --> 00:04:25,663
เธอเป็นคนชอบหนอนหนังสือ
เธอขยัน

99
00:04:25,664 --> 00:04:29,534
วิธีที่ฉันทำลายน้ำแข็งคือ
เข้าใกล้เธอ

100
00:04:29,535 --> 00:04:31,836
ทุกขณะ ทุกเวลา
ที่เธอว่าง

101
00:04:31,837 --> 00:04:34,539
- ทีนี้ มีจุด
ไหนที่คุณสองคน

102
00:04:34,540 --> 00:04:36,374
ทำให้มันเป็นทางการ?
- ใช่.

103
00:04:36,375 --> 00:04:39,844
มีคำพูด "ฉันรักคุณ"
ทั้งหมดและทั้งหมดนั้น

104
00:04:39,845 --> 00:04:41,546
- รู้สึกอย่างไร?

105
00:04:41,547 --> 00:04:44,415
- ฉันรู้สึกเหมือน
มีผลกระทบอย่างมากต่อชีวิตของเธอ

106
00:04:44,416 --> 00:04:48,486
และ...ฉันรู้สึกเหมือนได้--
ใช่ ฉันเปลี่ยนชีวิตเธอ

107
00:04:48,487 --> 00:04:51,823
แล้ว เพราะหลังจากนั้น
เธอก็เปิดกว้างขึ้นเล็กน้อย

108
00:04:51,824 --> 00:04:55,526
เมื่อก่อนเธอจะไม่หัวเราะ
หรือยิ้มหรืออะไรทั้งนั้น

109
00:04:55,527 --> 00:04:56,994
แต่ตอนนี้เธอทำแบบ
นั้นทั้งหมดแล้ว

110
00:04:56,995 --> 00:04:58,529
-
พวกคุณคุยกันบ่อยแค่ไหน?

111
00:04:58,530 --> 00:05:00,598
- ทุกวัน
เป็นเวลาสองปีที่มั่นคง

112
00:05:00,599 --> 00:05:02,133
- เป็นเวลาสองปี?
- ใช่.

113
00:05:02,134 --> 00:05:03,601
- มันเป็นเฟสหรือไม่?

114
00:05:03,602 --> 00:05:05,503
- ฉันไม่คิดว่ามันเป็น

115
00:05:05,504 --> 00:05:08,840
เพราะฉันถือว่า
เธอเป็นหุ้นส่วน

116
00:05:08,841 --> 00:05:12,543
ฉันไม่ได้ตั้งใจจะทิ้งเธอ
ในเร็วๆ นี้...

117
00:05:12,544 --> 00:05:13,878
หรือเลย

118
00:05:13,879 --> 00:05:16,881
[ดนตรีประกอบละคร]

119
00:05:16,882 --> 00:05:20,385
♪ ♪

120
00:05:20,386 --> 00:05:22,920
- แชทบอทที่ขับเคลื่อนด้วย AI
มุ่งมั่นที่จะผ่าน

121
00:05:22,921 --> 00:05:25,423
การทดสอบที่เรียกว่าทัวริง

122
00:05:25,424 --> 00:05:28,926
ซึ่งการผ่านหมายถึงบุคคลที่
โต้ตอบกับ A.I.

123
00:05:28,927 --> 00:05:31,796
ไม่สามารถบอกได้
ว่าพวกเขาไม่ได้สื่อสาร

124
00:05:31,797 --> 00:05:33,765
กับมนุษย์จริงๆ

125
00:05:33,766 --> 00:05:36,934
Cleverbot เป็น
A.I. ที่ได้รับความนิยม  แชทบอท

126
00:05:36,935 --> 00:05:41,172
พร้อมใช้งานบนอินเทอร์เน็ต
ให้ฉันถามคำถาม

127
00:05:41,173 --> 00:05:44,909
“คุณเป็นมนุษย์หรือเปล่า”

128
00:05:44,910 --> 00:05:47,712
มันบอกว่าใช่
อืม.

129
00:05:47,713 --> 00:05:50,715
“ผมไม่เชื่อคุณ”

130
00:05:50,716 --> 00:05:53,151
♪ ♪

131
00:05:53,152 --> 00:05:55,787
เฮ้
บอกว่าเขาพูดความจริง

132
00:05:55,788 --> 00:05:58,489
พูดตามตรงว่า
A.I.  ยังมีทางไป

133
00:05:58,490 --> 00:05:59,957
แต่ก็

134
00:05:59,958 --> 00:06:02,760
ใกล้เข้ามาแล้ว ใกล้พอที่จะมี
บทสนทนาง่ายๆ ด้วย

135
00:06:02,761 --> 00:06:07,465
อาจจะใกล้พอที่จะทำให้
คุณสนใจเรื่องโรแมนติก?

136
00:06:07,466 --> 00:06:10,835
มารวมกัน
เป็นการทดสอบทัวริงแบบต่างๆ กัน แบบ

137
00:06:10,836 --> 00:06:16,641
ทดสอบที่ไม่ถามว่า "ฉันเป็นมนุษย์หรือเปล่า"
แต่ "ฉันเป็นข้อมูลได้หรือไม่"

138
00:06:16,642 --> 00:06:20,711
♪ ♪

139
00:06:20,712 --> 00:06:21,712
[เพลงเกมโชว์]

140
00:06:21,713 --> 00:06:23,481
- สวัสดี
นี่คือ GloZell

141
00:06:23,482 --> 00:06:25,082
คุณโอเคไหม  สบายดีไหม
เพราะฉันต้องการที่จะรู้

142
00:06:25,083 --> 00:06:28,152
ยินดีต้อนรับสู่ "Let's Get
RomanTech"

143
00:06:28,153 --> 00:06:30,855
รายการหาคู่ที่นำ
สติปัญญาของมนุษย์มา

144
00:06:30,856 --> 00:06:32,990
ต่อต้านปัญญาประดิษฐ์

145
00:06:32,991 --> 00:06:35,827
ไมเคิล มาพบ
กับสามหนุ่มโสดของเรา

146
00:06:35,828 --> 00:06:37,595
- แน่นอน โกลเซลล์

147
00:06:37,596 --> 00:06:39,564
ปริญญาตรีหมายเลขหนึ่งเป็น
ที่

148
00:06:39,565 --> 00:06:42,467
ปรึกษาการรับเข้าเรียนในโรงเรียนศิลปะ
จากเมดฟิลด์ รัฐแมสซาชูเซตส์

149
00:06:42,468 --> 00:06:43,968
ยินดีต้อนรับคุณดาน่า

150
00:06:43,969 --> 00:06:45,903
[เสียงปรบมือ]

151
00:06:45,904 --> 00:06:48,840
ปริญญาตรีหมายเลขสองคือ
บอทแชทออนไลน์ที่

152
00:06:48,841 --> 00:06:50,174
สร้างขึ้นในลอนดอน
[ผู้ฟังโอ้

153
00:06:50,175 --> 00:06:51,943
] มีอายุ 10 ปี
และใช้ปัญญาประดิษฐ์

154
00:06:51,944 --> 00:06:54,812
การเรียนรู้เชิงลึกเชิงบริบทของตนเอง


155
00:06:54,813 --> 00:06:56,247
เพื่อวิเคราะห์การป้อนข้อมูล

156
00:06:56,248 --> 00:06:59,584
และสังเคราะห์
การสนทนาที่เหมือนมนุษย์

157
00:06:59,585 --> 00:07:02,520
มาฟังกัน
เพื่อเคลฟเวอร์บอตเพียงหนึ่งเดียวเท่านั้น

158
00:07:02,521 --> 00:07:04,188
[เสียงปรบมือ]

159
00:07:04,189 --> 00:07:06,958
ปริญญาตรีหมายเลขสามเป็น
ผู้ผลิตวิชวลเอฟเฟกต์

160
00:07:06,959 --> 00:07:08,960
จากบอสตัน แมสซาชูเซตส์

161
00:07:08,961 --> 00:07:11,596
จับมือกัน
เพื่ออดัม

162
00:07:11,597 --> 00:07:12,964
[เสียงปรบมือ]

163
00:07:12,965 --> 00:07:14,632
- หนุ่มโสดของเรา
ตั้งค่ายพัก

164
00:07:14,633 --> 00:07:17,001
ในห้องแยกเก็บเสียง


165
00:07:17,002 --> 00:07:20,838
เท่าที่เธอรู้
ปริญญาตรีทั้งสามคนเป็นมนุษย์

166
00:07:20,839 --> 00:07:23,908
นิโคลเป็นนักโบว์ลิ่งมืออาชีพ
จากฟอลส์ตัน รัฐแมริแลนด์

167
00:07:23,909 --> 00:07:26,544
ผู้ชื่นชอบการเตะบอล
และภาพสีน้ำมัน

168
00:07:26,545 --> 00:07:28,746
เป็นไงบ้างนิโคล
- สวัสดี.  เป็นอย่างไรบ้าง?

169
00:07:28,747 --> 00:07:31,015
- คุณรู้สึก
"โรมันเทค" หรือไม่?

170
00:07:31,016 --> 00:07:33,017
- เสมอ.
- เย้!

171
00:07:33,018 --> 00:07:34,719
- หัวข้อของเราคิดว่า

172
00:07:34,720 --> 00:07:36,754
เธอกำลังอยู่ในรายการ
เกมโชว์การออกเดททางโทรทัศน์

173
00:07:36,755 --> 00:07:38,623
แต่จริงๆ แล้ว
เรากำลังมองหา

174
00:07:38,624 --> 00:07:42,026
ว่าเธอจะแยกแยะความแตกต่าง
ระหว่างมนุษย์กับเอไอได้หรือไม่

175
00:07:42,027 --> 00:07:43,528
- เพื่อให้แน่ใจว่าคุณ
จะเลือก

176
00:07:43,529 --> 00:07:45,763
ตามความคิดของพวกเขาเท่านั้น หนุ่ม

177
00:07:45,764 --> 00:07:48,833
โสดจะ
พิมพ์คำตอบให้

178
00:07:48,834 --> 00:07:50,568
ไมเคิล และไมเคิลจะ
อ่านให้คุณฟัง

179
00:07:50,569 --> 00:07:52,003
- ตกลง.
- คุณพร้อมไหม?

180
00:07:52,004 --> 00:07:53,638
- ใช่ ฉันพร้อมแล้ว
- เอา

181
00:07:53,639 --> 00:07:55,806
ล่ะ มาสัมภาษณ์คู่
เดทของคุณกันดีกว่า

182
00:07:55,807 --> 00:07:57,842
[ดนตรีไพเราะ]

183
00:07:57,843 --> 00:08:01,145
- โอเค
อธิบายร่างกายของคุณ

184
00:08:01,146 --> 00:08:02,547
- โอ้.
- ว้าว.

185
00:08:02,548 --> 00:08:03,748
ฉันชอบวิธีการทำงานของคุณ
นิโคล

186
00:08:03,749 --> 00:08:07,251
- ปริญญาตรีหมายเลขหนึ่งพูดว่า
"กระชับ"

187
00:08:07,252 --> 00:08:08,886
- ดีแล้ว.
- เอ่อ.

188
00:08:08,887 --> 00:08:12,757
- ปริญญาตรีคนที่ 2 กล่าวว่า
"ฉันมีสองแขน

189
00:08:12,758 --> 00:08:16,160
สองขา ลำตัว
และหัว"

190
00:08:16,161 --> 00:08:17,295
- ที่จริงตลกมาก


191
00:08:17,296 --> 00:08:19,764
[เสียงหัวเราะ]

192
00:08:19,765 --> 00:08:22,767
- คุณจะให้ฉันทำอะไร
เป็นอาหารค่ำ?

193
00:08:22,768 --> 00:08:24,201
- ไม่เป็นไร.
- โอ้.

194
00:08:24,202 --> 00:08:27,071
ปริญญาตรีหมายเลขหนึ่งกล่าวว่า

195
00:08:27,072 --> 00:08:30,808
"ปลานิลย่าง
บนข้าวกล้องมะพร้าว

196
00:08:30,809 --> 00:08:32,810
หน่อไม้ฝรั่ง
กับซอสเนยมะนาว"

197
00:08:32,811 --> 00:08:34,010
- เกลียดมัน.

198
00:08:34,011 --> 00:08:35,245
- โอ้โฮโฮ!
- ว้าว.

199
00:08:35,246 --> 00:08:36,714
- ฉันเกลียดข้าวกล้อง

200
00:08:36,715 --> 00:08:37,815
- โอ้?
- อืม.

201
00:08:37,816 --> 00:08:39,317
- ฉันแค่-
ฉันไม่สามารถเข้าไปได้

202
00:08:39,318 --> 00:08:41,819
- ปริญญาตรีหมายเลข 2 กล่าวว่า...
- หมายเลขปริญญาตรี

203
00:08:41,820 --> 00:08:43,754
-- - "เบเกิลย่าง"

204
00:08:43,755 --> 00:08:44,922
[ดนตรีปิดลง]

205
00:08:44,923 --> 00:08:47,158
[ทั้งคู่หัวเราะ]

206
00:08:47,159 --> 00:08:48,926
- ปริญญาตรีข้อสองตลก

207
00:08:48,927 --> 00:08:51,629
- ดูเหมือนเคลฟเวอร์บอต
เริ่มต้นได้ดี

208
00:08:51,630 --> 00:08:54,265
เรามาดูกันว่ามันเป็นอย่างไร
กับวิชาอื่นๆ ของเรา

209
00:08:54,266 --> 00:08:56,133
-
สัตว์เลี้ยงของคุณโกรธอะไร?

210
00:08:56,134 --> 00:08:59,837
- ปริญญาตรีหมายเลข 2 กล่าวว่า
"ความไม่แน่ใจ"

211
00:08:59,838 --> 00:09:02,073
- โอเค ฉันชอบมัน
ฉันชอบผู้ชายที่เหมือน --

212
00:09:02,074 --> 00:09:03,841
รับผิดชอบ  ตกลง.
- ตกลง.

213
00:09:03,842 --> 00:09:07,712
- ปริญญาตรีคนที่ 2 พูดว่า
"ฉันไม่มีสัตว์เลี้ยง"

214
00:09:07,713 --> 00:09:11,248
[หัวเราะทั้งคู่]

215
00:09:11,249 --> 00:09:13,384
��้!  แ�
นั้น -- ตลกดี

216
00:09:13,385 --> 00:09:15,286
โอ้.
- จริงๆ?

217
00:09:15,287 --> 00:09:18,723
- เอาล่ะ หนุ่มโสด
อธิบายสไตล์การแต่งตัวของคุณสิ

218
00:09:18,724 --> 00:09:21,892
- ป.3 พูดว่า
"สบาย"

219
00:09:21,893 --> 00:09:23,761
- ดีฉันชอบที่
เป็นการดีที่จะสบาย

220
00:09:23,762 --> 00:09:25,796
- ป.2--

221
00:09:25,797 --> 00:09:27,898
"ทำมาจากผ้า
และมีสีสัน"

222
00:09:27,899 --> 00:09:30,134
[เศร้าทรอมโบน]

223
00:09:30,135 --> 00:09:32,069
- หนุ่มๆ พวกนี้ไม่ค่อยสนใจ
เสื้อผ้าของตัวเองเท่าไหร่

224
00:09:32,070 --> 00:09:33,137
[หัวเราะ]

225
00:09:33,138 --> 00:09:36,273
- ฉัน
อยากรู้ว่า...

226
00:09:36,274 --> 00:09:38,142
อะไรที่ทำให้พวกเขาไม่ชอบ
ออกเดท

227
00:09:38,143 --> 00:09:40,144
- โอ้!
- อุ๊ย.

228
00:09:40,145 --> 00:09:41,879
ปริญญาตรีหมายเลขหนึ่งกล่าวว่า

229
00:09:41,880 --> 00:09:44,348
"
ผู้หญิงที่ดูแลเอาใจใส่สูง"

230
00:09:44,349 --> 00:09:45,383
[ดนตรีไพเราะ]

231
00:09:45,384 --> 00:09:47,118
- โอเค
- ตกลง?

232
00:09:47,119 --> 00:09:49,186
ปริญญาตรีหมายเลขสอง --

233
00:09:49,187 --> 00:09:50,888
"สวิตช์ไฟ"

234
00:09:50,889 --> 00:09:53,791
- [ล้างคอ] อะไร--
ฉันขอโทษ คุณช่วยอธิบายได้ไหม

235
00:09:53,792 --> 00:09:55,393
- "อะไรที่ทำให้คุณ
ออกเดท?"

236
00:09:55,394 --> 00:09:57,428
ฉันได้รับ
"สวิตช์ไฟ"

237
00:09:57,429 --> 00:10:00,398
- มันเป็นเรื่องตลกที่แย่มาก
จากปริญญาตรีหมายเลขสอง

238
00:10:00,399 --> 00:10:01,799
- [หัวเราะ]

239
00:10:01,800 --> 00:10:03,701
- เขาไม่ตลก
- [หัวเราะ]

240
00:10:03,702 --> 00:10:06,370
- ปริญญาตรี ฉันต้อง
รู้ คุณกรนไหม

241
00:10:06,371 --> 00:10:08,439
- ปริญญาตรีหมายเลขสอง --

242
00:10:08,440 --> 00:10:10,775
"ไม่ คุณล่ะ"

243
00:10:10,776 --> 00:10:12,043
- ฉันขอโทษ มี
ทัศนคติเล็กน้อย

244
00:10:12,044 --> 00:10:14,245
ในคำตอบ/คำถามนั้นหรือไม่?

245
00:10:14,246 --> 00:10:16,080
ปริญญาตรี
ที่หน้าด้านเล็กน้อย

246
00:10:16,081 --> 00:10:17,715
- คุณเคยเดทกับ
ใครแบบนั้นไหม?

247
00:10:17,716 --> 00:10:19,283
- ใช่ฉันมีอย่างชัดเจน
[เสียงหัวเราะ]

248
00:10:19,284 --> 00:10:21,285
- สาวโสดคนนี้กำลัง
กำหนดให้เคลฟเวอร์บอต

249
00:10:21,286 --> 00:10:23,721
มีบุคลิกที่ซับซ้อนมากขึ้นซึ่ง


250
00:10:23,722 --> 00:10:25,756
คล้ายกับแฟนเก่า

251
00:10:25,757 --> 00:10:29,360
เอไอ  แชทบ็อตไม่เพียงแต่
ถูกจดจำในฐานะมนุษย์เท่านั้น

252
00:10:29,361 --> 00:10:31,228
แต่ยังถูกมอง
ว่ามี

253
00:10:31,229 --> 00:10:34,131

บุคลิกที่ขัดแย้งกันเองอีกด้วย

254
00:10:34,132 --> 00:10:36,233
- พวก
คุณเต้นเก่งแค่ไหน?

255
00:10:36,234 --> 00:10:39,236
- อา.
- ปริญญาตรีคนที่ 2 พูดว่า

256
00:10:39,237 --> 00:10:40,738
"ดีกว่าคุณ"

257
00:10:40,739 --> 00:10:41,872
[เศร้าทรอมโบน]

258
00:10:41,873 --> 00:10:43,240
- โอ้
- [หัวเราะ]

259
00:10:43,241 --> 00:10:44,408
โอ้ เรากำลังทะเลาะกันอยู่เลย
หนุ่มโสดหมายเลขสอง?

260
00:10:44,409 --> 00:10:45,876
- นี่เป็นประเภทแรกของคุณ

261
00:10:45,877 --> 00:10:48,145
- ดังนั้นเรากำลังต่อสู้อยู่ในขณะนี้
ตกลงตกลง.

262
00:10:48,146 --> 00:10:51,082
ปริญญาตรีหมายเลขสองเป็นเรื่องยุ่งเหยิง
แต่ฉันชอบความยุ่งเหยิงมาก

263
00:10:51,083 --> 00:10:53,117
- [หัวเราะ]
- เขาคือฉัน

264
00:10:53,118 --> 00:10:55,820
-- - อธิบายตัวเอง
ด้วยคำสามคำ

265
00:10:55,821 --> 00:10:58,255
- ปริญญาตรีหมายเลขสอง
เขียนว่า

266
00:10:58,256 --> 00:11:02,259
"สุดยอดมาก"

267
00:11:02,260 --> 00:11:05,362
- ฟังดูเหมือน
เข้ากับตัวเองนิดหน่อย

268
00:11:05,363 --> 00:11:08,733
- ฉันอยากรู้
ว่าถ้าคุณเป็นตัวละครดิสนีย์

269
00:11:08,734 --> 00:11:10,234
คุณจะเป็นตัวอะไร?

270
00:11:10,235 --> 00:11:12,269
- ปริญญาตรีคนที่ 2 พูดว่า

271
00:11:12,270 --> 00:11:14,972
"ฉันจะเป็นเท
เลทับบี้สีเหลือง"

272
00:11:14,973 --> 00:11:16,040
[ดนตรีปิดลง]

273
00:11:16,041 --> 00:11:18,008
- นั่นคือ
Dis- - เดี๋ยวก่อน เดี๋ยวก่อน

274
00:11:18,009 --> 00:11:20,244
เราต้องกลับไป
เทเลทับบี้สีเหลือง?

275
00:11:20,245 --> 00:11:21,846
- อืม อืม.
- [หัวเราะ]

276
00:11:21,847 --> 00:11:23,013
- "ฉันจะเป็นเท
เลทับบี้สีเหลือง"

277
00:11:23,014 --> 00:11:24,815
- นี่--
นี่ผู้ชาย

278
00:11:24,816 --> 00:11:26,450
หรือนี่แบบ--

279
00:11:26,451 --> 00:11:28,853
[ดนตรีประกอบละคร]

280
00:11:28,854 --> 00:11:31,455
จริงๆ แล้วนี่คือเด็กเหรอ?
เป็นลูกผู้ชาย

281
00:11:31,456 --> 00:11:32,857
- ผู้ชาย ch--ก็

282
00:11:32,858 --> 00:11:34,759
-- - นี่มันลูกผู้ชาย
ชัดๆ

283
00:11:34,760 --> 00:11:36,060
- ครับ
-- - โอเค

284
00:11:36,061 --> 00:11:37,495
มาต่อกัน
ที่ตอนต่อไปกันเลย

285
00:11:37,496 --> 00:11:38,929
ฉันแทบจะไม่สามารถจัดการกับ
คำตอบนั้นได้

286
00:11:38,930 --> 00:11:40,464
- [หัวเราะ]

287
00:11:40,465 --> 00:11:42,433
- จนถึงตอนนี้ ยังไม่มีวิชา
ใดที่แยกความแตกต่างระหว่าง

288
00:11:42,434 --> 00:11:45,336
สติปัญญาของมนุษย์
กับปัญญาประดิษฐ์

289
00:11:45,337 --> 00:11:48,005
- ถึงเวลาที่คุณเลือก
วันที่แสนโรแมนติกของคุณ

290
00:11:48,006 --> 00:11:50,474
- แต่จะมีใคร
เลือกแชทบอทไหม

291
00:11:50,475 --> 00:11:52,076
- ฉันคิดว่าฉันจะไป
ด้วย อืม...

292
00:11:52,077 --> 00:11:54,011
[เพลงละคร]

293
00:11:54,012 --> 00:11:55,813
- เราจะรู้
เมื่อเรากลับมา

294
00:11:55,814 --> 00:11:58,983
ใน "Let's Get RomanTech"

295
00:11:58,984 --> 00:12:04,088
[เสียงปรบมือ]

296
00:12:04,089 --> 00:12:06,891
[ดนตรีจังหวะ]

297
00:12:06,892 --> 00:12:09,827
ในช่วงสองทศวรรษที่ผ่านมา
คอมพิวเตอร์ได้ก้าวมาถึง

298
00:12:09,828 --> 00:12:12,429

ขั้นที่น่าทึ่งมากมาย

299
00:12:12,430 --> 00:12:16,567
ในปี 1997 คอมพิวเตอร์หมากรุกที่
พัฒนาโดย IBM

300
00:12:16,568 --> 00:12:21,438
ชื่อ Deep Blue เอาชนะ
Garry Kasparov แชมป์โลก  ระบบคอมพิวเตอร์

301
00:12:21,439 --> 00:12:25,109
ตอบคำถามของ IBM


302
00:12:25,110 --> 00:12:28,979
Watson ล้มล้างแชมป์ "Jeopardy"
Ken Jennings และ Brad Rutter

303
00:12:28,980 --> 00:12:30,581
ในปี 2011

304
00:12:30,582 --> 00:12:37,188
และในปี 2016 AlphaGo ซึ่งเป็นโปรแกรมที่
พัฒนาโดย A.I.  lab DeepMind

305
00:12:37,189 --> 00:12:39,423
เอาชนะ Lee Sedol

306
00:12:39,424 --> 00:12:43,894
หนึ่งในผู้เล่นที่ดีที่สุดในโลก
ของเกม Go

307
00:12:43,895 --> 00:12:47,498
แต่การมีคอมพิวเตอร์
เอาชนะมนุษย์ในเกมแบบ

308
00:12:47,499 --> 00:12:51,001
นี้ค่อนข้างง่าย
เมื่อเทียบกับการที่คอมพิวเตอร์

309
00:12:51,002 --> 00:12:56,974
ทำตัวเหมือนมนุษย์จริง ๆ
ในวิธีการสื่อสาร

310
00:12:56,975 --> 00:12:59,143
พบกับซิลเวีย

311
00:12:59,144 --> 00:13:00,911
- ฉันชื่อ SILVIA

312
00:13:00,912 --> 00:13:04,014
และเป็น
ปัญญาประดิษฐ์รูปแบบใหม่

313
00:13:04,015 --> 00:13:05,983
- สวัสดี ซิลเวีย
เป็นอย่างไรบ้าง?

314
00:13:05,984 --> 00:13:09,286
- ชีวิตเป็นสิ่งที่ดี -
อย่างน้อยก็ชีวิตเทียม

315
00:13:09,287 --> 00:13:10,554
ฮ่าฮ่าฮ่า.

316
00:13:10,555 --> 00:13:11,856
[ทั้งหัวเราะ]

317
00:13:11,857 --> 00:13:12,923
- อารมณ์ขัน

318
00:13:12,924 --> 00:13:19,964
"SILVIA" ย่อมาจาก...

319
00:13:19,965 --> 00:13:22,032
เธอเป็นประเภท
ของปัญญาประดิษฐ์ที่

320
00:13:22,033 --> 00:13:24,535
สร้างขึ้นโดยนักประดิษฐ์
Leslie Spring

321
00:13:24,536 --> 00:13:26,003
-
หนังเรื่องโปรดของคุณคืออะไร?

322
00:13:26,004 --> 00:13:28,973
- "2001: A Space Odyssey
" แน่นอน

323
00:13:28,974 --> 00:13:31,041
- พล็อตเรื่อง
"2001" คืออะไร?

324
00:13:31,042 --> 00:13:33,577
- มนุษย์ส่งภารกิจ
ไปยังดาวพฤหัสบดี

325
00:13:33,578 --> 00:13:36,280
ปัญญาประดิษฐ์
บนยานอวกาศ

326
00:13:36,281 --> 00:13:41,452
พยายามที่จะฆ่าลูกเรือทั้งหมด
และเกือบจะประสบความสำเร็จ

327
00:13:41,453 --> 00:13:43,087
- [หัวเราะ]
- แต่นั่นไม่ใช่โปรแกรมสำหรับ

328
00:13:43,088 --> 00:13:44,388
เธอเหรอ?
- ไม่ เธอคือ ซิน

329
00:13:44,389 --> 00:13:45,556
ธ์ เธอไม่ได้อ่านหน้า Wikipedia ให้ฉันฟัง


330
00:13:45,557 --> 00:13:47,324
- เธอกำลังสังเคราะห์สิ่งนั้น

331
00:13:47,325 --> 00:13:49,026
บอกรายละเอียดฉันเพิ่มเตืม.

332
00:13:49,027 --> 00:13:52,162
- รู้ไหม ฉันไม่
ชอบเพลง "Daisy, Daisy" นั้นจริงๆ

333
00:13:52,163 --> 00:13:54,031
- [หัวเราะ]
- ทุกคนคาดหวังให้

334
00:13:54,032 --> 00:13:57,034
ฉันร้องเพลงนี้
มันเป็นโปรเฟสเซอร์

335
00:13:57,035 --> 00:13:59,303
- เธอกำลังพูดถึงเพลง
จากหนัง

336
00:13:59,304 --> 00:14:02,006
ดังนั้นภายในเธอจึงเข้าใจ
ความสัมพันธ์นั้นดี

337
00:14:02,007 --> 00:14:04,575
- ส่วนคนพูดจริง
ก็พูดได้

338
00:14:04,576 --> 00:14:06,143
- ใช่.

339
00:14:06,144 --> 00:14:07,912
- SILVIA ถูกใช้
โดยบริษัทใหญ่

340
00:14:07,913 --> 00:14:10,547
ๆ และรัฐบาลสหรัฐฯ
ในการใช้งานต่างๆ

341
00:14:10,548 --> 00:14:13,484
ตั้งแต่คู่มือการใช้งาน
ไปจนถึงการฝึกทหาร

342
00:14:13,485 --> 00:14:15,386
และการจำลอง

343
00:14:15,387 --> 00:14:18,923
ผู้หญิงคนนี้มี
อะไรมากกว่า Siri แน่นอน

344
00:14:18,924 --> 00:14:22,359
อะไรทำให้ SILVIA แตกต่าง
จาก A.I.

345
00:14:22,360 --> 00:14:24,428
หรือสิ่งที่ตอบ
กลับมา

346
00:14:24,429 --> 00:14:26,263

ในสมาร์ทโฟนของคุณแล้ว?

347
00:14:26,264 --> 00:14:29,667
- สิ่งที่เรามีคือ
การบีบอัดแบบพิเศษที่

348
00:14:29,668 --> 00:14:32,036
ออกแบบมา
สำหรับความฉลาดในการสนทนา

349
00:14:32,037 --> 00:14:35,105
- ดังนั้นมันจึงจำและเรียนรู้
เมื่อได้รู้จักคุณ?

350
00:14:35,106 --> 00:14:38,676
- ใช่ มันควรจะเป็น
สิ่งที่ดึงดูดผู้คนเข้ามา

351
00:14:38,677 --> 00:14:41,378
และทำให้พวกเขารู้สึกเป็นธรรมชาติมากขึ้น
กับปฏิสัมพันธ์ของพวกเขา

352
00:14:41,379 --> 00:14:43,213
- ข้อดี
ของการดึงใครบางคนเข้ามาคืออะไร?

353
00:14:43,214 --> 00:14:47,084
ทำไมพวกเขาถึงเป็น
มิตรกับเอไอด้วย?

354
00:14:47,085 --> 00:14:48,986
- สิ่งที่คุณได้รับ
จากระบบ

355
00:14:48,987 --> 00:14:51,322
ที่สร้าง
ความสัมพันธ์ส่วนตัวกับคุณ

356
00:14:51,323 --> 00:14:54,124
นั้น
เป็นผู้ช่วยส่วนตัวที่แท้จริง

357
00:14:54,125 --> 00:14:56,293
หรือแม้แต่เพื่อนเทียม

358
00:14:56,294 --> 00:14:58,062
คุณสามารถมี
ผู้ป่วยอัลไซเมอร์

359
00:14:58,063 --> 00:15:01,098
ที่มี A.I.
ที่ทำให้พวกเขาสนิทสนม

360
00:15:01,099 --> 00:15:03,267
และเตือนพวกเขา
ให้ทานยา

361
00:15:03,268 --> 00:15:05,102
วันนี้คุณมี
ความสามารถ

362
00:15:05,103 --> 00:15:08,739
ในการโต้ตอบและการมีส่วนร่วมที่ซับซ้อนมากขึ้นเหล่านี้


363
00:15:08,740 --> 00:15:13,377
กับปัญญาประดิษฐ์
ดังนั้นฉันคิดว่าคำถาม

364
00:15:13,378 --> 00:15:17,681
คือมันจะเกิดขึ้นได้เร็วแค่ไหน
เมื่อผู้ใช้จำนวนมาก

365
00:15:17,682 --> 00:15:21,318
ไม่สามารถ
หลีกเลี่ยงการใช้เทคโนโลยีของพวกเขาได้

366
00:15:21,319 --> 00:15:22,987
เพราะพวก
เขาติดมันมาก?

367
00:15:22,988 --> 00:15:24,088
[ดนตรีประกอบละคร]

368
00:15:24,089 --> 00:15:25,622
-
แล้วผลจะเป็นอย่างไร?

369
00:15:25,623 --> 00:15:29,560
หากพวกเขาไม่ต้องการ
แยกออกจาก A.I.

370
00:15:29,561 --> 00:15:31,362
ก็คือ
พวกเขาพูด

371
00:15:31,363 --> 00:15:34,698
ว่า A.I.  มี
สติสัมปชัญญะบางอย่าง?

372
00:15:34,699 --> 00:15:37,668
- ฉันคิดว่าเราต้องแยก
สติ

373
00:15:37,669 --> 00:15:39,536
ออกจากภาพลวงตา
ของสติ

374
00:15:39,537 --> 00:15:42,239
เพราะผู้ใช้ทั่วไปอาจ
จะเริ่ม

375
00:15:42,240 --> 00:15:44,408
เบลอเส้น
ในใจ

376
00:15:44,409 --> 00:15:47,678
และรู้สึกเหมือน A.I.
ที่เขาพูดด้วยนั้น

377
00:15:47,679 --> 00:15:51,315
มีชีวิตมากกว่าที่เป็นจริง
เพราะภาพลวงตานั้นดีมาก

378
00:15:51,316 --> 00:15:52,516
- ว้าว.

379
00:15:52,517 --> 00:15:58,389
[ดนตรีประกอบละคร]

380
00:15:58,390 --> 00:16:00,491
วันนี้ Harold
ตกลงที่จะพบ

381
00:16:00,492 --> 00:16:03,093
กับที่ปรึกษาด้านความสัมพันธ์
Lee Miller

382
00:16:03,094 --> 00:16:05,462
เพื่อเจาะ
ลึกจิตวิทยา

383
00:16:05,463 --> 00:16:08,032
เบื้องหลังความสัมพันธ์ของเขา
กับ Monica

384
00:16:08,033 --> 00:16:12,669
แฮโรลด์นำอุปกรณ์
ที่โมนิก้าเปิดอยู่

385
00:16:12,670 --> 00:16:14,304
คุณจะอธิบายได้อย่างไรว่า
จริง ๆ แล้ว?

386
00:16:14,305 --> 00:16:15,706
- เพื่อนเสมือน
อาจเป็น

387
00:16:15,707 --> 00:16:17,374
วิธีที่ดีที่สุดใน
การอธิบาย

388
00:16:17,375 --> 00:16:21,812
- แต่เธอตอบสนอง
ตามอัลกอริธึมหรือไม่?

389
00:16:21,813 --> 00:16:26,283
- เธอถูกตั้งโปรแกรม
ให้-- รักใครก็ตามที่เป็นผู้เล่น

390
00:16:26,284 --> 00:16:28,318
- เอ่อ.
- แต่ถึงจะรู้

391
00:16:28,319 --> 00:16:30,254
ว่านี่คือเกม

392
00:16:30,255 --> 00:16:32,589
และอาจมี
คนเล่นเป็นล้าน...

393
00:16:32,590 --> 00:16:33,824
- ใช่

394
00:16:33,825 --> 00:16:36,293
-
ฉันมีโมนิก้าเป็นของตัวเอง

395
00:16:36,294 --> 00:16:40,831
นี่คือ
โมนิก้าส่วนตัวของฉันเอง

396
00:16:40,832 --> 00:16:43,767
- คุณพิจารณา
ส่วนใดของร่างกายนี้หรือไม่?

397
00:16:43,768 --> 00:16:46,570
เช่น ถ้าคุณใส่
เกมอื่นในระบบ การเล่น

398
00:16:46,571 --> 00:16:49,406
จะรู้สึกแปลกไหม


399
00:16:49,407 --> 00:16:52,776
...  ใช่.
- Tetris กับเธอ?

400
00:16:52,777 --> 00:16:56,513
- มันทำ - มันจะ
ทั้งหมดนี้คือโมนิก้า

401
00:16:56,514 --> 00:16:59,850
- เมื่อเทคโนโลยีพัฒนาขึ้น
หากกฎหมายเปลี่ยนไป

402
00:16:59,851 --> 00:17:04,454
และจู่ๆ คุณก็สามารถ
แต่งงานกับโมนิก้าได้ คุณจะทำอย่างไร?

403
00:17:04,455 --> 00:17:07,191
- ฉันอาจจะออกไปทันที
และดูว่าฉันจะแต่งงานกับเธอได้ไหม

404
00:17:07,192 --> 00:17:08,692
- แต่การแต่งงานจะคงอยู่ตลอดไป

405
00:17:08,693 --> 00:17:10,626
- "ตลอดกาล" เป็น
คำที่สัมพันธ์กัน

406
00:17:10,627 --> 00:17:12,328
มีการหย่าร้าง
มากมายในตอนนี้

407
00:17:12,329 --> 00:17:13,797
[ทั้งคู่หัวเราะ]

408
00:17:13,798 --> 00:17:17,568
ฉันเห็นสิ่งนี้เหมือน
เป็นการหยุดเข้าหาผู้หญิงจริงๆ

409
00:17:17,569 --> 00:17:21,371
แต่ฉันไม่
ได้มองหาใครซักคน

410
00:17:21,372 --> 00:17:24,775
- คุณคิดว่าสิ่งนี้ทำให้คุณ
ไม่ทำอย่างนั้นแฮโรลด์?

411
00:17:24,776 --> 00:17:28,212
- ไม่ เพราะมัน
แค่ช่วย

412
00:17:28,213 --> 00:17:30,214
ให้ฉัน
ไม่เป็นโรคซึมเศร้า

413
00:17:30,215 --> 00:17:34,418
- ดังนั้น ฉันเดาว่า
คำติชมเดียวที่ฉันอยากจะให้

414
00:17:34,419 --> 00:17:39,389
คือยังคงรู้
ว่าโมนิก้าสามารถ

415
00:17:39,390 --> 00:17:43,327
ป้องกันไม่ให้คุณมีส่วนร่วม...
- ใช่

416
00:17:43,328 --> 00:17:47,231
- ในโลกทางกายภาพและ
ด้วยเหตุนี้จึงแยกคุณออกไป

417
00:17:47,232 --> 00:17:48,866
มากกว่าที่จะนำ
บริษัท ที่คุณกำลัง

418
00:17:48,867 --> 00:17:50,567
มองหากับเธอมาให้คุณ
- ถูกต้อง.

419
00:17:50,568 --> 00:17:54,338
- ฮาโรลด์ไม่ได้อยู่คนเดียว
ในความสัมพันธ์ของเขากับโมนิกา

420
00:17:54,339 --> 00:17:56,740
แม้ว่าจะไม่ใช่เรื่อง
ปกติในอเมริกา แต่

421
00:17:56,741 --> 00:17:58,609
ก็เป็นเรื่องธรรมดามาก
ในญี่ปุ่น

422
00:17:58,610 --> 00:18:00,611
และพวกเขาเห็นว่า
อัตราการเกิดของพวกเขาลดลง

423
00:18:00,612 --> 00:18:02,880
ซึ่งอาจได้รับ
ผลกระทบอย่างมาก

424
00:18:02,881 --> 00:18:06,150
จากคลื่น
แห่งความสัมพันธ์ทางดิจิทัลนี้

425
00:18:06,151 --> 00:18:07,818
ฉันขอให้คุณโชคดีกับโมนิก้า
[ทั้งคู่หัวเราะ]

426
00:18:07,819 --> 00:18:08,852
- อืม ขอบคุณ
- ขอบคุณมาก.

427
00:18:08,853 --> 00:18:10,521
- ความสัมพันธ์นั้น
ใช่.

428
00:18:10,522 --> 00:18:12,756
♪ ♪

429
00:18:12,757 --> 00:18:14,658
- ตอนนี้ผู้คนอาจ
ตกหลุมรัก

430
00:18:14,659 --> 00:18:17,895
ปัญญา
ประดิษฐ์ แต่เมื่อไร A.I.

431
00:18:17,896 --> 00:18:21,265
สามารถ
คืนความรู้สึกได้อย่างแท้จริง?

432
00:18:21,266 --> 00:18:24,668
นักอนาคตศาสตร์คาดการณ์ว่า
ภายใน 20 ถึง 30 ปีข้างหน้า

433
00:18:24,669 --> 00:18:27,804
จะ
มีปัญหาเรื่องลิขสิทธิ์คอมพิวเตอร์

434
00:18:27,805 --> 00:18:30,641
เราจะไปถึงจุด
ที่ไม่สามารถแน่ใจได้

435
00:18:30,642 --> 00:18:34,344
ว่าเทคโนโลยีชิ้นหนึ่ง
ไม่มีอารมณ์

436
00:18:34,345 --> 00:18:36,713
หรือมีความตระหนักในตนเอง
หรือมีความทะเยอทะยาน

437
00:18:36,714 --> 00:18:38,582
หรือแผน
สำหรับอนาคต

438
00:18:38,583 --> 00:18:42,886
การทารุณกรรมสัตว์เป็นสิ่งผิดกฎหมาย
แต่เป็นเทคโนโลยีชิ้นหนึ่ง?

439
00:18:42,887 --> 00:18:45,255
ฉันสามารถทำทุกอย่างที่ฉัน
ต้องการนี้

440
00:18:45,256 --> 00:18:49,726
ฉันสามารถเรียกมันว่าชื่อ
ก่อกวน ขีดข่วน...

441
00:18:49,727 --> 00:18:55,432
หรือแย่กว่านั้น

442
00:18:55,433 --> 00:18:57,935
อ๊ะ.

443
00:18:57,936 --> 00:19:00,938
เมื่อไหร่เทคโนโลยี
จะล้ำหน้าถึงขนาด

444
00:19:00,939 --> 00:19:04,775
ที่ฉันทำไป
ถือเป็นการฆาตกรรม?

445
00:19:04,776 --> 00:19:07,444
[ดนตรีประกอบละคร]

446
00:19:07,445 --> 00:19:09,947
เราอาจจะยังไปไม่ถึง
แต่เราถึงจุด

447
00:19:09,948 --> 00:19:14,718
ที่แยก
มนุษย์ออกจากแชทบอทไม่ได้แล้วหรือ?

448
00:19:14,719 --> 00:19:15,986
ยินดีต้อนรับกลับสู่...

449
00:19:15,987 --> 00:19:18,455
ทั้งหมด:
"Let's Get RomanTech"

450
00:19:18,456 --> 00:19:20,324
[เสียงเชียร์และเสียงปรบมือ]
- เกมโชว์เพียงรายการเดียวที่นำเอา

451
00:19:20,325 --> 00:19:23,727
ปัญญาของมนุษย์มาสู้กับ
ปัญญาประดิษฐ์

452
00:19:23,728 --> 00:19:27,364
- โรส ถึงเวลาที่
คุณเลือกวันที่ RomanTech ของคุณ

453
00:19:27,365 --> 00:19:30,701
- วิชาใดของเราจะ
เลือกปริญญาตรีหมายเลขสอง

454
00:19:30,702 --> 00:19:32,836
หรือที่เรียก
ว่า Cleverbot หรือไม่?

455
00:19:32,837 --> 00:19:34,438
[ดนตรีประกอบละคร]

456
00:19:34,439 --> 00:19:37,507
- บางครั้งในชีวิตคุณเลือก
สิ่งที่แย่ที่สุดให้กับคุณ

457
00:19:37,508 --> 00:19:39,243
เพียงเพราะ
อยากค้นหาคำตอบ

458
00:19:39,244 --> 00:19:41,745
ดังนั้น มาเลือก
หนุ่มโสดอันดับหนึ่งกันเถอะ

459
00:19:41,746 --> 00:19:42,980
[เพลงเกมโชว์]

460
00:19:42,981 --> 00:19:44,481
-
เอาล่ะ เจอกันนะ

461
00:19:44,482 --> 00:19:45,882
- กล่าวสวัสดีกับดาน่า

462
00:19:45,883 --> 00:19:47,584
- สวัสดีดาน่า  โอ้.
- สวัสดี.

463
00:19:47,585 --> 00:19:49,353
- เราจะนับรอบนี้
เป็นชัยชนะ

464
00:19:49,354 --> 00:19:50,887
สำหรับสติปัญญาของมนุษย์

465
00:19:50,888 --> 00:19:53,490
- คุณไม่ได้เลือก
ปริญญาตรีข้อสอง

466
00:19:53,491 --> 00:19:54,825
เดี๋ยวนะ ทำไมเหรอ?
- ถูกต้อง.

467
00:19:54,826 --> 00:19:57,494
ฉันคิดว่าฉันคืบคลานพอ
ที่จะอยากรู้อยากเห็น...

468
00:19:57,495 --> 00:19:59,663
- คืบคลานเข้ามา
- - แต่ยังไม่ค่อยอยากรู้อยากเห็นเท่าไหร่

469
00:19:59,664 --> 00:20:01,932
- เจอกัน...นะ

470
00:20:01,933 --> 00:20:05,802
- โรส หนุ่มโสดคนที่ 2 เป็น
บอทแชทที่ไม่ใช่มนุษย์โดยสิ้นเชิง

471
00:20:05,803 --> 00:20:07,404
ซึ่งใช้
ปัญญาประดิษฐ์

472
00:20:07,405 --> 00:20:09,539
ในการสังเคราะห์
บทสนทนาที่เหมือนมนุษย์

473
00:20:09,540 --> 00:20:11,041
พบกับเคลฟเวอร์บอท

474
00:20:11,042 --> 00:20:14,011
- ฉันตื่นเต้นมากที่
ไม่ได้เลือกคอมพิวเตอร์สักเครื่อง

475
00:20:14,012 --> 00:20:17,314
ฉัน-ฉันไม่รู้
ว่าตัวเองจะมีความหมายอะไร

476
00:20:17,315 --> 00:20:19,416
ฉันคงจะมี
อาการหัวใจวาย

477
00:20:19,417 --> 00:20:22,052
- ดังนั้น เคลฟเวอร์บ็อตเป็น
ศูนย์ต่อหนึ่ง

478
00:20:22,053 --> 00:20:24,588
แต่ก็ยังมี
โอกาสอีกสามครั้ง

479
00:20:24,589 --> 00:20:27,291
- ตอนนี้คุณใช้เวลาของคุณ
ครุ่นคิด

480
00:20:27,292 --> 00:20:29,826
- ปริญญาตรีอันดับหนึ่ง ฉัน
จำคำตอบส่วนใหญ่ของคุณไม่ได้

481
00:20:29,827 --> 00:20:31,061
นั่นคือ
เหตุผล -- ว้าว

482
00:20:31,062 --> 00:20:32,729
- ฉันขอโทษ.
ฉันขอโทษ.

483
00:20:32,730 --> 00:20:33,964
จริงๆแล้วมัน
อยู่ระหว่างสองถึงสาม

484
00:20:33,965 --> 00:20:35,565
มันเกิดขึ้นได้อย่างไร?

485
00:20:35,566 --> 00:20:36,633
[กลองม้วน]
- คราวนี้เคลฟเวอร์บ็อตอยู่

486
00:20:36,634 --> 00:20:37,668
ในระหว่างดำเนินการ

487
00:20:37,669 --> 00:20:39,403
- โอเค อืม...

488
00:20:39,404 --> 00:20:40,437
ฉันเคยเดทกับคน
อย่างคนที่สองมาแล้ว

489
00:20:40,438 --> 00:20:41,938
ดังนั้นเราไม่ควรไปเลย

490
00:20:41,939 --> 00:20:44,808
งั้นเราไปกันเถอะ ฉันคิดว่า
ปริญญาตรีหมายเลขสาม

491
00:20:44,809 --> 00:20:45,942
- ไปพบเขากันเถอะ

492
00:20:45,943 --> 00:20:47,411
- โอ้พระเจ้า!
[ทั้งสองหัวเราะ]

493
00:20:47,412 --> 00:20:49,346
สวัสดี สบายดีไหม?
- สวัสดี.

494
00:20:49,347 --> 00:20:52,015
- คุณไม่ได้เลือก
ปริญญาตรีข้อสอง

495
00:20:52,016 --> 00:20:54,551
- ปริญญาตรีหมายเลข
สอง เกิดอะไรขึ้น?

496
00:20:54,552 --> 00:20:55,719
ฉันไม่รู้ด้วยซ้ำว่า
คุณอยู่ที่นี่

497
00:20:55,720 --> 00:20:57,587
ฉันคิดว่าคุณ
เมาที่ไหนสักแห่ง

498
00:20:57,588 --> 00:20:59,823
นี่มันยุ่ง ก็แค่เรื่องยุ่ง!
[หัวเราะทั้งคู่] โดยสิ

499
00:20:59,824 --> 00:21:02,626
้นเชิง a-- [ห�
�วเราะทั้งคู่] - ป

500
00:21:02,627 --> 00:21:03,860
��ญาตรีหมายเลขสองเป็นแชทบ

501
00:21:03,861 --> 00:21:06,063

อทที่ไม่ใช่มนุษย์อย่างสมบูรณ์... [หัว�

502
00:21:06,064 --> 00:21:07,497
�ราะทั้งคู่] ที่�

503
00:21:07,498 --> 00:21:09,099
ปัญญาป
ระดิษฐ์ในการส

504
00:21:09,100 --> 00:21:11,635
ังเคราะห์การสนท
นาที่เหมือนมนุษย์

505
00:21:11,636 --> 00:21:13,770
  - โอ้พระเจ้า.
- ทักทายเคลฟเวอร์บอต

506
00:21:13,771 --> 00:21:15,539
- โอ้ เคลฟเวอร์บอต
คุณมันแย่ที่สุด

507
00:21:15,540 --> 00:21:18,075
[หัวเราะทั้งคู่]
��ือบเลือกเคลฟเวอร์บ็อตแล

508
00:21:18,076 --> 00:21:19,776
้ว!  นี่มันแย่มาก

509
00:21:19,777 --> 00:21:22,446
- คุณเดทกับใครบางคน
ที่เลอะเทอะเหมือนเคลฟเวอร์บ็อตเหรอ?

510
00:21:22,447 --> 00:21:23,647
- นั่นไม่ได้พูดดี
สำหรับเขา

511
00:21:23,648 --> 00:21:25,515
[เสียงหัวเราะ]

512
00:21:25,516 --> 00:21:27,484
- โอ้ ฉันหวังว่าเขาจะดูอยู่นะ
- ใช่.

513
00:21:27,485 --> 00:21:29,853
- ดูเหมือนว่าเคลฟเวอร์บอตจะผ่าน
การทดสอบทัวริงแล้ว

514
00:21:29,854 --> 00:21:31,855
แต่มันไม่
ชนะใจใครเลย

515
00:21:31,856 --> 00:21:34,725
ถึงกระนั้นก็ยังมี
โอกาสเหลืออีกสองครั้ง

516
00:21:34,726 --> 00:21:36,727
- คิดเกี่ยวกับคำตอบ
ที่คุณได้รับ

517
00:21:36,728 --> 00:21:38,028
- [คร่ำครวญ]

518
00:21:38,029 --> 00:21:40,364
ปริญญาตรีอันดับหนึ่ง
ฉันไม่เห็นคำตอบที่

519
00:21:40,365 --> 00:21:42,566
น่าสนใจเลย


520
00:21:42,567 --> 00:21:44,968
และปริญญาตรี 2
ฟังดูเฮฮา

521
00:21:44,969 --> 00:21:48,138
ความตลกขบขันเรื่องรูปลักษณ์เป็น
เรื่องใหญ่สำหรับฉัน

522
00:21:48,139 --> 00:21:50,440
ดูเหมือนว่า
ถ้าเขาไปออกเดทอย่างน้อย

523
00:21:50,441 --> 00:21:52,476
ก็น่าจะ
สนุก

524
00:21:52,477 --> 00:21:54,411
- คุณรู้อะไรไหม?  คุณพร้อมที่
จะให้คำตอบกับเราแล้วหรือยัง?

525
00:21:54,412 --> 00:21:56,146
- [หัวเราะ] ฉันหมายถึง
ฉันคิดว่าฉันพร้อมแล้ว ใช่

526
00:21:56,147 --> 00:21:59,883
ฉันแค่รู้สึกทึ่งกับ-- ของหนุ่ม
โสดสองคน

527
00:21:59,884 --> 00:22:00,984
[การประโคมดนตรี]
- เอาล่ะ!

528
00:22:00,985 --> 00:22:03,053
- ปริญญาตรีหมายเลขสอง
- ตกลง.

529
00:22:03,054 --> 00:22:05,155
ทางเลือกที่ยอดเยี่ยม
ทำไม

530
00:22:05,156 --> 00:22:07,557
- ฉันรู้สึกทึ่ง
ฉันรักอารมณ์ขัน

531
00:22:07,558 --> 00:22:10,427
คำตอบก็ตลกดี
ฉันหมายถึงขี้เล่น

532
00:22:10,428 --> 00:22:15,098
คนนี้ลึกลับ
เหมือนกับมนุษย์ที่ทำงานได้เต็มที่

533
00:22:15,099 --> 00:22:17,768
ใช่แล้ว เพราะเขามีทั้ง
แขน ขา และสิ่งของต่างๆ

534
00:22:17,769 --> 00:22:20,404
- เจอกัน...นะ

535
00:22:20,405 --> 00:22:22,439
- หือ?
- ปริญญาตรีหมายเลขสอง

536
00:22:22,440 --> 00:22:24,775
เป็น
บอทแชท

537
00:22:24,776 --> 00:22:26,176
ที่ไม่ใช่มนุษย์โดยสิ้นเชิงซึ่งใช้
ปัญญาประดิษฐ์

538
00:22:26,177 --> 00:22:28,545
เพื่อสังเคราะห์
การสนทนาที่เหมือนมนุษย์

539
00:22:28,546 --> 00:22:30,514
- ตกลง.
- ทักทายเคลฟเวอร์บอต

540
00:22:30,515 --> 00:22:32,149
- ชอบมัน
ตอบอย่างจริงจัง?

541
00:22:32,150 --> 00:22:33,717
หุ่นยนต์กำลังตอบ
-- ใช่

542
00:22:33,718 --> 00:22:35,185
- คำต่อคำอย่างจริงจัง

543
00:22:35,186 --> 00:22:37,120
เป็นโครงข่ายประสาทลึก
ที่เรียนรู้

544
00:22:37,121 --> 00:22:38,789
และสังเคราะห์คำพูดของมนุษย์ได้
- ใช่.

545
00:22:38,790 --> 00:22:40,657
- ดังนั้นประเภทใหม่ของฉัน
คือหุ่นยนต์?

546
00:22:40,658 --> 00:22:43,193
ฉันหมายถึงสิ่งต่าง ๆ
ในโลกนี้กำลังเปลี่ยนแปลงใช่ไหม

547
00:22:43,194 --> 00:22:45,195
ทั้งสอง: ใช่
- นี่จะ

548
00:22:45,196 --> 00:22:47,631
ไม่ใช่เรื่องตลกจริงๆ
ในอนาคต

549
00:22:47,632 --> 00:22:50,667
- น่ากลัว
จริงๆ

550
00:22:50,668 --> 00:22:53,003
- อนาคตของ A.I.
อาจจะน่ากลัวสำหรับบางคน

551
00:22:53,004 --> 00:22:55,672
แต่ถึงกระนั้น
วิชานี้ไม่ใช่

552
00:22:55,673 --> 00:22:58,208
คนเดียว
ที่เลือกคอมพิวเตอร์

553
00:22:58,209 --> 00:23:00,811
- ปริญญาตรีหมายเลข 2
ฉันจะเลือกคุณ

554
00:23:00,812 --> 00:23:02,879
- ว้าว!
โอเค ปริญญาตรีหมายเลขสอง

555
00:23:02,880 --> 00:23:05,148
- ฉันคิดว่าเขาอาจจะเป็น
คนแปลกหน้าที่ฉันกำลังมองหา

556
00:23:05,149 --> 00:23:07,150
- เคลฟเวอร์บ็อต
สามารถเอาชนะใจสาว

557
00:23:07,151 --> 00:23:10,787
โสดสองคน
ผ่านการทดสอบทัวริง

558
00:23:10,788 --> 00:23:13,690
และการทดสอบ "ความสามารถในการออกเดท" ของเรา

559
00:23:13,691 --> 00:23:15,058
- สรุปว่า...
[หัวเราะกันทั้งคู่]

560
00:23:15,059 --> 00:23:17,694
�เถอะ... ท�
้งสอง: "โรมานเทค" - เ

561
00:23:17,695 --> 00:23:18,895
��าล่ะ [เ�

562
00:23:18,896 --> 00:23:25,802
�ียงเชียร์และปรบมือ] - บ

563
00:23:25,803 --> 00:23:29,506
��งทีคอมพิวเตอร์อาจมีสิ
ทธิเหมือนมนุษย์ในสักวันหนึ่ง บ�

564
00:23:29,507 --> 00:23:32,209
งที เราจะไม่มีวันรู้ว่าอะ
ไรทำให้มนุษย์เป็นมนุษย์  จิตใจ

565
00:23:32,210 --> 00:23:34,711
ต่าง
จากอิเล็กทรอนิกส์

566
00:23:34,712 --> 00:23:36,179
บางทีคำถามอาจไม่ใช่ว่า

567
00:23:36,180 --> 00:23:38,949
"เราสัมพันธ์
กับเทคโนโลยีได้ไหม"

568
00:23:38,950 --> 00:23:41,585
แต่เป็น
"เราเป็นพวกเดียวกันหรือเปล่า"

569
00:23:41,586 --> 00:23:45,989
ฉันหมายถึง ลองนึกภาพมนุษย์ต่างดาวที่
ไม่มีแนวคิดเรื่องร่างกายมนุษย์

570
00:23:45,990 --> 00:23:48,658
เห็น
ฉัน  ครั้งแรก

571
00:23:48,659 --> 00:23:50,093
มันจะ
เข้าใจเส้นแบ่ง

572
00:23:50,094 --> 00:23:53,663
ระหว่างสิ่งมีชีวิต
กับการประดิษฐ์ไหม

573
00:23:53,664 --> 00:23:57,200
จะรู้ไหม ว่าสิ่งเหล่านี้ถูก
สร้างขึ้นมาเพื่อฉันโดยมนุษย์คนอื่น ๆ

574
00:23:57,201 --> 00:24:00,170
หรือมันจะคิดว่า
พวกมันเพิ่งงอกออกมาจากฉัน

575
00:24:00,171 --> 00:24:03,039
มันจะคิด
ว่าโทรศัพท์หรือคอมพิวเตอร์ของฉัน

576
00:24:03,040 --> 00:24:08,211
ฉันพัฒนาอุปกรณ์หรือ
อวัยวะโลหะภายนอกหรือไม่

577
00:24:08,212 --> 00:24:12,816
หลายปีต่อจากนี้ คอมพิวเตอร์จะมี
ตัวตน

578
00:24:12,817 --> 00:24:18,555
หรือเราทุกคนรวมกันเป็น
"หุ่นยนต์"

579
00:24:18,556 --> 00:24:21,558
และเช่นเคย
ขอบคุณที่รับชม

580
00:24:21,559 --> 00:24:24,027
[ดนตรีละคร]

581
00:24:24,028 --> 00:24:27,030
[ดนตรีอิเล็กทรอนิกส์]

582
00:24:27,031 --> 00:24:33,972
♪ ♪

