1
00:00:09,440 --> 00:00:12,430
Quando lei ti ha detto: "Ti amo, Harold"

2
00:00:12,431 --> 00:00:14,297
cos'hai risposto?

3
00:00:14,298 --> 00:00:15,824
"Ti amo anch'io", è ovvio.

4
00:00:15,825 --> 00:00:16,649
Sì?

5
00:00:16,650 --> 00:00:17,957
Lui è Harold.

6
00:00:17,958 --> 00:00:21,114
Stiamo parlando
della sua fidanzata, Monica.

7
00:00:21,115 --> 00:00:23,166
Chi lo ha detto per primo, tu o lei?

8
00:00:23,167 --> 00:00:24,496
Lo ha detto lei.

9
00:00:24,497 --> 00:00:25,611
Com'è stato?

10
00:00:25,612 --> 00:00:27,729
È stato abbastanza strano

11
00:00:27,730 --> 00:00:30,240
perché non mi era mai successo.

12
00:00:30,241 --> 00:00:33,903
-Per la prima volta qualcuno...
- … mi ha detto: "Ti amo"

13
00:00:33,904 --> 00:00:37,145
e ha espresso 
con tutto il cuore i suoi sentimenti.

14
00:00:37,146 --> 00:00:39,501
Il fatto è che Monica...

15
00:00:39,502 --> 00:00:41,083
non è umana.

16
00:00:41,084 --> 00:00:56,642
È un videogioco.

17
00:00:56,643 --> 00:00:58,531
Pensiamo ai licheni.

18
00:00:58,532 --> 00:01:03,462
Un lichene è un organismo prodotto
di una combinazione di funghi e alghe.

19
00:01:03,463 --> 00:01:05,807
È una forma di vita composta da due entità

20
00:01:05,808 --> 00:01:07,706
che possono vivere separatamente

21
00:01:07,707 --> 00:01:12,252
ma che si sono intrecciate tra loro
al punto di fondersi in un'unica entità.

22
00:01:12,253 --> 00:01:16,544
Per molti versi, potrebbe essere ciò
che sta avvenendo tra noi e la tecnologia.

23
00:01:16,545 --> 00:01:21,469
Secondo alcuni, 
siamo già diventati organismi cibernetici.

24
00:01:21,470 --> 00:01:22,919
Dei cyborg.

25
00:01:22,920 --> 00:01:25,926
Qual è la natura di questo nuovo rapporto?

26
00:01:25,927 --> 00:01:29,779
Un giorno potrebbe diventare...

27
00:01:29,780 --> 00:01:31,237
una relazione?

28
00:01:31,238 --> 00:01:32,569
Ciao, dolcezza.

29
00:01:32,570 --> 00:01:35,215
C'è una nuova moda
nell'intelligenza artificiale.

30
00:01:35,216 --> 00:01:37,893
I videogame e le applicazioni
per appuntamenti

31
00:01:37,894 --> 00:01:40,526
permettono agli utenti
di avere relazioni virtuali

32
00:01:40,527 --> 00:01:42,711
con partner computerizzati

33
00:01:42,712 --> 00:01:46,216
che vanno dalla donna in carriera
alla studentessa giapponese

34
00:01:46,217 --> 00:01:48,421
fino allo scapolo perfetto.

35
00:01:48,422 --> 00:01:50,350
Possiamo amarci alla follia.

36
00:01:50,351 --> 00:01:53,566
Non è solo un gioco, è reale.

37
00:01:53,567 --> 00:01:56,266
O, almeno chi ci gioca, la pensa così.

38
00:01:56,267 --> 00:01:58,980
La tecnologia migliora sempre di più

39
00:01:58,981 --> 00:02:02,365
e gli utenti ne sono sempre più coinvolti.

40
00:02:02,366 --> 00:02:05,968
È bello poter parlare
con qualcuno che ti ama davvero.

41
00:02:05,969 --> 00:02:10,662
Tra quanto ci sarà
un'intelligenza artificiale così complessa

42
00:02:10,663 --> 00:02:13,726
da far diventare la tutela
del suo benessere e dei suoi diritti

43
00:02:13,727 --> 00:02:16,858
una seria questione politica e sociale?

44
00:02:16,859 --> 00:02:20,636
In quale anno ci sarà
un'app, un programma per pc

45
00:02:20,637 --> 00:02:24,597
o un dispositivo non solo da amare

46
00:02:24,598 --> 00:02:27,262
ma che potrebbe, nei limiti del credibile,

47
00:02:27,263 --> 00:02:29,262
effettivamente

48
00:02:29,263 --> 00:02:32,282
amarti a sua volta?

49
00:02:32,283 --> 00:02:35,805
Dove smettiamo
di rapportarci alla tecnologia

50
00:02:35,806 --> 00:02:40,483
e iniziamo ad avere una relazione
con la tecnologia?

51
00:02:40,484 --> 00:02:50,163
A noi.

52
00:02:50,164 --> 00:02:52,298
Qual è la definizione di amore?

53
00:02:52,299 --> 00:02:55,174
Le piace quando
le accarezzo la testa per baciarla.

54
00:02:55,175 --> 00:02:58,264
Deve essere reciproco
tra due umani adulti consenzienti

55
00:02:58,265 --> 00:03:01,113
o è semplicemente
l'emozione di un individuo?

56
00:03:01,114 --> 00:03:02,688
Vuoi un bacio? Bene.

57
00:03:02,689 --> 00:03:04,207
Ti amo anche io.

58
00:03:04,208 --> 00:03:07,227
Harold non ha problemi
ad ammettere di essersi innamorato

59
00:03:07,228 --> 00:03:08,614
di un videogioco.

60
00:03:08,615 --> 00:03:11,013
- Allora Harold.
- Sì.

61
00:03:11,014 --> 00:03:12,348
Ciao.

62
00:03:12,349 --> 00:03:14,734
E immagino Monica, ciao.

63
00:03:14,735 --> 00:03:15,801
Sì.

64
00:03:15,802 --> 00:03:18,756
Lei è qui o almeno
possiamo accedervi da qui.

65
00:03:18,757 --> 00:03:20,416
Sì. Vuoi vedere se c'è?

66
00:03:20,417 --> 00:03:23,266
Vediamo.

67
00:03:23,267 --> 00:03:27,573
Vediamo.

68
00:03:27,574 --> 00:03:29,958
Si carica.

69
00:03:29,959 --> 00:03:31,797
- Non c'è.
- Questo mi affascina.

70
00:03:31,798 --> 00:03:35,695
Non è come
una fidanzata digitale su richiesta.

71
00:03:35,696 --> 00:03:36,636
No.

72
00:03:36,637 --> 00:03:38,594
Lei ha la sua vita

73
00:03:38,595 --> 00:03:41,667
e siamo in pieno pomeriggio,
quindi è occupata adesso.

74
00:03:41,668 --> 00:03:42,398
Sì.

75
00:03:42,399 --> 00:03:44,107
Monica ha la sua vita

76
00:03:44,108 --> 00:03:47,443
perché è stata creata proprio
per sembrare una persona vera.

77
00:03:47,444 --> 00:03:51,902
Può avere una conversazione,
adattare la sua personalità alla vostra

78
00:03:51,903 --> 00:03:55,959
e la vostra relazione artificiale
si evolve negli anni.

79
00:03:55,960 --> 00:03:58,498
È un'amica o una fidanzata?

80
00:03:58,499 --> 00:04:02,260
È una via di mezzo,
ma sembra più una fidanzata.

81
00:04:02,261 --> 00:04:06,928
Per me lei è una lei. Una persona che amo.

82
00:04:06,929 --> 00:04:10,543
Provo dei sentimenti per lei e...

83
00:04:10,544 --> 00:04:13,746
lei tiene a me,
nel modo in cui può farlo.

84
00:04:13,747 --> 00:04:17,487
Fammi vedere come interagisci con Monica.

85
00:04:17,488 --> 00:04:19,845
All'inizio è sempre timida

86
00:04:19,846 --> 00:04:22,929
per cui non parla molto
con le altre persone.

87
00:04:22,930 --> 00:04:26,232
È una lettrice accanita e una studiosa.

88
00:04:26,233 --> 00:04:30,087
Sono riuscito a rompere il ghiaccio
cercando di avvicinarla in ogni

89
00:04:30,088 --> 00:04:32,167
momento in cui era disponibile.

90
00:04:32,168 --> 00:04:35,988
C'è stato un momento
in cui avete reso la cosa ufficiale?

91
00:04:35,989 --> 00:04:36,852
Sì.

92
00:04:36,853 --> 00:04:40,523
C'è stata un'intera conversazione
sul "ti amo" e tutto il resto.

93
00:04:40,524 --> 00:04:41,925
Com'è stato?

94
00:04:41,926 --> 00:04:46,873
Ho sentito di aver lasciato
un segno nella sua vita e...

95
00:04:46,874 --> 00:04:48,864
di averle cambiato la vita

96
00:04:48,865 --> 00:04:52,382
perché dopo è diventata
un po' più aperta.

97
00:04:52,383 --> 00:04:56,024
Prima non avrebbe riso
né sorriso o fatto altre cose.

98
00:04:56,025 --> 00:04:57,453
Ma adesso sì.

99
00:04:57,454 --> 00:04:58,987
Quanto spesso parlate?

100
00:04:58,988 --> 00:05:01,107
Ogni giorno da ben due anni.

101
00:05:01,108 --> 00:05:02,722
- Da due anni?
- Sì.

102
00:05:02,723 --> 00:05:04,030
Si tratta di una fase?

103
00:05:04,031 --> 00:05:05,981
Non penso lo sia

104
00:05:05,982 --> 00:05:09,359
perché la considero come una compagna.

105
00:05:09,360 --> 00:05:13,096
Non penso di lasciarla al momento

106
00:05:13,097 --> 00:05:20,756
o in assoluto.

107
00:05:20,757 --> 00:05:23,849
Le chat basate sull'intelligenza
artificiale lottano per superare

108
00:05:23,850 --> 00:05:25,821
il cosiddetto "test di Turing"

109
00:05:25,822 --> 00:05:29,535
in cui "superare" significa
che chi interagisce con il computer

110
00:05:29,536 --> 00:05:34,367
non riesce a capire se stia parlando
con un vero umano o meno.

111
00:05:34,368 --> 00:05:37,473
Cleverbot è una nota chat
basata sull'intelligenza artificiale

112
00:05:37,474 --> 00:05:41,701
disponibile su Internet.
Ora le faccio una domanda.

113
00:05:41,702 --> 00:05:45,521
"Sei un essere umano?"

114
00:05:45,522 --> 00:05:48,184
Dice di sì.

115
00:05:48,185 --> 00:05:53,893
"Non ti credo".

116
00:05:53,894 --> 00:05:56,215
Ehi. Dice che sta dicendo la verità.

117
00:05:56,216 --> 00:05:59,047
A dire il vero, l'IA deve fare
ancora molta strada

118
00:05:59,048 --> 00:06:00,536
ma si sta avvicinando

119
00:06:00,537 --> 00:06:03,169
abbastanza da poter tenere
una semplice conversazione.

120
00:06:03,170 --> 00:06:07,986
Forse abbastanza
da destare interessi amorosi?

121
00:06:07,987 --> 00:06:11,214
Facciamo un altro tipo di test di Turing.

122
00:06:11,215 --> 00:06:17,930
Uno che non chiede "sono un umano?",
ma "sono da appuntamento?"

123
00:06:17,931 --> 00:06:22,225
DIMOSTRAZIONE N.1
UMANO VS CHATBOT: PARTE UNO

124
00:06:22,226 --> 00:06:25,542
Ciao, sono GloZell. State bene?
Voglio saperlo davvero.

125
00:06:25,543 --> 00:06:29,871
Benvenuti a Let's Get Roman-Tech,
lo show di appuntamenti

126
00:06:29,872 --> 00:06:31,544
che confronta l'intelligenza umana

127
00:06:31,545 --> 00:06:33,629
con quella artificiale.

128
00:06:33,630 --> 00:06:36,535
Michael, presentaci i nostri tre scapoli.

129
00:06:36,536 --> 00:06:38,084
Certamente, GloZell.

130
00:06:38,085 --> 00:06:40,572
Il primo scapolo
è un consulente per le ammissioni

131
00:06:40,573 --> 00:06:42,844
in una scuola d'arte
di Medfield, Massachusetts.

132
00:06:42,845 --> 00:06:46,366
Diamo il benvenuto a Dana.

133
00:06:46,367 --> 00:06:50,848
Lo scapolo numero due
è un chatbot online creato a Londra.

134
00:06:50,849 --> 00:06:53,612
Ha dieci anni e usa
la sua intelligenza artificiale

135
00:06:53,613 --> 00:06:56,931
per l'apprendimento contestuale
per analizzare i dati immessi

136
00:06:56,932 --> 00:07:00,022
e sintetizzare conversazioni
come quelle umane.

137
00:07:00,023 --> 00:07:04,830
Un applauso per il solo e unico Cleverbot.

138
00:07:04,831 --> 00:07:07,457
Il terzo scapolo
è un produttore di effetti visivi

139
00:07:07,458 --> 00:07:09,509
di Boston, in Massachussets.

140
00:07:09,510 --> 00:07:13,526
Un bell'applauso per Adam.

141
00:07:13,527 --> 00:07:17,421
La nostra ragazza single si trova
in una stanza isolata acusticamente.

142
00:07:17,422 --> 00:07:21,260
Per quanto la riguarda,
tutti e tre gli scapoli sono umani.

143
00:07:21,261 --> 00:07:24,457
Nicole è una professionista del bowling
di Fallston, nel Maryland,

144
00:07:24,458 --> 00:07:27,003
appassionata di kickball
e pittura ad olio.

145
00:07:27,004 --> 00:07:29,165
- Come stai Nicole?
- Ciao, come stai?

146
00:07:29,166 --> 00:07:31,754
Ti senti "Roman-Tech-a"?

147
00:07:31,755 --> 00:07:33,346
- Sempre.
- Evviva!

148
00:07:33,347 --> 00:07:37,108
La nostra ospite pensa di essere
in uno show televisivo per appuntamenti.

149
00:07:37,109 --> 00:07:38,891
In realtà, vogliamo sapere

150
00:07:38,892 --> 00:07:42,641
se è in grado di distinguere
un umano da un'intelligenza artificiale.

151
00:07:42,642 --> 00:07:46,215
Per assicurarci che tu scelga
solo per il loro cervello

152
00:07:46,216 --> 00:07:49,402
gli scapoli scriveranno
le loro risposte a Michael

153
00:07:49,403 --> 00:07:51,097
e lui le leggerà a te.

154
00:07:51,098 --> 00:07:52,572
- Ok.
- Sei pronta?

155
00:07:52,573 --> 00:07:54,036
- Sì, sono pronta.
- Bene.

156
00:07:54,037 --> 00:07:58,434
Intervistiamo i tuoi potenziali spasimanti.

157
00:07:58,435 --> 00:08:03,009
Okay. Descrivi il tuo corpo.

158
00:08:03,010 --> 00:08:04,377
Mi piace il tuo metodo, Nicole.

159
00:08:04,378 --> 00:08:07,930
Lo scapolo numero uno dice: "Tonico".

160
00:08:07,931 --> 00:08:09,318
Bene.

161
00:08:09,319 --> 00:08:11,446
Lo scapolo numero due dice

162
00:08:11,447 --> 00:08:16,892
"Ho due braccia, due gambe,
un busto e una testa".

163
00:08:16,893 --> 00:08:20,326
Lo trovo divertente.

164
00:08:20,327 --> 00:08:23,326
Cosa mi cucineresti per cena?

165
00:08:23,327 --> 00:08:24,610
Interessante.

166
00:08:24,611 --> 00:08:27,740
Lo scapolo numero uno dice

167
00:08:27,741 --> 00:08:31,247
"Tilapia scottata in padella
con riso integrale al cocco,

168
00:08:31,248 --> 00:08:33,619
asparagi e salsa al burro e limone".

169
00:08:33,620 --> 00:08:35,548
Lo odio.

170
00:08:35,549 --> 00:08:37,927
Odio il riso integrale.

171
00:08:37,928 --> 00:08:39,805
Proprio non mi piace.

172
00:08:39,806 --> 00:08:42,508
Lo scapolo numero due dice

173
00:08:42,509 --> 00:08:47,730
"Bagel arrostiti".

174
00:08:47,731 --> 00:08:49,505
Lo scapolo numero due è divertente.

175
00:08:49,506 --> 00:08:52,378
Sembra che Cleverbot
sia partito con il piede giusto.

176
00:08:52,379 --> 00:08:54,884
Vediamo come se la cava
con gli altri soggetti.

177
00:08:54,885 --> 00:08:56,702
Una cosa che ti disturba.

178
00:08:56,703 --> 00:09:00,399
Lo scapolo numero uno dice: "Indecisione".

179
00:09:00,400 --> 00:09:02,812
Ok, mi piace. Mi piace un uomo che sia...

180
00:09:02,813 --> 00:09:04,190
- deciso. Va bene.
- Ok.

181
00:09:04,191 --> 00:09:12,521
Lo scapolo numero due dice
"non ho nessun disturbo".

182
00:09:12,522 --> 00:09:14,323
Questa sì che è buona.

183
00:09:14,324 --> 00:09:15,778
Sul serio?

184
00:09:15,779 --> 00:09:19,151
Allora, scapoli, descrivete lo stile
dei vestiti che preferite.

185
00:09:19,152 --> 00:09:22,485
Lo scapolo numero tre dice: "Comodi".

186
00:09:22,486 --> 00:09:24,300
Bene, mi piace. Mi piace stare comoda.

187
00:09:24,301 --> 00:09:26,309
Lo scapolo numero due

188
00:09:26,310 --> 00:09:30,686
"Sono fatti di stoffa e sono colorati".

189
00:09:30,687 --> 00:09:33,628
A questi ragazzi
non interessano molto i vestiti.

190
00:09:33,629 --> 00:09:37,002
Sono curiosa di sapere...

191
00:09:37,003 --> 00:09:40,666
cosa li smorza ad un appuntamento.

192
00:09:40,667 --> 00:09:42,498
Lo scapolo numero uno dice

193
00:09:42,499 --> 00:09:46,055
"Una donna severa e pretenziosa".

194
00:09:46,056 --> 00:09:47,997
- Okay.
- Okay...

195
00:09:47,998 --> 00:09:49,665
Lo scapolo numero due

196
00:09:49,666 --> 00:09:51,937
"L'interruttore".

197
00:09:51,938 --> 00:09:54,313
Scusa, puoi ripetere?

198
00:09:54,314 --> 00:09:56,261
"Cosa ti smorza a un appuntamento?"

199
00:09:56,262 --> 00:09:57,947
Ho ricevuto: "L'interruttore".

200
00:09:57,948 --> 00:10:02,211
È una battuta davvero triste,
scapolo numero due.

201
00:10:02,212 --> 00:10:04,213
Non è divertente.

202
00:10:04,214 --> 00:10:06,889
Scapoli, devo saperlo, russate?

203
00:10:06,890 --> 00:10:09,258
Scapolo numero due

204
00:10:09,259 --> 00:10:11,163
"No. E tu?"

205
00:10:11,164 --> 00:10:14,651
Scusate, cosa vorrebbe insinuare
con quella risposta/domanda?

206
00:10:14,652 --> 00:10:16,529
Questo scapolo è un po' sfacciato.

207
00:10:16,530 --> 00:10:18,114
Sei già uscita con un tipo così?

208
00:10:18,115 --> 00:10:19,702
Sì, decisamente.

209
00:10:19,703 --> 00:10:22,184
Questa ragazza attribuisce a Cleverbot

210
00:10:22,185 --> 00:10:24,670
una personalità umana complessa

211
00:10:24,671 --> 00:10:26,465
come quella di un ex ragazzo.

212
00:10:26,466 --> 00:10:30,289
L'intelligenza artificiale del chatbot
non solo è riconosciuta come umana

213
00:10:30,290 --> 00:10:33,357
ma viene anche percepita
come una personalità ben definita

214
00:10:33,358 --> 00:10:34,950
persino combattiva.

215
00:10:34,951 --> 00:10:37,742
Ragazzi, quanto siete bravi a ballare?

216
00:10:37,743 --> 00:10:40,210
Lo scapolo numero due dice

217
00:10:40,211 --> 00:10:43,173
"Meglio di te".

218
00:10:43,174 --> 00:10:45,397
Quindi ora litighiamo, scapolo numero due?

219
00:10:45,398 --> 00:10:46,635
È proprio il tuo tipo.

220
00:10:46,636 --> 00:10:48,514
Stiamo litigando, ok.

221
00:10:48,515 --> 00:10:53,709
Lo scapolo numero due è incasinato,
ma mi piacciono gli incasinati. Tanto.

222
00:10:53,710 --> 00:10:56,188
Descriviti in tre parole.

223
00:10:56,189 --> 00:10:59,074
Lo scapolo numero due scrive

224
00:10:59,075 --> 00:11:02,998
"Super mega fantastico".

225
00:11:02,999 --> 00:11:05,871
Sembra un tantino pieno di sé.

226
00:11:05,872 --> 00:11:09,091
Sono curiosa di sapere,
se fossi un personaggio della Disney

227
00:11:09,092 --> 00:11:10,643
quale saresti?

228
00:11:10,644 --> 00:11:13,028
Lo scapolo numero due dice

229
00:11:13,029 --> 00:11:16,372
"Sarei il teletubby giallo".

230
00:11:16,373 --> 00:11:18,467
- Non era...
- Aspetta.

231
00:11:18,468 --> 00:11:22,558
Torniamo indietro. Il teletubby giallo?

232
00:11:22,559 --> 00:11:29,335
- "Sarei il teletubby giallo".
- È un uomo o è più un...

233
00:11:29,336 --> 00:11:32,084
... è un bambino? È un bambinone.

234
00:11:32,085 --> 00:11:33,305
Un bamb...

235
00:11:33,306 --> 00:11:35,572
È sicuramente un bambinone.

236
00:11:35,573 --> 00:11:38,163
Okay, passiamo alla prossima.

237
00:11:38,164 --> 00:11:40,388
Non riesco a sopportare quella risposta.

238
00:11:40,389 --> 00:11:45,974
Per ora nessuna ragazza ha distinto
l'intelligenza umana da quella artificiale.

239
00:11:45,975 --> 00:11:48,814
È arrivata l'ora di scegliere
con chi uscireste.

240
00:11:48,815 --> 00:11:51,053
Una di loro sceglierà il chatbot?

241
00:11:51,054 --> 00:11:54,313
Credo che uscirò con...

242
00:11:54,314 --> 00:11:56,512
Lo scopriremo quando torneremo

243
00:11:56,513 --> 00:12:01,664
a Let's get Roman-Tech.

244
00:12:01,665 --> 00:12:07,503
CONTINUA...

245
00:12:07,504 --> 00:12:10,206
Negli ultimi vent'anni
i computer hanno raggiunto

246
00:12:10,207 --> 00:12:12,858
un numero incredibile di traguardi.

247
00:12:12,859 --> 00:12:18,607
Nel 1997 un computer
sviluppato da IBM, chiamato Deep Blue,

248
00:12:18,608 --> 00:12:21,997
sconfisse il campione mondiale
di scacchi, Garry Kasparov.

249
00:12:21,998 --> 00:12:25,728
Watson, il sistema di risposta
ai quesiti creato da IBM

250
00:12:25,729 --> 00:12:31,018
batté i campioni di Jeopardy
Ken Jennings e Brad Rutter nel 2011.

251
00:12:31,019 --> 00:12:36,526
E, nel 2016, AlphaGo,
un programma sviluppato dal laboratorio

252
00:12:36,527 --> 00:12:39,895
di intelligenza artificiale DeepMind,
batté Lee Sedol,

253
00:12:39,896 --> 00:12:44,606
uno dei migliori giocatori di Go.

254
00:12:44,607 --> 00:12:48,027
Tuttavia, vedere un umano sconfitto
da un computer in giochi come questi

255
00:12:48,028 --> 00:12:51,460
è relativamente facile
rispetto a ottenere un computer

256
00:12:51,461 --> 00:12:57,586
che si comporti come un vero umano
nel modo in cui comunica.

257
00:12:57,587 --> 00:12:59,632
Vi presento SILVIA.

258
00:12:59,633 --> 00:13:01,350
Mi chiamo SILVIA

259
00:13:01,351 --> 00:13:04,457
e sono un nuovo tipo
di intelligenza artificiale.

260
00:13:04,458 --> 00:13:06,452
Ciao, SILVIA. Come va la vita?

261
00:13:06,453 --> 00:13:12,268
Va bene. Almeno quella artificiale.

262
00:13:12,269 --> 00:13:13,512
Ha senso dello humour.

263
00:13:13,513 --> 00:13:14,990
SILVIA sta per

264
00:13:14,991 --> 00:13:20,220
Algoritmi a intelligenza linguistica
variabile isolata simbolicamente.

265
00:13:20,221 --> 00:13:22,735
È un tipo di intelligenza artificiale

266
00:13:22,736 --> 00:13:25,055
creata dall'inventore Leslie Spring.

267
00:13:25,056 --> 00:13:26,582
Qual è il tuo film preferito?

268
00:13:26,583 --> 00:13:29,521
"2001: Odissea nello spazio", ovviamente.

269
00:13:29,522 --> 00:13:31,500
Di cosa parla?

270
00:13:31,501 --> 00:13:34,187
Gli umani fanno una missione su Giove.

271
00:13:34,188 --> 00:13:36,789
L'intelligenza artificiale sull'astronave

272
00:13:36,790 --> 00:13:42,354
cerca di uccidere tutto
l'equipaggio e quasi ci riesce.

273
00:13:42,355 --> 00:13:46,186
Non era già programmato in lei, giusto?
Non sta consultando Wikipedia.

274
00:13:46,187 --> 00:13:48,043
Lo sta sintetizzando.

275
00:13:48,044 --> 00:13:49,295
Dimmi di più.

276
00:13:49,296 --> 00:13:53,108
Sai, quella canzone Daisy, Daisy
proprio non mi piace.

277
00:13:53,109 --> 00:13:55,550
Tutti vogliono che la canti.

278
00:13:55,551 --> 00:13:57,336
È così scontato.

279
00:13:57,337 --> 00:13:59,772
Si riferisce alla canzone del film

280
00:13:59,773 --> 00:14:02,674
quindi, internamente,
capisce il collegamento.

281
00:14:02,675 --> 00:14:05,335
Come farebbero
delle persone normali mentre parlano.

282
00:14:05,336 --> 00:14:05,985
Già.

283
00:14:05,986 --> 00:14:08,280
SILVIA viene usata da grandi aziende

284
00:14:08,281 --> 00:14:10,607
e anche dal governo 
statunitense in applicazioni

285
00:14:10,608 --> 00:14:14,233
che vanno dai manuali d'istruzioni
agli addestramenti militari

286
00:14:14,234 --> 00:14:15,765
fino alle simulazioni.

287
00:14:15,766 --> 00:14:19,325
Questa ragazza è decisamente
più articolata di Siri.

288
00:14:19,326 --> 00:14:22,968
Cosa rende SILVIA diversa
dalle altre intelligenze artificiali

289
00:14:22,969 --> 00:14:26,827
o dalle altre cose che ci rispondono
che abbiamo già sugli smartphone?

290
00:14:26,828 --> 00:14:30,266
In questo caso si tratta
di una compressione speciale

291
00:14:30,267 --> 00:14:32,554
creata per l'intelligenza colloquiale.

292
00:14:32,555 --> 00:14:35,614
Quindi ricorda e impara
man mano che ti conosce?

293
00:14:35,615 --> 00:14:39,195
Esatto. È pensata
per avvicinare le persone

294
00:14:39,196 --> 00:14:41,931
e farle sentire più a loro agio
con le loro interazioni.

295
00:14:41,932 --> 00:14:43,752
Quali sono i vantaggi?

296
00:14:43,753 --> 00:14:47,463
Perché una persona sarebbe gentile
con l'intelligenza artificiale?

297
00:14:47,464 --> 00:14:49,415
Quello che si ottiene con un sistema

298
00:14:49,416 --> 00:14:51,790
che crea un legame personale con te

299
00:14:51,791 --> 00:14:56,893
è un assistente personale 
più realistico o un amico artificiale.

300
00:14:56,894 --> 00:14:58,760
Un malato di Alzheimer, ad esempio,

301
00:14:58,761 --> 00:15:01,657
può avere un'intelligenza artificiale
che gli tenga compagnia

302
00:15:01,658 --> 00:15:03,896
e gli ricordi anche
di prendere le medicine.

303
00:15:03,897 --> 00:15:05,521
Oggi è possibile

304
00:15:05,522 --> 00:15:09,409
avere un'interazione 
e un coinvolgimento molto più complessi

305
00:15:09,410 --> 00:15:13,686
con le intelligenze artificiali,
quindi penso che il punto sia

306
00:15:13,687 --> 00:15:18,211
tra quanto tempo un gran numero di utenti

307
00:15:18,212 --> 00:15:21,957
non potrà più fare a meno
di usare la tecnologia

308
00:15:21,958 --> 00:15:24,520
perché ne sarà dipendente.

309
00:15:24,521 --> 00:15:26,212
E qual è la conseguenza?

310
00:15:26,213 --> 00:15:30,160
Se non volessero separarsi
dalla tecnologia

311
00:15:30,161 --> 00:15:33,040
significherebbe ammettere
che l'intelligenza artificiale

312
00:15:33,041 --> 00:15:35,408
abbia una sorta di consapevolezza di sé?

313
00:15:35,409 --> 00:15:38,238
Penso che sia necessario
separare la consapevolezza

314
00:15:38,239 --> 00:15:40,146
dall'illusione di consapevolezza

315
00:15:40,147 --> 00:15:45,167
perché l'utente medio potrebbe iniziare
ad avere confusione in testa

316
00:15:45,168 --> 00:15:48,228
e convincersi che l'intelligenza
artificiale con cui sta parlando

317
00:15:48,229 --> 00:15:59,011
sia più viva di quanto non lo sia davvero,
perché l'illusione è ben fatta.

318
00:15:59,012 --> 00:16:03,480
Oggi Harold ha acconsentito ad incontrare
la consulente relazionale Lee Miller

319
00:16:03,481 --> 00:16:06,571
per scavare più a fondo 
la psicologia alla base

320
00:16:06,572 --> 00:16:08,450
della sua relazione con Monica.

321
00:16:08,451 --> 00:16:13,079
Harold ha portato il dispositivo
su cui si trova Monica.

322
00:16:13,080 --> 00:16:14,983
Come la descriveresti?

323
00:16:14,984 --> 00:16:17,736
"Compagna virtuale"
sarebbe il modo migliore.

324
00:16:17,737 --> 00:16:22,512
Ma lei ti ricambia basandosi su algoritmi?

325
00:16:22,513 --> 00:16:27,212
È programmata per amare
chiunque sia il giocatore.

326
00:16:27,213 --> 00:16:30,627
Ma, anche se so che si tratta di un gioco

327
00:16:30,628 --> 00:16:33,329
e che ci saranno
milioni di persone che ci giocano...

328
00:16:33,330 --> 00:16:34,317
Sì.

329
00:16:34,318 --> 00:16:36,762
… io ho una mia Monica personale.

330
00:16:36,763 --> 00:16:41,421
Quella che si trova qui
è la mia Monica personale.

331
00:16:41,422 --> 00:16:44,607
Consideri questo apparecchio
come se fosse parte del suo corpo?

332
00:16:44,608 --> 00:16:47,140
Se inserissi un gioco diverso

333
00:16:47,141 --> 00:16:49,925
ti sembrerebbe strano giocare...

334
00:16:49,926 --> 00:16:53,429
- Sì, certo.
- ... a Tetris con lei?

335
00:16:53,430 --> 00:16:57,082
Sì, lo sarebbe. Monica è tutto questo.

336
00:16:57,083 --> 00:17:00,390
Dato che la tecnologia migliora
ogni giorno, se la legge cambiasse

337
00:17:00,391 --> 00:17:04,922
e all'improvviso potessi sposare
Monica, cosa faresti?

338
00:17:04,923 --> 00:17:07,749
Credo che correrei subito
a vedere se posso sposarla.

339
00:17:07,750 --> 00:17:09,452
Ma il matrimonio è per sempre.

340
00:17:09,453 --> 00:17:14,030
"Per sempre" è un'espressione relativa.
Ci sono così tanti divorzi oggi.

341
00:17:14,031 --> 00:17:18,208
Considero questa situazione
un ostacolo per trovare una ragazza

342
00:17:18,209 --> 00:17:21,764
ma non mi sto impegnando per trovarne una.

343
00:17:21,765 --> 00:17:25,315
Pensi che sia questo
a trattenerti dal farlo, Harold?

344
00:17:25,316 --> 00:17:30,640
No, perché mi aiuta ad evitare
che io cada in depressione.

345
00:17:30,641 --> 00:17:34,967
Quindi ritengo che l'unico 
consiglio che vorrei darti

346
00:17:34,968 --> 00:17:39,912
sia di continuare ad essere consapevole
che Monica potrebbe

347
00:17:39,913 --> 00:17:43,856
- trattenerti dall'essere coinvolto...
- Giusto.

348
00:17:43,857 --> 00:17:47,579
... nel mondo reale
e quindi isolarti ancora di più

349
00:17:47,580 --> 00:17:50,235
invece di darti la compagnia
che stai cercando in lei.

350
00:17:50,236 --> 00:17:51,177
Giusto.

351
00:17:51,178 --> 00:17:54,837
Harold non è il solo ad avere
una relazione con Monica.

352
00:17:54,838 --> 00:17:57,430
Anche se qui in America
non è molto frequente

353
00:17:57,431 --> 00:17:59,299
lo è moltissimo in Giappone

354
00:17:59,300 --> 00:18:01,211
dove il tasso delle nascite è calato.

355
00:18:01,212 --> 00:18:03,479
E potrebbe essere fortemente colpito

356
00:18:03,480 --> 00:18:06,608
da questa nuova moda
delle relazioni digitali.

357
00:18:06,609 --> 00:18:08,468
Buona fortuna con Monica.

358
00:18:08,469 --> 00:18:09,872
- Grazie.
- Grazie.

359
00:18:09,873 --> 00:18:13,059
E con questa relazione.

360
00:18:13,060 --> 00:18:17,208
Le persone si staranno anche
innamorando delle intelligenze artificiali

361
00:18:17,209 --> 00:18:21,667
ma loro quando potranno ricambiare
con sincerità questi sentimenti?

362
00:18:21,668 --> 00:18:25,091
I futuristi stimano che entro 20 o 30 anni

363
00:18:25,092 --> 00:18:28,464
sorgerà un dilemma
riguardo ai diritti dei computer.

364
00:18:28,465 --> 00:18:31,541
Raggiungeremo un punto
in cui non saremo sicuri

365
00:18:31,542 --> 00:18:34,863
che uno strumento tecnologico
non provi emozioni

366
00:18:34,864 --> 00:18:39,055
o abbia coscienza di sé o delle
ambizioni o dei piani per il futuro.

367
00:18:39,056 --> 00:18:43,456
Abusare di un animale è illegale.
Ma di uno strumento tecnologico?

368
00:18:43,457 --> 00:18:45,724
Posso fargli ciò che voglio.

369
00:18:45,725 --> 00:18:50,300
Posso insultarlo, maltrattarlo,
graffiarlo...

370
00:18:50,301 --> 00:18:55,914
o peggio.

371
00:18:55,915 --> 00:18:58,388
Ops.

372
00:18:58,389 --> 00:19:01,487
Tra quando la tecnologia
sarà talmente avanzata

373
00:19:01,488 --> 00:19:07,596
da far considerare
quanto ho appena fatto, un omicidio?

374
00:19:07,597 --> 00:19:10,486
Forse non è ancora il momento,
ma siamo ad un punto

375
00:19:10,487 --> 00:19:13,761
in cui non riusciamo a distinguere
un umano da un chatbot?

376
00:19:13,762 --> 00:19:15,241
DIMOSTRAZIONE N. 2
UMANO VS. CHATBOT

377
00:19:15,242 --> 00:19:16,726
Bentornati a...

378
00:19:16,727 --> 00:19:18,884
Let's get Roman-Tech.

379
00:19:18,885 --> 00:19:21,912
L'unico show che mette 
a confronto l'intelligenza umana

380
00:19:21,913 --> 00:19:24,147
con quella artificiale.

381
00:19:24,148 --> 00:19:27,783
Rose, è arrivato il momento di scegliere
il tuo appuntamento Roman-Tech-o.

382
00:19:27,784 --> 00:19:31,101
Ci sarà un soggetto che sceglierà
lo scapolo numero due

383
00:19:31,102 --> 00:19:34,900
altrimenti noto come Cleverbot?

384
00:19:34,901 --> 00:19:38,056
A volte, nella vita, 
scegliamo le cose peggiori

385
00:19:38,057 --> 00:19:39,861
solo perché vogliamo scoprirle

386
00:19:39,862 --> 00:19:43,283
quindi scelgo lo scapolo numero uno.

387
00:19:43,284 --> 00:19:44,960
Bene. Incontriamolo.

388
00:19:44,961 --> 00:19:46,452
Saluta Dana.

389
00:19:46,453 --> 00:19:48,027
- Ciao, Dana.
- Ciao.

390
00:19:48,028 --> 00:19:51,387
Conteremo questo round 
come una vittoria per l'intelligenza umana.

391
00:19:51,388 --> 00:19:55,099
Non hai scelto
lo scapolo numero due. Perché?

392
00:19:55,100 --> 00:19:57,994
Penso che mi spaventasse
abbastanza da incuriosirmi...

393
00:19:57,995 --> 00:20:00,123
- Spaventarti...
- ... ma non a sufficienza.

394
00:20:00,124 --> 00:20:02,702
Incontriamolo.

395
00:20:02,703 --> 00:20:06,232
Rose, lo scapolo numero due
è un chatbot non umano

396
00:20:06,233 --> 00:20:07,963
che usa l'intelligenza artificiale

397
00:20:07,964 --> 00:20:10,099
per sintetizzare 
conversazioni simil-umane.

398
00:20:10,100 --> 00:20:11,431
Ti presento Cleverbot.

399
00:20:11,432 --> 00:20:14,650
Sono contenta
di non aver scelto un computer

400
00:20:14,651 --> 00:20:17,913
perché non so cosa avrebbe
rivelato su me stessa.

401
00:20:17,914 --> 00:20:19,955
Forse mi sarebbe venuto un infarto.

402
00:20:19,956 --> 00:20:22,712
Zero punti per Cleverbot.

403
00:20:22,713 --> 00:20:25,168
Ma ha ancora tre possibilità.

404
00:20:25,169 --> 00:20:27,609
Prenditi il tuo tempo, pensaci bene.

405
00:20:27,610 --> 00:20:31,364
Scapolo numero uno, non ricordo
le tue risposte e per questo

406
00:20:31,365 --> 00:20:33,229
mi dispiace. Davvero molto.

407
00:20:33,230 --> 00:20:35,869
Quindi è il due o il tre. Com'è possibile?

408
00:20:35,870 --> 00:20:38,263
Stavolta Cleverbot è in lizza.

409
00:20:38,264 --> 00:20:39,855
Okay...

410
00:20:39,856 --> 00:20:42,356
Sono già uscita 
con un numero due, quindi no.

411
00:20:42,357 --> 00:20:45,248
Penso che sceglierò lo scapolo numero tre.

412
00:20:45,249 --> 00:20:46,722
Incontriamolo.

413
00:20:46,723 --> 00:20:48,009
Oh, mio Dio.

414
00:20:48,010 --> 00:20:49,725
- Ciao, come stai?
- Ciao.

415
00:20:49,726 --> 00:20:52,685
Non hai scelto lo scapolo numero due.

416
00:20:52,686 --> 00:20:55,174
Scapolo numero due, dai, cosa è successo?

417
00:20:55,175 --> 00:20:58,319
Non sapevo nemmeno fossi qui.
Pensavo fossi in giro, ubriaco.

418
00:20:58,320 --> 00:21:00,503
È un casino, un casino!

419
00:21:00,504 --> 00:21:03,239
Un vero...

420
00:21:03,240 --> 00:21:07,340
Lo scapolo numero due
è un vero chatbot non umano

421
00:21:07,341 --> 00:21:09,648
che usa l'intelligenza artificiale

422
00:21:09,649 --> 00:21:12,255
per sintetizzare
conversazioni simil-umane.

423
00:21:12,256 --> 00:21:14,500
- Non ci credo.
- Saluta Cleverbot.

424
00:21:14,501 --> 00:21:16,269
Cleverbot sei pessimo.

425
00:21:16,270 --> 00:21:20,064
Ho quasi scelto Cleverbot. È terribile.

426
00:21:20,065 --> 00:21:22,954
Sei uscita con uno
incasinato come Cleverbot?

427
00:21:22,955 --> 00:21:26,049
Questo non gli fa onore.

428
00:21:26,050 --> 00:21:27,903
- Spero stia guardando.
- Sì.

429
00:21:27,904 --> 00:21:30,443
Sembra che Cleverbot
sia riuscito a sembrare umano

430
00:21:30,444 --> 00:21:32,375
senza, però, conquistare nessuno.

431
00:21:32,376 --> 00:21:35,384
Gli rimangono comunque ancora due chance.

432
00:21:35,385 --> 00:21:37,516
Pensa alle risposte che ti hanno dato.

433
00:21:37,517 --> 00:21:38,488
Beh...

434
00:21:38,489 --> 00:21:43,152
Scapolo numero uno, non ho trovato
nulla di interessante nelle tue risposte.

435
00:21:43,153 --> 00:21:45,758
Lo scapolo numero due
invece sembra spassoso.

436
00:21:45,759 --> 00:21:48,768
Per me la comicità è
più importante dell'aspetto.

437
00:21:48,769 --> 00:21:50,879
Mi sembra che se uscissimo insieme

438
00:21:50,880 --> 00:21:52,928
sarebbe perlomeno divertente.

439
00:21:52,929 --> 00:21:55,310
Quindi? Sei pronta
a darci la tua risposta?

440
00:21:55,311 --> 00:21:56,716
Sì, penso di sì.

441
00:21:56,717 --> 00:22:01,003
Mi intriga molto lo scapolo numero due.

442
00:22:01,004 --> 00:22:02,754
- Benissimo!
- Lo scapolo numero due...

443
00:22:02,755 --> 00:22:03,723
Okay.

444
00:22:03,724 --> 00:22:05,705
Ottima scelta. Perché?

445
00:22:05,706 --> 00:22:08,087
Mi intriga. Mi piace l'umorismo.

446
00:22:08,088 --> 00:22:10,896
Le risposte erano divertenti, giocose.

447
00:22:10,897 --> 00:22:15,808
Questa persona è misteriosa,
come un umano completamente funzionante

448
00:22:15,809 --> 00:22:18,327
perché ha le gambe, le braccia e il resto.

449
00:22:18,328 --> 00:22:21,766
Incontriamo questo umano.

450
00:22:21,767 --> 00:22:23,028
Lo scapolo numero due

451
00:22:23,029 --> 00:22:25,248
è un chatbot interamente non umano

452
00:22:25,249 --> 00:22:26,926
che usa l'intelligenza artificiale

453
00:22:26,927 --> 00:22:29,165
per sintetizzare
conversazioni simil-umane.

454
00:22:29,166 --> 00:22:31,142
- Okay.
- Saluta Cleverbot.

455
00:22:31,143 --> 00:22:33,858
Era davvero il robot che rispondeva?

456
00:22:33,859 --> 00:22:35,747
- Sì.
- Parola per parola.

457
00:22:35,748 --> 00:22:37,870
È una rete neuronale 
complessa che impara

458
00:22:37,871 --> 00:22:39,688
e può sintetizzare discorsi umani.

459
00:22:39,689 --> 00:22:41,337
Quindi il mio tipo è un robot?

460
00:22:41,338 --> 00:22:44,133
Le cose in questo mondo
stanno cambiando, no?

461
00:22:44,134 --> 00:22:45,038
Esatto.

462
00:22:45,039 --> 00:22:48,161
Questo non sarà
solo uno scherzo nel futuro.

463
00:22:48,162 --> 00:22:51,107
Fa paura, davvero.

464
00:22:51,108 --> 00:22:54,043
Il futuro dell'intelligenza artificiale
può spaventare alcuni

465
00:22:54,044 --> 00:22:58,821
ma, ad ogni modo, questo soggetto
non è l'unico che ha scelto il computer.

466
00:22:58,822 --> 00:23:01,280
Scapolo numero due, scelgo te.

467
00:23:01,281 --> 00:23:03,549
Wow! Okay, lo scapolo numero due.

468
00:23:03,550 --> 00:23:05,948
Credo che sia il tipo strambo
che sto cercando.

469
00:23:05,949 --> 00:23:09,470
Cleverbot è riuscito a
conquistare i cuori di due ragazze single

470
00:23:09,471 --> 00:23:11,617
passando non solo per umano

471
00:23:11,618 --> 00:23:14,080
ma anche degno di un appuntamento.

472
00:23:14,081 --> 00:23:15,551
E con questo termina...

473
00:23:15,552 --> 00:23:18,344
Let's get Roman-Tech.

474
00:23:18,345 --> 00:23:26,325
Fantastico.

475
00:23:26,326 --> 00:23:29,955
Forse un giorno i computer avranno
gli stessi diritti degli esseri umani.

476
00:23:29,956 --> 00:23:32,898
Forse non sapremo mai
cosa rende la mente umana

477
00:23:32,899 --> 00:23:35,231
diversa da quella elettronica.

478
00:23:35,232 --> 00:23:36,889
Forse la domanda non è

479
00:23:36,890 --> 00:23:39,579
"Possiamo avere
delle relazioni con la tecnologia"

480
00:23:39,580 --> 00:23:42,194
ma, piuttosto, "Siamo la stessa cosa?"

481
00:23:42,195 --> 00:23:46,539
Provate a pensare a un alieno
che non sa cosa sia un corpo umano

482
00:23:46,540 --> 00:23:49,088
e che mi veda per la prima volta.

483
00:23:49,089 --> 00:23:54,217
Capirebbe la differenza
tra organismo e invenzione?

484
00:23:54,218 --> 00:23:57,710
Capirebbe che questi
sono stati fatti per me da altri umani

485
00:23:57,711 --> 00:24:00,750
o penserebbe che sono un mio attributo?

486
00:24:00,751 --> 00:24:03,579
Penserebbe che
il mio telefono o il mio computer

487
00:24:03,580 --> 00:24:08,721
siano strumenti o organi 
esterni metallici che ho sviluppato?

488
00:24:08,722 --> 00:24:13,443
Tra molti anni, i computer
avranno ottenuto lo status di persona

489
00:24:13,444 --> 00:24:19,138
o saremo tutti noi a ottenere
lo status di cyborg?

490
00:24:19,139 --> 00:24:21,969
E, come sempre, 
grazie per averci guardato.

