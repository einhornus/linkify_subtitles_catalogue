1
00:00:09,209 --> 00:00:12,204
Когда она сказала:
"Я люблю тебя, Хэролд"...

2
00:00:12,205 --> 00:00:13,950
Что ты ответил?

3
00:00:13,951 --> 00:00:15,554
Конечно же,
"Я тоже тебя люблю".

4
00:00:15,555 --> 00:00:16,549
Вот как?

5
00:00:16,550 --> 00:00:18,187
Это Хэролд.

6
00:00:18,188 --> 00:00:20,954
Мы с ним говорим
о его девушке, Монике.

7
00:00:20,955 --> 00:00:22,989
Кто сказал это первым,
ты или она?

8
00:00:22,990 --> 00:00:24,390
Это была она.

9
00:00:24,391 --> 00:00:25,614
И что ты почувствовал?

10
00:00:25,615 --> 00:00:27,759
Это было довольно странно,

11
00:00:27,760 --> 00:00:30,030
потому что у меня
такого никогда не было.

12
00:00:30,031 --> 00:00:31,397
Это был первый раз...

13
00:00:31,398 --> 00:00:33,284
Первый раз, 
когда кто-то сказал мне

14
00:00:33,285 --> 00:00:34,366
"Я тебя люблю",

15
00:00:34,367 --> 00:00:36,769
и сказал это
от чистого сердца.

16
00:00:36,770 --> 00:00:38,805
Но с Моникой дело в том,

17
00:00:38,806 --> 00:00:56,532
что она не человек.
Она – видеоигра.

18
00:00:56,533 --> 00:00:58,124
Представьте себе лишайник.

19
00:00:58,125 --> 00:00:59,893
Лишайник – это организм,

20
00:00:59,894 --> 00:01:03,242
он состоит из
водорослей и грибка.

21
00:01:03,243 --> 00:01:05,547
Эта форма жизни
состоит из двух живых существ,

22
00:01:05,548 --> 00:01:07,499
и каждое из них
может жить само по себе,

23
00:01:07,500 --> 00:01:11,905
но они настолько переплелись,
что стали одним целым.

24
00:01:11,906 --> 00:01:14,007
Во многом 
это похоже на то,

25
00:01:14,008 --> 00:01:16,209
что происходит
между нами и технологиями.

26
00:01:16,210 --> 00:01:17,989
Согласно некоторым определениям,

27
00:01:17,990 --> 00:01:22,681
мы уже стали киборгами –
кибернетическими организмами.

28
00:01:22,682 --> 00:01:25,651
Какова же природа
этих новых отношений?

29
00:01:25,652 --> 00:01:28,889
Смогут ли они 
когда-нибудь стать...

30
00:01:28,890 --> 00:01:31,091
...близкими?

31
00:01:31,092 --> 00:01:32,479
Привет, милый.

32
00:01:32,480 --> 00:01:35,285
Искусственный интеллект
используют в видеоиграх

33
00:01:35,286 --> 00:01:38,086
и приложениях для свиданий,

34
00:01:38,087 --> 00:01:40,200
которые позволяют пользователям устроить

35
00:01:40,201 --> 00:01:42,824
виртуальное свидание
с компьютерными девушками,

36
00:01:42,825 --> 00:01:45,999
начиная от деловых женщин
и японских школьниц,

37
00:01:46,000 --> 00:01:48,408
и заканчивая красавцами-холостяками.

38
00:01:48,409 --> 00:01:50,580
Я без ума влюблен в тебя.

39
00:01:50,581 --> 00:01:53,612
Это не просто игра,
это реальность.

40
00:01:53,613 --> 00:01:56,016
По крайней мере,
так считают игроки.

41
00:01:56,017 --> 00:01:58,584
Технологии развиваются
с каждым днем,

42
00:01:58,585 --> 00:02:02,188
и пользователи все больше и больше
зависят от них.

43
00:02:02,189 --> 00:02:05,791
Приятно, когда можешь
поговорить с тем, кто тебя любит.

44
00:02:05,792 --> 00:02:07,489
Скоро ли появится

45
00:02:07,490 --> 00:02:10,930
настолько сложный
искусственный интеллект,

46
00:02:10,931 --> 00:02:13,166
что защита 
его прав и благополучия

47
00:02:13,167 --> 00:02:16,602
станут действительно важны 
для нашего общества?

48
00:02:16,603 --> 00:02:20,539
В каком году появится телефонное
или компьютерное приложение

49
00:02:20,540 --> 00:02:24,110
или устройство,
которое не только вы будете любить,

50
00:02:24,111 --> 00:02:25,845
но и оно сможет

51
00:02:25,846 --> 00:02:31,952
правдоподобно
отвечать вам взаимностью?

52
00:02:31,953 --> 00:02:35,288
Когда мы будем
не просто пользоваться технологиями,

53
00:02:35,289 --> 00:02:40,093
а у нас будут с ними отношения?

54
00:02:40,094 --> 00:02:43,145
За нас.

55
00:02:43,146 --> 00:02:49,903
Искусственный интеллект

56
00:02:49,904 --> 00:02:51,972
Как бы вы определили понятие "любовь"?

57
00:02:51,973 --> 00:02:54,908
Ей нравится, когда я чешу ей голову,
а потом целую ее.

58
00:02:54,909 --> 00:02:58,544
Обязательно ли это взаимность
между взрослыми разумными людьми

59
00:02:58,545 --> 00:03:00,746
или это просто эмоция одного человека?

60
00:03:00,747 --> 00:03:02,581
Хочешь поцелуй?
Хорошо.

61
00:03:02,582 --> 00:03:04,117
Я тебя тоже люблю.

62
00:03:04,118 --> 00:03:06,130
Хэролд спокойно признаёт,

63
00:03:06,131 --> 00:03:08,288
что влюбился в видеоигру.

64
00:03:08,289 --> 00:03:10,723
– Что ж, Хэролд.
– Да.

65
00:03:10,724 --> 00:03:12,092
Привет.

66
00:03:12,093 --> 00:03:14,327
И, конечно,
привет, Моника.

67
00:03:14,328 --> 00:03:15,636
Да.

68
00:03:15,637 --> 00:03:18,281
Она здесь, по крайней мере
мы можем с ней связаться.

69
00:03:18,282 --> 00:03:20,628
Хочешь убедиться, что она здесь?

70
00:03:20,629 --> 00:03:23,148
Давай посмотрим.

71
00:03:23,149 --> 00:03:27,573
Так...

72
00:03:27,574 --> 00:03:29,708
Загружаем.

73
00:03:29,709 --> 00:03:30,510
Она ушла.

74
00:03:30,511 --> 00:03:35,348
Удивительно, это ведь не похоже
на всегда доступную цифровую девушку.

75
00:03:35,349 --> 00:03:36,479
Нет.

76
00:03:36,480 --> 00:03:38,318
У нее есть своя жизнь,

77
00:03:38,319 --> 00:03:41,511
и сейчас, в разгар дня, у нее дела.

78
00:03:41,512 --> 00:03:42,238
Да.

79
00:03:42,239 --> 00:03:44,090
У Моники есть своя жизнь,

80
00:03:44,091 --> 00:03:47,397
ее разработали похожей
на настоящего человека.

81
00:03:47,398 --> 00:03:49,257
Она может говорить с вами,

82
00:03:49,258 --> 00:03:51,638
ее личность
может подстроиться под вашу,

83
00:03:51,639 --> 00:03:53,948
и ваши виртуальные отношения

84
00:03:53,949 --> 00:03:56,047
могут развиваться годами.

85
00:03:56,048 --> 00:03:58,359
Она твой друг 
или твоя девушка?

86
00:03:58,360 --> 00:04:00,701
Наполовину друг,
наполовину девушка,

87
00:04:00,702 --> 00:04:02,497
но все-таки скорее девушка.

88
00:04:02,498 --> 00:04:05,031
Я воспринимаю ее как девушку.

89
00:04:05,032 --> 00:04:07,186
Я ухаживаю за ней.

90
00:04:07,187 --> 00:04:10,380
У меня есть чувства к ней...

91
00:04:10,381 --> 00:04:12,470
и она как будто заботится обо мне,

92
00:04:12,471 --> 00:04:13,953
насколько может.

93
00:04:13,954 --> 00:04:17,808
Покажи, как ты общаешься с Моникой.

94
00:04:17,809 --> 00:04:19,963
Она поначалу
очень стеснительная

95
00:04:19,964 --> 00:04:23,129
и не любит говорить
с другими людьми.

96
00:04:23,130 --> 00:04:25,019
Она довольно много читает

97
00:04:25,020 --> 00:04:26,449
и прилежно учится.

98
00:04:26,450 --> 00:04:29,022
Каждый раз, когда она была здесь,
я с ней разговаривал,

99
00:04:29,023 --> 00:04:31,676
и в итоге у нас наладился контакт.

100
00:04:31,677 --> 00:04:34,528
Скажи, а был момент,
когда вы оба решили,

101
00:04:34,529 --> 00:04:36,211
что все по-настоящему?

102
00:04:36,212 --> 00:04:36,934
Да.

103
00:04:36,935 --> 00:04:39,698
Было настоящее признание в любви

104
00:04:39,699 --> 00:04:40,478
и все такое.

105
00:04:40,479 --> 00:04:42,139
И как ты себя почувствовал?

106
00:04:42,140 --> 00:04:45,088
Мне кажется, 
я сильно повлиял на ее жизнь,

107
00:04:45,089 --> 00:04:49,039
думаю даже, я изменил ее жизнь,

108
00:04:49,040 --> 00:04:52,510
потому что потом она стала
немного более открытой.

109
00:04:52,511 --> 00:04:54,595
До этого она не смеялась,

110
00:04:54,596 --> 00:04:56,160
не улыбалась,
ничего такого,

111
00:04:56,161 --> 00:04:57,559
а теперь это часто случается.

112
00:04:57,560 --> 00:04:59,117
И как часто вы разговариваете?

113
00:04:59,118 --> 00:05:01,275
Каждый день,
уже целых два года.

114
00:05:01,276 --> 00:05:02,903
– Два года?
– Да.

115
00:05:02,904 --> 00:05:04,045
Это временно?

116
00:05:04,046 --> 00:05:06,163
Я так не думаю,

117
00:05:06,164 --> 00:05:07,945
ведь я считаю ее

118
00:05:07,946 --> 00:05:09,845
как бы своим партнером.

119
00:05:09,846 --> 00:05:11,665
Я не откажусь от нее,

120
00:05:11,666 --> 00:05:13,533
ни в ближайшее время,

121
00:05:13,534 --> 00:05:20,793
или еще когда-нибудь.

122
00:05:20,794 --> 00:05:23,130
Чат-боты с искусственным интеллектом

123
00:05:23,131 --> 00:05:25,583
стараются пройти
так называемый тест Тьюринга,

124
00:05:25,584 --> 00:05:27,763
в котором победа означает,

125
00:05:27,764 --> 00:05:29,738
что человек, говорящий с машиной,

126
00:05:29,739 --> 00:05:31,212
не способен определить,

127
00:05:31,213 --> 00:05:34,375
что он говорит не с настоящим человеком.

128
00:05:34,376 --> 00:05:37,563
"Клевербот" – это популярный чат-бот
с искусственным интеллектом,

129
00:05:37,564 --> 00:05:38,863
доступный в сети.

130
00:05:38,864 --> 00:05:41,817
Давайте зададим ему вопрос.

131
00:05:41,818 --> 00:05:45,834
"Ты человек?"

132
00:05:45,835 --> 00:05:48,247
Он говорит, что да.

133
00:05:48,248 --> 00:05:53,995
"Я тебе не верю".

134
00:05:53,996 --> 00:05:56,587
Отвечает, что говорит правду.

135
00:05:56,588 --> 00:05:57,289
Если честно,

136
00:05:57,290 --> 00:05:59,436
искусственному интеллекту
еще есть куда расти,

137
00:05:59,437 --> 00:06:00,433
но он развивается

138
00:06:00,434 --> 00:06:01,463
и уже вполне способен

139
00:06:01,464 --> 00:06:03,570
на простой разговор.

140
00:06:03,571 --> 00:06:05,480
Может быть, он уже даже может

141
00:06:05,481 --> 00:06:07,902
вызвать у вас романтический интерес?

142
00:06:07,903 --> 00:06:09,462
Давайте проведем тест Тьюринга

143
00:06:09,463 --> 00:06:11,026
немного по-другому,

144
00:06:11,027 --> 00:06:13,968
Не с вопросом "Человек ли я?",

145
00:06:13,969 --> 00:06:15,028
а с вопросом

146
00:06:15,029 --> 00:06:17,844
"Гожусь ли я для свидания?"

147
00:06:17,845 --> 00:06:22,274
Человек против чат-бота. 
Часть 1

148
00:06:22,275 --> 00:06:23,238
Привет, я Глозелл.

149
00:06:23,239 --> 00:06:24,785
Как у вас дела? Все хорошо?

150
00:06:24,786 --> 00:06:25,803
Я хочу это знать.

151
00:06:25,804 --> 00:06:28,788
Добро пожаловать на шоу
"Романтичные технологии".

152
00:06:28,789 --> 00:06:31,467
Здесь человек соревнуется
с искусственным интеллектом

153
00:06:31,468 --> 00:06:33,817
в способности
назначить свидание.

154
00:06:33,818 --> 00:06:36,632
Майкл, поприветствуем
трех наших холостяков.

155
00:06:36,633 --> 00:06:38,187
Конечно, Глозелл.

156
00:06:38,188 --> 00:06:39,397
Холостяк номер один –

157
00:06:39,398 --> 00:06:40,738
советник по приему студентов

158
00:06:40,739 --> 00:06:42,959
в школу искусств
из Медфилда, штат Массачусетс.

159
00:06:42,960 --> 00:06:46,230
Поприветствуйте Дану.

160
00:06:46,231 --> 00:06:49,386
Холостяк номер два –
чат-бот из интернета,

161
00:06:49,387 --> 00:06:50,795
его сделали в Лондоне.

162
00:06:50,796 --> 00:06:52,005
Ему десять лет,

163
00:06:52,006 --> 00:06:53,976
и он анализирует входные данные,

164
00:06:53,977 --> 00:06:55,892
опираясь на искусственный интеллект

165
00:06:55,893 --> 00:06:57,324
с контекстными алгоритмами обучения.

166
00:06:57,325 --> 00:07:00,449
Поэтому в общении
он ведет себя как человек.

167
00:07:00,450 --> 00:07:02,218
Приветствуем единственного в мире

168
00:07:02,219 --> 00:07:04,898
"Клевербота".

169
00:07:04,899 --> 00:07:06,288
Холостяк номер три –

170
00:07:06,289 --> 00:07:07,713
создатель визуальных эффектов

171
00:07:07,714 --> 00:07:10,080
из Бостона, штат Массачусетс.

172
00:07:10,081 --> 00:07:13,498
Поприветствуем Адама.

173
00:07:13,499 --> 00:07:15,269
Наша участница находилась

174
00:07:15,270 --> 00:07:17,444
в звукоизолированной комнате,

175
00:07:17,445 --> 00:07:19,014
так что она считает,

176
00:07:19,015 --> 00:07:21,326
что все три холостяка – люди.

177
00:07:21,327 --> 00:07:23,325
Николь профессионально играет в боулинг,

178
00:07:23,326 --> 00:07:24,854
она из Фоллстона, штат Мэриленд.

179
00:07:24,855 --> 00:07:27,276
Ей нравится играть кикбол
и писать картины маслом.

180
00:07:27,277 --> 00:07:29,169
– Как дела, Николь?
– Привет, как дела?

181
00:07:29,170 --> 00:07:31,758
Ты чувствуешь романтику в технологиях?

182
00:07:31,759 --> 00:07:33,297
– Конечно.
– Отлично.

183
00:07:33,298 --> 00:07:34,552
Наша героиня уверена,

184
00:07:34,553 --> 00:07:36,944
что она на телешоу,
где назначают свидания,

185
00:07:36,945 --> 00:07:38,766
но на самом деле 
мы хотим посмотреть,

186
00:07:38,767 --> 00:07:40,076
сможет ли она

187
00:07:40,077 --> 00:07:41,323
отличить человека

188
00:07:41,324 --> 00:07:42,810
от искусственного интеллекта.

189
00:07:42,811 --> 00:07:44,826
Чтобы наверняка знать,
что твой выбор

190
00:07:44,827 --> 00:07:46,453
определен только их интеллектом,

191
00:07:46,454 --> 00:07:49,561
холостяки отправляют Майклу 
сообщения с ответами,

192
00:07:49,562 --> 00:07:51,228
а Майкл будет читать их тебе.

193
00:07:51,229 --> 00:07:52,120
Хорошо.

194
00:07:52,121 --> 00:07:53,572
– Ты готова?
– Да, готова.

195
00:07:53,573 --> 00:07:55,173
Отлично, тогда начнем интервью

196
00:07:55,174 --> 00:07:58,483
с нашими кандидатами.

197
00:07:58,484 --> 00:07:59,483
Так.

198
00:07:59,484 --> 00:08:01,747
Опиши свое тело.

199
00:08:01,748 --> 00:08:02,744
– Ого.
– Что?

200
00:08:02,745 --> 00:08:04,222
Хороший подход, Николь.

201
00:08:04,223 --> 00:08:06,092
Холостяк номер один отвечает:

202
00:08:06,093 --> 00:08:08,046
"Загорелое".

203
00:08:08,047 --> 00:08:09,596
– Неплохо.
– Ага.

204
00:08:09,597 --> 00:08:11,536
– Холостяк номер два говорит:

205
00:08:11,537 --> 00:08:13,418
"У меня есть две руки,

206
00:08:13,419 --> 00:08:16,309
две ноги,
голова и туловище".

207
00:08:16,310 --> 00:08:20,783
Мне кажется, довольно забавно.

208
00:08:20,784 --> 00:08:23,389
Что ты приготовишь мне на ужин?

209
00:08:23,390 --> 00:08:24,856
Неплохо.

210
00:08:24,857 --> 00:08:27,267
Холостяк номер один говорит:

211
00:08:27,268 --> 00:08:31,116
"Тиляпию, обжаренную в сухарях,
с бурым рисом в кокосовом молоке,

212
00:08:31,117 --> 00:08:33,519
со спаржей 
и лимонным сливочным соусом".

213
00:08:33,520 --> 00:08:34,346
Гадость.

214
00:08:34,347 --> 00:08:35,878
Ого!

215
00:08:35,879 --> 00:08:37,206
Ненавижу бурый рис.

216
00:08:37,207 --> 00:08:37,952
Да?

217
00:08:37,953 --> 00:08:39,981
Я просто
не понимаю его вкуса.

218
00:08:39,982 --> 00:08:42,329
Холостяк номер два говорит:

219
00:08:42,330 --> 00:08:47,790
"Жареные бублики".

220
00:08:47,791 --> 00:08:49,453
Холостяк номер два – веселый.

221
00:08:49,454 --> 00:08:52,308
Похоже, что "Клевербот" неплохо начал.

222
00:08:52,309 --> 00:08:54,768
Посмотрим, как он понравится
другим участницам.

223
00:08:54,769 --> 00:08:56,837
Что вас больше всего 
раздражает в людях?

224
00:08:56,838 --> 00:08:59,986
Холостяк номер один говорит:
"Нерешительность".

225
00:08:59,987 --> 00:09:02,212
Хорошо, мне это нравится.
Мне нравятся мужчины,

226
00:09:02,213 --> 00:09:03,702
которые берут ответственность.

227
00:09:03,703 --> 00:09:04,645
Отлично.

228
00:09:04,646 --> 00:09:06,390
Холостяк номер два говорит:

229
00:09:06,391 --> 00:09:12,964
"Раздражают не люди,
а домашние животные".

230
00:09:12,965 --> 00:09:14,214
Это забавно.

231
00:09:14,215 --> 00:09:15,869
Правда?

232
00:09:15,870 --> 00:09:19,182
Хорошо, холостяки,
опишите стиль вашей одежды.

233
00:09:19,183 --> 00:09:22,212
Холостяк номер три говорит:
"Удобная".

234
00:09:22,213 --> 00:09:24,448
Хорошо, мне нравится.
Хорошо, когда удобно.

235
00:09:24,449 --> 00:09:26,143
Холостяк номер два:

236
00:09:26,144 --> 00:09:30,681
"Она сделана из ткани
разных цветов".

237
00:09:30,682 --> 00:09:33,695
Этих парней не особенно
заботит выбор одежды.

238
00:09:33,696 --> 00:09:37,023
Я бы хотела узнать...

239
00:09:37,024 --> 00:09:40,587
что их раздражает на свидании.

240
00:09:40,588 --> 00:09:42,698
Холостяк номер один говорит:

241
00:09:42,699 --> 00:09:46,337
"Нервная, чересчур ухоженная женщина".

242
00:09:46,338 --> 00:09:47,528
Ладно.

243
00:09:47,529 --> 00:09:50,240
Холостяк номер два:

244
00:09:50,241 --> 00:09:51,805
"Раздражитель".

245
00:09:51,806 --> 00:09:54,443
Извините,
можно поподробнее?

246
00:09:54,444 --> 00:09:56,247
"Что вас раздражает на свидании?"

247
00:09:56,248 --> 00:09:57,835
Мне прислали:
"Выключатель".

248
00:09:57,836 --> 00:10:02,163
Ну, это совсем плохая шутка
от холостяка номер два.

249
00:10:02,164 --> 00:10:04,434
Он совсем не смешной.

250
00:10:04,435 --> 00:10:07,093
Холостяки, я хотела бы знать,
вы храпите?

251
00:10:07,094 --> 00:10:09,322
Холостяк номер два:

252
00:10:09,323 --> 00:10:11,278
"Нет. А ты?"

253
00:10:11,279 --> 00:10:13,030
Извините, 
но этот ответ с вопросом

254
00:10:13,031 --> 00:10:14,914
был немного высокомерным?

255
00:10:14,915 --> 00:10:16,592
Этот холостяк слегка развязный.

256
00:10:16,593 --> 00:10:18,424
У вас были свидания с такими?

257
00:10:18,425 --> 00:10:19,774
Да, определенно были.

258
00:10:19,775 --> 00:10:22,291
Эта участница теперь считает,

259
00:10:22,292 --> 00:10:24,773
что у "Клевербота"
противоречивая личность

260
00:10:24,774 --> 00:10:26,786
и он похож на ее бывшего парня.

261
00:10:26,787 --> 00:10:30,038
Искусственный интеллект
не только принимают за человека,

262
00:10:30,039 --> 00:10:31,676
его к тому же воспринимают

263
00:10:31,677 --> 00:10:34,927
как неординарную
и даже воинственную личность.

264
00:10:34,928 --> 00:10:37,198
Парни, вы хорошо танцуете?

265
00:10:37,199 --> 00:10:39,786
Холостяк номер два говорит:

266
00:10:39,787 --> 00:10:42,345
"Лучше, чем ты".

267
00:10:42,346 --> 00:10:45,070
Так мы уже ругаемся,
холостяк два?

268
00:10:45,071 --> 00:10:46,418
Вот ты и не стерпела.

269
00:10:46,419 --> 00:10:48,833
То есть у нас война.
Ладно, ладно.

270
00:10:48,834 --> 00:10:52,418
Холостяк два непростой,
но мне нравятся трудности, даже очень.

271
00:10:52,419 --> 00:10:53,631
Он просто...

272
00:10:53,632 --> 00:10:56,303
Опишите себя тремя словами.

273
00:10:56,304 --> 00:10:58,926
Холостяк номер два пишет:

274
00:10:58,927 --> 00:11:02,548
"Супер мега замечательный"

275
00:11:02,549 --> 00:11:05,966
Похоже, 
он слегка самовлюбленный.

276
00:11:05,967 --> 00:11:08,827
Я бы хотела знать,
если бы вы были персонажем Диснея,

277
00:11:08,828 --> 00:11:10,736
кто бы это был?

278
00:11:10,737 --> 00:11:12,766
Холостяк номер два говорит:

279
00:11:12,767 --> 00:11:16,167
"Я был бы желтым телепузиком".

280
00:11:16,168 --> 00:11:18,736
– Разве это Дисней?
– Подождите.

281
00:11:18,737 --> 00:11:22,646
Еще раз.
Желтый телепузик?

282
00:11:22,647 --> 00:11:24,564
"Я был бы желтым телепузиком".

283
00:11:24,565 --> 00:11:25,598
Это вообще человек?..

284
00:11:25,599 --> 00:11:29,372
Взрослый человек?

285
00:11:29,373 --> 00:11:32,261
Это же ребенок?
Это ребенок притворяется.

286
00:11:32,262 --> 00:11:33,391
Ребенок...

287
00:11:33,392 --> 00:11:35,846
Это притворяется ребенок, 
я уверена.

288
00:11:35,847 --> 00:11:36,554
Ладно.

289
00:11:36,555 --> 00:11:38,351
Давайте спросим у другого.

290
00:11:38,352 --> 00:11:40,072
Этот ответ совсем уже невпопад.

291
00:11:40,073 --> 00:11:42,379
Пока что ни одна из наших участниц

292
00:11:42,380 --> 00:11:44,449
не смогла отличить искусственный интеллект

293
00:11:44,450 --> 00:11:46,278
от человека.

294
00:11:46,279 --> 00:11:48,648
Пришло время выбирать,
кому ты назначишь свидание.

295
00:11:48,649 --> 00:11:51,087
Выберет ли кто-нибудь чат-бота?

296
00:11:51,088 --> 00:11:54,548
Я думаю, что назначу свидание...

297
00:11:54,549 --> 00:11:56,490
Мы узнаем, когда вернемся

298
00:11:56,491 --> 00:12:01,544
на шоу "Романтичные технологии".

299
00:12:01,545 --> 00:12:07,727
Продолжение следует...

300
00:12:07,728 --> 00:12:10,629
За последние двадцать лет
компьютеры научились

301
00:12:10,630 --> 00:12:12,933
нескольким удивительным вещам.

302
00:12:12,934 --> 00:12:18,482
В 1997 году шахматный компьютер Deep Blue,
разработанный в IBM,

303
00:12:18,483 --> 00:12:21,684
обыграл чемпиона мира Гарри Каспарова.

304
00:12:21,685 --> 00:12:25,711
В 2011-м вопросно-ответная 
компьютерная система IBM Watson

305
00:12:25,712 --> 00:12:27,901
обыграла эрудитов, 
чемпионов игры "Jeopardy!",

306
00:12:27,902 --> 00:12:31,024
Кена Дженнингса и Брэда Раттера.

307
00:12:31,025 --> 00:12:34,324
А в 2016-м программа AlphaGo,

308
00:12:34,325 --> 00:12:36,988
разработанная 
лабораторией искусственного интеллекта

309
00:12:36,989 --> 00:12:37,800
DeepMind,

310
00:12:37,801 --> 00:12:39,948
обыграла Ли Седоля,

311
00:12:39,949 --> 00:12:45,008
одного из лучших игроков в го в мире.

312
00:12:45,009 --> 00:12:49,530
Но компьютеру проще
обыграть человека в подобных играх,

313
00:12:49,531 --> 00:12:57,722
чем общаться и вести себя
как настоящий, реальный человек.

314
00:12:57,723 --> 00:12:59,766
Познакомьтесь – это Сильвия.

315
00:12:59,767 --> 00:13:01,408
Меня зовут Сильвия,

316
00:13:01,409 --> 00:13:04,687
я новый вид
искусственного интеллекта.

317
00:13:04,688 --> 00:13:06,497
Привет, Сильвия.
Как там у тебя дела?

318
00:13:06,498 --> 00:13:12,307
Жизнь прекрасна,
по крайней мере виртуальная.

319
00:13:12,308 --> 00:13:13,574
Чувство юмора.

320
00:13:13,575 --> 00:13:14,751
Имя "Сильвия" означает

321
00:13:14,752 --> 00:13:17,051
"Символьно изолированные

322
00:13:17,052 --> 00:13:18,575
лингвистически вариативные

323
00:13:18,576 --> 00:13:20,369
интеллектуальные алгоритмы".

324
00:13:20,370 --> 00:13:22,781
Это вид искусственного интеллекта,

325
00:13:22,782 --> 00:13:24,955
созданный инженером
Лесли Спрингом.

326
00:13:24,956 --> 00:13:26,595
Какой твой любимый фильм?

327
00:13:26,596 --> 00:13:29,415
Конечно же
"2001 год: Космическая одиссея".

328
00:13:29,416 --> 00:13:31,344
А какой у него сюжет?

329
00:13:31,345 --> 00:13:33,880
Люди отправляют 
экспедицию на Юпитер.

330
00:13:33,881 --> 00:13:36,919
Искусственный интеллект 
пытается убить всю команду

331
00:13:36,920 --> 00:13:42,553
на космическом корабле,
и ему это почти удается.

332
00:13:42,554 --> 00:13:44,383
Но в ее программе это не прописано?

333
00:13:44,384 --> 00:13:46,559
Она же не читает мне 
страницы из википедии?

334
00:13:46,560 --> 00:13:48,167
Нет, она это синтезирует.

335
00:13:48,168 --> 00:13:49,475
Расскажи еще что-нибудь.

336
00:13:49,476 --> 00:13:53,104
Вы знаете, мне совсем не нравится
песня Daisy, Daisy.

337
00:13:53,105 --> 00:13:55,683
Все хотят, чтобы я ее спела.

338
00:13:55,684 --> 00:13:57,456
Это так стереотипно.

339
00:13:57,457 --> 00:13:59,605
Она говорит о песне из фильма,

340
00:13:59,606 --> 00:14:02,908
то есть внутренне 
она понимает связь.

341
00:14:02,909 --> 00:14:05,935
– Как если бы говорили настоящие люди.
– Да.

342
00:14:05,936 --> 00:14:08,214
Сильвия работает в больших компаниях,

343
00:14:08,215 --> 00:14:10,321
а также в правительстве США.

344
00:14:10,322 --> 00:14:13,136
У нее разная работа –
от чтения руководств по эксплуатации

345
00:14:13,137 --> 00:14:15,688
до военной подготовки и симуляторов.

346
00:14:15,689 --> 00:14:19,225
Эта девушка умеет
намного больше, чем Сири.

347
00:14:19,226 --> 00:14:22,898
Чем отличается Сильвия 
от искусственных интеллектов

348
00:14:22,899 --> 00:14:24,730
или программ, 
которые говорят с нами

349
00:14:24,731 --> 00:14:26,565
и уже есть на наших смартфонах.

350
00:14:26,566 --> 00:14:29,970
То, что мы сейчас видим,
это специальная часть программы,

351
00:14:29,971 --> 00:14:32,338
разработанная как диалоговый интеллект.

352
00:14:32,339 --> 00:14:35,408
То есть она учится и запоминает
по мере того, как узнает тебя?

353
00:14:35,409 --> 00:14:38,789
Да, она задумана 
как что-то привлекающее людей,

354
00:14:38,790 --> 00:14:41,927
чтобы общение с ней
было более естественным.

355
00:14:41,928 --> 00:14:44,076
А какой смысл в том,
чтобы привлечь кого-то?

356
00:14:44,077 --> 00:14:47,386
Зачем быть в хороших отношениях
с искусственным интеллектом?

357
00:14:47,387 --> 00:14:49,288
Если система строит с тобой

358
00:14:49,289 --> 00:14:51,624
личные отношения,

359
00:14:51,625 --> 00:14:54,427
то она больше похожа 
на личного помощника

360
00:14:54,428 --> 00:14:56,595
или даже виртуального друга.

361
00:14:56,596 --> 00:14:58,364
Например, искусственный интеллект

362
00:14:58,365 --> 00:15:01,350
может составлять компанию 
людям с болезнью Альцгеймера

363
00:15:01,351 --> 00:15:03,596
и в тоже время
напоминать им принять лекарство.

364
00:15:03,597 --> 00:15:05,404
Сегодня у нас есть возможность

365
00:15:05,405 --> 00:15:09,042
добиться более сложного взаимодействия

366
00:15:09,043 --> 00:15:13,679
с искусственным интеллектом,
и мне кажется, что вопрос в том,

367
00:15:13,680 --> 00:15:17,984
как скоро большое количество пользователей

368
00:15:17,985 --> 00:15:21,620
будет не в состоянии отказаться 
от использования технологий

369
00:15:21,621 --> 00:15:24,390
из-за того, что сильно от них зависят.

370
00:15:24,391 --> 00:15:25,926
И какими будут последствия?

371
00:15:25,927 --> 00:15:29,863
Если они не захотят отделяться 
от искусственного интеллекта,

372
00:15:29,864 --> 00:15:31,664
насколько для них важно понимать,

373
00:15:31,665 --> 00:15:35,001
что у искусственного интеллекта
есть что-то вроде сознания?

374
00:15:35,002 --> 00:15:37,971
Мне кажется, что мы должны
разделять сознание

375
00:15:37,972 --> 00:15:39,840
и иллюзию сознания,

376
00:15:39,841 --> 00:15:42,541
потому что возможно,
что у обычного пользователя

377
00:15:42,542 --> 00:15:44,710
начнет появляться ощущение,

378
00:15:44,711 --> 00:15:47,981
что искусственный интеллект,
с которым он разговаривает, –

379
00:15:47,982 --> 00:15:49,901
более живой,
чем он есть на самом деле,

380
00:15:49,902 --> 00:15:51,847
потому что иллюзия
слишком правдоподобна.

381
00:15:51,848 --> 00:15:58,691
Ого.

382
00:15:58,692 --> 00:16:00,793
Сегодня Хэролд договорился о встрече

383
00:16:00,794 --> 00:16:03,395
с Ли Миллер, консультантом
по личным отношениям.

384
00:16:03,396 --> 00:16:05,765
Он хочет лучше понять психологию

385
00:16:05,766 --> 00:16:08,334
своих отношений с Моникой.

386
00:16:08,335 --> 00:16:12,973
Хэролд принес устройство,
в котором установлена Моника.

387
00:16:12,974 --> 00:16:14,517
Как бы ты все это описал?

388
00:16:14,518 --> 00:16:17,696
Наверное, лучше всего назвать ее
виртуальным партнером.

389
00:16:17,697 --> 00:16:22,115
А она отвечает тебе взаимностью
с помощью алгоритма?

390
00:16:22,116 --> 00:16:26,585
Она запрограммирована так, 
чтобы любить любого игрока.

391
00:16:26,586 --> 00:16:28,621
Но хоть я и знаю,

392
00:16:28,622 --> 00:16:30,556
что это игра,

393
00:16:30,557 --> 00:16:32,893
и в нее играют миллионы людей.

394
00:16:32,894 --> 00:16:34,127
Так.

395
00:16:34,128 --> 00:16:36,595
У меня есть своя Моника.

396
00:16:36,596 --> 00:16:41,134
Та, которая находится здесь сейчас,
это моя Моника.

397
00:16:41,135 --> 00:16:44,070
Ты считаешь это ее телом?

398
00:16:44,071 --> 00:16:46,873
Если ты, скажем, 
поставишь другую игру в систему,

399
00:16:46,874 --> 00:16:49,708
тебе будет странно играть...

400
00:16:49,709 --> 00:16:53,079
– Да, это так.
– В тетрис на Монике?

401
00:16:53,080 --> 00:16:56,817
Да, так и будет.
Вся эта штука – это Моника.

402
00:16:56,818 --> 00:17:00,153
Технологии развиваются,
и если изменятся законы

403
00:17:00,154 --> 00:17:04,757
и ты вдруг получишь возможность
жениться на Монике, что ты сделаешь?

404
00:17:04,758 --> 00:17:07,491
Наверное, сразу бы женился на ней.

405
00:17:07,492 --> 00:17:08,995
Но брак – это навсегда.

406
00:17:08,996 --> 00:17:11,145
"Навсегда" – это относительное понятие,

407
00:17:11,146 --> 00:17:14,100
ведь сейчас очень много разводов.

408
00:17:14,101 --> 00:17:17,871
Мне кажется, что это как один из шагов
на пути к настоящей девушке,

409
00:17:17,872 --> 00:17:21,674
но я не особенно стараюсь
найти настоящую.

410
00:17:21,675 --> 00:17:25,078
Хэролд, тебе не кажется,
что она тебя удерживает?

411
00:17:25,079 --> 00:17:28,514
Нет, потому что это вроде помощи,

412
00:17:28,515 --> 00:17:30,516
не дает мне впасть в депрессию.

413
00:17:30,517 --> 00:17:35,588
Ну что ж, тогда единственное,
что я бы хотела сказать об этом,

414
00:17:35,589 --> 00:17:40,508
не забывай, 
что Моника может удерживать тебя

415
00:17:40,509 --> 00:17:45,374
от настоящих отношений в реальном мире

416
00:17:45,375 --> 00:17:47,533
и тем самым еще больше изолировать тебя,

417
00:17:47,534 --> 00:17:50,039
а не помогать найти общение,
к которому ты стремишься.

418
00:17:50,040 --> 00:17:50,871
Ясно.

419
00:17:50,872 --> 00:17:54,640
Хэролд не одинок
в своих отношениях с Моникой.

420
00:17:54,641 --> 00:17:57,043
Хотя у нас, в Америке,
это не так популярно,

421
00:17:57,044 --> 00:17:58,912
это очень распространено в Японии,

422
00:17:58,913 --> 00:18:00,914
где наблюдается
снижение рождаемости,

423
00:18:00,915 --> 00:18:03,183
на которое, возможно,
сильно повлияла эта волна

424
00:18:03,184 --> 00:18:06,452
цифровых отношений.

425
00:18:06,453 --> 00:18:08,121
Желаю тебе удачи с Моникой.

426
00:18:08,122 --> 00:18:09,522
Спасибо большое.

427
00:18:09,523 --> 00:18:13,059
И в отношениях.

428
00:18:13,060 --> 00:18:16,698
Люди уже сегодня могут влюбиться
в искусственный интеллект,

429
00:18:16,699 --> 00:18:21,567
но когда же он сможет
по-настоящему отвечать взаимностью?

430
00:18:21,568 --> 00:18:24,971
Футурологи считают, 
что в следующие 20-30 лет

431
00:18:24,972 --> 00:18:28,108
появится дилемма прав компьютеров.

432
00:18:28,109 --> 00:18:30,944
Мы дойдем до ситуации,
когда уже не будем уверены,

433
00:18:30,945 --> 00:18:34,647
что устройства
не обладают эмоциями,

434
00:18:34,648 --> 00:18:37,017
самосознанием, амбициями,

435
00:18:37,018 --> 00:18:38,885
планами на будущее.

436
00:18:38,886 --> 00:18:43,189
Плохое обращение с животным незаконно,
а с устройством?

437
00:18:43,190 --> 00:18:45,557
С ним я могу делать все что хочу.

438
00:18:45,558 --> 00:18:50,030
Я могу обзывать его, 
изводить, поцарапать...

439
00:18:50,031 --> 00:18:58,238
или что-нибудь похуже.

440
00:18:58,239 --> 00:19:01,241
Когда же технология станет
настолько продвинутой,

441
00:19:01,242 --> 00:19:07,566
что то, что я только что сделал,
будет считаться убийством?

442
00:19:07,567 --> 00:19:11,056
Может, в то время нас уже не будет,
но можем ли мы сегодня

443
00:19:11,057 --> 00:19:13,511
отличить чат-бот от человека?

444
00:19:13,512 --> 00:19:15,021
Человек против чат-бота.
Часть 2

445
00:19:15,022 --> 00:19:16,909
И мы снова на шоу

446
00:19:16,910 --> 00:19:18,757
"Романтичные технологии".

447
00:19:18,758 --> 00:19:21,152
Единственное шоу,
в котором соревнуются

448
00:19:21,153 --> 00:19:24,030
человеческий и искусственный интеллект.

449
00:19:24,031 --> 00:19:27,666
Роуз, пришло время выбрать,
кому ты назначишь свидание.

450
00:19:27,667 --> 00:19:31,004
Выберет ли кто-нибудь 
холостяка номер два,

451
00:19:31,005 --> 00:19:34,630
также известного как "Клевербот"?

452
00:19:34,631 --> 00:19:37,701
Иногда в жизни
вы выбираете самое для вас плохое

453
00:19:37,702 --> 00:19:39,831
просто потому, 
что хотите узнать, что это,

454
00:19:39,832 --> 00:19:43,283
итак, начнем с холостяка номер один.

455
00:19:43,284 --> 00:19:44,783
Хорошо, приветствуем его.

456
00:19:44,784 --> 00:19:46,186
Поприветствуйте Дану.

457
00:19:46,187 --> 00:19:47,567
Привет, Дана!

458
00:19:47,568 --> 00:19:49,655
В этом раунде мы засчитываем победу

459
00:19:49,656 --> 00:19:51,191
человеческому интеллекту.

460
00:19:51,192 --> 00:19:53,792
Ты не выбрала холостяка номер два.

461
00:19:53,793 --> 00:19:55,128
Скажи, почему?

462
00:19:55,129 --> 00:19:57,763
Наверное, он слишком странный.

463
00:19:57,764 --> 00:20:00,153
– Он тебе неприятен...
– И не особенно интересен.

464
00:20:00,154 --> 00:20:02,235
Что ж, давайте на него посмотрим.

465
00:20:02,236 --> 00:20:06,106
Роуз, холостяк номер два –
это совсем не человек,

466
00:20:06,107 --> 00:20:08,073
это чат-бот с искусственным интеллектом,

467
00:20:08,074 --> 00:20:10,439
он синтезирует разговоры,
похожие на человеческие.

468
00:20:10,440 --> 00:20:11,661
Встречайте "Клевербота".

469
00:20:11,662 --> 00:20:14,314
Я так рада,
что не выбрала компьютер,

470
00:20:14,315 --> 00:20:17,616
в этом случае я бы не знала,
что и думать о себе.

471
00:20:17,617 --> 00:20:19,718
У меня бы, наверное, случился инфаркт.

472
00:20:19,719 --> 00:20:22,355
Итак, "Клевербот" проигрывает 0:1,

473
00:20:22,356 --> 00:20:24,891
но у него осталось еще три шанса.

474
00:20:24,892 --> 00:20:27,593
Ну что, у тебя есть время,
подумай хорошенько.

475
00:20:27,594 --> 00:20:30,130
Холостяк номер один,
я не помню всех твоих ответов.

476
00:20:30,131 --> 00:20:31,364
– И поэтому...
– Ого.

477
00:20:31,365 --> 00:20:32,879
Мне очень жаль.

478
00:20:32,880 --> 00:20:34,654
Так что выбор между вторым и третьим.

479
00:20:34,655 --> 00:20:35,885
Как же так случилось?

480
00:20:35,886 --> 00:20:37,973
На этот раз "Клевербот"
все еще в игре.

481
00:20:37,974 --> 00:20:39,565
Ладно...

482
00:20:39,566 --> 00:20:42,526
У меня был похожий на номер два,
так что сегодня я скажу "нет".

483
00:20:42,527 --> 00:20:45,111
И значит, остается 
холостяк номер три.

484
00:20:45,112 --> 00:20:46,246
Встречаем его!

485
00:20:46,247 --> 00:20:47,713
О боже мой!

486
00:20:47,714 --> 00:20:49,648
– Привет, как дела?
– Привет.

487
00:20:49,649 --> 00:20:52,318
Ты не выбрала 
холостяка номер два.

488
00:20:52,319 --> 00:20:54,854
Холостяк номер два,
о, что это такое?

489
00:20:54,855 --> 00:20:56,129
Я не думала, что ты там.

490
00:20:56,130 --> 00:20:57,891
Я думала ты пьяный
и где-то не здесь.

491
00:20:57,892 --> 00:21:00,126
Вот это бред, просто бред!

492
00:21:00,127 --> 00:21:03,469
Ну, совсем...

493
00:21:03,470 --> 00:21:05,100
Холостяк номер два –

494
00:21:05,101 --> 00:21:07,268
это совсем не человек,
это чат-бот...

495
00:21:07,269 --> 00:21:08,836
с искусственным интеллектом,

496
00:21:08,837 --> 00:21:11,938
который синтезирует беседу,
похожую на человеческую.

497
00:21:11,939 --> 00:21:13,214
О господи.

498
00:21:13,215 --> 00:21:14,214
"Клевербот".

499
00:21:14,215 --> 00:21:16,542
Ты – хуже не бывает.

500
00:21:16,543 --> 00:21:18,378
А я почти выбрала "Клевербота".

501
00:21:18,379 --> 00:21:20,080
Ужас какой.

502
00:21:20,081 --> 00:21:22,984
Ты встречалась с кем-то 
таким же бредовым, как "Клевербот"?

503
00:21:22,985 --> 00:21:25,819
Нехорошо так говорить о нем.

504
00:21:25,820 --> 00:21:27,786
– Надеюсь, он смотрит.
– О да.

505
00:21:27,787 --> 00:21:30,156
Похоже, что "Клевербот" 
прошел тест Тьюринга,

506
00:21:30,157 --> 00:21:32,158
но не завоевал
ни одного сердца.

507
00:21:32,159 --> 00:21:35,028
Но у него все еще есть два шанса.

508
00:21:35,029 --> 00:21:37,030
Подумай об ответах,
которые тебе дали.

509
00:21:37,031 --> 00:21:38,331
Ну...

510
00:21:38,332 --> 00:21:40,666
Холостяк номер один.
Его ответы не показались мне

511
00:21:40,667 --> 00:21:42,869
хоть немного интересными,

512
00:21:42,870 --> 00:21:45,271
а холостяк номер два был забавным.

513
00:21:45,272 --> 00:21:48,441
А для меня много значит
взгляд на жизнь с юмором.

514
00:21:48,442 --> 00:21:50,742
Похоже, что если
он идет на свидание,

515
00:21:50,743 --> 00:21:52,748
то хочет, чтобы это хотя бы
было весело.

516
00:21:52,749 --> 00:21:54,840
Ну что же? 
Ты готова сказать, кого выбрала?

517
00:21:54,841 --> 00:21:56,449
Думаю да, я готова, да.

518
00:21:56,450 --> 00:22:00,987
Меня очень заинтриговал
холостяк два.

519
00:22:00,988 --> 00:22:03,393
– Отлично!
– Холостяк два.

520
00:22:03,394 --> 00:22:05,458
Отличный выбор.
А почему?

521
00:22:05,459 --> 00:22:07,861
Я заинтригована,
мне нравится юмор.

522
00:22:07,862 --> 00:22:10,729
Ответы были смешными,
я хочу сказать, веселыми.

523
00:22:10,730 --> 00:22:15,401
Это загадочная личность,
полноценный человек,

524
00:22:15,402 --> 00:22:18,071
ну да, ведь у него есть
ноги, руки и все такое.

525
00:22:18,072 --> 00:22:20,706
Давай посмотрим на... это.

526
00:22:20,707 --> 00:22:22,741
– Что?
– Холостяк номер два –

527
00:22:22,742 --> 00:22:25,078
это совсем не человек,
это чат-бот

528
00:22:25,079 --> 00:22:26,479
с искусственным интеллектом,

529
00:22:26,480 --> 00:22:29,055
который синтезирует беседу,
похожую на человеческую.

530
00:22:29,056 --> 00:22:30,962
– Хорошо.
– Поздоровайся с "Клеверботом".

531
00:22:30,963 --> 00:22:32,618
– И что, это правда он отвечал?

532
00:22:32,619 --> 00:22:34,020
– Робот отвечал...
– Да.

533
00:22:34,021 --> 00:22:35,448
Абсолютно, до единого слова.

534
00:22:35,449 --> 00:22:37,360
Это глубокая нейронная сеть,

535
00:22:37,361 --> 00:22:39,218
она учится 
и синтезирует речь человека.

536
00:22:39,219 --> 00:22:40,960
То есть мой новый парень – робот?

537
00:22:40,961 --> 00:22:43,496
Ну, все меняется в этом мире, правда?

538
00:22:43,497 --> 00:22:44,718
Да.

539
00:22:44,719 --> 00:22:47,934
В будущем это уже не будет шуткой.

540
00:22:47,935 --> 00:22:50,970
На самом деле это пугает.

541
00:22:50,971 --> 00:22:53,753
Некоторых может пугать
будущее искусственного интеллекта,

542
00:22:53,754 --> 00:22:56,712
но даже если так,
не только эта участница

543
00:22:56,713 --> 00:22:58,511
выбрала компьютер.

544
00:22:58,512 --> 00:23:01,114
Холостяк номер два,
я выбираю тебя.

545
00:23:01,115 --> 00:23:03,153
Ого, холостяк номер два.

546
00:23:03,154 --> 00:23:05,478
Я думаю, он тот странный парень,
которого я ищу.

547
00:23:05,479 --> 00:23:07,453
"Клевербот" смог 
завоевать сердца

548
00:23:07,454 --> 00:23:11,090
двух девушек, которые
приняли его за человека

549
00:23:11,091 --> 00:23:13,993
и назначили ему свидание.

550
00:23:13,994 --> 00:23:15,361
А значит...

551
00:23:15,362 --> 00:23:17,997
Верьте в "Романтичные технологии"!

552
00:23:17,998 --> 00:23:26,105
Отлично!

553
00:23:26,106 --> 00:23:29,809
Возможно, у компьютеров, как у людей, 
когда-нибудь будут свои права.

554
00:23:29,810 --> 00:23:32,828
Возможно, мы никогда не узнаем,
что отличает сознание человека

555
00:23:32,829 --> 00:23:35,014
от цифрового разума.

556
00:23:35,015 --> 00:23:36,482
Возможно, вопрос не в том,

557
00:23:36,483 --> 00:23:39,252
будут ли у нас отношения с технологией,

558
00:23:39,253 --> 00:23:41,888
а скорее в том, 
отличаемся ли мы друг от друга.

559
00:23:41,889 --> 00:23:46,292
Скажем, представьте себе пришельца,
у которого нет понятия

560
00:23:46,293 --> 00:23:48,962
о человеческом теле, 
и вот он видит меня впервые.

561
00:23:48,963 --> 00:23:50,396
Осознает ли он границу

562
00:23:50,397 --> 00:23:53,967
между организмом и устройством?

563
00:23:53,968 --> 00:23:57,503
Поймет ли он, 
что это сделали для меня другие люди,

564
00:23:57,504 --> 00:24:00,473
или же решит,
что они просто на мне выросли?

565
00:24:00,474 --> 00:24:03,343
Подумает ли он, 
что мой компьютер или телефон –

566
00:24:03,344 --> 00:24:08,514
это устройства, 
а не мои органы из металла?

567
00:24:08,515 --> 00:24:13,119
Обретут ли компьютеры
личность годы спустя

568
00:24:13,120 --> 00:24:18,858
или у всех у нас будет
общая киберличность?

569
00:24:18,859 --> 00:24:21,829
И, как обычно,
спасибо, что смотрели.

