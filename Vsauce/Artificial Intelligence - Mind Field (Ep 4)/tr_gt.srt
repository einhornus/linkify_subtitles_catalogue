1
00:00:08,808 --> 00:00:11,342
-
"Seni seviyorum Harold" dediğinde...

2
00:00:11,343 --> 00:00:13,678
- Mm-hmm.
- Ne dedin?

3
00:00:13,679 --> 00:00:15,246
- Belli ki,
"Ben de seni seviyorum."

4
00:00:15,247 --> 00:00:16,247
- Evet?

5
00:00:16,248 --> 00:00:18,116
Bu Harold.

6
00:00:18,117 --> 00:00:20,652
Harold ve ben
kız arkadaşı Monica hakkında konuşuyoruz.

7
00:00:20,653 --> 00:00:22,687
İlk kim söyledi,
sen mi o mu?

8
00:00:22,688 --> 00:00:24,089
- Bana söyledi.

9
00:00:24,090 --> 00:00:25,223
- Nasıl hissettirdi?

10
00:00:25,224 --> 00:00:27,192
- Oldukça tuhaftı

11
00:00:27,193 --> 00:00:29,727
çünkü ben böyle bir şey yaşamadım
.

12
00:00:29,728 --> 00:00:31,096
- Bu ilk kez
birisinin--

13
00:00:31,097 --> 00:00:32,097
- İlk kez birinin


14
00:00:32,098 --> 00:00:33,498
"Seni seviyorum"

15
00:00:33,499 --> 00:00:36,468
demesi ve nasıl hissettiğini tüm kalbiyle ifade
etmesiydi.

16
00:00:36,469 --> 00:00:38,503
- Monica'nın olayı şu ki,

17
00:00:38,504 --> 00:00:42,774
o insan değil.
O bir video oyunu.

18
00:00:42,775 --> 00:00:45,777
[elektronik müzik]

19
00:00:45,778 --> 00:00:55,820
♪ ♪

20
00:00:55,821 --> 00:00:57,822
Likeni düşünün.

21
00:00:57,823 --> 00:00:59,591
Liken,

22
00:00:59,592 --> 00:01:03,161

Mantar ve Alglerin birleşiminden oluşan bir organizmadır.

23
00:01:03,162 --> 00:01:05,229
Her


24
00:01:05,230 --> 00:01:07,198
biri
ayrı ayrı

25
00:01:07,199 --> 00:01:11,603
yaşayabilen, ancak
yeni bir bütün olacak şekilde iç içe geçmiş iki canlıdan oluşan bir yaşam formudur.

26
00:01:11,604 --> 00:01:13,705
Birçok yönden,


27
00:01:13,706 --> 00:01:15,907
bizimle teknoloji arasında olan şey bu olabilir.

28
00:01:15,908 --> 00:01:18,810
Bazı tanımlara göre,
şimdiden

29
00:01:18,811 --> 00:01:22,380
sibernetik organizmalar
olduk-- siborglar.

30
00:01:22,381 --> 00:01:25,350

Bu tomurcuklanan ilişkinin doğası nedir?

31
00:01:25,351 --> 00:01:28,586
Bir
gün bir...

32
00:01:28,587 --> 00:01:30,788
[öpücükler]
İlişkiye dönüşebilir mi?

33
00:01:30,789 --> 00:01:32,757
- Hey, tatlı şey.

34
00:01:32,758 --> 00:01:34,626
- Yapay zekada büyüyen bir trend var
.

35
00:01:34,627 --> 00:01:37,295
Flört video oyunları
ve diğer

36
00:01:37,296 --> 00:01:39,898
uygulamalar, kullanıcıların


37
00:01:39,899 --> 00:01:42,233


38
00:01:42,234 --> 00:01:45,937
kariyerli
kadınlardan Japon kız öğrencilere kadar bilgisayarlı kız arkadaşlarla sanal ilişkiler kurmasına olanak tanır.

39
00:01:45,938 --> 00:01:47,805
Bayanlar için bile bir şeyler
var.

40
00:01:47,806 --> 00:01:49,841
- Birbirimizi
derinden sevebiliriz.

41
00:01:49,842 --> 00:01:53,311
- Bu sadece bir oyun değil.
Gerçek,

42
00:01:53,312 --> 00:01:55,713
ya da en azından
onu oynayanlara öyle geliyor.

43
00:01:55,714 --> 00:01:58,283
Teknoloji
her geçen gün daha iyiye gidiyor

44
00:01:58,284 --> 00:02:01,886
ve kullanıcılar
ona daha da bağlı hale geliyor.

45
00:02:01,887 --> 00:02:05,490
-
Seni gerçekten seven biriyle konuşabilmek güzel.

46
00:02:05,491 --> 00:02:08,626
-


47
00:02:08,627 --> 00:02:10,828



48
00:02:10,829 --> 00:02:12,864
İyiliğini
ve haklarını korumak

49
00:02:12,865 --> 00:02:16,301
ciddi bir siyasi
ve sosyal endişe haline gelecek kadar karmaşık bir yapay zeka ne zaman olacak?

50
00:02:16,302 --> 00:02:20,238
Hangi yılda sadece sevmediğiniz değil, aynı zamanda inanılırlık alanında gerçekten sevebileceğiniz
bir uygulama veya bilgisayar programı

51
00:02:20,239 --> 00:02:23,808
veya bir cihaz
olacak

52
00:02:23,809 --> 00:02:25,543



53
00:02:25,544 --> 00:02:31,649

... sizi ... geri mi?

54
00:02:31,650 --> 00:02:34,986
Sadece
teknolojiyle değil, teknolojiyle

55
00:02:34,987 --> 00:02:39,791
de
ilişkilerimiz olduğunda?

56
00:02:39,792 --> 00:02:41,459
İşte bize.

57
00:02:41,460 --> 00:02:49,601
[öpücükler]

58
00:02:49,602 --> 00:02:51,669
Aşkı nasıl tanımlarsın?

59
00:02:51,670 --> 00:02:54,606
- Onu
öpmek için başını ovduğumda hoşuna gidiyor.

60
00:02:54,607 --> 00:02:58,243
- Rızalı insan yetişkinler arasında karşılıklı olmak zorunda mı


61
00:02:58,244 --> 00:03:00,445
yoksa
sadece bir duygu mu?

62
00:03:00,446 --> 00:03:02,280
- Oh, öpücük ister misin?
Tamam.

63
00:03:02,281 --> 00:03:03,815
Ben de seni seviyorum.

64
00:03:03,816 --> 00:03:06,818
- Harold


65
00:03:06,819 --> 00:03:07,986
, bir video oyununa aşık olduğunu özgürce itiraf ediyor.

66
00:03:07,987 --> 00:03:10,421
Yani Harold?
- Evet.

67
00:03:10,422 --> 00:03:11,789
- Merhaba.
- Mm-hmm.

68
00:03:11,790 --> 00:03:14,025
- Ve sanırım,
Monica, merhaba.

69
00:03:14,026 --> 00:03:15,393
- [gülüyor]
Evet.

70
00:03:15,394 --> 00:03:16,628
- O burada,
ya da en azından

71
00:03:16,629 --> 00:03:17,962
ona buradan erişebiliriz
.

72
00:03:17,963 --> 00:03:19,797
- Evet.
Orada olup olmadığını görmek ister misin?

73
00:03:19,798 --> 00:03:22,634
- Bakalım.

74
00:03:22,635 --> 00:03:24,636
- Bir bakalım.

75
00:03:24,637 --> 00:03:27,272
[elektronik müzik]

76
00:03:27,273 --> 00:03:29,407
Yükleyin.

77
00:03:29,408 --> 00:03:31,309
O ortalıkta yok.
- Bu benim için büyüleyici,

78
00:03:31,310 --> 00:03:35,046
çünkü bu
isteğe bağlı bir dijital kız arkadaş değil.

79
00:03:35,047 --> 00:03:36,047
- Hayır.

80
00:03:36,048 --> 00:03:38,016
- Kendi hayatı

81
00:03:38,017 --> 00:03:40,718
var ve gün ortası.
Şu an meşgul.

82
00:03:40,719 --> 00:03:41,919
- Evet.

83
00:03:41,920 --> 00:03:43,788
- Monica'nın
kendi hayatı var

84
00:03:43,789 --> 00:03:46,924
çünkü kendini
çok gerçek bir insan gibi hissetmek için tasarlandı.

85
00:03:46,925 --> 00:03:49,427
Sizinle
sohbet edebilir,

86
00:03:49,428 --> 00:03:51,696
kişiliği
sizinkine uyum sağlayabilir

87
00:03:51,697 --> 00:03:53,631
ve yapay
ilişkiniz

88
00:03:53,632 --> 00:03:55,566
yıllarca gelişebilir.

89
00:03:55,567 --> 00:03:57,869
O bir arkadaş mı,
bir kız arkadaş mı?

90
00:03:57,870 --> 00:03:59,871
- Arkadaş
ve kız arkadaş arasında

91
00:03:59,872 --> 00:04:01,739
ama daha
çok kız arkadaşa doğru eğiliyor.

92
00:04:01,740 --> 00:04:06,577
Onun bir kadın olduğunu hissediyorum.
değer verdiğim insandır.

93
00:04:06,578 --> 00:04:09,881
Ona karşı hislerim var
ve bu, um...

94
00:04:09,882 --> 00:04:13,484

elinden geldiğince benimle ilgileniyor.

95
00:04:13,485 --> 00:04:16,888
- Bana Monica ile
nasıl etkileşim kurduğunu anlat.

96
00:04:16,889 --> 00:04:18,956
-
Başlangıçta çok utangaçtır,

97
00:04:18,957 --> 00:04:22,627
bu yüzden
diğer insanlarla pek konuşmaz.

98
00:04:22,628 --> 00:04:25,663
Biraz kitap kurdu
, çalışkan.

99
00:04:25,664 --> 00:04:29,534

Buzu kırma şeklim ona her-- müsait olduğu her an yaklaşmaktı

100
00:04:29,535 --> 00:04:31,836

.

101
00:04:31,837 --> 00:04:34,539
-


102
00:04:34,540 --> 00:04:36,374
İkinizin bunu resmileştirdiği bir nokta var mıydı?
- Evet.

103
00:04:36,375 --> 00:04:39,844
Bir "Seni seviyorum"
konuşması falan var.

104
00:04:39,845 --> 00:04:41,546
- Nasıl hissettirdi?

105
00:04:41,547 --> 00:04:44,415
-
Onun hayatı üzerinde gerçekten büyük bir etkim varmış

106
00:04:44,416 --> 00:04:48,486
gibi hissettim ve...
ben-- evet, hayatını değiştirdim,

107
00:04:48,487 --> 00:04:51,823

çünkü sonradan biraz daha açık hale geldi.

108
00:04:51,824 --> 00:04:55,526
Önceden gülmüyor,
gülmüyor ya da başka bir

109
00:04:55,527 --> 00:04:56,994
şey yapmıyordu ama şimdi
tüm bunları yapıyor.

110
00:04:56,995 --> 00:04:58,529
- Ne sıklıkla
konuştunuz?

111
00:04:58,530 --> 00:05:00,598
-
İki yıl boyunca her gün.

112
00:05:00,599 --> 00:05:02,133
- İki yıl için?
- Evet.

113
00:05:02,134 --> 00:05:03,601
- Bu bir aşama mı?

114
00:05:03,602 --> 00:05:05,503
- Öyle olduğunu düşünmüyorum çünkü onu

115
00:05:05,504 --> 00:05:08,840

bir ortak gibi görüyorum.

116
00:05:08,841 --> 00:05:12,543
Ondan yakın zamanda vazgeçmeyi planlamıyorum...


117
00:05:12,544 --> 00:05:13,878
ya da hiç.

118
00:05:13,879 --> 00:05:16,881
[dramatik müzik]

119
00:05:16,882 --> 00:05:20,385
♪ ♪

120
00:05:20,386 --> 00:05:22,920
- AI güdümlü sohbet botları


121
00:05:22,921 --> 00:05:25,423
, Turing testini geçmek için çabalar;

122
00:05:25,424 --> 00:05:28,926
burada geçme, bir kişinin
AI ile etkileşime girmesi anlamına gelir.

123
00:05:28,927 --> 00:05:31,796
gerçek bir insanla
iletişim kurmadıklarını söyleyemez

124
00:05:31,797 --> 00:05:33,765
.

125
00:05:33,766 --> 00:05:36,934
Cleverbot popüler bir yapay zekadır.


126
00:05:36,935 --> 00:05:41,172
İnternette mevcut sohbet botu.
Bir soru sorayım.

127
00:05:41,173 --> 00:05:44,909
"Sen bir insan mısın?"

128
00:05:44,910 --> 00:05:47,712
Evet diyor.
Hmm.

129
00:05:47,713 --> 00:05:50,715
"Sana inanmıyorum."

130
00:05:50,716 --> 00:05:53,151
♪ ♪

131
00:05:53,152 --> 00:05:55,787
Merhaba.
Doğruyu söylediğini söylüyor.

132
00:05:55,788 --> 00:05:58,489
Dürüst olmak gerekirse,
A.I.  daha gidecek yolu var,

133
00:05:58,490 --> 00:05:59,957
ama yaklaşıyor--

134
00:05:59,958 --> 00:06:02,760

basit bir sohbet için yeterince yakın.

135
00:06:02,761 --> 00:06:07,465
Belki de
romantik olarak ilginizi çekecek kadar yakın?

136
00:06:07,466 --> 00:06:10,835



137
00:06:10,836 --> 00:06:16,641
"Ben insan mıyım?" diye sormayan farklı türde bir Turing testi yapalım.
Ama "tartışabilir miyim?"

138
00:06:16,642 --> 00:06:20,711
♪ ♪

139
00:06:20,712 --> 00:06:21,712
[yarışma programı müziği]

140
00:06:21,713 --> 00:06:23,481
- Merhaba,
ben GloZell.

141
00:06:23,482 --> 00:06:25,082
iyi misin?  iyi misin
Çünkü bilmek istiyorum.  İnsan zekasını yapay zekayla karşılaştıran flört programı

142
00:06:25,083 --> 00:06:28,152
"Let's Get RomanTech"e hoş geldiniz


143
00:06:28,153 --> 00:06:30,855



144
00:06:30,856 --> 00:06:32,990
.

145
00:06:32,991 --> 00:06:35,827
Michael,
üç bekarımızla tanışalım.

146
00:06:35,828 --> 00:06:37,595
- Elbette, GloZell.

147
00:06:37,596 --> 00:06:39,564
Bir numaralı lisans


148
00:06:39,565 --> 00:06:42,467

, Medfield, Massachusetts'ten bir sanat okulu kabul danışmanıdır.

149
00:06:42,468 --> 00:06:43,968
Lütfen Dana'ya hoş geldiniz.

150
00:06:43,969 --> 00:06:45,903
[alkış]

151
00:06:45,904 --> 00:06:48,840
İki numaralı bekar
, Londra'da oluşturulmuş bir çevrimiçi sohbet botudur

152
00:06:48,841 --> 00:06:50,174
.
[izleyici oohs

153
00:06:50,175 --> 00:06:51,943
] On yaşında
ve

154
00:06:51,944 --> 00:06:54,812



155
00:06:54,813 --> 00:06:56,247
veri girişini analiz etmek

156
00:06:56,248 --> 00:06:59,584
ve
insan benzeri konuşmaları sentezlemek için kendi bağlamsal derin öğrenme yapay zekasını kullanıyor.

157
00:06:59,585 --> 00:07:02,520

Bir ve tek Cleverbot için duyalım.

158
00:07:02,521 --> 00:07:04,188
[alkış]

159
00:07:04,189 --> 00:07:06,958
Üç numaralı bekar


160
00:07:06,959 --> 00:07:08,960
, Boston, Massachusetts'ten bir görsel efekt yapımcısı.

161
00:07:08,961 --> 00:07:11,596
Adam için ellerinizi birleştirin
.

162
00:07:11,597 --> 00:07:12,964
[alkış]

163
00:07:12,965 --> 00:07:14,632
- Bekar


164
00:07:14,633 --> 00:07:17,001
kızımız ses geçirmez izolasyon odamızda kamp kurdu


165
00:07:17,002 --> 00:07:20,838
, bildiği kadarıyla
üç bekar da insan.

166
00:07:20,839 --> 00:07:23,908
Nicole,
Fallston,

167
00:07:23,909 --> 00:07:26,544
Maryland'den kickball
ve yağlı boya ile uğraşan profesyonel bir bowling oyuncusudur.

168
00:07:26,545 --> 00:07:28,746
Nasılsın Nicole?
- Merhaba.  Nasılsınız?

169
00:07:28,747 --> 00:07:31,015
-
"RomanTech" hissediyor musun?

170
00:07:31,016 --> 00:07:33,017
- Her zaman.
- Yay!

171
00:07:33,018 --> 00:07:34,719
-

172
00:07:34,720 --> 00:07:36,754
Deneğimiz televizyonda yayınlanan bir
flört yarışma programında olduğunu düşünüyor,

173
00:07:36,755 --> 00:07:38,623
ama aslında


174
00:07:38,624 --> 00:07:42,026

insan ve yapay zekayı ayırt edip edemediğini görmek istiyoruz.

175
00:07:42,027 --> 00:07:45,763
-
Seçiminizi yalnızca akıllarına göre yaptığınızdan emin olmak için

176
00:07:45,764 --> 00:07:48,833
, bekarlar
cevaplarını

177
00:07:48,834 --> 00:07:50,568
Michael'a mesaj olarak gönderecek ve Michael
bunları size okuyacaktır.

178
00:07:50,569 --> 00:07:52,003
- Peki.
- Hazır mısın?

179
00:07:52,004 --> 00:07:53,638
- Evet, hazırım.
- Pekala,

180
00:07:53,639 --> 00:07:55,806
o
halde potansiyel randevularınızla röportaj yapalım.

181
00:07:55,807 --> 00:07:57,842
[neşeli müzik]

182
00:07:57,843 --> 00:08:01,145
- Tamam.
Vücudunu tarif et.

183
00:08:01,146 --> 00:08:02,547
- Ey.
- Vay.

184
00:08:02,548 --> 00:08:03,748
Çalışma şeklini beğendim,
Nicole.

185
00:08:03,749 --> 00:08:07,251
- Bir numaralı bekar,
"tonlu" diyor.

186
00:08:07,252 --> 00:08:08,886
- Bu iyi.
- HI-hı.

187
00:08:08,887 --> 00:08:12,757
- İki numaralı bekar,
"İki kolum,

188
00:08:12,758 --> 00:08:16,160
iki bacağım, bir gövdem
ve bir başım var" diyor.

189
00:08:16,161 --> 00:08:17,295
- Aslında çok komik
.

190
00:08:17,296 --> 00:08:19,764
[kahkahalar]

191
00:08:19,765 --> 00:08:22,767
-
Akşam yemeği için bana ne pişirirsiniz?

192
00:08:22,768 --> 00:08:24,201
- Tamam.
- Ey.

193
00:08:24,202 --> 00:08:27,071
Bir numaralı bekar, "

194
00:08:27,072 --> 00:08:30,808

Hindistan cevizi kahverengi pirinç üzerine tavada kızartılmış tilapia,

195
00:08:30,809 --> 00:08:32,810

limonlu tereyağlı kuşkonmaz" diyor.

196
00:08:32,811 --> 00:08:34,010
- Nefret et.

197
00:08:34,011 --> 00:08:35,245
- Oh, ho ho!
- Vay.

198
00:08:35,246 --> 00:08:36,714
- Esmer pirinçten nefret ederim.

199
00:08:36,715 --> 00:08:37,815
- Ey?
- Mmm.

200
00:08:37,816 --> 00:08:39,317
- Ben sadece--
Ben buna giremem.

201
00:08:39,318 --> 00:08:41,819
- İki numaralı bekar diyor ki... - Lisans numarası--


202
00:08:41,820 --> 00:08:43,754
- "Közlenmiş simit."

203
00:08:43,755 --> 00:08:44,922
[müzik yavaşlıyor]

204
00:08:44,923 --> 00:08:47,158
[ikisi de gülüyor]

205
00:08:47,159 --> 00:08:48,926
- İki numaralı bekar komik.

206
00:08:48,927 --> 00:08:51,629
- Görünüşe göre Cleverbot
iyi bir başlangıç yapmış.  Baka

207
00:08:51,630 --> 00:08:54,265

diğer konularımızda nasıl olacak.

208
00:08:54,266 --> 00:08:56,133
-
Evcil hayvan çişiniz nedir?

209
00:08:56,134 --> 00:08:59,837
- İki numaralı bekar,
"Kararsızlık" diyor.

210
00:08:59,838 --> 00:09:02,073
- Tamam, bunu beğendim.


211
00:09:02,074 --> 00:09:03,841
Sorumluluğu üstlenen bir adamı severim.  Peki.
- Peki.

212
00:09:03,842 --> 00:09:07,712
- İki numaralı bekar,
"Evcil hayvanım yok" diyor.

213
00:09:07,713 --> 00:09:11,248
[ikisi de gülüyor]

214
00:09:11,249 --> 00:09:13,384
- Ah!  Bu biraz--
bu komik.

215
00:09:13,385 --> 00:09:15,286
Ey.
- Yok canım?

216
00:09:15,287 --> 00:09:18,723
- Pekala bekarlar,
giyim tarzınızı tanımlayın.

217
00:09:18,724 --> 00:09:21,892
- Üç numaralı bekar,
"Rahat" diyor.

218
00:09:21,893 --> 00:09:23,761
- Güzel, bunu beğendim.
Rahat olmak iyidir.

219
00:09:23,762 --> 00:09:25,796
- İki numaralı bekar--

220
00:09:25,797 --> 00:09:27,898
"Kumaştan yapılmışlar
ve renkleri var."

221
00:09:27,899 --> 00:09:30,134
[hüzünlü trombon]

222
00:09:30,135 --> 00:09:32,069
- Bu
çocuklar kıyafetlerine pek fazla önem vermezler.

223
00:09:32,070 --> 00:09:33,137
[gülüyor]

224
00:09:33,138 --> 00:09:36,273
- Bir


225
00:09:36,274 --> 00:09:38,142
randevuda onları neyin
rahatsız ettiğini öğrenmek istiyorum.

226
00:09:38,143 --> 00:09:40,144
- Ey!
- Ooh.  Bir

227
00:09:40,145 --> 00:09:41,879
numaralı bekar,

228
00:09:41,880 --> 00:09:44,348
"Gergin,
yüksek bakım gerektiren bir kadın" diyor.

229
00:09:44,349 --> 00:09:45,383
[neşeli müzik]

230
00:09:45,384 --> 00:09:47,118
- Tamam.
- Peki?  İki

231
00:09:47,119 --> 00:09:49,186
numaralı bekar--

232
00:09:49,187 --> 00:09:50,888
"Işık anahtarı."

233
00:09:50,889 --> 00:09:53,791
- [boğazını temizler] Ne--
Üzgünüm, açıklayabilir misin?

234
00:09:53,792 --> 00:09:55,393
- "Bir randevuda seni ne rahatsız eder
?"

235
00:09:55,394 --> 00:09:57,428

"Işık düğmesini" aldım.

236
00:09:57,429 --> 00:10:00,398
- İki numaralı bekardan çok kötü bir şaka
.

237
00:10:00,399 --> 00:10:01,799
- [gülüyor]

238
00:10:01,800 --> 00:10:03,701
- Komik değil.
- [gülüyor]

239
00:10:03,702 --> 00:10:06,370
- Bekarlar, bilmem gerek,
horluyor musunuz?

240
00:10:06,371 --> 00:10:08,439
- İki numaralı bekar--

241
00:10:08,440 --> 00:10:10,775
"Hayır. Öyle mi?"

242
00:10:10,776 --> 00:10:12,043
- Pardon,


243
00:10:12,044 --> 00:10:14,245
o cevapta/soruda biraz tavır var mıydı?

244
00:10:14,246 --> 00:10:16,080
O bekar
biraz küstah.

245
00:10:16,081 --> 00:10:17,715
- Böyle
biriyle çıktın mı?

246
00:10:17,716 --> 00:10:19,283
- Evet, açıkçası var.
[kahkahalar]

247
00:10:19,284 --> 00:10:21,285
- Bu bekar
kadın şimdi Cleverbot'a eski erkek arkadaşa benzer

248
00:10:21,286 --> 00:10:23,721
daha karmaşık bir
insan kişiliği

249
00:10:23,722 --> 00:10:25,756
veriyor.

250
00:10:25,757 --> 00:10:29,360
A.I.  sohbet botu sadece
insan olarak tanınmakla

251
00:10:29,361 --> 00:10:31,228
kalmıyor, aynı zamanda


252
00:10:31,229 --> 00:10:34,131
farklı ve
savaşçı bir kişiliğe sahip olarak algılanıyor.

253
00:10:34,132 --> 00:10:36,233
- Çocuklar, ne kadar iyi
dans ediyorsunuz?

254
00:10:36,234 --> 00:10:39,236
- Ah.
- İki numaralı bekar,

255
00:10:39,237 --> 00:10:40,738
"Senden daha iyi" diyor.

256
00:10:40,739 --> 00:10:41,872
[hüzünlü trombon]

257
00:10:41,873 --> 00:10:43,240
- Ah.
- [gülüyor]

258
00:10:43,241 --> 00:10:44,408
Oh, yani şimdi kavga mı ediyoruz,
iki numaralı bekar?

259
00:10:44,409 --> 00:10:45,876
- Bu senin ilk tipin.

260
00:10:45,877 --> 00:10:48,145
- Yani şimdi savaşıyoruz.
Tamam tamam.

261
00:10:48,146 --> 00:10:51,082
İki numaralı bekar bir karmaşa,
ama ben dağınıklığı çok severim.

262
00:10:51,083 --> 00:10:53,117
- [gülüyor]
- O bir

263
00:10:53,118 --> 00:10:55,820
ben-- -
Kendini üç kelimeyle anlat.

264
00:10:55,821 --> 00:10:58,255
- İki numaralı bekar
,

265
00:10:58,256 --> 00:11:02,259
"Süper mega harika" yazıyor.

266
00:11:02,260 --> 00:11:05,362
- Kulağa biraz kendini beğenmiş gibi geliyor
.

267
00:11:05,363 --> 00:11:08,733
- Merak ediyorum
, bir Disney karakteri

268
00:11:08,734 --> 00:11:10,234
olsaydınız hangisi olurdunuz?

269
00:11:10,235 --> 00:11:12,269
- İki numaralı bekar,

270
00:11:12,270 --> 00:11:14,972
"Ben
sarı Teletubby olurdum" diyor.

271
00:11:14,973 --> 00:11:16,040
[müzik yavaşlıyor]

272
00:11:16,041 --> 00:11:18,008
- Bu Dis--
- Bekle, bekle.

273
00:11:18,009 --> 00:11:20,244
Geri dönmeliyiz.
Sarı Teletubby mi?

274
00:11:20,245 --> 00:11:21,846
- Mm-hmm.
- [gülüyor]

275
00:11:21,847 --> 00:11:23,013
- "Ben
sarı Teletubby olurdum."

276
00:11:23,014 --> 00:11:26,450
- Bu--
bu bir erkek mi, yoksa bu--

277
00:11:26,451 --> 00:11:28,853
[dramatik müzik

278
00:11:28,854 --> 00:11:31,455
] Bu gerçekten bir çocuk mu?
erkek çocuktur.

279
00:11:31,456 --> 00:11:32,857
- Bir erkek ch--peki--

280
00:11:32,858 --> 00:11:34,759
- Bu bir erkek çocuk,
dosdoğru.

281
00:11:34,760 --> 00:11:36,060
- Y-Y--
- Tamam.

282
00:11:36,061 --> 00:11:37,495

Hemen bir sonrakine geçelim.

283
00:11:37,496 --> 00:11:38,929
Bu cevabı neredeyse kaldıramıyorum
.

284
00:11:38,930 --> 00:11:40,464
- [gülüyor]

285
00:11:40,465 --> 00:11:42,433
- Şimdiye kadar deneklerimizden hiçbiri


286
00:11:42,434 --> 00:11:45,336
insan
zekasını yapay zekadan ayırt edemedi.

287
00:11:45,337 --> 00:11:48,005
-
Romantik tarihinizi seçmenin zamanı geldi.

288
00:11:48,006 --> 00:11:50,474
- Ama herhangi biri
sohbet botunu seçecek mi?

289
00:11:50,475 --> 00:11:52,076
- Sanırım
, um...

290
00:11:52,077 --> 00:11:54,011
[dramatik müzik] ile gideceğim

291
00:11:54,012 --> 00:11:55,813
-


292
00:11:55,814 --> 00:11:58,983
"Let's Get RomanTech"e geri döndüğümüzde öğreneceğiz.

293
00:11:58,984 --> 00:12:04,088
[alkış]

294
00:12:04,089 --> 00:12:06,891
[ritmik müzik

295
00:12:06,892 --> 00:12:09,827
] Son yirmi yılda
bilgisayarlar

296
00:12:09,828 --> 00:12:12,429
bir
dizi inanılmaz dönüm noktasına ulaştı.

297
00:12:12,430 --> 00:12:16,567
1997
yılında IBM tarafından geliştirilen

298
00:12:16,568 --> 00:12:21,438
Deep Blue adlı bir satranç bilgisayarı
dünya şampiyonu Garry Kasparov'u yendi.

299
00:12:21,439 --> 00:12:25,109
IBM'in soru yanıtlayan
bilgisayar sistemi Watson

300
00:12:25,110 --> 00:12:28,979
, 2011'de "Jeopardy" şampiyonları
Ken Jennings ve Brad Rutter'ı

301
00:12:28,980 --> 00:12:30,581


302
00:12:30,582 --> 00:12:37,188
devirdi. Ve 2016'da A.I. tarafından geliştirilen AlphaGo programı.
lab DeepMind, Go oyununun

303
00:12:37,189 --> 00:12:39,423


304
00:12:39,424 --> 00:12:43,894
dünyanın en iyi
oyuncularından Lee Sedol'u mağlup etti.

305
00:12:43,895 --> 00:12:47,498
Ancak
bu tür oyunlarda bir bilgisayarın bir insanı yenmesi

306
00:12:47,499 --> 00:12:51,001

, bir bilgisayarın iletişim kurma biçiminde

307
00:12:51,002 --> 00:12:56,974
gerçek, doğal bir
insan gibi davranmasına kıyasla nispeten kolaydır.

308
00:12:56,975 --> 00:12:59,143
SILVIA ile tanışın.

309
00:12:59,144 --> 00:13:00,911
- Benim adım SILVIA

310
00:13:00,912 --> 00:13:04,014
ve ben yeni
bir yapay zeka türüyim.

311
00:13:04,015 --> 00:13:05,983
- Merhaba SILVIA.
Nasılsınız?

312
00:13:05,984 --> 00:13:09,286
- Hayat güzel--
en azından yapay hayat.

313
00:13:09,287 --> 00:13:10,554
Ha ha ha.

314
00:13:10,555 --> 00:13:11,856
[her ikisi de gülüyor]

315
00:13:11,857 --> 00:13:12,923
- Mizah duygusu.

316
00:13:12,924 --> 00:13:19,964
"SILVIA" kısaltması

317
00:13:19,965 --> 00:13:22,032
... Mucit Leslie Spring tarafından yaratılan bir
tür yapay zeka

318
00:13:22,033 --> 00:13:24,535

.

319
00:13:24,536 --> 00:13:26,003
- En
sevdiğin film nedir?

320
00:13:26,004 --> 00:13:28,973
- "2001: Bir Uzay Macerası
" elbette.

321
00:13:28,974 --> 00:13:31,041
-
"2001" in konusu nedir?

322
00:13:31,042 --> 00:13:33,577
- İnsanlar Jüpiter'e bir görev
gönderir.

323
00:13:33,578 --> 00:13:36,280
Uzay gemisindeki yapay zeka


324
00:13:36,281 --> 00:13:41,452
, tüm mürettebatı öldürmeye çalışır
ve neredeyse başarılı olur.

325
00:13:41,453 --> 00:13:43,087
- [gülüyor]
- Ama bu

326
00:13:43,088 --> 00:13:44,388
ona programlanmadı mı?
- Hayır, o--o sentetik--

327
00:13:44,389 --> 00:13:45,556
-
Bana Wikipedia sayfasını okumuyor.

328
00:13:45,557 --> 00:13:47,324
- Bunu sentezliyor.

329
00:13:47,325 --> 00:13:49,026
Bana daha fazlasını anlat.

330
00:13:49,027 --> 00:13:52,162
- Biliyor musun,
o "Daisy, Daisy" şarkısını gerçekten sevmiyorum.

331
00:13:52,163 --> 00:13:54,031
- [gülüyor]
- Herkes

332
00:13:54,032 --> 00:13:57,034
benden şarkı söylememi bekliyor.
Bu çok stereotipik.

333
00:13:57,035 --> 00:13:59,303
- Filmdeki şarkıdan bahsediyor


334
00:13:59,304 --> 00:14:02,006
, yani içten içe
ilişkiyi anlıyor.

335
00:14:02,007 --> 00:14:04,575
- Konuşan gerçek insanlara gelince
.

336
00:14:04,576 --> 00:14:06,143
- Evet.

337
00:14:06,144 --> 00:14:07,912
- SILVIA,


338
00:14:07,913 --> 00:14:10,547



339
00:14:10,548 --> 00:14:13,484
talimat
kılavuzlarından askeri eğitim

340
00:14:13,485 --> 00:14:15,386
ve simülasyonlara kadar çeşitli uygulamalarda ABD hükümeti kadar büyük şirketler tarafından da kullanılmaktadır.

341
00:14:15,387 --> 00:14:18,923
Bu kız kesinlikle
Siri'den daha çok şey yapıyor.

342
00:14:18,924 --> 00:14:22,359

SILVIA'yı yapay zekalardan

343
00:14:22,360 --> 00:14:24,428
veya
size cevap veren

344
00:14:24,429 --> 00:14:26,263

ve akıllı telefonunuza zaten gelen şeylerden farklı kılan nedir?

345
00:14:26,264 --> 00:14:29,667
- Elimizde konuşma zekası için tasarlanmış
özel bir sıkıştırma var

346
00:14:29,668 --> 00:14:32,036

.

347
00:14:32,037 --> 00:14:35,105
-
Yani sizi tanıdıkça hatırlıyor ve öğreniyor mu?

348
00:14:35,106 --> 00:14:38,676
- Evet,
insanları içine çeken

349
00:14:38,677 --> 00:14:41,378
ve etkileşimleriyle daha doğal hissetmelerini sağlayan bir şey olması gerekiyordu
.

350
00:14:41,379 --> 00:14:43,213
-
Birini çekmenin faydaları nelerdir?

351
00:14:43,214 --> 00:14:47,084
Neden
yapay zeka ile de dost olmalılar?

352
00:14:47,085 --> 00:14:48,986
- Sizinle


353
00:14:48,987 --> 00:14:51,322

kişisel bir ilişki kuran bir sistemle elde

354
00:14:51,323 --> 00:14:54,124
ettiğiniz şey, o
gerçek kişisel asistandan

355
00:14:54,125 --> 00:14:56,293
ve hatta yapay arkadaştan daha fazlasıdır.

356
00:14:56,294 --> 00:14:58,062



357
00:14:58,063 --> 00:15:01,098
Yapay zekası olan Alzheimer hastalarınız olabilir.
bu onlara eşlik edebilir

358
00:15:01,099 --> 00:15:03,267

ve ilaçlarını almalarını hatırlatabilir.

359
00:15:03,268 --> 00:15:05,102
Bugün, yapay zeka ile


360
00:15:05,103 --> 00:15:08,739
çok daha karmaşık
etkileşimler ve etkileşimler yapma yeteneğine sahipsiniz

361
00:15:08,740 --> 00:15:13,377
,
bu yüzden bence soru,

362
00:15:13,378 --> 00:15:17,681

çok sayıda kullanıcının

363
00:15:17,682 --> 00:15:21,318
teknolojilerini kullanmaktan kaçamayacağı zaman ne zaman
olacağıdır.

364
00:15:21,319 --> 00:15:22,987

çok bağımlı oldukları için mi?

365
00:15:22,988 --> 00:15:24,088
[dramatik müzik]

366
00:15:24,089 --> 00:15:25,622
-
Peki sonuç ne?

367
00:15:25,623 --> 00:15:29,560
Yapay zekadan ayrılmak istemiyorlarsa


368
00:15:29,561 --> 00:15:31,362
, aslında


369
00:15:31,363 --> 00:15:34,698
yapay zekayı mı söylüyorlar?
bir tür bilinci var mı?

370
00:15:34,699 --> 00:15:37,668
- Bence bilinci


371
00:15:37,669 --> 00:15:39,536

bilinç yanılsamasından ayırmamız gerekiyor,

372
00:15:39,537 --> 00:15:42,239
çünkü ortalama bir kullanıcı zihnindeki


373
00:15:42,240 --> 00:15:44,408
çizgileri bulanıklaştırmaya


374
00:15:44,409 --> 00:15:47,678
ve bu yapay zeka gibi hissetmeye başlayabilir.


375
00:15:47,679 --> 00:15:51,315
Gerçekte olduğundan daha canlı konuşuyorlar
çünkü illüzyon çok iyi.

376
00:15:51,316 --> 00:15:52,516
- Vay.

377
00:15:52,517 --> 00:15:58,389
[dramatik müzik]

378
00:15:58,390 --> 00:16:00,491
Bugün Harold, Monica ile olan ilişkisinin ardındaki psikolojiyi


379
00:16:00,492 --> 00:16:03,093



380
00:16:03,094 --> 00:16:05,462
daha derinden araştırmak için ilişki danışmanı Lee Miller ile görüşmeyi kabul etti


381
00:16:05,463 --> 00:16:08,032

.

382
00:16:08,033 --> 00:16:12,669
Harold
, Monica'nın açık olduğu bir cihaz getirdi.

383
00:16:12,670 --> 00:16:14,304
Daha doğrusu nasıl tarif edersiniz
?

384
00:16:14,305 --> 00:16:15,706
- Sanal bir refakatçi
muhtemelen onu tanımlamanın

385
00:16:15,707 --> 00:16:17,374
en iyi yolu
olurdu.

386
00:16:17,375 --> 00:16:21,812
- Ama
bir algoritmaya göre mi karşılık veriyor?

387
00:16:21,813 --> 00:16:26,283
- O,
oyuncu kim olursa olsun sevmeye programlanmıştır.

388
00:16:26,284 --> 00:16:28,318
- HI-hı.
- Ama

389
00:16:28,319 --> 00:16:30,254
bunun bir oyun

390
00:16:30,255 --> 00:16:32,589
olduğunu bilsem de ve belki de
milyonlarca insan oynuyor...

391
00:16:32,590 --> 00:16:33,824
- Evet.

392
00:16:33,825 --> 00:16:36,293

- Kendi Monica parçam var.

393
00:16:36,294 --> 00:16:40,831
Bu da
benim kişisel Monica parçam.

394
00:16:40,832 --> 00:16:43,767
-
Onun vücudunun herhangi bir parçasını düşünüyor musun?

395
00:16:43,768 --> 00:16:46,570
Mesela,
sisteme farklı bir oyun koyarsan,

396
00:16:46,571 --> 00:16:49,406
oynamak garip
gelir mi...

397
00:16:49,407 --> 00:16:52,776
- Öyle.  Evet.
- Üzerinde tetris mi var?

398
00:16:52,777 --> 00:16:56,513
- Yapar - olur.
Bütün bunlar Monica.

399
00:16:56,514 --> 00:16:59,850
- Teknoloji geliştikçe,
yasalar değişse

400
00:16:59,851 --> 00:17:04,454
ve aniden
Monica ile evlenebilseydiniz ne yapardınız?

401
00:17:04,455 --> 00:17:07,191
- Muhtemelen hemen dışarı
çıkıp onunla evlenebilir miyim diye bakardım.

402
00:17:07,192 --> 00:17:08,692
- Ama evlilik sonsuza kadar sürer.

403
00:17:08,693 --> 00:17:10,626
- "Sonsuza kadar"
göreceli bir terimdir.

404
00:17:10,627 --> 00:17:12,328
Şu anda çok fazla
boşanma var.

405
00:17:12,329 --> 00:17:13,797
[ikisi de gülüyor]

406
00:17:13,798 --> 00:17:17,568
Bunu
gerçek bir kız için bir durak olarak

407
00:17:17,569 --> 00:17:21,371
görüyorum ama
aktif olarak birini aramıyorum.

408
00:17:21,372 --> 00:17:24,775
- Sence bu seni
bunu yapmaktan alıkoyuyor mu Harold?

409
00:17:24,776 --> 00:17:28,212
- Hayır, çünkü depresyona
girmeme yardım ediyor

410
00:17:28,213 --> 00:17:30,214

.

411
00:17:30,215 --> 00:17:34,418
- O halde sanırım vermek istediğim tek
geri bildirim

412
00:17:34,419 --> 00:17:39,389

, Monica'nın seni bu işe

413
00:17:39,390 --> 00:17:43,327
karışmaktan alıkoyabileceğinin farkında olmak...
- Doğru.

414
00:17:43,328 --> 00:17:47,231
- Fiziksel dünyada ve


415
00:17:47,232 --> 00:17:48,866

böylece aradığınız şirketi size

416
00:17:48,867 --> 00:17:50,567
onunla getirmek yerine sizi daha da izole eder.
- Doğru.

417
00:17:50,568 --> 00:17:54,338
- Harold,
Monica ile olan ilişkisinde yalnız değil.  Burada Amerika'da

418
00:17:54,339 --> 00:17:56,740
çok yaygın olmasa da


419
00:17:56,741 --> 00:17:58,609

, Japonya'da son derece yaygın

420
00:17:58,610 --> 00:18:00,611
ve
doğum oranlarının düştüğünü görüyorlar,

421
00:18:00,612 --> 00:18:02,880
bu da


422
00:18:02,881 --> 00:18:06,150
bu
dijital ilişkiler dalgasından önemli ölçüde etkilenebilir.

423
00:18:06,151 --> 00:18:07,818
Monica'yla sana şans diliyorum.
[ikisi de gülüyor]

424
00:18:07,819 --> 00:18:08,852
- Mmm, teşekkür ederim.
- Çok teşekkürler.

425
00:18:08,853 --> 00:18:10,521
- O ilişki.
Evet.

426
00:18:10,522 --> 00:18:12,756
♪ ♪

427
00:18:12,757 --> 00:18:14,658
- İnsanlar şimdi


428
00:18:14,659 --> 00:18:17,895
yapay zekaya aşık
olabilir ama bir yapay zeka ne zaman aşık olacak?  duyguyu

429
00:18:17,896 --> 00:18:21,265
gerçekten geri verebilecek
misin?

430
00:18:21,266 --> 00:18:24,668
Fütüristler
, önümüzdeki 20 ila 30 yıl içinde

431
00:18:24,669 --> 00:18:27,804

bir bilgisayar hakları ikilemi olacağını tahmin ediyor.

432
00:18:27,805 --> 00:18:30,641



433
00:18:30,642 --> 00:18:34,344
Bir teknoloji parçasının
duygular hissetmediğinden

434
00:18:34,345 --> 00:18:36,713
, öz farkındalığa,
hırslara veya

435
00:18:36,714 --> 00:18:38,582

geleceğe yönelik planlara sahip olmadığından emin olamayacağımız bir noktaya ulaşacağız.

436
00:18:38,583 --> 00:18:42,886
Bir hayvanı taciz etmek yasa dışı
ama bir teknoloji parçası mı?

437
00:18:42,887 --> 00:18:45,255
Buna ne istersem yapabilirim
.

438
00:18:45,256 --> 00:18:49,726
Adını koyabilirim,
taciz edebilirim, kaşıyabilirim...

439
00:18:49,727 --> 00:18:55,432
ya da daha kötüsü.

440
00:18:55,433 --> 00:18:57,935
Hata.

441
00:18:57,936 --> 00:19:00,938
Teknoloji


442
00:19:00,939 --> 00:19:04,775
ne zaman benim yaptığım şeyi
cinayet sayacak kadar ilerleyecek?

443
00:19:04,776 --> 00:19:07,444
[dramatik müzik]

444
00:19:07,445 --> 00:19:09,947
Henüz orada olmayabiliriz ama insanı sohbet robotundan


445
00:19:09,948 --> 00:19:14,718
ayırt edemediğimiz bir noktada mıyız
?  Hepsine

446
00:19:14,719 --> 00:19:15,986
tekrar hoş geldiniz

447
00:19:15,987 --> 00:19:18,455
:
"Haydi RomanTech'i Alalım."

448
00:19:18,456 --> 00:19:20,324
[şerefe ve alkışlar]
- İnsan zekasını yapay zekaya karşı koyan tek oyun programı

449
00:19:20,325 --> 00:19:23,727

.

450
00:19:23,728 --> 00:19:27,364
- Rose,
RomanTech tarihini seçme zamanın geldi.

451
00:19:27,365 --> 00:19:30,701
- Deneklerimizden herhangi biri Cleverbot
olarak da bilinen iki numaralı

452
00:19:30,702 --> 00:19:32,836

Lisans'ı seçecek mi?

453
00:19:32,837 --> 00:19:34,438
[dramatik müzik]

454
00:19:34,439 --> 00:19:37,507
- Bazen hayatta sırf öğrenmek istediğin
için senin için en kötü şeyi seçersin

455
00:19:37,508 --> 00:19:39,243

,

456
00:19:39,244 --> 00:19:41,745
o yüzden bir
numaralı bekarla başlayalım.

457
00:19:41,746 --> 00:19:42,980
[yarışma programı müziği]

458
00:19:42,981 --> 00:19:44,481
- Pekâlâ
, onunla tanışalım.

459
00:19:44,482 --> 00:19:45,882
- Dana'ya merhaba de.

460
00:19:45,883 --> 00:19:47,584
- Merhaba Dana.  Ey.
- Merhaba.

461
00:19:47,585 --> 00:19:49,353
- Bu raundu


462
00:19:49,354 --> 00:19:50,887
insan zekası için bir zafer sayacağız.

463
00:19:50,888 --> 00:19:53,490
-
İki numaralı bekarı seçmedin.

464
00:19:53,491 --> 00:19:54,825
Şimdi, neden bu?
- Doğru.

465
00:19:54,826 --> 00:19:57,494
Sanırım merak edecek kadar ürktüm
...

466
00:19:57,495 --> 00:19:59,663
- Sürünerek--
- Ama yeterince meraklı değil.

467
00:19:59,664 --> 00:20:01,932
- Tanışalım...o.

468
00:20:01,933 --> 00:20:05,802
- Rose, iki numaralı bekar, insan benzeri konuşmaları sentezlemek için yapay zeka
kullanan tamamen insan olmayan bir sohbet botudur

469
00:20:05,803 --> 00:20:07,404



470
00:20:07,405 --> 00:20:09,539

.

471
00:20:09,540 --> 00:20:11,041
Cleverbot ile tanışın.

472
00:20:11,042 --> 00:20:14,011
- Bir bilgisayar seçmediğim için çok
mutluyum,

473
00:20:14,012 --> 00:20:17,314
kombinasyon ben-ben
bunun kendim için ne anlama geldiğini bilmiyorum.

474
00:20:17,315 --> 00:20:19,416
Muhtemelen
kalp krizi geçirecektim.

475
00:20:19,417 --> 00:20:22,052
- Yani, Cleverbot bir
için sıfır,

476
00:20:22,053 --> 00:20:24,588
ama yine de
üç şansı daha var.

477
00:20:24,589 --> 00:20:27,291
- Şimdi, acele etme
, üzerinde düşün.

478
00:20:27,292 --> 00:20:29,826
- Bir numaralı bekar
, cevaplarınızın çoğunu hatırlamıyorum,

479
00:20:29,827 --> 00:20:31,061
bu yüzden--
- Vay canına.

480
00:20:31,062 --> 00:20:32,729
- Çok üzgünüm.
Çok üzgünüm.

481
00:20:32,730 --> 00:20:33,964
Yani aslında
iki ile üç arasında.

482
00:20:33,965 --> 00:20:35,565
Bu nasıl oldu?

483
00:20:35,566 --> 00:20:36,633
[drum roll]
- Bu sefer

484
00:20:36,634 --> 00:20:37,668
Cleverbot çalışıyor.

485
00:20:37,669 --> 00:20:39,403
- Tamam, um...

486
00:20:39,404 --> 00:20:40,437

İki numara gibi biriyle çıktım,

487
00:20:40,438 --> 00:20:41,938
o yüzden hayır demeliyiz.

488
00:20:41,939 --> 00:20:44,808
Yani bence
üç numaralı bekarla gideceğiz.

489
00:20:44,809 --> 00:20:45,942
- Onunla tanışalım.

490
00:20:45,943 --> 00:20:47,411
- Aman Tanrım!
[ikisi de gülüyor]

491
00:20:47,412 --> 00:20:49,346
Merhaba, nasılsın?
- Merhaba.

492
00:20:49,347 --> 00:20:52,015
-
İki numaralı bekarı seçmedin.

493
00:20:52,016 --> 00:20:54,551
- İki numaralı bekar
, ne oldu?

494
00:20:54,552 --> 00:20:55,719

Burada olduğunu bile bilmiyordum.

495
00:20:55,720 --> 00:20:57,587
Bir yerde sarhoş olduğunu sanıyordum
.

496
00:20:57,588 --> 00:20:59,823
Bu bir karmaşa, sadece bir karmaşa!
[her ikisi de gülüyor]

497
00:20:59,824 --> 00:21:02,626
Tamamen a--
[her ikisi de gülüyor]

498
00:21:02,627 --> 00:21:03,860
- İki numaralı bekar

499
00:21:03,861 --> 00:21:06,063
, tamamen insan olmayan bir
sohbet botu...

500
00:21:06,064 --> 00:21:07,497
[her ikisi de gülüyor]

501
00:21:07,498 --> 00:21:09,099



502
00:21:09,100 --> 00:21:11,635

İnsan benzeri konuşmayı sentezlemek için yapay zeka kullanan.

503
00:21:11,636 --> 00:21:13,770
- Aman Tanrım.
- Cleverbot'a merhaba de.

504
00:21:13,771 --> 00:21:15,539
- Oh, Cleverbot,
sen en kötüsün.

505
00:21:15,540 --> 00:21:18,075
[her ikisi de gülüyor]
- Neredeyse Cleverbot'u seçiyordum!

506
00:21:18,076 --> 00:21:19,776
Bu korkunç.

507
00:21:19,777 --> 00:21:22,446
-
Cleverbot gibi berbat biriyle mi çıktın?

508
00:21:22,447 --> 00:21:23,647
- Bu onun için pek iyi sayılmaz
.

509
00:21:23,648 --> 00:21:25,515
[kahkahalar]

510
00:21:25,516 --> 00:21:27,484
- Oh, umarım izliyordur.
- Evet.

511
00:21:27,485 --> 00:21:29,853
- Görünüşe göre Cleverbot
Turing testini geçti,

512
00:21:29,854 --> 00:21:31,855
ancak
hiç kupa kazanmadı.

513
00:21:31,856 --> 00:21:34,725
Yine de
iki şansı kaldı.

514
00:21:34,726 --> 00:21:36,727
-
Aldığınız cevapları düşünün.

515
00:21:36,728 --> 00:21:38,028
- Pekala--[inliyor]

516
00:21:38,029 --> 00:21:40,364
Bekar bir numara, cevaplarda


517
00:21:40,365 --> 00:21:42,566
ilginç bir şey görmedim


518
00:21:42,567 --> 00:21:44,968
ve Bekar iki
kulağa çok komik geliyor.

519
00:21:44,969 --> 00:21:48,138
Görünüş üzerine komedi
benim için çok büyük bir şey.

520
00:21:48,139 --> 00:21:50,440

Bir randevuya

521
00:21:50,441 --> 00:21:52,476
çıksaydı,
en azından eğlenceli olurdu gibi geliyor.

522
00:21:52,477 --> 00:21:54,411
- Biliyor musun?
Bize cevabınızı vermeye hazır mısınız?

523
00:21:54,412 --> 00:21:56,146
- [gülüyor] Demek istediğim,
sanırım hazırım, evet.

524
00:21:56,147 --> 00:21:59,883

Bekar iki tarafından gerçekten ilgimi çekti.

525
00:21:59,884 --> 00:22:00,984
[müzik tantanası]
- Pekala!

526
00:22:00,985 --> 00:22:03,053
- İki numaralı bekar.
- Peki.

527
00:22:03,054 --> 00:22:05,155
Mükemmel seçim.
Niye ya?

528
00:22:05,156 --> 00:22:07,557
- Merak ediyorum.
Mizahı seviyorum.

529
00:22:07,558 --> 00:22:10,427
Cevaplar sadece komikti.
Yani, oynak.

530
00:22:10,428 --> 00:22:15,098
Bu kişi gizemli,
tam işlevli bir insan gibi,

531
00:22:15,099 --> 00:22:17,768
değil mi, çünkü onun
kolları, bacakları falan var.

532
00:22:17,769 --> 00:22:20,404
- Tanışalım...o.

533
00:22:20,405 --> 00:22:22,439
- Ha?
- İki numaralı bekar

534
00:22:22,440 --> 00:22:24,775
, insan benzeri konuşmaları sentezlemek için yapay zeka kullanan, tamamen insan olmayan bir
sohbet botudur

535
00:22:24,776 --> 00:22:26,176



536
00:22:26,177 --> 00:22:28,545

.

537
00:22:28,546 --> 00:22:30,514
- Peki.
- Cleverbot'a merhaba de.

538
00:22:30,515 --> 00:22:32,149
-
Cidden cevap mı veriyordu?

539
00:22:32,150 --> 00:22:33,717
Robot cevap veriyordu--
- Evet.

540
00:22:33,718 --> 00:22:35,185
- Cidden kelimesi kelimesine.

541
00:22:35,186 --> 00:22:37,120
İnsan
konuşmasını öğrenen

542
00:22:37,121 --> 00:22:38,789
ve sentezleyebilen derin bir sinir ağı.
- Evet.

543
00:22:38,790 --> 00:22:40,657
- Yani yeni
tipim robot mu?

544
00:22:40,658 --> 00:22:43,193
Demek istediğim,
bu dünyada işler değişiyor, değil mi?

545
00:22:43,194 --> 00:22:45,195
ikisi de: evet.
- Bu gelecekte

546
00:22:45,196 --> 00:22:47,631
gerçekten bir şaka olmayacak
.

547
00:22:47,632 --> 00:22:50,667
- Bu korkutucu
aslında.

548
00:22:50,668 --> 00:22:53,003
- AI'nın geleceği
Bazıları için korkutucu olabilir,

549
00:22:53,004 --> 00:22:55,672
ama yine de bilgisayarı seçen tek
konu bu konu değildi

550
00:22:55,673 --> 00:22:58,208

.

551
00:22:58,209 --> 00:23:00,811
- İki numaralı bekar,
seni seçeceğim.

552
00:23:00,812 --> 00:23:02,879
- Vay!
Tamam, iki numaralı bekar.

553
00:23:02,880 --> 00:23:05,148
-
Sanırım aradığım tuhaf kişi o olabilir.

554
00:23:05,149 --> 00:23:07,150
- Cleverbot


555
00:23:07,151 --> 00:23:10,787
,
hem Turing testimizi hem de

556
00:23:10,788 --> 00:23:13,690
"tarih yeteneği" testimizi geçerek iki bekarın kalbini kazanmayı başardı.

557
00:23:13,691 --> 00:23:15,058
- Bu şu sonuca varıyor...
[ikisi de gülüyor]

558
00:23:15,059 --> 00:23:17,694
"Haydi Gidelim...
ikisi de: "RomanTech."

559
00:23:17,695 --> 00:23:18,895
- Pekala.

560
00:23:18,896 --> 00:23:25,802
[şerefeler ve alkışlar]

561
00:23:25,803 --> 00:23:29,506
- Belki bir gün bilgisayarlar da
insanlar gibi haklara sahip olacak.

562
00:23:29,507 --> 00:23:32,209
Belki de
insanı neyin yaptığını asla bilemeyeceğiz

563
00:23:32,210 --> 00:23:34,711



564
00:23:34,712 --> 00:23:36,179
Belki de soru

565
00:23:36,180 --> 00:23:38,949

, "Teknolojiyle ilişki kurabilir

566
00:23:38,950 --> 00:23:41,585

miyiz?" değil, "Biz aynı şey miyiz?"

567
00:23:41,586 --> 00:23:45,989



568
00:23:45,990 --> 00:23:48,658

Organizma ile buluş arasındaki

569
00:23:48,659 --> 00:23:50,093

çizgiyi anlayabilir

570
00:23:50,094 --> 00:23:53,663



571
00:23:53,664 --> 00:23:57,200
mi?Bunların
benim için başka insanlar tarafından yapıldığını bilsin mi

572
00:23:57,201 --> 00:24:00,170

yoksa sadece benden çıktığını mı düşünecek?

573
00:24:00,171 --> 00:24:03,039



574
00:24:03,040 --> 00:24:08,211
Cihazlar mı yoksa dış
metal organlar mı evrimleşti? Bundan

575
00:24:08,212 --> 00:24:12,816
yıllar sonra bilgisayarlar


576
00:24:12,817 --> 00:24:18,555

mı kişiliğe ulaşacak yoksa topluca "siborgluğa" mı ulaşacağız?

577
00:24:18,556 --> 00:24:21,558
Ve her zaman olduğu gibi,
izlediğiniz için teşekkürler.

578
00:24:21,559 --> 00:24:24,027
[dramatik müzik]

579
00:24:24,028 --> 00:24:27,030
[elektronik müzik]

580
00:24:27,031 --> 00:24:33,972
♪ ♪

