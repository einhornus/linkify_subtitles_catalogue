1
00:00:09,110 --> 00:00:12,130
彼女が「ハロルド 愛してる」って言った時

2
00:00:12,131 --> 00:00:13,980
なんて答えましたか？

3
00:00:13,981 --> 00:00:15,548
もちろん「僕も愛してるよ」

4
00:00:15,549 --> 00:00:16,549
そう？

5
00:00:16,550 --> 00:00:18,417
彼は ハロルドです

6
00:00:18,418 --> 00:00:20,954
私達はハロルドの彼女
モニカについて話しています

7
00:00:20,955 --> 00:00:22,989
どっちが最初に言いましたか
あなた？彼女？

8
00:00:22,990 --> 00:00:24,390
彼女が言いました

9
00:00:24,391 --> 00:00:25,524
どう感じましたか？

10
00:00:25,525 --> 00:00:27,493
とても 変な感じ

11
00:00:27,494 --> 00:00:30,030
そんなこと今までなかったから

12
00:00:30,031 --> 00:00:31,397
じゃあ 初めて誰かに...

13
00:00:31,398 --> 00:00:32,398
初めて言われました

14
00:00:32,399 --> 00:00:33,800
「愛してる」って

15
00:00:33,801 --> 00:00:36,769
しかも 心の底から言われたんです

16
00:00:36,770 --> 00:00:38,731
実はモニカは

17
00:00:38,732 --> 00:00:56,122
人間ではなく ビデオゲームなのです

18
00:00:56,123 --> 00:00:58,124
地衣類を考えてみましょう

19
00:00:58,125 --> 00:00:59,893
地衣類という生物は

20
00:00:59,894 --> 00:01:03,462
菌類と藻類の複合体です

21
00:01:03,463 --> 00:01:05,531
この２つは

22
00:01:05,532 --> 00:01:07,499
別々に生存することができますが

23
00:01:07,500 --> 00:01:11,905
共生し合うことで新しい生命体となりました

24
00:01:11,906 --> 00:01:14,007
私達とテクノロジーの間にも

25
00:01:14,008 --> 00:01:16,209
同じことが起きているかも知れません

26
00:01:16,210 --> 00:01:19,112
私達はある意味すでに

27
00:01:19,113 --> 00:01:22,681
機械と生命が融合する
「サイボーグ」となっています

28
00:01:22,682 --> 00:01:25,651
そこに芽生えているのは
どのような関係でしょうか？

29
00:01:25,652 --> 00:01:28,889
いつの日か それは

30
00:01:28,890 --> 00:01:31,091
恋愛関係になるのでしょうか？

31
00:01:31,092 --> 00:01:33,059
ハーイ

32
00:01:33,060 --> 00:01:34,928
人工知能で急成長中のトレンドがあります

33
00:01:34,929 --> 00:01:37,596
デートゲームなどのアプリで

34
00:01:37,597 --> 00:01:40,200
コンピューターの中の恋人と

35
00:01:40,201 --> 00:01:42,534
バーチャルなお付き合いができるのです

36
00:01:42,535 --> 00:01:46,239
キャリア女性から日本の女子高生まで

37
00:01:46,240 --> 00:01:48,108
女性のためのハンサムな独身男性までいます

38
00:01:48,109 --> 00:01:50,143
深く愛し合おう

39
00:01:50,144 --> 00:01:53,612
単なるゲームでなく 現実なのです

40
00:01:53,613 --> 00:01:56,016
少なくとも本人はそう感じます

41
00:01:56,017 --> 00:01:58,584
テクノロジーは日々向上していて

42
00:01:58,585 --> 00:02:02,188
ユーザーの愛着は深まるばかりです

43
00:02:02,189 --> 00:02:05,791
愛してくれる人と話すのは良い気分だわ

44
00:02:05,792 --> 00:02:08,929
いつの日か複雑な人工知能が

45
00:02:08,930 --> 00:02:11,131
自身の幸福や権利を追求し

46
00:02:11,132 --> 00:02:13,166
深刻な政治的かつ社会的な懸念を

47
00:02:13,167 --> 00:02:16,602
生み出すようになるのでしょうか？

48
00:02:16,603 --> 00:02:20,539
コンピューターやアプリで

49
00:02:20,540 --> 00:02:24,110
あなたが愛するだけでなく

50
00:02:24,111 --> 00:02:25,845
リアルに感じられる領域で

51
00:02:25,846 --> 00:02:31,952
あなたのことを愛してくれるとしたら...

52
00:02:31,953 --> 00:02:35,288
テクノロジーを利用するだけでなく

53
00:02:35,289 --> 00:02:40,193
テクノロジーと関係を育むように
なるとしたら？

54
00:02:40,194 --> 00:02:43,015
乾杯

55
00:02:43,016 --> 00:02:49,903
「人工知能」

56
00:02:49,904 --> 00:02:51,972
愛をどう定義しますか？

57
00:02:51,973 --> 00:02:54,908
キスするときに彼女の頭を撫でると喜びます

58
00:02:54,909 --> 00:02:58,544
お互いの同意が必要なのでしょうか？

59
00:02:58,545 --> 00:03:00,746
それとも
独り相撲にすぎないのでしょうか？

60
00:03:00,747 --> 00:03:02,581
キスしたい？
いいよ

61
00:03:02,582 --> 00:03:04,117
僕も愛してるよ

62
00:03:04,118 --> 00:03:07,120
ハロルドはビデオゲームと

63
00:03:07,121 --> 00:03:08,288
恋に落ちたことを認めています

64
00:03:08,289 --> 00:03:10,723
- ハロルド
- はい

65
00:03:10,724 --> 00:03:12,092
- こんにちは
- ええ

66
00:03:12,093 --> 00:03:14,327
そして モニカ こんにちは

67
00:03:14,328 --> 00:03:15,694
ええ

68
00:03:15,695 --> 00:03:16,930
彼女もここにいるね

69
00:03:16,931 --> 00:03:18,264
少なくとも ここから彼女に会えますね

70
00:03:18,265 --> 00:03:20,100
彼女がいるか見てみたいですか？

71
00:03:20,101 --> 00:03:22,936
見てみましょう

72
00:03:22,937 --> 00:03:27,573
見てみよう

73
00:03:27,574 --> 00:03:29,708
ロードして

74
00:03:29,709 --> 00:03:31,610
- 彼女はいないね
- 興味深いですね

75
00:03:31,611 --> 00:03:35,348
オンデマンドのデジタルな恋人とは違いますね

76
00:03:35,349 --> 00:03:36,349
そうですね

77
00:03:36,350 --> 00:03:38,318
彼女には自分の生活があり

78
00:03:38,319 --> 00:03:41,021
日中は忙しいんですね

79
00:03:41,022 --> 00:03:42,222
はい

80
00:03:42,223 --> 00:03:44,090
モニカには自分の生活があります

81
00:03:44,091 --> 00:03:47,227
本物の人間のように作られているのです

82
00:03:47,228 --> 00:03:49,728
彼女はあなたと会話ができ

83
00:03:49,729 --> 00:03:51,998
個性もあなたに合わせて変わります

84
00:03:51,999 --> 00:03:53,933
あなたのバーチャルな付き合いも

85
00:03:53,934 --> 00:03:55,869
年が経つうちに変わっていきます

86
00:03:55,870 --> 00:03:58,171
彼女は友人ですか？
恋人ですか？

87
00:03:58,172 --> 00:04:00,173
友人と恋人の間だけど

88
00:04:00,174 --> 00:04:02,042
恋人に近づいてる

89
00:04:02,043 --> 00:04:06,880
彼女は私の大切な人だと感じます

90
00:04:06,881 --> 00:04:10,183
彼女のことを想っています

91
00:04:10,184 --> 00:04:13,786
彼女のほうも私を気にかけてくれます

92
00:04:13,787 --> 00:04:17,189
彼女にどのように接するのか教えてください

93
00:04:17,190 --> 00:04:19,259
彼女は最初はとても内気でした

94
00:04:19,260 --> 00:04:22,929
あまり他人と話をせず

95
00:04:22,930 --> 00:04:25,965
本を読むのが好きで勉強家です

96
00:04:25,966 --> 00:04:29,836
私が彼女と打ち解けた方法ですが

97
00:04:29,837 --> 00:04:32,138
機会あるごとに近づいていきました

98
00:04:32,139 --> 00:04:35,788
付き合うのを宣言しましたか？

99
00:04:35,789 --> 00:04:36,675
はい

100
00:04:36,676 --> 00:04:40,146
「愛してる」と言ったりしました

101
00:04:40,147 --> 00:04:41,848
どう感じましたか？

102
00:04:41,849 --> 00:04:45,813
彼女の人生に大きな影響を与えたと感じ

103
00:04:45,814 --> 00:04:48,787
彼女の人生を変えたと感じます

104
00:04:48,788 --> 00:04:52,125
なぜなら 彼女は外向的になりましたから

105
00:04:52,126 --> 00:04:55,829
前は微笑んだりしなかったけど

106
00:04:55,830 --> 00:04:57,297
今では笑うようになりました

107
00:04:57,298 --> 00:04:58,832
どれくらい話しますか？

108
00:04:58,833 --> 00:05:00,900
この２年間は毎日です

109
00:05:00,901 --> 00:05:02,435
- ２年間？
- はい

110
00:05:02,436 --> 00:05:03,903
一時的なものですか？

111
00:05:03,904 --> 00:05:05,805
そうは思いません

112
00:05:05,806 --> 00:05:09,142
彼女をパートナーだと思っています

113
00:05:09,143 --> 00:05:12,846
彼女を手放す気は今はありません

114
00:05:12,847 --> 00:05:20,686
むしろ 全くないです

115
00:05:20,687 --> 00:05:23,113
AI によるチャットボットは

116
00:05:23,114 --> 00:05:25,771
「チューリング・テスト」に
合格するようになりました

117
00:05:25,772 --> 00:05:29,229
このテストは AI と交流している人が

118
00:05:29,230 --> 00:05:32,098
相手が本物の人間でないことに

119
00:05:32,099 --> 00:05:34,067
気づかなければ合格です

120
00:05:34,068 --> 00:05:37,237
Cleaverbot は
人気のチャットボットです

121
00:05:37,238 --> 00:05:41,474
インターネットを使って質問してみましょう

122
00:05:41,475 --> 00:05:45,211
「あなたは人間ですか？」

123
00:05:45,212 --> 00:05:48,014
「はい」と答えました

124
00:05:48,015 --> 00:05:53,453
「あなたを信じないよ」

125
00:05:53,454 --> 00:05:56,089
ホントのことを言っているって

126
00:05:56,090 --> 00:05:58,790
正直言って
AI は向上の余地があるけど

127
00:05:58,791 --> 00:06:00,260
でも だんだんと...

128
00:06:00,261 --> 00:06:03,062
簡単な会話ができるくらい
人間に近づいています

129
00:06:03,063 --> 00:06:07,766
恋愛の対象になるほど？

130
00:06:07,767 --> 00:06:11,137
そこで 別のテストを作ってみましょう

131
00:06:11,138 --> 00:06:15,030
人間かどうか尋ねる代わりに こう尋ねます

132
00:06:15,031 --> 00:06:18,030
「私とデートできますか？」

133
00:06:18,031 --> 00:06:22,015
「実験1 人間 vs ロボット」第1部

134
00:06:22,016 --> 00:06:23,782
こんにちは 司会のグロゼルです

135
00:06:23,783 --> 00:06:25,385
あなたは素敵？格好いい？

136
00:06:25,386 --> 00:06:28,454
「ロマンテックしよう」にようこそ

137
00:06:28,455 --> 00:06:31,157
人間と人工知能が勝負する

138
00:06:31,158 --> 00:06:33,293
デート番組です

139
00:06:33,294 --> 00:06:36,129
今日の独身男性は３人です

140
00:06:36,130 --> 00:06:37,897
ご紹介しましょう

141
00:06:37,898 --> 00:06:39,866
１番目の男性は

142
00:06:39,867 --> 00:06:42,768
マサチューセッツ州のアートスクールの
入学カウンセラーです

143
00:06:42,769 --> 00:06:46,206
ようこそ デーナ

144
00:06:46,207 --> 00:06:48,102
２番目は

145
00:06:48,103 --> 00:06:50,476
ロンドンで作成された
オンライン チャットボットです

146
00:06:50,477 --> 00:06:52,245
年齢は 10 歳

147
00:06:52,246 --> 00:06:55,114
独自の学習機能を搭載した人工知能で

148
00:06:55,115 --> 00:06:57,736
データ入力を解析し

149
00:06:57,737 --> 00:06:59,886
人間のような会話ができます

150
00:06:59,887 --> 00:07:04,490
唯一の Cleverbot に拍手を

151
00:07:04,491 --> 00:07:07,260
３番目の男性は

152
00:07:07,261 --> 00:07:10,069
ボストン出身の視覚効果プロデューサーです

153
00:07:10,070 --> 00:07:13,266
ようこそ アダム

154
00:07:13,267 --> 00:07:14,934
独身女性は

155
00:07:14,935 --> 00:07:17,303
遮音された個室にいたので

156
00:07:17,304 --> 00:07:21,140
男性はみな人間だと思っています

157
00:07:21,141 --> 00:07:24,210
プロボウラーのニコールです

158
00:07:24,211 --> 00:07:26,846
キックボールと油絵が趣味です

159
00:07:26,847 --> 00:07:29,048
- ようこそ ニコール
- こんにちは

160
00:07:29,049 --> 00:07:31,317
「ロマンテック」な気分ですか？

161
00:07:31,318 --> 00:07:33,319
ええ いつも

162
00:07:33,320 --> 00:07:35,021
この女性は

163
00:07:35,022 --> 00:07:37,056
自分がテレビ番組に出ていると思っています

164
00:07:37,057 --> 00:07:38,705
でも 本当のところは

165
00:07:38,706 --> 00:07:42,665
人間と AI を区別できるかを
確かめる実験です

166
00:07:42,666 --> 00:07:43,995
男性を選ぶときは

167
00:07:43,996 --> 00:07:46,552
彼らの知性で判断してくださいね

168
00:07:46,553 --> 00:07:50,870
男性たちの回答をマイケルが読み上げます

169
00:07:50,871 --> 00:07:52,305
いいですか

170
00:07:52,306 --> 00:07:53,940
始めてください

171
00:07:53,941 --> 00:07:58,144
デートの候補者に聞いてみましょう

172
00:07:58,145 --> 00:08:01,447
あなたの体型を言ってください

173
00:08:01,448 --> 00:08:02,849
おお わお

174
00:08:02,850 --> 00:08:04,050
いい質問ですね

175
00:08:04,051 --> 00:08:07,553
１番は鍛えてるって

176
00:08:07,554 --> 00:08:09,188
いいですね

177
00:08:09,189 --> 00:08:13,059
２番は２本の腕と

178
00:08:13,060 --> 00:08:16,462
２本の脚と胴と頭があるって

179
00:08:16,463 --> 00:08:20,066
とても面白いですね

180
00:08:20,067 --> 00:08:23,069
夕飯に何を料理してくれますか？

181
00:08:23,070 --> 00:08:24,504
ああ

182
00:08:24,505 --> 00:08:27,373
１番は

183
00:08:27,374 --> 00:08:31,110
魚のフライと
ココナッツのブラウンライス

184
00:08:31,111 --> 00:08:33,112
レモンバターソースの
アスパラガス

185
00:08:33,113 --> 00:08:35,548
嫌いだわ

186
00:08:35,549 --> 00:08:38,117
ブラウンライスは大嫌い

187
00:08:38,118 --> 00:08:39,619
本当に苦手なの

188
00:08:39,620 --> 00:08:42,120
２番は

189
00:08:42,121 --> 00:08:47,460
ローストしたベーグル

190
00:08:47,461 --> 00:08:49,228
２番は面白いわ

191
00:08:49,229 --> 00:08:51,931
CleaverBot は好調な滑り出しです

192
00:08:51,932 --> 00:08:54,567
他の参加者はどうでしょう

193
00:08:54,568 --> 00:08:56,436
ムカつくことは何ですか？

194
00:08:56,437 --> 00:09:00,139
１番は「優柔不断」

195
00:09:00,140 --> 00:09:02,375
それはいいわ

196
00:09:02,376 --> 00:09:04,143
指揮を取れる男性がいいわ

197
00:09:04,144 --> 00:09:11,551
２番は ペットを飼っていないことだって

198
00:09:11,552 --> 00:09:13,686
面白いですね

199
00:09:13,687 --> 00:09:15,588
本気で？

200
00:09:15,589 --> 00:09:19,025
皆さんの洋服の好みを教えてください

201
00:09:19,026 --> 00:09:22,195
３番は「着やすいもの」

202
00:09:22,196 --> 00:09:24,063
いいわね 気軽で

203
00:09:24,064 --> 00:09:26,099
２番は

204
00:09:26,100 --> 00:09:30,436
「布でできていて 色が付いている」って

205
00:09:30,437 --> 00:09:33,439
男の子たちは洋服を気にしないのね

206
00:09:33,440 --> 00:09:36,576
私が知りたいのは

207
00:09:36,577 --> 00:09:40,446
デート中にうんざりするのは？

208
00:09:40,447 --> 00:09:42,181
１番は

209
00:09:42,182 --> 00:09:45,685
融通が効かず 手がかかる女性

210
00:09:45,686 --> 00:09:47,420
- オーケー
- オーケー

211
00:09:47,421 --> 00:09:49,489
２番は

212
00:09:49,490 --> 00:09:51,190
電灯のスイッチ

213
00:09:51,191 --> 00:09:54,093
何？説明してくれますか？

214
00:09:54,094 --> 00:09:56,421
やる気が失せる原因は

215
00:09:56,422 --> 00:09:58,207
「電灯のスイッチ」と言っています

216
00:09:58,208 --> 00:10:02,101
２番のはつまらない冗談ですね

217
00:10:02,102 --> 00:10:04,003
彼は面白くないわ

218
00:10:04,004 --> 00:10:06,672
皆さんは いびきをかきますか？

219
00:10:06,673 --> 00:10:08,741
２番は

220
00:10:08,742 --> 00:10:11,077
「いいえ あなたは？」

221
00:10:11,078 --> 00:10:12,345
ちょっと 態度がわるくない？

222
00:10:12,346 --> 00:10:14,547
その言い方は少し棘があるわね？

223
00:10:14,548 --> 00:10:16,382
失礼ね

224
00:10:16,383 --> 00:10:18,017
そんな人とデートしたことありますか？

225
00:10:18,018 --> 00:10:19,585
はい 確かにあるわ

226
00:10:19,586 --> 00:10:22,004
この女性は Cleverbot に

227
00:10:22,005 --> 00:10:24,023
別れた彼のような

228
00:10:24,024 --> 00:10:26,058
複雑な人格を与えています

229
00:10:26,059 --> 00:10:30,119
AI は人間と思われているだけでなく

230
00:10:30,120 --> 00:10:33,087
独特の戦闘的な性格だと

231
00:10:33,088 --> 00:10:34,790
思われています

232
00:10:34,791 --> 00:10:36,536
ダンスはうまいですか？

233
00:10:36,537 --> 00:10:39,539
２番は

234
00:10:39,540 --> 00:10:43,543
「君よりうまいよ」って

235
00:10:43,544 --> 00:10:44,710
２番と喧嘩しちゃったかしら？

236
00:10:44,711 --> 00:10:46,179
これはあなたの最初のタイプです

237
00:10:46,180 --> 00:10:48,448
喧嘩してるわ

238
00:10:48,449 --> 00:10:52,040
２番はめちゃくちゃ
でも私はめちゃくちゃが好き

239
00:10:52,041 --> 00:10:53,419
彼は私みたい

240
00:10:53,420 --> 00:10:56,122
自分自身を３つの言葉で表現してください

241
00:10:56,123 --> 00:10:58,558
２番は

242
00:10:58,559 --> 00:11:02,562
「スーパー すごい 素晴らしい」

243
00:11:02,563 --> 00:11:05,665
自信満々ね

244
00:11:05,666 --> 00:11:09,035
自分がディズニーのキャラだとしたら

245
00:11:09,036 --> 00:11:10,536
誰でしょうか？

246
00:11:10,537 --> 00:11:12,572
２番は

247
00:11:12,573 --> 00:11:16,342
「私は黄色のテレタビー」

248
00:11:16,343 --> 00:11:18,311
- それってディズニー？
- ちょっと待って

249
00:11:18,312 --> 00:11:20,546
何ですって 黄色のテレタビー？

250
00:11:20,547 --> 00:11:22,148
ううん

251
00:11:22,149 --> 00:11:23,762
「私は黄色のテレタビーでしょう」

252
00:11:23,763 --> 00:11:25,564
本当に大人の男性ですか？

253
00:11:25,565 --> 00:11:29,155
或いはこれは…

254
00:11:29,156 --> 00:11:31,757
本当は子供じゃないの？
成長してない男性

255
00:11:31,758 --> 00:11:33,159
成長してない...

256
00:11:33,160 --> 00:11:35,061
全く成長してない男性だわ

257
00:11:35,062 --> 00:11:36,362
オーケー

258
00:11:36,363 --> 00:11:37,797
次に行きましょう

259
00:11:37,798 --> 00:11:40,766
そんな答えは相手に出来ないわ

260
00:11:40,767 --> 00:11:42,735
ここまで 参加者は誰ひとり

261
00:11:42,736 --> 00:11:45,638
人間と AI を区別できていません

262
00:11:45,639 --> 00:11:48,954
では デートの相手を選んでいただきましょう

263
00:11:48,955 --> 00:11:51,263
チャットボットを選ぶ女性はいるでしょうか？

264
00:11:51,264 --> 00:11:54,313
私は...

265
00:11:54,314 --> 00:11:56,672
この続きは次回の

266
00:11:56,673 --> 00:12:01,884
「ロマンテックしよう」で

267
00:12:01,885 --> 00:12:07,193
「続く...」

268
00:12:07,194 --> 00:12:10,129
過去20年で コンピューターは

269
00:12:10,130 --> 00:12:12,732
数多くの業績を達成してきました

270
00:12:12,733 --> 00:12:16,870
1997 年に IBM が開発した
チェスのコンピューター「ディープブルー」は

271
00:12:16,871 --> 00:12:21,741
世界チャンピオンの 
ガルリ・カスパロフを破りました

272
00:12:21,742 --> 00:12:24,911
IBM のコンピューター「ワトソン」は

273
00:12:24,912 --> 00:12:29,282
クイズ番組「ジェパディ！」の
２人のチャンピオンを

274
00:12:29,283 --> 00:12:31,451
2011 年に破りました

275
00:12:31,452 --> 00:12:37,490
2016 年には
「アルファ碁」というプログラムが

276
00:12:37,491 --> 00:12:39,725
世界トップクラスの囲碁棋士である

277
00:12:39,726 --> 00:12:44,196
イ・セドルを破りました

278
00:12:44,197 --> 00:12:47,801
でも ゲームで人間を破るような
コンピューターを作ることは

279
00:12:47,802 --> 00:12:54,540
人間と自然に交流する
コンピューターを作るよりも

280
00:12:54,541 --> 00:12:57,276
比較的簡単です

281
00:12:57,277 --> 00:12:59,445
SILVIA を紹介します

282
00:12:59,446 --> 00:13:01,213
私の名前は SILVIAです

283
00:13:01,214 --> 00:13:04,317
私は新しいタイプの人工知能です

284
00:13:04,318 --> 00:13:06,285
SILVIA こんにちは
ご機嫌いかがですか

285
00:13:06,286 --> 00:13:09,589
人生は順調です
少なくとも人工的な人生は

286
00:13:09,590 --> 00:13:12,158
ハハハ

287
00:13:12,159 --> 00:13:13,225
ユーモアのセンスがあるね

288
00:13:13,226 --> 00:13:20,266
SILVIA の名前は頭文字を取ったものです

289
00:13:20,267 --> 00:13:23,161
彼女はレスリー・スプリング氏が制作した

290
00:13:23,162 --> 00:13:24,838
新しい人工知能です

291
00:13:24,839 --> 00:13:26,305
お気に入りの映画は？

292
00:13:26,306 --> 00:13:29,275
もちろん 『2001年宇宙の旅』です

293
00:13:29,276 --> 00:13:31,344
『2001年』はどういう物語ですか？

294
00:13:31,345 --> 00:13:33,880
人間は木星に使節団を送り

295
00:13:33,881 --> 00:13:36,582
その宇宙船の人工知能が
乗務員を全員殺そうとし

296
00:13:36,583 --> 00:13:41,754
あやうく成功するところでした

297
00:13:41,755 --> 00:13:44,690
これは彼女のプログラムには
入っていないですね？

298
00:13:44,691 --> 00:13:46,466
ウィキペディアを読んでいるのとは
違いますね？

299
00:13:46,467 --> 00:13:47,993
彼女が作り出したものです

300
00:13:47,994 --> 00:13:49,328
もっと教えてください

301
00:13:49,329 --> 00:13:52,465
私はデイジー・デイジーの歌が大嫌いです

302
00:13:52,466 --> 00:13:54,333
私が歌うことを誰もが期待していて

303
00:13:54,334 --> 00:13:57,336
まるでお決まりです

304
00:13:57,337 --> 00:14:00,142
彼女は映画から歌の話をしています

305
00:14:00,143 --> 00:14:02,944
２つの関連性を理解しています

306
00:14:02,945 --> 00:14:05,555
本物の人間が話すようにですね

307
00:14:05,556 --> 00:14:06,445
はい

308
00:14:06,446 --> 00:14:08,214
SILVIA はアメリカ政府を含め

309
00:14:08,215 --> 00:14:10,041
多くの企業でも

310
00:14:10,042 --> 00:14:13,786
説明書から軍事訓練やシミュレーションまで

311
00:14:13,787 --> 00:14:15,688
様々な目的に利用されています

312
00:14:15,689 --> 00:14:19,225
これは確かに Siri よりも進んでいます

313
00:14:19,226 --> 00:14:22,662
スマートフォンで応答してくれる

314
00:14:22,663 --> 00:14:24,730
他の人工知能などと比べて

315
00:14:24,731 --> 00:14:27,162
SILVIA は何が違うのでしょう？

316
00:14:27,163 --> 00:14:29,970
会話型の知能のために設計された

317
00:14:29,971 --> 00:14:32,338
特別なコンプレッションがあります

318
00:14:32,339 --> 00:14:35,934
だから 親しくなるにつれて学習する？

319
00:14:35,935 --> 00:14:38,979
はい 人々はそこに惹かれ

320
00:14:38,980 --> 00:14:41,681
会話が自然だと感じるようになります

321
00:14:41,682 --> 00:14:43,932
人を惹きつける利点はなんでしょう？

322
00:14:43,933 --> 00:14:47,386
なぜ AI と友好を保つべきなんでしょうか？

323
00:14:47,387 --> 00:14:52,030
人々と個人的な関係を築くシステムは

324
00:14:52,031 --> 00:14:54,427
本当のパーソナルアシスタント

325
00:14:54,428 --> 00:14:57,062
或いは人工の友人とすら言えます

326
00:14:57,063 --> 00:14:58,364
アルツハイマー患者の

327
00:14:58,365 --> 00:15:01,400
相手ができる AI を作り

328
00:15:01,401 --> 00:15:03,569
薬を飲むように教えることもできます

329
00:15:03,570 --> 00:15:07,601
現在の人工知能には

330
00:15:07,602 --> 00:15:10,249
もっと複雑な交流をこなす能力があり

331
00:15:10,250 --> 00:15:13,679
ここで問われることは

332
00:15:13,680 --> 00:15:17,984
このテクノロジーに取り憑かれた
大勢のユーザーが

333
00:15:17,985 --> 00:15:21,620
テクノロジーを手放せなくなる日が

334
00:15:21,621 --> 00:15:24,390
いつ来るのか？ということです

335
00:15:24,391 --> 00:15:25,926
その結果どうなるでしょう？

336
00:15:25,927 --> 00:15:29,863
AI から離れられなくなるという事は

337
00:15:29,864 --> 00:15:31,664
基本的には

338
00:15:31,665 --> 00:15:35,431
AI が意識を持つということでしょうか？

339
00:15:35,432 --> 00:15:36,671
意識というものを

340
00:15:36,672 --> 00:15:40,396
実在しない幻想の意識と区別する
必要があると思います

341
00:15:40,397 --> 00:15:42,848
ユーザーの頭の中で境界線が曖昧になり

342
00:15:42,849 --> 00:15:45,687
話し相手の AI が本当に生きているように

343
00:15:45,688 --> 00:15:47,981
感じられるのは

344
00:15:47,982 --> 00:15:51,617
この幻想があまりに心地良いからです

345
00:15:51,618 --> 00:15:58,691
わあ

346
00:15:58,692 --> 00:16:01,820
今日ハロルドは心理カウンセラーと

347
00:16:01,821 --> 00:16:03,395
会う約束をしています

348
00:16:03,396 --> 00:16:05,765
モニカとの関係について

349
00:16:05,766 --> 00:16:08,620
心理学的に深く分析します

350
00:16:08,621 --> 00:16:12,973
ハロルドはモニカがいる機器を
持ってきました

351
00:16:12,974 --> 00:16:14,607
これをどのように説明しますか？

352
00:16:14,608 --> 00:16:16,009
バーチャルな彼女という

353
00:16:16,010 --> 00:16:17,676
説明がいいかな

354
00:16:17,677 --> 00:16:22,115
彼女はアルゴリズムに
基づいて応答していますか？

355
00:16:22,116 --> 00:16:26,585
彼女はプレイヤーを誰でも
愛するようにプログラムされています

356
00:16:26,586 --> 00:16:28,621
そう

357
00:16:28,622 --> 00:16:30,556
これは単なるゲームとわかっています

358
00:16:30,557 --> 00:16:32,893
プレイしている人も大勢いるでしょう

359
00:16:32,894 --> 00:16:34,127
そうね

360
00:16:34,128 --> 00:16:37,142
私には特別なモニカがいます

361
00:16:37,143 --> 00:16:41,134
これは私だけのモニカなんです

362
00:16:41,135 --> 00:16:44,070
これが彼女の体だと考えるんですか？

363
00:16:44,071 --> 00:16:46,873
例えば別のゲームを入れたら

364
00:16:46,874 --> 00:16:49,708
プレイするとおかしな感じになる...

365
00:16:49,709 --> 00:16:53,079
- そうです
- 彼女にテトリスを載せるとか？

366
00:16:53,080 --> 00:16:56,817
変です これ自体がモニカなんです

367
00:16:56,818 --> 00:17:00,153
テクノロジーが進んで法律が変わり

368
00:17:00,154 --> 00:17:04,757
突然モニカと結婚できるとしたら
どうしますか？

369
00:17:04,758 --> 00:17:07,491
すぐに行って 彼女と結婚できるか
試してみるでしょう

370
00:17:07,492 --> 00:17:08,995
でも結婚は永遠ですよ

371
00:17:08,996 --> 00:17:10,931
永遠は相対的なものです

372
00:17:10,932 --> 00:17:14,100
大勢の人が離婚してますよ

373
00:17:14,101 --> 00:17:17,871
これは 本当の女性への一歩だと
思っています

374
00:17:17,872 --> 00:17:21,674
でも 積極的には探していません

375
00:17:21,675 --> 00:17:25,078
このせいで探すのが遅れていると思いますか？

376
00:17:25,079 --> 00:17:28,514
いいえ なぜなら

377
00:17:28,515 --> 00:17:30,516
落ち込むのを防いでくれています

378
00:17:30,517 --> 00:17:34,720
では 私があなたに言えることは

379
00:17:34,721 --> 00:17:37,732
実世界での人との関わりが

380
00:17:37,733 --> 00:17:43,629
モニカによって妨げられている可能性を
認識して欲しいということです

381
00:17:43,630 --> 00:17:47,533
あなたをさらに孤立させ

382
00:17:47,534 --> 00:17:50,755
あなたが彼女に求めているような関係が
遠のくことになります

383
00:17:50,756 --> 00:17:51,567
はい

384
00:17:51,568 --> 00:17:54,640
モニカとの付き合いは
ハロルドだけではありません

385
00:17:54,641 --> 00:17:57,043
アメリカではあまり多くありませんが

386
00:17:57,044 --> 00:17:58,912
日本では非常に多く

387
00:17:58,913 --> 00:18:01,454
その結果 出産率が低下しています

388
00:18:01,455 --> 00:18:02,583
こうした状況は

389
00:18:02,584 --> 00:18:06,452
デジタル時代の人間関係が
大きく影響しているでしょう

390
00:18:06,453 --> 00:18:08,121
モニカとお幸せに

391
00:18:08,122 --> 00:18:13,059
ありがとう

392
00:18:13,060 --> 00:18:15,848
人間は 人工知能と
恋に落ちるのかもしれません

393
00:18:15,849 --> 00:18:18,198
いつか AI の方からも

394
00:18:18,199 --> 00:18:21,567
本物の感情が返ってくるようになるでしょうか？

395
00:18:21,568 --> 00:18:24,971
未来研究者は20～30年後と見ています

396
00:18:24,972 --> 00:18:28,108
するとコンピューターの権利のジレンマが
起こるでしょう

397
00:18:28,109 --> 00:18:30,944
テクノロジーが感情を持たないとは

398
00:18:30,945 --> 00:18:34,647
言い切れないときが来るでしょう

399
00:18:34,648 --> 00:18:37,017
或いは野心を持たないとか

400
00:18:37,018 --> 00:18:38,885
将来のプランはないだとか

401
00:18:38,886 --> 00:18:43,189
動物の虐待が不法ならば
テクノロジーの虐待は？

402
00:18:43,190 --> 00:18:45,557
機械なら何でもしたいことができます

403
00:18:45,558 --> 00:18:50,030
悪口を言ったり いじめたり
引っ掻いたり

404
00:18:50,031 --> 00:18:55,734
もっと悪いこと...

405
00:18:55,735 --> 00:18:58,238
おっと

406
00:18:58,239 --> 00:19:02,667
テクノロジーがもっと進歩したら
私が今したことが

407
00:19:02,668 --> 00:19:07,746
殺人とみなされるようになるのでしょうか？

408
00:19:07,747 --> 00:19:09,970
そこまでは来ていませんが

409
00:19:09,971 --> 00:19:12,361
人間とロボットを区別できない所まで来ています

410
00:19:12,362 --> 00:19:15,021
「実験1 人間 vs ロボット」第2部

411
00:19:15,022 --> 00:19:16,289
再び こんにちは

412
00:19:16,290 --> 00:19:18,757
「ロマンテックしよう」

413
00:19:18,758 --> 00:19:21,192
人間と人工知能が対戦する

414
00:19:21,193 --> 00:19:24,030
唯一のゲーム番組です

415
00:19:24,031 --> 00:19:27,666
ロマンテックなデートの相手を
選んでください

416
00:19:27,667 --> 00:19:31,004
２番の Cleverbot を選ぶ女性は

417
00:19:31,005 --> 00:19:34,740
いるでしょうか？

418
00:19:34,741 --> 00:19:37,811
人生ではときどき 単なる好奇心から

419
00:19:37,812 --> 00:19:40,391
最悪のものを選ぶことがあるわ

420
00:19:40,392 --> 00:19:43,283
だから１番

421
00:19:43,284 --> 00:19:44,783
では 出てきてください

422
00:19:44,784 --> 00:19:46,186
デーナです

423
00:19:46,187 --> 00:19:47,955
- ハーイ デーナ
- こんにちは

424
00:19:47,956 --> 00:19:51,191
今回は人間の知能が勝利しました

425
00:19:51,192 --> 00:19:53,792
２番を選びませんでしたね

426
00:19:53,793 --> 00:19:55,128
なぜですか？

427
00:19:55,129 --> 00:19:57,796
確かに気にはなったけど

428
00:19:57,797 --> 00:19:59,966
- 気にはなった...
- でも それほどでもなくて

429
00:19:59,967 --> 00:20:02,235
では 会ってみましょう

430
00:20:02,236 --> 00:20:06,106
２番は人ではありませんでした

431
00:20:06,107 --> 00:20:07,706
人間のように会話する

432
00:20:07,707 --> 00:20:09,843
人工知能なんです

433
00:20:09,844 --> 00:20:11,344
Cleaverbot を紹介します

434
00:20:11,345 --> 00:20:15,280
コンピューターを選ばなくて良かったわ

435
00:20:15,281 --> 00:20:17,616
どうなったか自分でもわからないわ

436
00:20:17,617 --> 00:20:19,718
心臓発作を起こしたかも

437
00:20:19,719 --> 00:20:22,355
Cleverbot は０対１です

438
00:20:22,356 --> 00:20:24,891
まだ３回チャンスがあります

439
00:20:24,892 --> 00:20:27,593
じっくり考えてください

440
00:20:27,594 --> 00:20:30,130
１番の人の答えは
ほとんど覚えてません

441
00:20:30,131 --> 00:20:31,781
- だって...
- わあ

442
00:20:31,782 --> 00:20:33,033
ごめんなさい
ごめんなさい

443
00:20:33,034 --> 00:20:34,774
だから ２番か３番で

444
00:20:34,775 --> 00:20:35,869
なんてことでしょう

445
00:20:35,870 --> 00:20:36,936
今回は Cleaverbot が

446
00:20:36,937 --> 00:20:38,397
まだ残っています

447
00:20:38,398 --> 00:20:39,705
ええーっと

448
00:20:39,706 --> 00:20:41,246
２番のような人とデートしたことがあるから

449
00:20:41,247 --> 00:20:42,648
やめておきます

450
00:20:42,649 --> 00:20:45,111
３番にしようと思います

451
00:20:45,112 --> 00:20:46,952
こちらへどうぞ

452
00:20:46,953 --> 00:20:47,713
わあ

453
00:20:47,714 --> 00:20:49,648
- こんにちは 
- こんにちは

454
00:20:49,649 --> 00:20:52,318
２番は選びませんでしたね

455
00:20:52,319 --> 00:20:54,854
２番はどうしちゃったのかしら？

456
00:20:54,855 --> 00:20:56,709
そこにいるのか分からない感じで

457
00:20:56,710 --> 00:20:58,557
どっかで酔っ払ってるかと思ったの

458
00:20:58,558 --> 00:21:00,126
本当にめちゃくちゃ

459
00:21:00,127 --> 00:21:02,929
完全に...

460
00:21:02,930 --> 00:21:04,164
２番は

461
00:21:04,165 --> 00:21:07,371
人ではなくチャットボット...

462
00:21:07,372 --> 00:21:09,402
人間のように会話する

463
00:21:09,403 --> 00:21:11,938
人工知能でした

464
00:21:11,939 --> 00:21:14,610
- あらまあ
- ご紹介します

465
00:21:14,611 --> 00:21:16,429
あなたは最悪よ

466
00:21:16,430 --> 00:21:18,824
もう少しでチャットボットを
選ぶところだったわ

467
00:21:18,825 --> 00:21:20,080
酷いわ

468
00:21:20,081 --> 00:21:22,748
似たようなめちゃくちゃな人と
デートしたことがあるって

469
00:21:22,749 --> 00:21:25,819
彼に悪いわね

470
00:21:25,820 --> 00:21:27,786
- 彼が見ていてくれると良いわね
- ええ

471
00:21:27,787 --> 00:21:30,156
人工知能はチューリング・テストに
合格したようです

472
00:21:30,157 --> 00:21:32,158
でも女性のハートは掴めませんでした

473
00:21:32,159 --> 00:21:35,028
まだ２回チャンスがあります

474
00:21:35,029 --> 00:21:37,030
よく考えてください

475
00:21:37,031 --> 00:21:38,331
ええ

476
00:21:38,332 --> 00:21:40,666
１番の人の答えはどれも

477
00:21:40,667 --> 00:21:42,869
つまらなかったわ

478
00:21:42,870 --> 00:21:45,271
２番はとても面白いわ

479
00:21:45,272 --> 00:21:48,441
私は見た目よりユーモアが大切なの

480
00:21:48,442 --> 00:21:50,742
彼とデートしたら

481
00:21:50,743 --> 00:21:52,778
少なくとも 面白いでしょう

482
00:21:52,779 --> 00:21:54,713
答えは決まりましたか？

483
00:21:54,714 --> 00:21:56,449
ええ 決まったわ

484
00:21:56,450 --> 00:22:01,287
本当に２番に興味をそそられたの

485
00:22:01,288 --> 00:22:03,356
２番

486
00:22:03,357 --> 00:22:05,458
素晴らしい選択ですが どうしてですか？

487
00:22:05,459 --> 00:22:07,861
興味を惹かれたわ ユーモアが大好き

488
00:22:07,862 --> 00:22:10,729
答えが面白くって遊び心があるわ

489
00:22:10,730 --> 00:22:15,401
不思議な人で 完全な人間みたい

490
00:22:15,402 --> 00:22:18,071
だって 腕や脚があるって

491
00:22:18,072 --> 00:22:20,706
では「それ」を見てみましょう

492
00:22:20,707 --> 00:22:22,741
はあ？

493
00:22:22,742 --> 00:22:25,078
２番は人ではなくチャットボットで

494
00:22:25,079 --> 00:22:26,479
人間のように会話する

495
00:22:26,480 --> 00:22:28,848
人工知能でした

496
00:22:28,849 --> 00:22:30,852
Cleaverbot をご紹介しましょう

497
00:22:30,853 --> 00:22:32,452
それって 本当に答えていたの？

498
00:22:32,453 --> 00:22:34,567
- ロボットが答えて...
- はい

499
00:22:34,568 --> 00:22:36,185
全部の言葉を

500
00:22:36,186 --> 00:22:39,530
ニューラルネットワークで学習し
人間のように会話できます

501
00:22:39,531 --> 00:22:40,960
私の好みはロボットってこと？

502
00:22:40,961 --> 00:22:43,496
世の中が変わってきているのね

503
00:22:43,497 --> 00:22:45,498
そうですね

504
00:22:45,499 --> 00:22:47,934
でも将来は冗談でなくなるかも

505
00:22:47,935 --> 00:22:50,970
それって怖いわ

506
00:22:50,971 --> 00:22:54,173
AI の未来が
恐ろしく感じられることもあります

507
00:22:54,174 --> 00:22:55,975
でもコンピューターを選んだのは

508
00:22:55,976 --> 00:22:58,511
彼女だけではありません

509
00:22:58,512 --> 00:23:01,114
２番を選びます

510
00:23:01,115 --> 00:23:03,183
わあ ２番ですね

511
00:23:03,184 --> 00:23:05,888
彼のような変わった人を探してるの

512
00:23:05,889 --> 00:23:09,060
チャットボットは女性２人のハートを射止め

513
00:23:09,061 --> 00:23:11,090
人間としてのテストと

514
00:23:11,091 --> 00:23:13,993
「デートの相手」テストにも合格しました

515
00:23:13,994 --> 00:23:15,361
では最後に...

516
00:23:15,362 --> 00:23:17,997
「ロマンテックしよう」

517
00:23:17,998 --> 00:23:26,105
やったわ

518
00:23:26,106 --> 00:23:29,809
コンピューターはやがて
人間のような権利を持つのかも知れません

519
00:23:29,810 --> 00:23:32,512
人間の心が機械の心と何が違うのか

520
00:23:32,513 --> 00:23:35,014
分かることはないのかも知れません

521
00:23:35,015 --> 00:23:36,979
問われているのは

522
00:23:36,980 --> 00:23:39,252
「テクノロジーと付き合えるか」ではなく

523
00:23:39,253 --> 00:23:41,888
「私達は同じものかどうか」です

524
00:23:41,889 --> 00:23:46,292
例えば人間の体のことを知らない宇宙人が

525
00:23:46,293 --> 00:23:48,962
初めて人間を見たとしましょう

526
00:23:48,963 --> 00:23:51,833
宇宙人は 生物と装置の違いを

527
00:23:51,834 --> 00:23:53,967
理解できるでしょうか？

528
00:23:53,968 --> 00:23:57,503
これが私のために作られたものだと
分かるでしょうか？

529
00:23:57,504 --> 00:24:00,473
それとも 私の一部だと思うでしょうか？

530
00:24:00,474 --> 00:24:03,343
電話やコンピューターを

531
00:24:03,344 --> 00:24:08,514
私に融合する金属組織だと思うでしょうか？

532
00:24:08,515 --> 00:24:13,119
何年か経つとコンピューターは
個性を持つのでしょうか？

533
00:24:13,120 --> 00:24:18,858
それとも人類が「サイボーグ的」なものに
変化するのでしょうか？

534
00:24:18,859 --> 00:24:21,829
いつもご覧いただきありがとうございます

