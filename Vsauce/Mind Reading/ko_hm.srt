1
00:00:05,171 --> 00:00:06,872
읽는 걸 꺼리냐고요?

2
00:00:06,873 --> 00:00:07,973
물론 아니죠

3
00:00:07,974 --> 00:00:10,876
전 리딩이 좋아요

4
00:00:10,877 --> 00:00:15,247
보시죠, 마인드 리딩은
사이비 과학처럼 들릴지 모릅니다

5
00:00:15,248 --> 00:00:16,582
제 표현을 양해해주세요

6
00:00:16,583 --> 00:00:18,050
헛소리이죠

7
00:00:18,051 --> 00:00:21,387
마인드 리딩의 과학 버전이라고
할 수 있는 생각 인식은

8
00:00:21,388 --> 00:00:23,655
실제로 존재하는 것이죠

9
00:00:23,656 --> 00:00:26,592
신경 촬영법과
머신 러닝에 기반을 두고 있죠

10
00:00:26,593 --> 00:00:30,095
마인드 리딩 실험이
단지 누군가의 생각을

11
00:00:30,096 --> 00:00:33,399
염탐하는 것만이 아니라는 건
정말 멋진 일입니다

12
00:00:33,400 --> 00:00:37,403
생각의 구성을
알아내는 것이기도 하죠

13
00:00:37,404 --> 00:00:39,238
제가 뭔가를 생각한다면

14
00:00:39,239 --> 00:00:42,841
마음의 그림은
실제로 어떻게 보일까요?

15
00:00:42,842 --> 00:00:44,376
해상도는 어떨까요?

16
00:00:44,377 --> 00:00:46,712
기억의 충실도는 어느 정도며

17
00:00:46,713 --> 00:00:49,081
시간이 지나면서
어떻게 변화할까요?

18
00:00:49,082 --> 00:00:50,282
이번 에피소드에서는

19
00:00:50,283 --> 00:00:52,451
사람의 정신을 읽는 것이
우리가 이 질문에 답하는 데

20
00:00:52,452 --> 00:00:54,553
어떻게 도움이 되는지를
알아봅니다

21
00:00:54,554 --> 00:00:58,257
제 여정은 바로 여기
오리건대학에서 시작합니다

22
00:00:58,258 --> 00:01:01,060
저는 큘 실험실의
브라이스 큘 박사와 만납니다

23
00:01:01,061 --> 00:01:03,462
큘 박사는 신경 촬영법과
머신 러닝을 사용하여

24
00:01:03,463 --> 00:01:06,665
사람들이 생각하는 바를
직접 듣지 않고

25
00:01:06,666 --> 00:01:23,248
알아내려는 신경 과학자입니다

26
00:01:23,249 --> 00:01:27,953
"마인드 리딩"

27
00:01:27,954 --> 00:01:30,823
"오리건대학"

28
00:01:30,824 --> 00:01:33,559
여기서 무슨 일을 하는지
말씀해주시죠

29
00:01:33,560 --> 00:01:34,693
"브라이스 큘
심리학과 부교수"

30
00:01:34,694 --> 00:01:36,528
저는 여기 인지 신경과학
프로그램 소속입니다

31
00:01:36,529 --> 00:01:38,130
인간의 기억을 연구하죠

32
00:01:38,131 --> 00:01:40,766
제 연구소는 주로
신경 촬영법을 사용해서

33
00:01:40,767 --> 00:01:42,568
기능적 자기 공명 영상
즉 fMRI로

34
00:01:42,569 --> 00:01:45,671
많은 연구를 합니다

35
00:01:45,672 --> 00:01:49,508
기억을 조사하는 데
fMRI를 어떻게 사용하시나요?

36
00:01:49,509 --> 00:01:51,143
우리는 신경 활동의 패턴을 봅니다

37
00:01:51,144 --> 00:01:54,246
기억이 형성될 때
일정한 패턴이 있고

38
00:01:54,247 --> 00:01:56,548
우리는 그 패턴을 기록할 수 있죠

39
00:01:56,549 --> 00:01:59,618
이후 한 시점에
기억을 하려고 할 때

40
00:01:59,619 --> 00:02:02,254
패턴이 회복되거나
재활성화되는지를 테스트합니다

41
00:02:02,255 --> 00:02:06,158
우리가 두뇌 활동의 패턴을 보고
무엇이 기억되는지 또는

42
00:02:06,159 --> 00:02:09,794
회상되고 있는지를
추론할 수 있다는 말인가요?

43
00:02:09,795 --> 00:02:10,996
간단한 생각조차도요?

44
00:02:10,997 --> 00:02:13,666
네, 우리는 그걸
해독이라고 부릅니다

45
00:02:13,667 --> 00:02:15,401
그래서 기본적으로...

46
00:02:15,402 --> 00:02:19,038
입력 패턴은 당신이
뭔가를 기억하고 있을 때

47
00:02:19,039 --> 00:02:20,873
우리가 기록하는
활동의 패턴입니다

48
00:02:20,874 --> 00:02:23,575
그리고 우리는 당신이
기억하고 있는 걸 추측하죠

49
00:02:23,576 --> 00:02:26,278
마인드 리딩처럼
들린다는 걸 아시겠군요

50
00:02:26,279 --> 00:02:28,947
네, 그렇습니다

51
00:02:28,948 --> 00:02:32,484
그렇다면 브라이스
오늘 제게 뭘 하실 건가요?

52
00:02:32,485 --> 00:02:35,988
오늘 우리가 하려는 건
미지의 영역입니다

53
00:02:35,989 --> 00:02:38,290
당신에게 새로운 실험을
해 보려고 해요

54
00:02:38,291 --> 00:02:41,894
그래서 어떤 특정한 결과도
보장할 수 없습니다

55
00:02:41,895 --> 00:02:46,231
하지만 우리가 가려고 하는
방향이 어디인지를 나타내죠

56
00:02:46,232 --> 00:02:48,400
오늘은 얼굴을 연구하는 실험에

57
00:02:48,401 --> 00:02:50,235
참여하실 겁니다

58
00:02:50,236 --> 00:02:53,839
유명인 12명의
사진을 관찰하시게 됩니다

59
00:02:53,840 --> 00:02:55,107
제가 이미 익숙한 사람이군요

60
00:02:55,108 --> 00:02:56,975
- 아는 사람이에요
- 네

61
00:02:56,976 --> 00:02:58,877
우선 그 사진들을
기억하려 노력하시고

62
00:02:58,878 --> 00:03:00,946
다음에는 MRI 스캐너에
들어가셔서

63
00:03:00,947 --> 00:03:03,849
가능한 한 생생하게 그 사진을
마음에 떠올리려고 노력하세요

64
00:03:03,850 --> 00:03:06,051
우리는 당신이 사진을
상상하려 노력하는 동안

65
00:03:06,052 --> 00:03:08,253
당신의 두뇌 활동을 기록하고

66
00:03:08,254 --> 00:03:10,089
그 얼굴을 재건하게 될 겁니다

67
00:03:10,090 --> 00:03:12,257
그러니까 당신이 기억하는
그림을 그리는 거죠

68
00:03:12,258 --> 00:03:13,992
- 그림을요?
- 네, 그림입니다

69
00:03:13,993 --> 00:03:18,030
출력해서 벽에 걸 수 있는
실제 그림인가요?

70
00:03:18,031 --> 00:03:20,232
원하신다면요

71
00:03:20,233 --> 00:03:25,270
첫 단계는 12명의 유명인의
특정 사진을 기억하는 겁니다

72
00:03:25,271 --> 00:03:28,674
이후 브라이스는
제 생각을 감지하려 노력합니다

73
00:03:28,675 --> 00:03:31,543
이 작업을 위해
대학원생인 맥스와 함께 앉았습니다

74
00:03:31,544 --> 00:03:32,878
"맥스 드래셔
심리학 박사 과정"

75
00:03:32,879 --> 00:03:37,716
실험의 성공은
제가 fMRI 내부에 있는 동안

76
00:03:37,717 --> 00:03:42,588
사진 속 얼굴을 얼마나 생생하게
기억해낼 수 있는가에 달렸습니다

77
00:03:42,589 --> 00:03:45,591
좋아요

78
00:03:45,592 --> 00:03:51,063
저는 이 얼굴들을
꽤 잘 기억하고 있다고 봐요

79
00:03:51,064 --> 00:03:53,699
- 좋아요
- 위험도가 높은 거 같군요

80
00:03:53,700 --> 00:03:58,203
유명인의 얼굴을
기억해내길 기대하면서

81
00:03:58,204 --> 00:04:01,340
저는 금속 탐지기를 거친 후
다음 단계에서 브라이스가

82
00:04:01,341 --> 00:04:04,143
제 뇌 활동을 기록하고 감독할
fMRI로 들어갑니다

83
00:04:04,144 --> 00:04:07,913
그다음 브라이스는 얼굴 재건을 위해
기록을 알고리즘에 입력합니다

84
00:04:07,914 --> 00:04:12,084
장기 기억에서 얼굴을 재건하는
첫 시도라고 하는군요

85
00:04:12,085 --> 00:04:14,153
이 작업이 매우 어려운 이유는
제가 한 시간 전에 본

86
00:04:14,154 --> 00:04:16,821
유명인의 사진을 얼마나
명확히 기억하는가에

87
00:04:16,822 --> 00:04:19,058
의존하기 때문입니다

88
00:04:19,059 --> 00:04:20,792
눈이 맘에 들어요, 보세요

89
00:04:20,793 --> 00:04:22,661
네, 아이들이 더 편안히
느끼도록 하기 위해서죠

90
00:04:22,662 --> 00:04:24,396
여기 아이들이 많이 와요, 네

91
00:04:24,397 --> 00:04:26,932
아이들이 묻던가요?
'저게 날 잡아먹나요?'

92
00:04:26,933 --> 00:04:31,236
"시연
기억 재건"

93
00:04:31,237 --> 00:04:34,239
fMRI는 뇌를 복셀 또는
입체적인 픽셀로 불리는

94
00:04:34,240 --> 00:04:36,975
수천 개의 작은
정육면체로 나누어

95
00:04:36,976 --> 00:04:39,945
뇌 안의 활동을 관찰합니다

96
00:04:39,946 --> 00:04:43,749
이 각각의 복셀은 수십만 개의
뉴런을 담고 있습니다

97
00:04:43,750 --> 00:04:47,753
우리는 fMRI를 이용하여
이 복셀 내 혈류를 감지할 수 있는데

98
00:04:47,754 --> 00:04:50,089
뇌의 해당 부분이
활성화된 걸 의미합니다

99
00:04:50,090 --> 00:04:53,125
제가 수염이 있는
여러 명의 사진을 본다면

100
00:04:53,126 --> 00:04:56,428
제 뇌는 각각 얼굴의 특징에
반응할 겁니다

101
00:04:56,429 --> 00:04:59,965
하지만 줄곧 관여하는
뇌의 공통적인 위치도 있을 겁니다

102
00:04:59,966 --> 00:05:03,936
제 뇌의 해당 부분이
수염에 반응한 결과일 수도 있습니다

103
00:05:03,937 --> 00:05:09,341
이후 제가 얼굴을 상상할 때
해당 위치가 반응하는 것을 보면

104
00:05:09,342 --> 00:05:13,779
브라이스는 제가 수염을 생각한다고
추측할 수 있습니다

105
00:05:13,780 --> 00:05:15,814
지금 마이클은
스캐너 안에 들어와 있고

106
00:05:15,815 --> 00:05:17,716
한 번에 하나씩 화면에 나타나는
단어를 보면서

107
00:05:17,717 --> 00:05:18,851
"존 조 - 메간 폭스"

108
00:05:18,852 --> 00:05:20,819
얼굴을 시각화하려고
노력하고 있습니다

109
00:05:20,820 --> 00:05:23,255
얼굴을 가능한 한
상세히 기억하세요

110
00:05:23,256 --> 00:05:25,691
여기 보이는 건
우리가 얻는 이미지입니다

111
00:05:25,692 --> 00:05:29,028
2초마다 이 뇌 이미지를
하나씩 받습니다

112
00:05:29,029 --> 00:05:33,666
우리가 이미지를 얻으면
다시 최신 상태로 실시간 변합니다

113
00:05:33,667 --> 00:05:36,101
fMRI 첫 시간이 끝나고

114
00:05:36,102 --> 00:05:38,971
브라이스와 그의 팀이 뇌 스캔으로
이미지를 해독하기 위해

115
00:05:38,972 --> 00:05:44,843
제 뇌 활동의 언어를 배우는
두 번째 시간이 찾아왔습니다

116
00:05:44,844 --> 00:05:46,545
안녕하세요, 마이클
아직도 잘 되고 있나요?

117
00:05:46,546 --> 00:05:48,113
네

118
00:05:48,114 --> 00:05:52,718
이분들은 수백 개의
독특한 얼굴을 제게 보여주고

119
00:05:52,719 --> 00:05:55,020
뇌가 얼굴의 특정한 특징에
반응하는 방식을 기록할 겁니다

120
00:05:55,021 --> 00:05:59,491
그러고 나서 이 정보를 사용하여
제가 첫 스캔 단계에서 생각한

121
00:05:59,492 --> 00:06:03,328
유명인의 얼굴을 재건합니다
실험 첫 단계에서

122
00:06:03,329 --> 00:06:06,198
마이클에게 얼굴을 많이 보여줄수록
더 좋은 결과가 나올 거라고 생각했습니다

123
00:06:06,199 --> 00:06:09,802
마이클이 힘들어하지 않는 선에서
가능한 한 오래 그 안에 둘 겁니다

124
00:06:09,803 --> 00:06:13,372
fMRI 안에 있는
최대 시간은 2시간이었습니다

125
00:06:13,373 --> 00:06:18,310
하지만 저는 400개 이상의
얼굴을 볼 수 있었기에

126
00:06:18,311 --> 00:06:21,080
꽤 흥미로운 결과를
얻기에 충분할 겁니다

127
00:06:21,081 --> 00:06:22,681
마이클, 끝났습니다
훌륭했어요

128
00:06:22,682 --> 00:06:26,652
- 꺼내드리겠습니다
- 좋아요

129
00:06:26,653 --> 00:06:28,821
으악, 와

130
00:06:28,822 --> 00:06:31,390
오늘 얼굴을 많이 봤어요

131
00:06:31,391 --> 00:06:32,858
세상에

132
00:06:32,859 --> 00:06:36,328
당신이 거기 들어가 있는 동안
우리가 찍은 사진의 일부가 여기 있습니다

133
00:06:36,329 --> 00:06:39,965
당신 뇌 사진이죠
이제 수치화하려고 합니다

134
00:06:39,966 --> 00:06:42,034
맥스가 데이터를 분석할 겁니다

135
00:06:42,035 --> 00:06:45,270
내일 다시 만나
결과를 보기로 합시다

136
00:06:45,271 --> 00:06:47,973
우리가 방금 수집한
뇌 데이터에서 나온 얼굴 이미지를

137
00:06:47,974 --> 00:06:51,377
- 재건하려 노력하겠습니다
- 알겠습니다, 내일 뵙죠

138
00:06:51,378 --> 00:06:54,646
- 좋습니다, 고맙습니다
- 맥스, 고마워요, 기대돼요

139
00:06:54,647 --> 00:07:04,356
밤을 새워야 할 거예요
이 데이터가 완벽하면 좋겠어요

140
00:07:04,357 --> 00:07:06,892
좋습니다, 저는 큘 박사의
연구실로 돌아왔습니다

141
00:07:06,893 --> 00:07:08,994
하루 사이에 그의 팀이
데이터를 분석했습니다

142
00:07:08,995 --> 00:07:15,701
제가 무슨 생각을 했다고 보는지
몹시 알고 싶습니다

143
00:07:15,702 --> 00:07:17,536
제 결과가 어떤가요?

144
00:07:17,537 --> 00:07:19,171
괜찮아 보입니다

145
00:07:19,172 --> 00:07:20,773
잠시 후 여기서 보기로 하죠

146
00:07:20,774 --> 00:07:22,341
좋아요, 기대돼요

147
00:07:22,342 --> 00:07:24,243
- 앉아도 될까요?
- 네, 앉으세요

148
00:07:24,244 --> 00:07:26,645
좋아요

149
00:07:26,646 --> 00:07:30,349
우선, 제가 뭘 보고 있죠?

150
00:07:30,350 --> 00:07:32,818
제가 실제 암기한 사진들인가요?

151
00:07:32,819 --> 00:07:34,787
- 그렇습니다
- 그리고 이게

152
00:07:34,788 --> 00:07:38,023
제 상상을 재건하신 거군요

153
00:07:38,024 --> 00:07:40,726
- 맞아요
- 네

154
00:07:40,727 --> 00:07:44,530
이게 재건된 것 중 하나고요

155
00:07:44,531 --> 00:07:45,931
재미있어요

156
00:07:45,932 --> 00:07:47,966
저건 존 조군요

157
00:07:47,967 --> 00:07:50,402
괜찮네요

158
00:07:50,403 --> 00:07:53,872
- 나란히 볼 수 있을까요?
- 네

159
00:07:53,873 --> 00:07:59,678
일반적으로 표정에
유사성이 보입니다

160
00:07:59,679 --> 00:08:02,414
여기 헤어라인이
거의 일치하는 걸 볼 수 있어요

161
00:08:02,415 --> 00:08:04,983
제가 생각한 얼굴 형태는

162
00:08:04,984 --> 00:08:06,985
사각형이었어요

163
00:08:06,986 --> 00:08:08,320
- 네
- 이것들이

164
00:08:08,321 --> 00:08:09,421
제게서 나왔군요

165
00:08:09,422 --> 00:08:12,791
제가 존 조의
이 이미지를 시각화할 때

166
00:08:12,792 --> 00:08:16,495
사격형 얼굴이 우선
가장 두드러졌어요

167
00:08:16,496 --> 00:08:20,065
- 재미있군요
- 사격형 사람이라고 계속 생각했죠

168
00:08:20,066 --> 00:08:23,335
훌륭해요, 좋아요

169
00:08:23,336 --> 00:08:28,307
저건 메간 폭스예요

170
00:08:28,308 --> 00:08:30,142
보여주실 때...
나왔네요, 나란히요

171
00:08:30,143 --> 00:08:31,844
나란히, 맞습니다

172
00:08:31,845 --> 00:08:36,682
당신이 실제 본 사진이고
이건 우리가 재건한 겁니다

173
00:08:36,683 --> 00:08:39,817
메간 폭스를 말씀드리자면

174
00:08:39,818 --> 00:08:42,021
저는 명확한 그림을
마음에 그릴 수 없었어요

175
00:08:42,022 --> 00:08:45,057
어떤 이유에서인지
이미지를 마음에 가져오는 게

176
00:08:45,058 --> 00:08:46,992
어려웠습니다

177
00:08:46,993 --> 00:08:50,963
제가 인식한 건
얼굴이 근엄하다는 거였어요

178
00:08:50,964 --> 00:08:54,066
제겐 여성스러움으로 보였습니다

179
00:08:54,067 --> 00:08:58,804
당신은 근엄함을 보았으니
합치면 일치하죠

180
00:08:58,805 --> 00:09:02,474
브라이스와 그의 팀이 이걸
제 기억에서 읽었다는 걸 기억하세요

181
00:09:02,475 --> 00:09:07,112
제가 얼굴을 기억할 때
사진 같은 정확성을 가지고

182
00:09:07,113 --> 00:09:08,747
동시에 모든
세부사항을 그리나요?

183
00:09:08,748 --> 00:09:11,016
아니면 제가 한 번에
몇 개에 집중하나요?

184
00:09:11,017 --> 00:09:16,121
제 마음을 읽으시면, 제 기억이 얼마나
나쁜지, 어떻게 작용하는지 아실 거예요

185
00:09:16,122 --> 00:09:19,024
저예요!

186
00:09:19,025 --> 00:09:25,330
좋아요, 이건 제 이미지에 대한
제 생각을 재건한 거군요

187
00:09:25,331 --> 00:09:27,499
맞습니다

188
00:09:27,500 --> 00:09:29,435
수염은 어디 갔죠?

189
00:09:29,436 --> 00:09:32,137
모르겠어요, 제게
말해주실 거라 기대했어요

190
00:09:32,138 --> 00:09:36,542
예를 들어, 이건 제가
제 얼굴을 기억한 그림입니다

191
00:09:36,543 --> 00:09:39,244
저처럼 보이지 않아요
하지만 문제는

192
00:09:39,245 --> 00:09:41,613
제가 자신을 얼마나
잘 그리는가입니다

193
00:09:41,614 --> 00:09:45,784
전 제 얼굴을 자주 생각하지 않아요
그래서 결과가 이상한 건

194
00:09:45,785 --> 00:09:48,020
기술의 결함만큼이나

195
00:09:48,021 --> 00:09:51,824
제 기억과 자신에 대한 마음속 그림의
결함 때문일 수 있습니다

196
00:09:51,825 --> 00:09:54,460
저건 제니퍼 로렌스일 겁니다

197
00:09:54,461 --> 00:09:56,095
제니퍼 로렌스요?

198
00:09:56,096 --> 00:10:01,800
제니퍼 로렌스의
훨씬 나이 든 삼촌처럼 보여요

199
00:10:01,801 --> 00:10:05,371
깜짝 놀랄 정도로 비슷한 건 없군요

200
00:10:05,372 --> 00:10:09,208
하지만 이제야
장기 기억에 대해

201
00:10:09,209 --> 00:10:12,678
노력을 기울이기
시작하셨으니까요

202
00:10:12,679 --> 00:10:15,214
브라이스와 그의 팀이

203
00:10:15,215 --> 00:10:18,217
수백 개의 fMRI 속 이미지가 아니라
수천 개를 보여줬으면

204
00:10:18,218 --> 00:10:22,855
더 정확했을 수 있습니다
왜냐하면 그래야 알고리즘이

205
00:10:22,856 --> 00:10:25,057
제 뇌의 언어를
더 철저히 배웠을 테니까요

206
00:10:25,058 --> 00:10:29,228
하지만 그렇다고 해도
제 기억의 질은 여전히 문제였을 겁니다

207
00:10:29,229 --> 00:10:33,298
등식에서 기억이 완전히 잘려나가면
무슨 일이 생기는지 보시죠

208
00:10:33,299 --> 00:10:37,302
브라이스는 또한 제가 fMRI에서
상상이 아니라 얼굴을 보고 있었을 때

209
00:10:37,303 --> 00:10:39,238
제 뇌 활동을 읽었습니다

210
00:10:39,239 --> 00:10:45,144
그리고 이 결과는 제 기억에서
재건된 것보다 훨씬 더 비슷했습니다

211
00:10:45,145 --> 00:10:47,546
좋아요, 제가 여기
보고 있는 건 뭐죠?

212
00:10:47,547 --> 00:10:52,284
여기 윗줄에 보고 계시는 건
스캐너 안에 계셨을 때

213
00:10:52,285 --> 00:10:53,919
보셨던 이미지들입니다

214
00:10:53,920 --> 00:10:57,022
그 아래 밑줄은 우리가 모은
뇌 활동의 패턴으로부터

215
00:10:57,023 --> 00:11:00,092
우리가 그린 재건 모습입니다

216
00:11:00,093 --> 00:11:01,193
"윗줄: 원본 이미지
밑줄: 재건 이미지"

217
00:11:01,194 --> 00:11:03,696
- 이게 원본 이미지에서 왔군요
- 네

218
00:11:03,697 --> 00:11:05,464
이건 제 뇌에서 왔고요

219
00:11:05,465 --> 00:11:07,566
- 맞습니다
- 꽤 비슷한데요

220
00:11:07,567 --> 00:11:10,102
네, 전체적으로 꽤 비슷하죠

221
00:11:10,103 --> 00:11:11,704
완벽하진 않아도요

222
00:11:11,705 --> 00:11:14,239
다양하게 나타나는 걸 보실 수가 있죠

223
00:11:14,240 --> 00:11:17,076
하지만 우리가 전에
발견한 것과 일치합니다

224
00:11:17,077 --> 00:11:20,412
당신이 얼굴을 볼 때
우리가 만든 재건 이미지와 말이죠

225
00:11:20,413 --> 00:11:22,481
실제 얼굴과
일치하는 것이 있습니다

226
00:11:22,482 --> 00:11:26,552
그래서 이건 당신이 이미지를 볼 때
우리가 실제 이미지를 재건할 수 있는지의

227
00:11:26,553 --> 00:11:28,954
- 온전성 검사입니다
- 맞아요

228
00:11:28,955 --> 00:11:31,590
꽤 괜찮아요

229
00:11:31,591 --> 00:11:35,361
브라이스, 맥스
참여하게 해주셔서 감사합니다

230
00:11:35,362 --> 00:11:36,729
제 데이터가 유용하길 기원합니다

231
00:11:36,730 --> 00:11:38,530
감사합니다, 즐거웠습니다

232
00:11:38,531 --> 00:11:43,836
이런 건 항상 유용합니다

233
00:11:43,837 --> 00:11:47,740
"일본 교토"

234
00:11:47,741 --> 00:11:51,443
브라이스 큘 박사의 기억 연구는
생각을 알아내기 위해

235
00:11:51,444 --> 00:11:54,279
컴퓨터가 인간의 정신을

236
00:11:54,280 --> 00:11:56,915
읽는 것이 가능하다는 걸
보여줍니다

237
00:11:56,916 --> 00:11:59,051
하지만 여전히
많은 진전이 필요합니다

238
00:11:59,052 --> 00:12:02,221
예를 들어, 제가 지금 무슨
생각을 하고 있는지 알기 원하시면

239
00:12:02,222 --> 00:12:05,524
말해달라고 요청하는 게
여전히 훨씬 쉽습니다

240
00:12:05,525 --> 00:12:08,327
하지만 제가 말해줄 수 없다면요?

241
00:12:08,328 --> 00:12:11,363
유키야수 카미타니 박사는

242
00:12:11,364 --> 00:12:15,100
수면에 관한 미지의 영역을
개척하기 위해 노력하는

243
00:12:15,101 --> 00:12:18,237
연구자이자 교수, 개척자입니다

244
00:12:18,238 --> 00:12:20,472
저는 그를 만나

245
00:12:20,473 --> 00:12:24,677
생각이 아닌 꿈을 읽기 위해
여기 교토대학에

246
00:12:24,678 --> 00:12:27,513
왔습니다

247
00:12:27,514 --> 00:12:29,548
"과학 개척자 실험실"

248
00:12:29,549 --> 00:12:31,650
카미타니 선생님, 저는 마이클입니다

249
00:12:31,651 --> 00:12:33,385
- 안녕하세요, 전 유키입니다
- 유키, 만나서 반갑습니다

250
00:12:33,386 --> 00:12:34,753
네, 만나서 반갑습니다

251
00:12:34,754 --> 00:12:36,355
지난 10년간

252
00:12:36,356 --> 00:12:40,225
카미타니 박사는 머신 마인드 리딩의
선두에 있었습니다

253
00:12:40,226 --> 00:12:44,396
피실험자가 들어갈 준비가 됐습니다

254
00:12:44,397 --> 00:12:46,098
브라이스 큘과 비슷하게도

255
00:12:46,099 --> 00:12:49,201
그의 초기 실험은
뇌 활동에 기초하여

256
00:12:49,202 --> 00:12:52,771
fMRI 안의 피실험자에게
보여준 이미지의 재건을 연구했습니다

257
00:12:52,772 --> 00:12:55,974
카미타니의 경우는
이미지가 흑백 형태였고

258
00:12:55,975 --> 00:12:59,578
재건 결과가
놀랄 만큼 정확했습니다

259
00:12:59,579 --> 00:13:03,382
최근 카미타니는
심층 신경망과 머신 러닝을 이용하여

260
00:13:03,383 --> 00:13:06,485
피실험자가 훨씬 더 복잡한
사진을 보는 동안

261
00:13:06,486 --> 00:13:09,955
뇌 활동을 해독하는 데
집중해왔습니다

262
00:13:09,956 --> 00:13:13,726
보고 계신 건
심층 신경망의 결과로

263
00:13:13,727 --> 00:13:18,097
사진을 보고 있는 피실험자의
뇌 활동을 처리하고 있습니다

264
00:13:18,098 --> 00:13:20,933
미래에는 무수히 많은
응용이 가능할 수 있습니다

265
00:13:20,934 --> 00:13:26,939
예를 든다면, 범죄 조사와
대인 의사소통 분야입니다

266
00:13:26,940 --> 00:13:28,941
완벽과는 거리가 멀지만

267
00:13:28,942 --> 00:13:32,211
여전히 눈과 귀는 보입니다

268
00:13:32,212 --> 00:13:33,812
"유키야수 카미타니 박사
교토대학 인포매틱스 대학원 교수"

269
00:13:33,813 --> 00:13:35,414
네

270
00:13:35,415 --> 00:13:37,116
색깔도요

271
00:13:37,117 --> 00:13:39,952
네, 어느 정도는요

272
00:13:39,953 --> 00:13:43,088
하지만 그의 가장 최근의
연구 주제는 무의식입니다

273
00:13:43,089 --> 00:13:45,591
그는 꿈을 읽는
매우 야심찬

274
00:13:45,592 --> 00:13:47,526
시도를 하고 있습니다

275
00:13:47,527 --> 00:13:52,398
자신을 수면 연구자와 시각 연구자 중
무엇으로 부르겠습니까?

276
00:13:52,399 --> 00:13:54,266
아마도 뇌 해독자입니다

277
00:13:54,267 --> 00:13:56,001
뇌 해독자요

278
00:13:56,002 --> 00:13:58,303
꽤 멋진 직무 설명이군요

279
00:13:58,304 --> 00:14:02,374
꿈에 대해 하시는 일 중
보여주실 수 있는 게 있나요?

280
00:14:02,375 --> 00:14:03,942
네

281
00:14:03,943 --> 00:14:08,681
우리는 동시 EEG/MRI 기록을
하고 있습니다

282
00:14:08,682 --> 00:14:13,485
카미타니 박사의 꿈 해독에 대한 연구는
큘 박사와 유사한 과정으로 시작합니다

283
00:14:13,486 --> 00:14:17,389
피실험자가 fMRI 안에 있을 때
수천 개의 이미지를 보여줍니다

284
00:14:17,390 --> 00:14:22,094
특정한 걸 생각할 때
뇌가 어떻게 보이는지를 알기 위해서죠

285
00:14:22,095 --> 00:14:24,663
일단 머신 러닝 알고리즘이

286
00:14:24,664 --> 00:14:27,566
피실험자가 생각하는
이미지를 잘 확인하면

287
00:14:27,567 --> 00:14:31,837
EEG 모자를 쓴 피실험자를
fMRI 안에 놓고

288
00:14:31,838 --> 00:14:33,972
잠이 들도록 합니다

289
00:14:33,973 --> 00:14:37,076
EEG 파가 수면 중인 걸 나타낼 때

290
00:14:37,077 --> 00:14:42,247
알고리즘은 피실험자가 아마도
무슨 꿈을 꾸는지를 추정합니다

291
00:14:42,248 --> 00:14:45,851
현재 알고리즘은
20개 범주를 찾고 있습니다

292
00:14:45,852 --> 00:14:51,423
건물, 교통편
언어의 글자 같은 것이죠

293
00:14:51,424 --> 00:14:55,828
그다음 연구자들은 피실험자를 깨워
무슨 꿈을 꾸었는지 묻고

294
00:14:55,829 --> 00:15:00,299
알고리즘 추정과 회상한 꿈이
일치하는지를 확인합니다

295
00:15:00,300 --> 00:15:03,836
카미타니 실험의
실제 데이터가 여기 있습니다

296
00:15:03,837 --> 00:15:06,305
밑에는 범주를 나타내는 단어들입니다

297
00:15:06,306 --> 00:15:08,841
각 범주의 이름이
피실험자의 현재 꿈의

298
00:15:08,842 --> 00:15:11,143
확률을 기반으로

299
00:15:11,144 --> 00:15:13,846
실시간으로
더 커지거나 작아집니다

300
00:15:13,847 --> 00:15:15,848
지금 보시다시피
활동이 현재 '글자' 범주에서

301
00:15:15,849 --> 00:15:18,984
가장 강합니다
문자를 의미하죠

302
00:15:18,985 --> 00:15:23,822
이 시점에 피실험자는 깨어나 있고
이건 보고된 내용입니다

303
00:15:23,823 --> 00:15:26,692
제가 보고 있던 건
문자였습니다

304
00:15:26,693 --> 00:15:30,729
글을 쓰는 양식 같은 게
있었습니다

305
00:15:30,730 --> 00:15:32,998
- 꽤 으스스하군요
- 네

306
00:15:32,999 --> 00:15:37,102
그렇죠? 꿈을 염탐하셨어요

307
00:15:37,103 --> 00:15:39,938
어떤 면에선 그렇죠

308
00:15:39,939 --> 00:15:42,174
하지만 정확도가
그리 대단하지 않아요

309
00:15:42,175 --> 00:15:44,710
정확도가 그리 대단하지 않지만

310
00:15:44,711 --> 00:15:47,579
제가 남의 꿈을 추측하는
평균적인 정확도는 0이에요

311
00:15:47,580 --> 00:15:48,947
맞아요

312
00:15:48,948 --> 00:15:52,518
꿈의 내용을 추정하는
연구를 지속하면서

313
00:15:52,519 --> 00:15:55,554
카미타니 박사는
우리 꿈에서 이미지를 재건하는

314
00:15:55,555 --> 00:15:59,224
최신 프로젝트를 시작했습니다

315
00:15:59,225 --> 00:16:05,831
실험실에서 꿈을 재건한
데이터를 가져오셨군요

316
00:16:05,832 --> 00:16:08,467
이건 우리가
여전히 작업 중인 건데

317
00:16:08,468 --> 00:16:11,337
일반적인 경향이 있습니다

318
00:16:11,338 --> 00:16:13,972
해독기에 뭘 넣든지

319
00:16:13,973 --> 00:16:18,344
재건 결과는 가운데 방울이 있죠

320
00:16:18,345 --> 00:16:20,779
맞아요, 모두
방울에 대한 꿈 같네요

321
00:16:20,780 --> 00:16:22,014
네

322
00:16:22,015 --> 00:16:25,217
저는 한 걸음 물러나서

323
00:16:25,218 --> 00:16:28,654
우리가 이 화면에서 보고 있는 게
어떤 면에서 우리 꿈의

324
00:16:28,655 --> 00:16:34,793
첫 번째 사진이라는 것을
인정하고 싶네요

325
00:16:34,794 --> 00:16:38,497
우리는 혁명적인 연구의
초기 단계를 보고 있습니다

326
00:16:38,498 --> 00:16:43,535
언젠가 우리는 꿈에 대한 이미지나
심지어 기록 영상도 볼지 모릅니다

327
00:16:43,536 --> 00:16:47,539
그리고 카미타니 박사는
이 일을 하는 세계에서 유일한 인물입니다

328
00:16:47,540 --> 00:16:51,643
그는 우리의 무의식을 여행하는
유일한 탐험가입니다

329
00:16:51,644 --> 00:16:54,546
이 연구는 아직 발표되지 않았나요?

330
00:16:54,547 --> 00:16:56,015
네

331
00:16:56,016 --> 00:16:59,985
제게 보여주셔서 감사합니다

332
00:16:59,986 --> 00:17:02,888
"캘리포니아주 로스앤젤레스"

333
00:17:02,889 --> 00:17:06,991
큘 박사와 카미타니 박사 같은
연구자들이 미래에

334
00:17:06,992 --> 00:17:10,162
마인드 리딩으로
어떤 성과를 이루게 될지를

335
00:17:10,163 --> 00:17:15,034
완벽하게 헤아리기는 어렵습니다

336
00:17:15,035 --> 00:17:18,337
하지만 잠시 속도를 늦춰보겠습니다
왜냐하면 우리는 우리가 자신을 아는 것보다

337
00:17:18,338 --> 00:17:22,174
우리를 더 잘 알 수 있는
기술에 대해 말하고 있기 때문입니다

338
00:17:22,175 --> 00:17:24,309
우리가 정말 이걸 해야 할까요?

339
00:17:24,310 --> 00:17:25,978
그 질문을 다루기 위해

340
00:17:25,979 --> 00:17:28,247
저는 윤리, 신경과학, 인공지능 전문가인

341
00:17:28,248 --> 00:17:32,918
줄리아 보스만을 만납니다

342
00:17:32,919 --> 00:17:35,521
팬텀 컴퓨팅에서 전략 책임자인 그녀는

343
00:17:35,522 --> 00:17:37,990
세계 경제 포럼의 위원이며

344
00:17:37,991 --> 00:17:41,393
레이 커즈와일의
싱귤래리티대학 졸업생이자

345
00:17:41,394 --> 00:17:44,063
미래 기술과 그 영향을
전문으로 하는 싱크탱크인

346
00:17:44,064 --> 00:17:51,337
포어사이트 인스티튜트의
전 소장이기도 합니다

347
00:17:51,338 --> 00:17:53,939
줄리아, 대화할 시간을
내주셔서 감사합니다

348
00:17:53,940 --> 00:17:55,641
- 네, 천만에요
- 제가 이 질문을 드릴

349
00:17:55,642 --> 00:17:57,009
완벽한 분이셔요

350
00:17:57,010 --> 00:17:58,410
심오한 문제예요

351
00:17:58,411 --> 00:18:01,814
하지만 극도로 중요하고
점점 더 긴급해지고 있죠

352
00:18:01,815 --> 00:18:04,817
지금 우리는 아주 재미있는 때에
살고 있다고 생각해요

353
00:18:04,818 --> 00:18:06,985
뇌와 기계가 실제로
가깝게 함께 움직이고 있는 시기죠

354
00:18:06,986 --> 00:18:08,787
"줄리아 보스만
세계 경제 포럼 - 세계 미래 위원회"

355
00:18:08,788 --> 00:18:10,889
뇌 활동 관찰에 있어

356
00:18:10,890 --> 00:18:15,627
윤리적인 선을
여기 어디에 그어야 할까요?

357
00:18:15,628 --> 00:18:18,497
내적 생각은 얼마나
사생활로 보아야 합니까?

358
00:18:18,498 --> 00:18:23,769
강력한 기술이라면
그걸 행사하는 손에 달려있죠

359
00:18:23,770 --> 00:18:25,070
이 모든 새 기술은

360
00:18:25,071 --> 00:18:29,608
사용자를 더 강하게
만들 수 있습니다

361
00:18:29,609 --> 00:18:32,711
그래서 우리가 탓할 건
기술이 아닙니다

362
00:18:32,712 --> 00:18:36,181
사용법과 사용자를 봐야 합니다

363
00:18:36,182 --> 00:18:40,519
자격이 있는 사람이
이 기술을 갖는 걸 어떻게 확신할까요?

364
00:18:40,520 --> 00:18:42,921
미래 기술의 이해를 위해
정책과 법에서 활동하는 사람을

365
00:18:42,922 --> 00:18:49,395
포함하는 게
매우 중요하다고 생각합니다

366
00:18:49,396 --> 00:18:52,631
저는 그 공동의 측면에서
희망을 갖습니다

367
00:18:52,632 --> 00:18:54,667
그러면 장점에 대해 말해보죠

368
00:18:54,668 --> 00:18:57,069
여기 응용할 수 있는 건
뭐가 있을까요?

369
00:18:57,070 --> 00:19:00,673
예를 들어 고인이신
스티븐 호킹에 대해 생각하면

370
00:19:00,674 --> 00:19:05,010
만약 그분에게 세상 또는 컴퓨터와
더 잘 교류할 수 있는

371
00:19:05,011 --> 00:19:09,348
방법이 있었더라면, 우리에게
뭘 나누셨을지 상상해 보시죠

372
00:19:09,349 --> 00:19:11,350
감금증후군을 가진 분들이죠, 맞나요?

373
00:19:11,351 --> 00:19:14,920
그런 분들이 있어요
본인들도 그걸 알고 있고요

374
00:19:14,921 --> 00:19:17,156
하지만 우리는 그들이
말하려고 하는 게 무엇인지 또는

375
00:19:17,157 --> 00:19:19,158
무얼 느끼는지 알려면
뇌를 들여다볼

376
00:19:19,159 --> 00:19:21,527
- 뭔가가 필요하죠
- 맞아요

377
00:19:21,528 --> 00:19:27,132
우리의 진정한 자연적 자아를
기술에 넘겨준다고

378
00:19:27,133 --> 00:19:33,172
기술을 두려워하는 분에게
무슨 말씀을 하고 싶으신가요?

379
00:19:33,173 --> 00:19:38,344
인간 진화 또는
문명 개발 등으로 불리는

380
00:19:38,345 --> 00:19:41,380
다음 단계에 도달하는 건

381
00:19:41,381 --> 00:19:43,816
매력적입니다

382
00:19:43,817 --> 00:19:47,152
우리는 어떤 면에서 이미
자연적인 삶을 살고 있지 않아요

383
00:19:47,153 --> 00:19:50,322
그렇다면 우리 대부분은
아마도 30 또는 40세 전에

384
00:19:50,323 --> 00:19:52,658
죽기 때문이에요

385
00:19:52,659 --> 00:19:56,228
모든 종류의 병이 생기고
이 옷도 입고 있지 않을 거예요

386
00:19:56,229 --> 00:19:57,629
안경도 없겠죠

387
00:19:57,630 --> 00:19:58,831
- 콘택트렌즈도요
- 맞아요

388
00:19:58,832 --> 00:20:00,933
항생제도 없을 거고

389
00:20:00,934 --> 00:20:03,369
우리는 이미

390
00:20:03,370 --> 00:20:06,205
매우 미래적인 사이보그입니다
만약 우리 자신을

391
00:20:06,206 --> 00:20:09,875
지금의 우리와
유전학적으로 거의 동일한

392
00:20:09,876 --> 00:20:12,878
1만 년 전의 인간과
비교한다면요

393
00:20:12,879 --> 00:20:18,517
네, 그렇죠

394
00:20:18,518 --> 00:20:20,753
인지를 이해하기 위해선

395
00:20:20,754 --> 00:20:23,956
우리는 당장 기본적으로
사람들이 무슨 생각을 하는지

396
00:20:23,957 --> 00:20:27,726
묻거나 행동을 관찰해야 해요

397
00:20:27,727 --> 00:20:31,530
하지만 생각을 직접 읽는 게
훨씬 나을 겁니다

398
00:20:31,531 --> 00:20:34,400
이건 큘 박사가
기억을 연구하는 방법이고

399
00:20:34,401 --> 00:20:39,071
카미타니 박사가
수면과 꿈을 연구하는 방법이에요

400
00:20:39,072 --> 00:20:41,907
하지만 비록 기술이
갈 길이 멀다고 해도

401
00:20:41,908 --> 00:20:45,978
윤리적인 문제가 될 수 있다는 걸
아는 건 어렵지 않습니다

402
00:20:45,979 --> 00:20:47,680
그게 말이죠

403
00:20:47,681 --> 00:20:53,052
완전히 야생인 인간은 없습니다

404
00:20:53,053 --> 00:20:56,989
우리는 기술과 함께 진화하고 있어요

405
00:20:56,990 --> 00:21:00,793
오늘날 인간과 기술은
갈라놓을 수 없습니다

406
00:21:00,794 --> 00:21:04,630
우리가 하는 모든 새로운 일에 대해
조심할 필요가 있다는 건 사실이지만

407
00:21:04,631 --> 00:21:09,234
그런 일이 발생할 거라는
사실을 바꿀 수는 없습니다

408
00:21:09,235 --> 00:21:12,738
우리가 반복해서
살아온 이야기입니다

409
00:21:12,739 --> 00:21:15,274
우리는 둘러앉은 채 영원히

410
00:21:15,275 --> 00:21:18,210
속도 제한이 존재해야 하는지
그리고 그걸 집행할 권한이

411
00:21:18,211 --> 00:21:20,979
누구에게 있는지
논쟁할 수 있습니다

412
00:21:20,980 --> 00:21:22,348
하지만 그러지 않았죠

413
00:21:22,349 --> 00:21:25,851
대신 우리는 밀고 나아가
자동차를 만들었고

414
00:21:25,852 --> 00:21:30,089
진행해 감에 따라
세부사항을 책임감 있게 해결했습니다

415
00:21:30,090 --> 00:21:32,591
신기술에 대한 윤리적인 질문은

416
00:21:32,592 --> 00:21:37,196
기술을 용이하게 할 때
가장 이롭습니다

417
00:21:37,197 --> 00:21:40,699
발전을 불필요하게
막을 때가 아니고요

418
00:21:40,700 --> 00:21:42,668
당신의 꿈을 따르세요

419
00:21:42,669 --> 00:21:46,005
그리고 꿈을 이루면
저에게도 보여주시기 바랍니다

420
00:21:46,006 --> 00:21:48,408
늘 그렇듯, 시청해주셔서 감사합니다

