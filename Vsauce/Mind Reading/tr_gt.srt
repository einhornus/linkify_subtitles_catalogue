1
00:00:05,237 --> 00:00:06,438
Akıl okuma?

2
00:00:06,439 --> 00:00:08,172
Tabii ki değil.

3
00:00:08,173 --> 00:00:11,376
Okumayı seviyorum.

4
00:00:11,377 --> 00:00:15,413
Bak, zihin okuma kulağa
sahte-bilimsel gibi gelebilir--

5
00:00:15,414 --> 00:00:16,614
dilim

6
00:00:16,615 --> 00:00:18,416
kusura bakma-- bullshoot.

7
00:00:18,417 --> 00:00:21,486
Ama onun bilimsel karşılığı olan
düşünce

8
00:00:21,487 --> 00:00:23,855
tanımlaması çok gerçek bir şeydir.

9
00:00:23,856 --> 00:00:26,524
Nörogörüntüleme
ve makine öğrenimine dayanır

10
00:00:26,525 --> 00:00:29,861
ve gerçekten harika olan
şey, zihin okuma

11
00:00:29,862 --> 00:00:33,498
deneylerinin sadece
birinin ne düşündüğünü gözetlemekle ilgili olmamasıdır.

12
00:00:33,499 --> 00:00:37,602
Düşüncelerin neyden yapıldığını bulmakla ilgililer
.

13
00:00:37,603 --> 00:00:39,504
Yani, bir şey


14
00:00:39,505 --> 00:00:43,174
düşündüğümde, bu zihinsel resim
gerçekte neye benziyor?

15
00:00:43,175 --> 00:00:44,709
Hangi çözünürlükte var?  Bir hafızanın

16
00:00:44,710 --> 00:00:47,145
aslına uygunluğu ne kadardır


17
00:00:47,146 --> 00:00:49,380
ve
zaman içinde nasıl değişirler?

18
00:00:49,381 --> 00:00:51,116
Bu bölümde,

19
00:00:51,117 --> 00:00:52,750

insanların zihinlerini okumanın bu soruları

20
00:00:52,751 --> 00:00:54,719
cevaplamamıza nasıl yardımcı olabileceğine bakacağım
.

21
00:00:54,720 --> 00:00:58,490
Yolculuğum tam burada
Oregon Üniversitesi'nde başlıyor.

22
00:00:58,491 --> 00:01:01,259
Kuhl laboratuvarından Dr. Brice Kuhl ile buluşacağım
.

23
00:01:01,260 --> 00:01:03,394
O, insanların ona söylemeden ne düşündüklerini anlamak
için beyin görüntüleme

24
00:01:03,395 --> 00:01:06,664
ve makine öğrenimini kullanan bir sinirbilimci


25
00:01:06,665 --> 00:01:31,789
.

26
00:01:31,790 --> 00:01:33,625
Bana
burada ne yaptığını söyle.

27
00:01:33,626 --> 00:01:36,794
Burada bilişsel
sinirbilim

28
00:01:36,795 --> 00:01:38,396
programındayım ve insan hafızası üzerine çalışıyorum.

29
00:01:38,397 --> 00:01:41,099
Laboratuvarım öncelikle
nörogörüntüleme yöntemlerini kullanıyor,

30
00:01:41,100 --> 00:01:42,567
bu nedenle

31
00:01:42,568 --> 00:01:44,169
fonksiyonel manyetik
rezonans görüntüleme

32
00:01:44,170 --> 00:01:45,637
veya fMRI kullanarak çok fazla iş yapıyoruz.

33
00:01:45,638 --> 00:01:49,340
Ve
anıları araştırmak için fMRI'yi nasıl kullanıyorsunuz?

34
00:01:49,341 --> 00:01:51,776

Nöral aktivite modeline bakıyoruz.

35
00:01:51,777 --> 00:01:54,445
Bir bellek oluşturduğunuzda,
belirli bir kalıp vardır.

36
00:01:54,446 --> 00:01:56,548
Ve bu kalıbı kaydedebilir


37
00:01:56,549 --> 00:01:59,617
ve sonra
bu kalıbın eski haline getirilip getirilmediğini

38
00:01:59,618 --> 00:02:02,554
veya daha sonraki bir noktada,
örneğin onu hatırladığınız zaman gibi yeniden etkinleştirilip etkinleştirilmediğini test edebiliriz.

39
00:02:02,555 --> 00:02:05,823
Bu
, beyin aktivitesinin kalıplarına bakabileceğimiz

40
00:02:05,824 --> 00:02:10,061
ve neyin
hatırlandığını, hatırlanacağını,

41
00:02:10,062 --> 00:02:11,262
hatta sadece düşünüldüğünü çıkarabileceğimiz anlamına mı geliyor?

42
00:02:11,263 --> 00:02:13,631
Evet ve buna
kod çözme diyoruz.

43
00:02:13,632 --> 00:02:16,568
Bu nedenle, temel olarak
girdi modelinizi

44
00:02:16,569 --> 00:02:18,469
,


45
00:02:18,470 --> 00:02:21,272
siz bir şeyi hatırlarken kaydettiğimiz bir tür etkinlik kalıbı olarak alır
.

46
00:02:21,273 --> 00:02:23,441
Ve hatırladıklarınız hakkında bir tahminde bulunuyoruz
.

47
00:02:23,442 --> 00:02:27,178
Bunun
zihin okuma gibi geldiğini görebilirsiniz.

48
00:02:27,179 --> 00:02:28,713
[gülüyor]
Evet.  Kulağa öyle geliyor.

49
00:02:28,714 --> 00:02:32,584
Brice,
bugün bana ne yapacaksın?

50
00:02:32,585 --> 00:02:34,419
Yani bugün yapacağımız şey bizim


51
00:02:34,420 --> 00:02:36,354
için keşfedilmemiş bir bölge
.

52
00:02:36,355 --> 00:02:38,623
Bu yüzden


53
00:02:38,624 --> 00:02:40,258
, sizin üzerinizde deneyin yeni bir çeşidini deneyeceğiz.

54
00:02:40,259 --> 00:02:42,660
Bu yüzden
belirli sonuçları garanti edemem.

55
00:02:42,661 --> 00:02:44,195
Ama
alanın nerede olduğunu

56
00:02:44,196 --> 00:02:46,664
ve
nereye gitmeye çalıştığımızı temsil ediyor.

57
00:02:46,665 --> 00:02:48,800
Bugün,


58
00:02:48,801 --> 00:02:50,268
yüzler üzerinde çalışacağınız bir deneye katılacaksınız.

59
00:02:50,269 --> 00:02:51,803
Bu yüzden size


60
00:02:51,804 --> 00:02:53,404
ünlülerin 12 fotoğrafını incelemenizi sağlayacağız.

61
00:02:53,405 --> 00:02:54,872
Zaten aşina olduğum insanlar
.

62
00:02:54,873 --> 00:02:56,674
- Tanıdığın insanlar, evet.
-Peki.

63
00:02:56,675 --> 00:02:59,143
Ve
o resimleri hatırlamaya çalışacaksın.

64
00:02:59,144 --> 00:03:01,112
O zaman
seni MRI tarayıcısına sokacağız.

65
00:03:01,113 --> 00:03:04,249
Bu resmi
mümkün olduğunca canlı bir şekilde akla getirmeye çalışın.

66
00:03:04,250 --> 00:03:06,417
Ve siz bu resimleri hayal etmeye çalışırken biz de beyin aktivitenizi kaydedeceğiz


67
00:03:06,418 --> 00:03:08,753

.

68
00:03:08,754 --> 00:03:10,555

Yüzü oluşturmaya çalışacağız.

69
00:03:10,556 --> 00:03:12,590
Esasen
hatırladığınız şeyin bir resmini çizin.

70
00:03:12,591 --> 00:03:14,125
-Bir resim?
-Bir resim.

71
00:03:14,126 --> 00:03:16,327
Çıktısını


72
00:03:16,328 --> 00:03:17,729
alabileceğimiz ve
benim duvarıma asabileceğim gerçek bir resim.

73
00:03:17,730 --> 00:03:19,831
[gülüyor]
İsterseniz.

74
00:03:19,832 --> 00:03:22,634
[Michael] İlk adım
,

75
00:03:22,635 --> 00:03:25,336



76
00:03:25,337 --> 00:03:28,640
Brice'ın daha sonra
düşündüğümü tespit etmeye çalışacağı 12 özel ünlü fotoğrafını ezberlemem.

77
00:03:28,641 --> 00:03:33,278
Bu
yüksek lisans öğrencisi Max'i yapmak için oturdum.

78
00:03:33,279 --> 00:03:35,280
Tahminlerinin
başarısı, kısmen, fMRI içindeyken

79
00:03:35,281 --> 00:03:37,415

bu yüzleri

80
00:03:37,416 --> 00:03:43,087
olabildiğince canlı bir şekilde hatırlama yeteneğime bağlı
.

81
00:03:43,088 --> 00:03:44,422
Pekala, yani...

82
00:03:44,423 --> 00:03:46,157
[iç çeker]

83
00:03:46,158 --> 00:03:50,728
Sanırım bunların hepsiyle ilgili oldukça iyi bir
anım var.

84
00:03:50,729 --> 00:03:53,698
-Harika.
- Risklerin yüksek olduğunu hissediyorum.

85
00:03:53,699 --> 00:03:56,701
Ünlülerin yüzleri
umarım ezberlenir,

86
00:03:56,702 --> 00:03:58,303
bir sonraki adımın zamanı geldi

87
00:03:58,304 --> 00:04:00,071

: metal detektöründen

88
00:04:00,072 --> 00:04:01,706
ve fMRI'ye girmek,

89
00:04:01,707 --> 00:04:04,676
burada Brice
beyin aktivitemi kaydedecek ve izleyecek

90
00:04:04,677 --> 00:04:08,746
ve daha
sonra yüzleri yeniden oluşturmak için algoritmasına besleyecek.

91
00:04:08,747 --> 00:04:10,448
Bu, uzun süreli hafızadan


92
00:04:10,449 --> 00:04:12,383
yüzleri yeniden oluşturmaya çalıştığı ilk sefer olacak
,

93
00:04:12,384 --> 00:04:14,385
ki bu çok zor,
çünkü bir saat önce gördüğüm ünlülerin fotoğraflarını

94
00:04:14,386 --> 00:04:16,720
ne kadar net hatırlayabildiğime güveniyoruz


95
00:04:16,721 --> 00:04:19,090
.

96
00:04:19,091 --> 00:04:21,225
Gözlerini seviyorum.
Şuna bak.

97
00:04:21,226 --> 00:04:24,362
[kadın]

98
00:04:24,363 --> 00:04:31,102
Çocuk
"Beni yiyecek" gibi olmaz mı?

99
00:04:31,103 --> 00:04:34,205
Bir fMRI
, beyindeki aktiviteyi,

100
00:04:34,206 --> 00:04:36,774
onu


101
00:04:36,775 --> 00:04:39,744
voksel
veya hacimsel piksel adı verilen binlerce küçük kübe bölerek izler.

102
00:04:39,745 --> 00:04:41,446
Bu voksellerin her biri

103
00:04:41,447 --> 00:04:43,581
yüz
binlerce nöron içerir.

104
00:04:43,582 --> 00:04:46,117
fMRI kullanarak,
bu voksellerdeki kan akışını tespit edebiliyoruz

105
00:04:46,118 --> 00:04:47,719

,

106
00:04:47,720 --> 00:04:50,088
bu da beynin o bölümünün aktif olduğu anlamına geliyor
.

107
00:04:50,089 --> 00:04:53,124
Bana
bıyıklı insanların birkaç resmi gösterilirse,

108
00:04:53,125 --> 00:04:56,327
beynim
her yüzün özelliklerine tepki verecektir.

109
00:04:56,328 --> 00:04:58,329
Ama
beynimin baştan sona meşgul olan ortak bir alanı olacak

110
00:04:58,330 --> 00:05:00,164

.

111
00:05:00,165 --> 00:05:04,102

Beynimin bıyıklara tepki veren bölgesi olabilir.

112
00:05:04,103 --> 00:05:07,171
Daha sonra,
bir yüz hayal ettiğimde

113
00:05:07,172 --> 00:05:09,440
, Brice
o bölgenin meşgul olduğunu fark ederse, bıyık

114
00:05:09,441 --> 00:05:11,476
düşündüğümü tahmin edebilir


115
00:05:11,477 --> 00:05:13,811
.

116
00:05:13,812 --> 00:05:15,780
Yani şu anda
Michael tarayıcıda

117
00:05:15,781 --> 00:05:18,282
ve
ekranda birer birer kelimelerin belirdiğini görüyor

118
00:05:18,283 --> 00:05:20,651

ve yüzü görselleştirmeye, yüzü

119
00:05:20,652 --> 00:05:23,187

mümkün olduğunca ayrıntılı bir şekilde hatırlamaya çalışıyor.

120
00:05:23,188 --> 00:05:25,356
Burada görebilecekleriniz
, elde ettiğimiz görüntülerdir.

121
00:05:25,357 --> 00:05:28,793

Her iki saniyede bir bu beyin hacimlerinden birini alıyoruz.

122
00:05:28,794 --> 00:05:32,797
Yani
biz görüntüleri toplarken bunlar gerçek zamanlı olarak yenileniyor.

123
00:05:32,798 --> 00:05:35,633
[Michael]
fMRI seansının birinci bölümü bittiğinde

124
00:05:35,634 --> 00:05:38,503

, Brice ve ekibinin

125
00:05:38,504 --> 00:05:41,773



126
00:05:41,774 --> 00:05:44,776
daha sonra
beyin taramaları yoluyla deşifre edebilmeleri için beyin aktivitemin dilini öğrenecekleri ikinci bölümün zamanı geldi.

127
00:05:44,777 --> 00:05:46,544
Merhaba Michael.
Hala iyi misin?

128
00:05:46,545 --> 00:05:48,312
[Michael]
Evet.

129
00:05:48,313 --> 00:05:50,381
Bana
yüzlerce eşsiz yüz gösterecekler

130
00:05:50,382 --> 00:05:52,784
ve beynimin

131
00:05:52,785 --> 00:05:54,852
belirli yüz
özelliklerine nasıl tepki verdiğini kaydedecekler.

132
00:05:54,853 --> 00:05:57,188
Daha sonra
bu bilgiyi

133
00:05:57,189 --> 00:05:59,657



134
00:05:59,658 --> 00:06:03,127

, taramanın ilk aşamasında düşündüğüm ünlülerin yüzlerini yeniden oluşturmak için kullanacaklar.

135
00:06:03,128 --> 00:06:05,530
Gerçekten, Michael'a ne kadar çok yüz
gösterebilirsek o kadar iyi.

136
00:06:05,531 --> 00:06:08,166
Bu yüzden,


137
00:06:08,167 --> 00:06:09,600
rahat olduğu sürece onu temelde orada tutacağız.

138
00:06:09,601 --> 00:06:11,636
[Michael] fMRI'ye girebildiğimiz
maksimum süre iki saatti

139
00:06:11,637 --> 00:06:13,538
.

140
00:06:13,539 --> 00:06:17,175
Ancak
400'den fazla yüze bakabildim,

141
00:06:17,176 --> 00:06:18,743
bu da oldukça ilginç sonuçlar elde etmek için yeterli olmalı

142
00:06:18,744 --> 00:06:20,778

.

143
00:06:20,779 --> 00:06:22,447
Hey, Michael, başardın.
Bu harikaydı.

144
00:06:22,448 --> 00:06:23,681
Seni almaya geleceğiz
.

145
00:06:23,682 --> 00:06:33,157
[Michael]
Pekala.

146
00:06:33,158 --> 00:06:34,725
Evet, bunlar sadece siz oradayken


147
00:06:34,726 --> 00:06:36,561
çektiğimiz fotoğrafları gösteriyor
.

148
00:06:36,562 --> 00:06:38,095
Beyninizin bazı görüntüleri.

149
00:06:38,096 --> 00:06:39,764
Şimdi
bazı sayıları toplamaya çalışacağız.

150
00:06:39,765 --> 00:06:42,200
Max verilerinizi analiz
edecek.

151
00:06:42,201 --> 00:06:43,701
Yarın tekrar buluşacağız


152
00:06:43,702 --> 00:06:45,369

, sonuçlara bakacağız, az önce topladığımız beyin verilerinden

153
00:06:45,370 --> 00:06:47,638

yüz görüntülerini gerçekten yeniden oluşturmaya çalışacağız

154
00:06:47,639 --> 00:06:49,740

.

155
00:06:49,741 --> 00:06:51,175
Tamam.
Yarın görüşürüz.

156
00:06:51,176 --> 00:06:52,577
Tamam.
Çok teşekkürler.

157
00:06:52,578 --> 00:06:54,178
Max, ben de teşekkür ederim.
bekleyemem

158
00:06:54,179 --> 00:06:55,847

Bütün geceyi çeksen iyi olur.

159
00:06:55,848 --> 00:07:04,288
Bu verilerin
mükemmel olmasını istiyorum.

160
00:07:04,289 --> 00:07:06,524
Pekala,
Dr. Kuhl'un laboratuvarına geri döndüm.

161
00:07:06,525 --> 00:07:08,693
Bir
gecede ekibi verileri karıştırdı

162
00:07:08,694 --> 00:07:15,500
ve beni ne düşünürken gördüklerini düşündüklerini görmek için sabırsızlanıyorum
.

163
00:07:15,501 --> 00:07:17,101
Sonuçlarım nasıl?

164
00:07:17,102 --> 00:07:18,736
Bence iyi görünüyorlar.

165
00:07:18,737 --> 00:07:20,705

Birazdan buraya bir göz atacağız.

166
00:07:20,706 --> 00:07:22,406
Tamam,
bekleyemem.

167
00:07:22,407 --> 00:07:24,342
- O zaman oturabilir miyim?
-Evet, otur.

168
00:07:24,343 --> 00:07:26,143
Pekala, yani...

169
00:07:26,144 --> 00:07:28,212
her şeyden önce...

170
00:07:28,213 --> 00:07:30,081
ne görüyorum?
Oh, tamam, peki,

171
00:07:30,082 --> 00:07:32,283
bunlar
gerçekten ezberlediğim resimler.

172
00:07:32,284 --> 00:07:34,252
-Doğru.
- Ve bu

173
00:07:34,253 --> 00:07:37,822
benim hayal gücümden
yeniden oluşturduğun şey.

174
00:07:37,823 --> 00:07:40,091
-Doğru.
-Vay canına.  Peki.

175
00:07:40,092 --> 00:07:43,094
[Brice]
Pekala, bu, oluşturulan
rekonstrüksiyonlardan biri

176
00:07:43,095 --> 00:07:44,562
.

177
00:07:44,563 --> 00:07:46,063
[Michael]
İlginç.

178
00:07:46,064 --> 00:07:47,698
[Max]
Demek bu John Cho.

179
00:07:47,699 --> 00:07:50,668
[Michael]
Fena değil.  Fena değil.

180
00:07:50,669 --> 00:07:53,337
-Yan yana görebilir miyiz?
-Evet.

181
00:07:53,338 --> 00:07:55,673
[Michael] Genel


182
00:07:55,674 --> 00:08:00,044
olarak yüz
ifadelerinde benzerlikler görüyorum.

183
00:08:00,045 --> 00:08:02,213
Bilirsiniz,
burada neredeyse saç çizgisinin uyumlu olduğunu görebiliyordunuz.

184
00:08:02,214 --> 00:08:04,682
Yüzün şeklinin
de şu olduğunu düşündüm--

185
00:08:04,683 --> 00:08:06,684
Bir tür
kare şekli vardı.

186
00:08:06,685 --> 00:08:08,152
-Evet.  Evet.
-Demek

187
00:08:08,153 --> 00:08:09,387
benim aklıma gelenler bunlar.

188
00:08:09,388 --> 00:08:11,289
Ve böylece


189
00:08:11,290 --> 00:08:13,257
John Cho'nun bu görüntüsünü

190
00:08:13,258 --> 00:08:16,260
zihnimde canlandırırken, yüzün
kareliği ilk ve en göze çarpan şeydi.

191
00:08:16,261 --> 00:08:19,697
Düşünmeye devam ettim,
o kare adamdı.

192
00:08:19,698 --> 00:08:23,401
Harika, tamam.

193
00:08:23,402 --> 00:08:26,704
[Brice]
Demek Megan Fox bu.

194
00:08:26,705 --> 00:08:28,439
[Michael]
Mm-hmm.

195
00:08:28,440 --> 00:08:30,207
Bize
yan yana göstereceksin.

196
00:08:30,208 --> 00:08:31,776
[Michael
] Yan yana.  Doğru.

197
00:08:31,777 --> 00:08:33,644
[Brice]
Gerçekte gördüğünüz resmi görebilirsiniz


198
00:08:33,645 --> 00:08:36,547
ve bu
bizim oluşturduğumuz rekonstrüksiyon.

199
00:08:36,548 --> 00:08:39,417
ben sana bunu.
Megan Fox, kafamda

200
00:08:39,418 --> 00:08:42,353
çok net bir resim oluşturamadım
.

201
00:08:42,354 --> 00:08:45,056
Nedense, onun bu görüntüsünü


202
00:08:45,057 --> 00:08:47,058
zihnimde canlandırmak benim için gerçekten zordu.

203
00:08:47,059 --> 00:08:50,595
Yüzündeki sertlik
, benim fark ettiğim bir şeydi.

204
00:08:50,596 --> 00:08:53,698
Ben de orada olduğunu hissettim--
Kadınsı görünüyordu.

205
00:08:53,699 --> 00:08:55,533
Ve
sertliği yakaladın.

206
00:08:55,534 --> 00:08:58,769
Ve böylece birlikte,
bu bir eşleşme üretir.

207
00:08:58,770 --> 00:09:00,538
[Michael]
Brice ve ekibinin

208
00:09:00,539 --> 00:09:02,773

bunları hafızamdan okuduklarını unutmayın.

209
00:09:02,774 --> 00:09:04,609
Ama bir yüzü hatırladığımda,

210
00:09:04,610 --> 00:09:07,678
her ayrıntıyı
aynı

211
00:09:07,679 --> 00:09:09,313
anda fotoğrafik bir doğrulukla resmediyor muyum?

212
00:09:09,314 --> 00:09:10,748
Yoksa
bir seferde sadece birkaçına mı katılayım?

213
00:09:10,749 --> 00:09:13,417
Aklımı okuyarak,


214
00:09:13,418 --> 00:09:15,219
hafızamın ne kadar kötü olduğunu
ve nasıl çalıştığını görüyor olabilirler.

215
00:09:15,220 --> 00:09:18,689
-Ben!  Ben!
-[Brice güler]

216
00:09:18,690 --> 00:09:21,525
Pekala, bu benim bu


217
00:09:21,526 --> 00:09:24,729
imajım hakkında düşünmemi yeniden
canlandırmanız.

218
00:09:24,730 --> 00:09:26,497
[Brice]
Bu doğru.

219
00:09:26,498 --> 00:09:28,666
Sakal nereye gitti?

220
00:09:28,667 --> 00:09:31,068
[Brice] Bilmiyorum.
Bana söyleyebileceğini umuyordum.

221
00:09:31,069 --> 00:09:36,240
[Michael]
Örneğin, bu
benim kendi yüzümü hatırladığım bir resim.

222
00:09:36,241 --> 00:09:38,743
Gerçekten bana benzemiyor
ama soru şu:

223
00:09:38,744 --> 00:09:41,345
Kendimi hayal etmede ne kadar iyiyim
?

224
00:09:41,346 --> 00:09:44,048
Kendi yüzümü
o kadar sık düşünmüyorum, bu y�

225
00:09:44,049 --> 00:09:45,616
zden sonuçtaki tuhaflık, tekn
olojideki kusur

226
00:09:45,617 --> 00:09:47,752
ar kadar kendi
hafızamdaki ve ke

227
00:09:47,753 --> 00:09:51,288
dimin zihinsel resmindeki kusur
arla ilgili olabi

228
00:09:51,289 --> 00:09:53,691
ir.  Demek Jennifer Lawrence bu,
sanırım.

229
00:09:53,692 --> 00:09:55,726
[Michael
] Jennifer Lawrence bu mu?

230
00:09:55,727 --> 00:09:59,664
Jennifer
Lawrence'ın kendisinden çok daha büyük amcası gibi görünüyor.

231
00:09:59,665 --> 00:10:01,365
[hepsi kıkırdar]

232
00:10:01,366 --> 00:10:05,069
Buradaki hiçbir şey
akıllara durgunluk verecek kadar yakın değildi.

233
00:10:05,070 --> 00:10:09,407
Ama bu,


234
00:10:09,408 --> 00:10:11,409
bu tür uzun süreli
anıları denemeye yeni başladığınız bir şey.

235
00:10:11,410 --> 00:10:14,679
Bana fMRI'da yüzlerce yerine binlerce görüntü gösterselerdi, Brice ve ekibinin
aklımda okudukları

236
00:10:14,680 --> 00:10:18,549
daha doğru olabilirdi


237
00:10:18,550 --> 00:10:20,284

,

238
00:10:20,285 --> 00:10:22,520
çünkü o zaman algoritma


239
00:10:22,521 --> 00:10:24,655
beynimin dilini
daha iyi öğrenirdi.

240
00:10:24,656 --> 00:10:27,358
Ama ne olursa olsun
, hatıralarımın kalitesi

241
00:10:27,359 --> 00:10:29,226

hala bir sorun olurdu.

242
00:10:29,227 --> 00:10:30,661
Demek istediğim,


243
00:10:30,662 --> 00:10:33,164
hafıza denklemden tamamen çıkarıldığında ne olduğuna bakın
.

244
00:10:33,165 --> 00:10:35,166
Brice ayrıca


245
00:10:35,167 --> 00:10:37,168

fMRI'da yüzlere bakarken beyin aktivitemi de okudu.

246
00:10:37,169 --> 00:10:39,103
sadece onları hayal etmek değil.

247
00:10:39,104 --> 00:10:41,672
Ve bu sonuçlar
, hafızamdan

248
00:10:41,673 --> 00:10:44,675
yeniden oluşturulanlardan çok daha yakındı
.

249
00:10:44,676 --> 00:10:47,111
Tamam, peki,
tam burada neye bakıyorum?

250
00:10:47,112 --> 00:10:48,679
[Brice]
Pekala,

251
00:10:48,680 --> 00:10:51,682
burada en üst sırada gördükleriniz,
bunlar tarayıcıdayken gördüğünüz görüntüler

252
00:10:51,683 --> 00:10:53,584
.

253
00:10:53,585 --> 00:10:56,754
Bunun altında, bu alt sırada,


254
00:10:56,755 --> 00:11:00,725

topladığımız beyin aktivitesi modellerinden çizdiğimiz rekonstrüksiyonlar var.

255
00:11:00,726 --> 00:11:03,828
-Bu kaynak görüntüden.
-Doğru.

256
00:11:03,829 --> 00:11:05,629
[Michael]
Bunlar benim beynimden.

257
00:11:05,630 --> 00:11:07,565
-[Brice] Doğru.
-[Michael] Oldukça yakınlar.

258
00:11:07,566 --> 00:11:09,700
Evet, genel olarak
oldukça yakınlardı.

259
00:11:09,701 --> 00:11:11,602
Yani mükemmel değil.

260
00:11:11,603 --> 00:11:13,771
Bunlar--
bunlarda bazı değişkenlikler olduğunu görebilirsiniz.

261
00:11:13,772 --> 00:11:16,640
Ancak bu,
daha önce bulduğumuz şeyle tutarlıdır,

262
00:11:16,641 --> 00:11:18,409
oluşturduğumuz rekonstrüksiyonlar


263
00:11:18,410 --> 00:11:20,244

, yüzleri incelerken

264
00:11:20,245 --> 00:11:22,279

, gerçek yüz arasında bir benzerlik vardır.

265
00:11:22,280 --> 00:11:23,714
Yani bu bir
nevi akıl sağlığı kontrolü,

266
00:11:23,715 --> 00:11:25,750
yani siz onları izlerken
görüntüleri yeniden oluşturabiliyoruz

267
00:11:25,751 --> 00:11:28,219
.
-Doğru doğru.

268
00:11:28,220 --> 00:11:31,355
Oldukça iyiler.

269
00:11:31,356 --> 00:11:33,190
Brice, Max,


270
00:11:33,191 --> 00:11:35,126

bunun bir parçası olmama izin verdiğin için çok teşekkür ederim.

271
00:11:35,127 --> 00:11:36,660
Umarım verilerim işe yarar.

272
00:11:36,661 --> 00:11:38,596
Teşekkürler.
Çok eğlenceliydi.

273
00:11:38,597 --> 00:11:46,837
Bunları düşünmek bizim için her zaman yararlıdır
.

274
00:11:46,838 --> 00:11:50,808
Dr. Brice Kuhl'un hafıza araştırması
,

275
00:11:50,809 --> 00:11:53,677
bir
bilgisayarın birinin zihnini okumasının mümkün olduğunu gösteriyor.

276
00:11:53,678 --> 00:11:56,313
Ne düşündüklerini anlamak için
.

277
00:11:56,314 --> 00:11:58,415
Ancak hala çok ilerleme kaydedilmesi
gerekiyor.

278
00:11:58,416 --> 00:12:00,050
Demek istediğim,

279
00:12:00,051 --> 00:12:01,619
şu anda ne düşündüğümü bilmek istiyorsan,
örneğin, sana

280
00:12:01,620 --> 00:12:05,189
söylememi istemek daha kolay
.

281
00:12:05,190 --> 00:12:07,491
Ama ya
sana söyleyemezsem?

282
00:12:07,492 --> 00:12:10,594
Dr. Yukiyasu Kamitani
, uyku duvarının arkasındaki sınırı araştıran bir araştırmacı,

283
00:12:10,595 --> 00:12:14,498
profesör ve öncüdür


284
00:12:14,499 --> 00:12:17,535
.

285
00:12:17,536 --> 00:12:19,703

Buraya Kyoto Üniversitesi'ne

286
00:12:19,704 --> 00:12:21,672
onunla tanışmak ve


287
00:12:21,673 --> 00:12:24,175
birinin
ne düşündüğünü değil,

288
00:12:24,176 --> 00:12:29,647

birinin rüyasını okumak nasıl bir şey olduğunu görmek için geldim.

289
00:12:29,648 --> 00:12:31,348
Kamitani sensei,
ben Michael.

290
00:12:31,349 --> 00:12:33,818
-Merhaba, ben Yuki.
-Yuki, tanıştığıma memnun oldum.

291
00:12:33,819 --> 00:12:36,320
[Michael
] Son on yıldır,

292
00:12:36,321 --> 00:12:38,455
Dr. Kamitani


293
00:12:38,456 --> 00:12:40,124
makine zihin okumasının ön saflarında yer aldı.

294
00:12:40,125 --> 00:12:43,527
Denek, bilirsiniz,
içeri girmeye hazır.

295
00:12:43,528 --> 00:12:45,462
Brice Kuhl'a benzer şekilde

296
00:12:45,463 --> 00:12:48,632
, ilk deneyleri


297
00:12:48,633 --> 00:12:52,236

, beyin aktivitelerine dayalı olarak bir fMRI'da deneklere gösterilen görüntülerin yeniden yapılandırılmasını araştırdı.

298
00:12:52,237 --> 00:12:53,637
Kamitani'nin durumunda

299
00:12:53,638 --> 00:12:55,706
, görüntüler
siyah beyaz şekillerdi ve

300
00:12:55,707 --> 00:12:58,375

rekonstrüksiyonlar çarpıcı biçimde doğruydu.

301
00:12:58,376 --> 00:13:03,180
Son zamanlarda, Kamitani, deneklerin çok daha karmaşık fotoğrafları görüntülerken beyin aktivitelerini deşifre etmek için
derin sinir ağlarını

302
00:13:03,181 --> 00:13:04,815
ve makine öğrenimini kullanmaya odaklandı

303
00:13:04,816 --> 00:13:06,450



304
00:13:06,451 --> 00:13:08,686

.

305
00:13:08,687 --> 00:13:12,756
Gördüğünüz şey, fotoğrafa bakan bir öznenin beyin aktivitesini işleyen
derin bir sinir ağının sonucudur

306
00:13:12,757 --> 00:13:15,226



307
00:13:15,227 --> 00:13:17,795
.

308
00:13:17,796 --> 00:13:20,431
Bunun
gelecekte

309
00:13:20,432 --> 00:13:22,733

örneğin cezai soruşturmalarda

310
00:13:22,734 --> 00:13:26,470
ve kişiler arası
iletişimde sayısız uygulaması olabilir.

311
00:13:26,471 --> 00:13:28,739
[Kamitani]
Bu mükemmel olmaktan çok uzak.

312
00:13:28,740 --> 00:13:33,177
Ama bence hala bazı gözleri görüyorsun,
bilirsin, gözler ve bilirsin...

313
00:13:33,178 --> 00:13:34,778
[Michael]
Şey, evet.

314
00:13:34,779 --> 00:13:36,447
Ve renkler de.

315
00:13:36,448 --> 00:13:39,783
[Kamitani]
Evet, bir dereceye kadar, evet.

316
00:13:39,784 --> 00:13:42,419
Ancak en güncel çalışması
bilinçaltıyla ilgili.

317
00:13:42,420 --> 00:13:45,256
Son
derece iddialı bir şeye girişiyor:

318
00:13:45,257 --> 00:13:46,824
rüyalarımızı kaydetmek.

319
00:13:46,825 --> 00:13:49,326

Kendinize uyku

320
00:13:49,327 --> 00:13:50,828
araştırmacısı mı yoksa vizyon araştırmacısı mı derdiniz?

321
00:13:50,829 --> 00:13:53,664
Belki bir beyin şifre çözücü.

322
00:13:53,665 --> 00:13:55,432
Bir beyin kod çözücü.

323
00:13:55,433 --> 00:13:57,534
Bu çok güzel bir
iş tanımı.

324
00:13:57,535 --> 00:14:01,739
Bana
rüyalarla yaptıklarından bir şey gösterebilir misin?

325
00:14:01,740 --> 00:14:08,379
[Kamitani]
Mm-hmm, evet.

326
00:14:08,380 --> 00:14:10,514
Dr. Kamitani'nin
rüya kod çözme çalışması, Dr. Kuhl'unkine

327
00:14:10,515 --> 00:14:13,317
benzer bir süreçle başlar
: belirli şeyleri düşünürken beynin nasıl

328
00:14:13,318 --> 00:14:15,452
göründüğünü öğrenmek için test


329
00:14:15,453 --> 00:14:17,187
deneğine bir fMRI'dayken binlerce görüntü göstermek

330
00:14:17,188 --> 00:14:18,722



331
00:14:18,723 --> 00:14:21,358

.

332
00:14:21,359 --> 00:14:23,794
Makine öğrenimi
algoritması,

333
00:14:23,795 --> 00:14:26,764

deneğin hangi görüntüleri düşündüğünü belirlemede oldukça başarılı olduğunda

334
00:14:26,765 --> 00:14:29,300
, süje, başında


335
00:14:29,301 --> 00:14:31,335
bir EEG başlığı olan bir fMRI'ye yerleştirilir


336
00:14:31,336 --> 00:14:33,470
ve uykuya dalmaya davet edilir.

337
00:14:33,471 --> 00:14:36,573
EEG dalgaları
kişinin rüya gördüğünü gösterdiğinde

338
00:14:36,574 --> 00:14:39,243
, algoritma


339
00:14:39,244 --> 00:14:41,645
deneğin ne tür
rüyalar gördüğünü tahmin eder.

340
00:14:41,646 --> 00:14:45,215
Şu anda, algoritma
20 kategori arar.  Bir dilde

341
00:14:45,216 --> 00:14:48,485
binalar,
ulaşım

342
00:14:48,486 --> 00:14:50,621
ve karakterler gibi şeyler
.

343
00:14:50,622 --> 00:14:53,324
Araştırmacılar daha
sonra konuyu uyandırır,

344
00:14:53,325 --> 00:14:55,326
onlara ne
hakkında rüya

345
00:14:55,327 --> 00:14:57,227
gördüklerini sorar ve algoritmanın
tahmini

346
00:14:57,228 --> 00:14:59,530
ile kişinin
hatırlamasının uyuşup uyuşmadığını görür.

347
00:14:59,531 --> 00:15:03,367
İşte
Kamitani'nin deneylerinden birinin gerçek verileri.

348
00:15:03,368 --> 00:15:05,703
Aşağıda kategorilerden oluşan bir kelime
bulutu bulunmaktadır.

349
00:15:05,704 --> 00:15:08,339
Her kategorinin adı


350
00:15:08,340 --> 00:15:10,574



351
00:15:10,575 --> 00:15:13,344

, öznenin o anki rüyasında bulunma olasılığına bağlı olarak gerçek zamanlı olarak büyür veya küçülür.

352
00:15:13,345 --> 00:15:15,346
Şimdi, görebileceğiniz gibi,
etkinlik şu anda yazılı dil anlamına gelen

353
00:15:15,347 --> 00:15:18,349
"karakter" kategorisi için en güçlü durumda
.

354
00:15:18,350 --> 00:15:20,684
Bu
noktada konu uyandı

355
00:15:20,685 --> 00:15:29,660
ve
bunu bildirdiler.

356
00:15:29,661 --> 00:15:32,062
Bu oldukça ürkütücü.

357
00:15:32,063 --> 00:15:33,697
-[gülüyor]
-Doğru mu?  Demek istediğim,

358
00:15:33,698 --> 00:15:36,700
sen onların rüyasını gözetledin.

359
00:15:36,701 --> 00:15:39,370
Evet, bir şekilde.
Ama

360
00:15:39,371 --> 00:15:42,406
... doğruluk
o kadar iyi değil, yani

361
00:15:42,407 --> 00:15:44,341
... Doğruluk
o kadar büyük değil ama, bilirsiniz, insanların

362
00:15:44,342 --> 00:15:46,677
rüyalarını tahmin etme konusundaki normal doğruluğum
sıfır.

363
00:15:46,678 --> 00:15:48,145
Doğru.

364
00:15:48,146 --> 00:15:49,580



365
00:15:49,581 --> 00:15:52,182



366
00:15:52,183 --> 00:15:54,785
Dr. Kamitani
, rüyaların içeriğini tahmin etme araştırmasına devam ederken, en yeni projesine başlıyor:

367
00:15:54,786 --> 00:15:58,389
aslında rüyalarımızdan görüntüleri yeniden inşa etmek
.

368
00:15:58,390 --> 00:16:01,458
Demek


369
00:16:01,459 --> 00:16:02,659
laboratuvarınızın yarattığı bazı rekonstrüksiyonları getirdiniz...

370
00:16:02,660 --> 00:16:04,061
Mm-hmm.

371
00:16:04,062 --> 00:16:17,741
...rüyaların.

372
00:16:17,742 --> 00:16:20,210
Doğru, hepsi
lekelerle ilgili rüyalara benziyor.

373
00:16:20,211 --> 00:16:21,779
[Kamitani]
Evet.

374
00:16:21,780 --> 00:16:24,448
Demek istediğim,
sadece bir adım geri atmak istiyorum ve

375
00:16:24,449 --> 00:16:27,785

bu ekranda baktığımız şeyin

376
00:16:27,786 --> 00:16:31,655
bir bakıma bir rüyanın ilk
fotoğraflarından bazıları olduğunu takdir ediyorum.

377
00:16:31,656 --> 00:16:33,357
Mm-hmm.

378
00:16:33,358 --> 00:16:35,759



379
00:16:35,760 --> 00:16:38,062
Devrimci araştırmanın en erken aşamasına bakıyoruz.

380
00:16:38,063 --> 00:16:40,164
Bir gün, kendi
hayallerimizin görüntülerini alabilir

381
00:16:40,165 --> 00:16:42,766
, hatta filmlerini kaydedebiliriz
.

382
00:16:42,767 --> 00:16:45,335
Ve Dr. Kamitani,
dünyada

383
00:16:45,336 --> 00:16:47,237
şimdiye kadar bunu yapan tek kişidir.

384
00:16:47,238 --> 00:16:50,707
O, bilinçaltımıza yolculuk eden yalnız bir kaşif
.

385
00:16:50,708 --> 00:16:53,644
Yani bu eser
henüz yayımlanmadı bile.

386
00:16:53,645 --> 00:16:55,345
Hayır

387
00:16:55,346 --> 00:17:01,752
. -Bana gösterdiğin için teşekkürler.
-[gülüyor]

388
00:17:01,753 --> 00:17:06,155

Dr. Kuhl ve Dr. Kamitani gibi araştırmacıların zihin okuma

389
00:17:06,156 --> 00:17:11,328

sayesinde gelecekte elde

390
00:17:11,329 --> 00:17:13,697

edebilecekleri görüşleri tam olarak anlamak zor.

391
00:17:13,698 --> 00:17:15,399
Ama
biraz yavaşlayalım,

392
00:17:15,400 --> 00:17:17,233
çünkü bizi


393
00:17:17,234 --> 00:17:21,105

bizden daha iyi tanıyan bir teknolojiden bahsediyoruz.  Bunu

394
00:17:21,106 --> 00:17:23,740
gerçekten yapmalı mıyız
?

395
00:17:23,741 --> 00:17:25,275
Bu soruyu ele


396
00:17:25,276 --> 00:17:27,310
almak için
etik,

397
00:17:27,311 --> 00:17:30,447
sinirbilim
ve yapay zeka alanında bir uzmanla görüşeceğim:

398
00:17:30,448 --> 00:17:32,216
Julia Bossmann.

399
00:17:32,217 --> 00:17:34,518



400
00:17:34,519 --> 00:17:37,087

Dünya Ekonomik Forumu konsey üyesi

401
00:17:37,088 --> 00:17:40,424
, Ray Kurzweil'in
Singularity Üniversitesi mezunu

402
00:17:40,425 --> 00:17:43,293
ve geleceğin teknolojileri ve etkileri konusunda
uzmanlaşmış bir düşünce kuruluşu olan Foresight Institute'un eski başkanı Fathom Computing'de strateji direktörüdür

403
00:17:43,294 --> 00:17:46,530



404
00:17:46,531 --> 00:17:50,200
.

405
00:17:50,201 --> 00:17:52,669
Julia, sohbet etmek için biraz zaman ayırdığın için teşekkürler
.

406
00:17:52,670 --> 00:17:54,438
-Evet tabiki.
-Bu soruları yöneltebileceğim mükemmel insansın

407
00:17:54,439 --> 00:17:55,739

.

408
00:17:55,740 --> 00:17:57,274
-Mm-hmm.
-Ve onlar derin sorular.

409
00:17:57,275 --> 00:17:58,709
Ama bence
son derece önemliler

410
00:17:58,710 --> 00:18:00,577
ve giderek
daha fazla baskı oluşturuyorlar.

411
00:18:00,578 --> 00:18:04,348
Bence
şu anda çok ilginç bir zamanda

412
00:18:04,349 --> 00:18:06,316
yaşıyoruz çünkü
beyinlerin ve

413
00:18:06,317 --> 00:18:07,751
makinelerin aslında
birbirine yaklaştığı bu zamandayız.

414
00:18:07,752 --> 00:18:10,020
Peki konu


415
00:18:10,021 --> 00:18:12,356
beyin aktivitesine bakabilmek olduğunda,

416
00:18:12,357 --> 00:18:15,292

buradaki etik çizgiler nerede?  İç düşüncelerim

417
00:18:15,293 --> 00:18:17,327
ne kadar özel
olmalı?

418
00:18:17,328 --> 00:18:19,663
Herhangi bir güçlü
teknolojide olduğu gibi,

419
00:18:19,664 --> 00:18:22,266
onu kullanan
ellere bağlıdır.

420
00:18:22,267 --> 00:18:24,401
Tüm bu yeni teknolojiler

421
00:18:24,402 --> 00:18:28,472
,
onları kullananları daha güçlü kılabilecek şeyler.

422
00:18:28,473 --> 00:18:32,042
Bu yüzden
teknolojiyi suçlamak istemiyoruz ama istiyoruz--

423
00:18:32,043 --> 00:18:33,477
nasıl kullanılıyor

424
00:18:33,478 --> 00:18:35,445
ve kim kullanıyor?

425
00:18:35,446 --> 00:18:37,748
Peki
bu

426
00:18:37,749 --> 00:18:39,416
teknolojinin doğru ellerde olduğundan nasıl emin olacağız?

427
00:18:39,417 --> 00:18:41,718
Bu nedenle, gelecekte ne olacağını anlamak


428
00:18:41,719 --> 00:18:45,322
için politika ve yasalara göre hareket eden insanları dahil

429
00:18:45,323 --> 00:18:48,592

etmenin çok önemli olduğunu düşünüyorum.

430
00:18:48,593 --> 00:18:51,528

İşbirlikçi yönü konusunda umutluyum.

431
00:18:51,529 --> 00:18:53,430

Şimdi iyi şeylerden bahsedelim.

432
00:18:53,431 --> 00:18:56,133
Demek istediğim,
buradaki uygulamalar nelerdir?

433
00:18:56,134 --> 00:18:58,135
Evet, yani

434
00:18:58,136 --> 00:18:59,803
merhum Stephen Hawking'i düşünürsek,
örneğin dünyayla veya bilgisayarlarla

435
00:18:59,804 --> 00:19:04,608
daha zengin bir arayüz oluşturma yöntemi olsaydı


436
00:19:04,609 --> 00:19:06,643
,
bizimle neler paylaşabileceğini ancak hayal edebiliriz

437
00:19:06,644 --> 00:19:08,645

.

438
00:19:08,646 --> 00:19:10,647
Kilitli sendromu olanlar,
değil mi?

439
00:19:10,648 --> 00:19:13,584
Ordalar.
Orada olduklarını biliyorlar.

440
00:19:13,585 --> 00:19:15,786
Ama ne söylemeye çalıştıklarını ya da ne hissettiklerini görmek
için beyinlerine bakmak için bir şeye ihtiyacımız var

441
00:19:15,787 --> 00:19:17,788



442
00:19:17,789 --> 00:19:20,657
.
-Doğru, aynen.

443
00:19:20,658 --> 00:19:22,793
Peki,


444
00:19:22,794 --> 00:19:26,396

teknolojiden,

445
00:19:26,397 --> 00:19:31,802
gerçek
doğal benliğimizi teknolojiye teslim etmekten bu kadar korkan insanlara ne diyorsunuz?

446
00:19:31,803 --> 00:19:36,640



447
00:19:36,641 --> 00:19:40,177
Bazı
insanların insan evrimi

448
00:19:40,178 --> 00:19:43,280
veya uygarlık gelişimi
vb. olarak adlandırabilecekleri bir sonraki seviyeye geçme konusunda cezbedici bir şey var.

449
00:19:43,281 --> 00:19:46,250
Bir bakıma zaten
doğal yaşamlar yaşamıyoruz değil mi?

450
00:19:46,251 --> 00:19:51,822
Çünkü o zaman çoğumuz
30-40 yaşından önce

451
00:19:51,823 --> 00:19:53,490

ölürdük. Her türlü hastalığımız olurdu.

452
00:19:53,491 --> 00:19:55,492

Bu kıyafeti giymeyecektik.

453
00:19:55,493 --> 00:19:58,161
Gözlüklerimiz
veya kontak lenslerimiz olmazdı.

454
00:19:58,162 --> 00:19:59,763
Antibiyotiğimiz olmazdı.

455
00:19:59,764 --> 00:20:03,233
[Julia]
Kendimizi

456
00:20:03,234 --> 00:20:05,335



457
00:20:05,336 --> 00:20:08,805

10.000 yıl önce yaşayan

458
00:20:08,806 --> 00:20:10,574
ve genetik


459
00:20:10,575 --> 00:20:11,808
olarak şimdi olduğumuz kişiyle neredeyse aynı olan insanla karşılaştırırsak, bizler zaten çok fütürist siborglarız.

460
00:20:11,809 --> 00:20:17,748
[Michael]
Evet, gerçekten öyleyiz.

461
00:20:17,749 --> 00:20:19,549
Bilişi anlamak için


462
00:20:19,550 --> 00:20:22,686
şu anda temel
olarak ya insanlardan

463
00:20:22,687 --> 00:20:24,321
ne düşündükleri hakkında konuşmalarını istememiz


464
00:20:24,322 --> 00:20:26,556
ya da davranışlarını gözlemlememiz gerekiyor.

465
00:20:26,557 --> 00:20:30,360
Ancak düşünceleri doğrudan okumak
çok daha iyi olurdu.

466
00:20:30,361 --> 00:20:33,630
Dr. Kuhl
hafızayı böyle inceliyor

467
00:20:33,631 --> 00:20:38,402
ve Dr. Kamitani
de uyku ve rüyaları böyle inceliyor.

468
00:20:38,403 --> 00:20:40,671
Ancak teknolojinin
kat etmesi gereken uzun bir yol olsa da,

469
00:20:40,672 --> 00:20:43,106

etik soruların

470
00:20:43,107 --> 00:20:44,841
nasıl bir sorun haline gelebileceğini görmek kolay.

471
00:20:44,842 --> 00:20:47,110
Şey, işte şu:

472
00:20:47,111 --> 00:20:51,782

Tamamen vahşi bir insan diye bir şey yoktur.

473
00:20:51,783 --> 00:20:55,886
Teknoloji ile birlikte gelişiyoruz
.

474
00:20:55,887 --> 00:21:00,090
Günümüzde insan ve teknoloji
ayrılmaz bir bütündür.

475
00:21:00,091 --> 00:21:01,725
Şimdi, yaptığımız


476
00:21:01,726 --> 00:21:03,760
her yeni şeyde dikkatli olmamız gerektiği doğru

477
00:21:03,761 --> 00:21:08,332
ama
bunların olacağı gerçeğini değiştiremeyiz.

478
00:21:08,333 --> 00:21:11,635
Tekrar tekrar yaşadığımız bir hikaye
.

479
00:21:11,636 --> 00:21:14,171
Bilirsiniz,
sonsuza kadar oturup

480
00:21:14,172 --> 00:21:16,807

bir hız sınırının olması gerekip gerekmediğini

481
00:21:16,808 --> 00:21:19,743
ve
bunu uygulama yetkisinin kimde olması gerektiğini tartışabilirdik.

482
00:21:19,744 --> 00:21:21,445
Ama yapmadık.

483
00:21:21,446 --> 00:21:24,715
Bunun yerine, devam ettik
ve arabaları icat ettik

484
00:21:24,716 --> 00:21:29,252
ve ilerledikçe ayrıntıları sorumlu bir şekilde
çözdük.

485
00:21:29,253 --> 00:21:31,254

Yeni teknolojilerle ilgili etik sorular

486
00:21:31,255 --> 00:21:35,726

, ilerlemeyi gereksiz yere engellediklerinde değil, teknolojiyi kolaylaştırdıklarında en iyi sonucu verir

487
00:21:35,727 --> 00:21:40,130

.

488
00:21:40,131 --> 00:21:41,498
Öyleyse hayallerinin peşinden git.

489
00:21:41,499 --> 00:21:44,634
Ve mümkün olan en kısa sürede
onları bana göster.

490
00:21:44,635 --> 00:21:47,606
Ve her zamanki gibi,
izlediğiniz için teşekkürler.

