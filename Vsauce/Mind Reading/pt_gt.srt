1
00:00:05,237 --> 00:00:06,438
Leitura de mente?

2
00:00:06,439 --> 00:00:08,172
Claro que não.

3
00:00:08,173 --> 00:00:11,376
Eu amo ler.

4
00:00:11,377 --> 00:00:15,413
Olha, a leitura da mente pode soar
como pseudocientífico -

5
00:00:15,414 --> 00:00:16,614
perdoe minha linguagem -

6
00:00:16,615 --> 00:00:18,416
disparate.

7
00:00:18,417 --> 00:00:21,486
Mas sua contrapartida científica, a
identificação do pensamento,

8
00:00:21,487 --> 00:00:23,855
é uma coisa muito real.

9
00:00:23,856 --> 00:00:26,524
É baseado em neuroimagem
e aprendizado de máquina,

10
00:00:26,525 --> 00:00:29,861
e o mais legal é
que os experimentos de leitura da mente

11
00:00:29,862 --> 00:00:33,498
não são apenas espionar o
que alguém está pensando.

12
00:00:33,499 --> 00:00:37,602
Eles tratam de descobrir do
que os pensamentos são feitos.

13
00:00:37,603 --> 00:00:39,504
Quero dizer, quando penso
em algo,

14
00:00:39,505 --> 00:00:43,174
como é que essa imagem mental
realmente se parece?

15
00:00:43,175 --> 00:00:44,709
Em que resolução está?

16
00:00:44,710 --> 00:00:47,145
Quão alta fidelidade
é uma memória

17
00:00:47,146 --> 00:00:49,380
e como elas mudam ao
longo do tempo?

18
00:00:49,381 --> 00:00:51,116
Bem, neste episódio,

19
00:00:51,117 --> 00:00:52,750
vou ver como
ler a mente das pessoas

20
00:00:52,751 --> 00:00:54,719
pode nos ajudar a responder a
essas perguntas.

21
00:00:54,720 --> 00:00:58,490
Minha jornada começa aqui mesmo
na Universidade de Oregon.

22
00:00:58,491 --> 00:01:01,259
Vou me encontrar com o Dr. Brice Kuhl
do laboratório Kuhl.

23
00:01:01,260 --> 00:01:03,394
Ele é um neurocientista
que usa neuroimagem

24
00:01:03,395 --> 00:01:06,664
e aprendizado de máquina para descobrir
o que as pessoas estão pensando

25
00:01:06,665 --> 00:01:31,789
sem que elas lhe digam.

26
00:01:31,790 --> 00:01:33,625
Então me diga o que
você está fazendo aqui.

27
00:01:33,626 --> 00:01:36,794
Bem, estou
aqui no programa de neurociência cognitiva

28
00:01:36,795 --> 00:01:38,396
e estudo a memória humana.

29
00:01:38,397 --> 00:01:41,099
Meu laboratório usa principalmente
métodos de neuroimagem,

30
00:01:41,100 --> 00:01:42,567
então fazemos muito trabalho usando

31
00:01:42,568 --> 00:01:44,169

ressonância magnética funcional,

32
00:01:44,170 --> 00:01:45,637
ou fMRI.

33
00:01:45,638 --> 00:01:49,340
E como você usa
fMRI para investigar memórias?

34
00:01:49,341 --> 00:01:51,776
Estamos olhando para o padrão
de atividade neural.

35
00:01:51,777 --> 00:01:54,445
Quando você forma uma memória,
há um certo padrão.

36
00:01:54,446 --> 00:01:56,548
E podemos gravar
esse padrão

37
00:01:56,549 --> 00:01:59,617
e depois testar se
esse padrão é restabelecido

38
00:01:59,618 --> 00:02:02,554
ou reativado posteriormente,
como quando você o está lembrando.

39
00:02:02,555 --> 00:02:05,823
Isso significa que podemos olhar para
os padrões de atividade cerebral

40
00:02:05,824 --> 00:02:10,061
e deduzir o que está
sendo lembrado, ou lembrado,

41
00:02:10,062 --> 00:02:11,262
ou mesmo apenas pensado?

42
00:02:11,263 --> 00:02:13,631
Sim, e por isso chamamos isso de
decodificação.

43
00:02:13,632 --> 00:02:16,568
Então, basicamente,
seu padrão de entrada

44
00:02:16,569 --> 00:02:18,469
é algum padrão de atividade
que gravamos

45
00:02:18,470 --> 00:02:21,272
enquanto você está se lembrando de
algo.

46
00:02:21,273 --> 00:02:23,441
E fazemos uma previsão
sobre o que você está lembrando.

47
00:02:23,442 --> 00:02:27,178
Você pode ver como isso soa
como leitura da mente.

48
00:02:27,179 --> 00:02:28,713
[risos]
Sim.  Parece isso.

49
00:02:28,714 --> 00:02:32,584
Então, Brice, o que você
vai fazer comigo hoje?

50
00:02:32,585 --> 00:02:34,419
Então, o que
vamos fazer hoje

51
00:02:34,420 --> 00:02:36,354
é um território desconhecido
para nós.

52
00:02:36,355 --> 00:02:38,623
Então, vamos testar
um tipo de nova variante

53
00:02:38,624 --> 00:02:40,258
do experimento em você.

54
00:02:40,259 --> 00:02:42,660
Portanto, não posso garantir
nenhum resultado específico.

55
00:02:42,661 --> 00:02:44,195
Mas representa
onde está o campo

56
00:02:44,196 --> 00:02:46,664
e para onde
estamos tentando ir.

57
00:02:46,665 --> 00:02:48,800
Hoje, você
participará de um experimento

58
00:02:48,801 --> 00:02:50,268
onde estudará rostos.

59
00:02:50,269 --> 00:02:51,803
Então vamos
fazer você estudar

60
00:02:51,804 --> 00:02:53,404
12 fotos de celebridades.

61
00:02:53,405 --> 00:02:54,872
Pessoas que já
conheço.

62
00:02:54,873 --> 00:02:56,674
-Pessoas que você conhece, sim.
-Ok.

63
00:02:56,675 --> 00:02:59,143
E você vai tentar
se lembrar dessas fotos.

64
00:02:59,144 --> 00:03:01,112
Então vamos fazer você entrar
no scanner de ressonância magnética.

65
00:03:01,113 --> 00:03:04,249
Tente trazer essa imagem
à mente da forma mais vívida possível.

66
00:03:04,250 --> 00:03:06,417
E vamos gravar
sua atividade cerebral

67
00:03:06,418 --> 00:03:08,753
enquanto você tenta imaginar
essas imagens.

68
00:03:08,754 --> 00:03:10,555
Vamos
tentar construir o rosto.

69
00:03:10,556 --> 00:03:12,590
Essencialmente, desenhe uma imagem do
que você está lembrando.

70
00:03:12,591 --> 00:03:14,125
-Uma foto?
-Uma foto.

71
00:03:14,126 --> 00:03:16,327
Uma foto real
que podemos imprimir

72
00:03:16,328 --> 00:03:17,729
e eu poderia, tipo,
pendurar na minha parede.

73
00:03:17,730 --> 00:03:19,831
[risos]
Se você quisesse.

74
00:03:19,832 --> 00:03:22,634
[Michael]O primeiro passo
é memorizar

75
00:03:22,635 --> 00:03:25,336
as 12 fotografias específicas de
celebridades que

76
00:03:25,337 --> 00:03:28,640
Brice mais tarde tentará
me detectar pensando.

77
00:03:28,641 --> 00:03:33,278
Sentei-me para fazer este
estudante de pós-graduação, Max.

78
00:03:33,279 --> 00:03:35,280
O sucesso de suas previsões
depende, em parte,

79
00:03:35,281 --> 00:03:37,415
da minha capacidade
de lembrar esses rostos da forma

80
00:03:37,416 --> 00:03:43,087
mais vívida possível
enquanto estiver dentro da fMRI.

81
00:03:43,088 --> 00:03:44,422
Tudo bem, então...

82
00:03:44,423 --> 00:03:46,157
[suspira]

83
00:03:46,158 --> 00:03:50,728
Acho que tenho uma boa
memória de tudo isso.

84
00:03:50,729 --> 00:03:53,698
-Excelente.
-Sinto que as apostas são altas.

85
00:03:53,699 --> 00:03:56,701
Com os rostos das
celebridades memorizados

86
00:03:56,702 --> 00:03:58,303
, é hora do próximo passo:

87
00:03:58,304 --> 00:04:00,071
passar
pelo detector de metais

88
00:04:00,072 --> 00:04:01,706
e entrar na fMRI,

89
00:04:01,707 --> 00:04:04,676
onde Brice gravará
e monitorará minha atividade cerebral

90
00:04:04,677 --> 00:04:08,746
e depois a alimentará em seu
algoritmo para reconstruir os rostos.

91
00:04:08,747 --> 00:04:10,448
Esta será a primeira vez que
ele

92
00:04:10,449 --> 00:04:12,383
tentará reconstruir rostos
da memória de longo prazo, o

93
00:04:12,384 --> 00:04:14,385
que é muito difícil,
porque estamos contando

94
00:04:14,386 --> 00:04:16,720
com a clareza com que consigo me lembrar
das fotos de celebridades

95
00:04:16,721 --> 00:04:19,090
que vi uma hora atrás.

96
00:04:19,091 --> 00:04:21,225
Eu amo seus olhos.
Olhe para isso.

97
00:04:21,226 --> 00:04:24,362
[mulher] A

98
00:04:24,363 --> 00:04:31,102
criança não ficaria tipo,
"Vai me comer"?

99
00:04:31,103 --> 00:04:34,205
Uma fMRI monitora a atividade
dentro do cérebro

100
00:04:34,206 --> 00:04:36,774
, dividindo-a
em milhares de pequenos cubos

101
00:04:36,775 --> 00:04:39,744
chamados voxels,
ou pixels volumétricos.

102
00:04:39,745 --> 00:04:41,446
Cada um desses voxels contém

103
00:04:41,447 --> 00:04:43,581
centenas de milhares
de neurônios.

104
00:04:43,582 --> 00:04:46,117
Usando fMRI,
somos capazes de detectar

105
00:04:46,118 --> 00:04:47,719
o fluxo sanguíneo
dentro desses voxels, o

106
00:04:47,720 --> 00:04:50,088
que significa que essa parte
do cérebro está ativa.

107
00:04:50,089 --> 00:04:53,124
Se me mostrarem várias fotos
de pessoas com bigodes,

108
00:04:53,125 --> 00:04:56,327
meu cérebro reagirá
às características de cada rosto.

109
00:04:56,328 --> 00:04:58,329
Mas haverá
uma área comum do meu cérebro

110
00:04:58,330 --> 00:05:00,164
que está envolvida por
toda parte.

111
00:05:00,165 --> 00:05:04,102
Essa pode ser a área do meu
cérebro que reage aos bigodes.

112
00:05:04,103 --> 00:05:07,171
Então, mais tarde,
quando imagino um rosto,

113
00:05:07,172 --> 00:05:09,440
se Brice perceber
que essa área está ocupada,

114
00:05:09,441 --> 00:05:11,476
ele pode prever
que estou pensando

115
00:05:11,477 --> 00:05:13,811
em um bigode.

116
00:05:13,812 --> 00:05:15,780
Então agora Michael está
no scanner,

117
00:05:15,781 --> 00:05:18,282
e ele está vendo as palavras aparecerem
na tela uma de cada vez,

118
00:05:18,283 --> 00:05:20,651
e ele está
tentando visualizar o rosto,

119
00:05:20,652 --> 00:05:23,187
lembrar o rosto com o máximo de
detalhes possível.

120
00:05:23,188 --> 00:05:25,356
O que você pode ver aqui são
as imagens que estamos adquirindo.

121
00:05:25,357 --> 00:05:28,793
Recebemos um desses
volumes cerebrais a cada dois segundos.

122
00:05:28,794 --> 00:05:32,797
Portanto, eles são atualizados em tempo real à
medida que coletamos as imagens.

123
00:05:32,798 --> 00:05:35,633
[Michael]Com a parte um
da sessão de fMRI terminada

124
00:05:35,634 --> 00:05:38,503
, é hora da parte dois,
onde Brice e sua

125
00:05:38,504 --> 00:05:41,773
equipe aprenderão a linguagem
da minha atividade cerebral,

126
00:05:41,774 --> 00:05:44,776
para que possam
decodificar posteriormente por exames cerebrais.

127
00:05:44,777 --> 00:05:46,544
Olá Michael.
Você está bem ainda?

128
00:05:46,545 --> 00:05:48,312
[Michael]
Sim.

129
00:05:48,313 --> 00:05:50,381
Eles me mostrarão centenas
de rostos únicos

130
00:05:50,382 --> 00:05:52,784
e registrarão como meu cérebro reage

131
00:05:52,785 --> 00:05:54,852
a certas
características faciais.

132
00:05:54,853 --> 00:05:57,188
Eles então usarão
essas informações

133
00:05:57,189 --> 00:05:59,657
para reconstruir
os rostos de celebridades em

134
00:05:59,658 --> 00:06:03,127
que pensei durante
a primeira fase da varredura.

135
00:06:03,128 --> 00:06:05,530
Realmente, quanto mais rostos
pudermos mostrar a Michael, melhor.

136
00:06:05,531 --> 00:06:08,166
Então, basicamente, vamos mantê-
lo lá

137
00:06:08,167 --> 00:06:09,600
enquanto ele estiver confortável.

138
00:06:09,601 --> 00:06:11,636
[Michael]
Duas horas foi o tempo máximo

139
00:06:11,637 --> 00:06:13,538
que conseguimos na fMRI.

140
00:06:13,539 --> 00:06:17,175
Mas consegui
ver mais de 400 rostos, o

141
00:06:17,176 --> 00:06:18,743
que deve ser suficiente para obter

142
00:06:18,744 --> 00:06:20,778
resultados bastante interessantes
.

143
00:06:20,779 --> 00:06:22,447
Ei, Michael, você conseguiu.
Isso foi ótimo.

144
00:06:22,448 --> 00:06:23,681
Nós vamos
te tirar daqui.

145
00:06:23,682 --> 00:06:33,157
[Michael]
Tudo bem.

146
00:06:33,158 --> 00:06:34,725
Sim, então estas apenas mostram
algumas das fotos

147
00:06:34,726 --> 00:06:36,561
que estávamos tirando
enquanto você estava lá.

148
00:06:36,562 --> 00:06:38,095
Algumas imagens do seu cérebro.

149
00:06:38,096 --> 00:06:39,764
Agora
vamos analisar alguns números.

150
00:06:39,765 --> 00:06:42,200
Max vai analisar
seus dados.

151
00:06:42,201 --> 00:06:43,701
Nos encontraremos
novamente amanhã,

152
00:06:43,702 --> 00:06:45,369
onde
veremos os resultados,

153
00:06:45,370 --> 00:06:47,638
onde tentaremos
reconstruir as imagens do rosto a

154
00:06:47,639 --> 00:06:49,740
partir dos dados cerebrais
que acabamos de coletar.

155
00:06:49,741 --> 00:06:51,175
Tudo bem.
Bem, até amanhã.

156
00:06:51,176 --> 00:06:52,577
Tudo bem.
Muito obrigado.

157
00:06:52,578 --> 00:06:54,178
Max, obrigado também.
Eu não posso esperar.

158
00:06:54,179 --> 00:06:55,847
É melhor você
passar a noite toda.

159
00:06:55,848 --> 00:07:04,288
Eu quero que esses
dados sejam perfeitos.

160
00:07:04,289 --> 00:07:06,524
Certo, estou de volta
ao laboratório do Dr. Kuhl.

161
00:07:06,525 --> 00:07:08,693
Da noite para o dia, sua equipe
analisou os dados

162
00:07:08,694 --> 00:07:15,500
e mal posso esperar para ver o que
eles acham que me viram pensando.

163
00:07:15,501 --> 00:07:17,101
Como estão meus resultados?

164
00:07:17,102 --> 00:07:18,736
Eu acho que eles parecem bons.

165
00:07:18,737 --> 00:07:20,705
Nós vamos dar uma olhada
em apenas um momento aqui.

166
00:07:20,706 --> 00:07:22,406
Tudo bem,
mal posso esperar.

167
00:07:22,407 --> 00:07:24,342
-Então posso me sentar?
-Sim, sente-se.

168
00:07:24,343 --> 00:07:26,143
Tudo bem, então... em

169
00:07:26,144 --> 00:07:28,212
primeiro lugar... o

170
00:07:28,213 --> 00:07:30,081
que estou vendo?
Oh, ok, bem,

171
00:07:30,082 --> 00:07:32,283
estas são as fotos que
eu realmente memorizei.

172
00:07:32,284 --> 00:07:34,252
-Está certo.
-E isso é o

173
00:07:34,253 --> 00:07:37,822
que você reconstruiu
da minha imaginação.

174
00:07:37,823 --> 00:07:40,091
-Está certo.
-Uau.  OK.

175
00:07:40,092 --> 00:07:43,094
[Brice]
Ok, então esta é uma
das reconstruções

176
00:07:43,095 --> 00:07:44,562
que foram geradas.

177
00:07:44,563 --> 00:07:46,063
[Michael]
Interessante.

178
00:07:46,064 --> 00:07:47,698
[Max]
Então é John Cho.

179
00:07:47,699 --> 00:07:50,668
[Michael]
Nada mal.  Nada mal.

180
00:07:50,669 --> 00:07:53,337
-Podemos ver o lado a lado?
-Sim.

181
00:07:53,338 --> 00:07:55,673
[Michael]
Eu vejo, você sabe, semelhanças

182
00:07:55,674 --> 00:08:00,044
no tipo de
expressões faciais em geral.

183
00:08:00,045 --> 00:08:02,213
Você sabe, você quase podia
ver a linha do cabelo combinando aqui.

184
00:08:02,214 --> 00:08:04,682
O formato do rosto
eu também achei que era

185
00:08:04,683 --> 00:08:06,684

meio quadrado.

186
00:08:06,685 --> 00:08:08,152
-Sim.  Sim.
-Então, essas são as coisas

187
00:08:08,153 --> 00:08:09,387
que saíram para mim.

188
00:08:09,388 --> 00:08:11,289
E então, quando eu estava
visualizando

189
00:08:11,290 --> 00:08:13,257
essa imagem de John Cho,

190
00:08:13,258 --> 00:08:16,260
a quadratura do rosto era
a primeira coisa mais saliente.

191
00:08:16,261 --> 00:08:19,697
Eu só ficava pensando,
ele era o cara quadrado.

192
00:08:19,698 --> 00:08:23,401
Excelente, tudo bem.

193
00:08:23,402 --> 00:08:26,704
[Brice]
Então essa é Megan Fox.

194
00:08:26,705 --> 00:08:28,439
[Michael]
Mm-hmm.

195
00:08:28,440 --> 00:08:30,207
Você vai nos mostrar o...
lado a lado.

196
00:08:30,208 --> 00:08:31,776
[Michael]
O lado a lado.  Certo.

197
00:08:31,777 --> 00:08:33,644
[Brice]
Você pode ver a imagem
que realmente viu,

198
00:08:33,645 --> 00:08:36,547
e essa é a reconstrução
que geramos.

199
00:08:36,548 --> 00:08:39,417
Eu vou isso.
Megan Fox, não

200
00:08:39,418 --> 00:08:42,353
consegui ter uma imagem realmente clara
em minha mente.

201
00:08:42,354 --> 00:08:45,056
Por alguma razão, essa
imagem dela foi muito difícil para

202
00:08:45,057 --> 00:08:47,058
mim trazer de volta à minha mente.

203
00:08:47,059 --> 00:08:50,595
A severidade no rosto foi
algo que eu percebi.

204
00:08:50,596 --> 00:08:53,698
Então eu senti que havia...
Parecia feminino.

205
00:08:53,699 --> 00:08:55,533
E você pegou
na severidade.

206
00:08:55,534 --> 00:08:58,769
E assim, juntos,
isso produz uma correspondência.

207
00:08:58,770 --> 00:09:00,538
[Michael]Tenha em mente
que Brice e sua equipe

208
00:09:00,539 --> 00:09:02,773
leram isso
da minha memória.

209
00:09:02,774 --> 00:09:04,609
Mas quando me lembro de um rosto

210
00:09:04,610 --> 00:09:07,678
, imagino todos os detalhes
simultaneamente

211
00:09:07,679 --> 00:09:09,313
com precisão fotográfica?

212
00:09:09,314 --> 00:09:10,748
Ou apenas atendo alguns
de cada vez?

213
00:09:10,749 --> 00:09:13,417
Ao ler minha mente,
eles podem estar vendo o

214
00:09:13,418 --> 00:09:15,219
quão ruim é minha memória
e como ela funciona.

215
00:09:15,220 --> 00:09:18,689
-Eu!  Eu!
-[Brice ri]

216
00:09:18,690 --> 00:09:21,525
Ok, então essa é a sua
reconstrução

217
00:09:21,526 --> 00:09:24,729
de mim pensando sobre
essa imagem de mim mesmo.

218
00:09:24,730 --> 00:09:26,497
[Brice]
Isso mesmo.

219
00:09:26,498 --> 00:09:28,666
Para onde foi a barba?

220
00:09:28,667 --> 00:09:31,068
[Brice] Eu não sei.
Eu esperava que você pudesse me dizer.

221
00:09:31,069 --> 00:09:36,240
[Michael]
Por exemplo, esta é uma
foto minha lembrando meu próprio rosto.

222
00:09:36,241 --> 00:09:38,743
Realmente não parece comigo,
mas a questão é:

223
00:09:38,744 --> 00:09:41,345
quão bom sou
em me imaginar?

224
00:09:41,346 --> 00:09:44,048
Eu não penso em meu próprio rosto com
tanta frequência,

225
00:09:44,049 --> 00:09:45,616
então a estranheza
no resultado

226
00:09:45,617 --> 00:09:47,752
pode ser tanto sobre falhas
na minha própria memória

227
00:09:47,753 --> 00:09:51,288
e imagem mental de mim
quanto falhas na tecnologia.

228
00:09:51,289 --> 00:09:53,691
Então essa é Jennifer Lawrence,
eu acredito.

229
00:09:53,692 --> 00:09:55,726
[Michael]
Essa é Jennifer Lawrence?

230
00:09:55,727 --> 00:09:59,664
Parece que é
o tio muito mais velho de Jennifer Lawrence.

231
00:09:59,665 --> 00:10:01,365
[todos riem]

232
00:10:01,366 --> 00:10:05,069
Nada aqui era tão
alucinantemente próximo.

233
00:10:05,070 --> 00:10:09,407
Mas isso é algo que
você está apenas começando a experimentar

234
00:10:09,408 --> 00:10:11,409
esses tipos de memórias de longo prazo
.

235
00:10:11,410 --> 00:10:14,679
O que Brice e sua equipe
leram em minha mente

236
00:10:14,680 --> 00:10:18,549
poderia ter sido mais preciso
se eles tivessem me mostrado milhares em

237
00:10:18,550 --> 00:10:20,284
vez de centenas de imagens
na fMRI,

238
00:10:20,285 --> 00:10:22,520
porque assim o algoritmo
teria aprendido

239
00:10:22,521 --> 00:10:24,655
a linguagem do meu cérebro
mais profundamente.

240
00:10:24,656 --> 00:10:27,358
Mas, independentemente disso,
a qualidade das minhas memórias

241
00:10:27,359 --> 00:10:29,226
ainda
seria um problema.

242
00:10:29,227 --> 00:10:30,661
Quero dizer, veja o que acontece
quando a memória

243
00:10:30,662 --> 00:10:33,164
é totalmente eliminada da equação
.

244
00:10:33,165 --> 00:10:35,166
Brice também leu
minha atividade cerebral

245
00:10:35,167 --> 00:10:37,168
quando eu estava olhando
para rostos na fMRI.

246
00:10:37,169 --> 00:10:39,103
não apenas imaginando-os.

247
00:10:39,104 --> 00:10:41,672
E esses resultados
foram muito mais próximos do

248
00:10:41,673 --> 00:10:44,675
que os reconstruídos
da minha memória.

249
00:10:44,676 --> 00:10:47,111
Ok, então, o que estou
vendo aqui?

250
00:10:47,112 --> 00:10:48,679
[Brice]
Ok, então o que você está vendo aqui

251
00:10:48,680 --> 00:10:51,682
na linha superior
, são imagens que você viu

252
00:10:51,683 --> 00:10:53,584
enquanto estava no scanner.

253
00:10:53,585 --> 00:10:56,754
Abaixo disso, nesta linha inferior,
estas são as reconstruções

254
00:10:56,755 --> 00:11:00,725
que extraímos dos padrões
de atividade cerebral que coletamos.

255
00:11:00,726 --> 00:11:03,828
-Isso é da imagem de origem.
-Certo.

256
00:11:03,829 --> 00:11:05,629
[Michael]
Estes são do meu cérebro.

257
00:11:05,630 --> 00:11:07,565
-[Brice] Certo.
-[Michael] Eles são muito próximos.

258
00:11:07,566 --> 00:11:09,700
Sim, no geral eles estavam
bem próximos.

259
00:11:09,701 --> 00:11:11,602
Então não é perfeito.

260
00:11:11,603 --> 00:11:13,771
Estes são -- você pode ver que há
alguma variabilidade neles.

261
00:11:13,772 --> 00:11:16,640
Mas isso é consistente
com o que descobrimos antes,

262
00:11:16,641 --> 00:11:18,409
que nas reconstruções
que geramos,

263
00:11:18,410 --> 00:11:20,244
quando você está vendo
os rostos,

264
00:11:20,245 --> 00:11:22,279
há alguma correspondência
entre o rosto real.

265
00:11:22,280 --> 00:11:23,714
Então isso é uma espécie de
verificação de sanidade, para

266
00:11:23,715 --> 00:11:25,750
que possamos
reconstruir as imagens

267
00:11:25,751 --> 00:11:28,219
- quando você as estiver visualizando.
-Certo, certo.

268
00:11:28,220 --> 00:11:31,355
Eles são muito bons.

269
00:11:31,356 --> 00:11:33,190
Bem, Brice, Max,
muito obrigado

270
00:11:33,191 --> 00:11:35,126
por me deixar
fazer parte disso.

271
00:11:35,127 --> 00:11:36,660
Espero que meus dados sejam úteis.

272
00:11:36,661 --> 00:11:38,596
Obrigada.
Tem sido muito divertido.

273
00:11:38,597 --> 00:11:46,837
É sempre útil para
nós pensar sobre essas coisas.

274
00:11:46,838 --> 00:11:50,808
A pesquisa de memória do Dr. Brice Kuhl
está mostrando que é possível

275
00:11:50,809 --> 00:11:53,677
para um
computador ler a mente de alguém.

276
00:11:53,678 --> 00:11:56,313
Para descobrir o
que eles estão pensando.

277
00:11:56,314 --> 00:11:58,415
Mas muito progresso
ainda precisa ser feito.

278
00:11:58,416 --> 00:12:00,050
Quer dizer, se você quer saber

279
00:12:00,051 --> 00:12:01,619
o que estou pensando agora,
por exemplo

280
00:12:01,620 --> 00:12:05,189
, ainda é mais fácil me pedir
para dizer a você.

281
00:12:05,190 --> 00:12:07,491
Mas e se eu não puder
te contar?

282
00:12:07,492 --> 00:12:10,594
Dr. Yukiyasu Kamitani
é pesquisador,

283
00:12:10,595 --> 00:12:14,498
professor e pioneiro
explorando a fronteira

284
00:12:14,499 --> 00:12:17,535
por trás da parede do sono.

285
00:12:17,536 --> 00:12:19,703
Eu vim aqui
para a Universidade de Kyoto

286
00:12:19,704 --> 00:12:21,672
para me encontrar com ele e ver
como é

287
00:12:21,673 --> 00:12:24,175
ler não o que alguém
está pensando,

288
00:12:24,176 --> 00:12:29,647
mas o que alguém
está sonhando.

289
00:12:29,648 --> 00:12:31,348
Kamitani sensei,
eu sou Michael.

290
00:12:31,349 --> 00:12:33,818
-Oi, eu sou Yuki.
-Yuki, prazer em conhecê-lo.

291
00:12:33,819 --> 00:12:36,320
[Michael]
Nos últimos dez anos, o

292
00:12:36,321 --> 00:12:38,455
Dr. Kamitani tem estado
na vanguarda

293
00:12:38,456 --> 00:12:40,124
da leitura da mente da máquina.

294
00:12:40,125 --> 00:12:43,527
O sujeito está, você sabe,
pronto para entrar.

295
00:12:43,528 --> 00:12:45,462
Semelhante a Brice Kuhl,

296
00:12:45,463 --> 00:12:48,632
seus primeiros experimentos exploraram a
reconstrução de imagens

297
00:12:48,633 --> 00:12:52,236
mostradas a sujeitos em uma fMRI com
base em sua atividade cerebral.

298
00:12:52,237 --> 00:12:53,637
No caso de Kamitani,

299
00:12:53,638 --> 00:12:55,706
as imagens eram
formas em preto e branco

300
00:12:55,707 --> 00:12:58,375
e as reconstruções
eram surpreendentemente precisas.

301
00:12:58,376 --> 00:13:03,180
Recentemente, Kamitani se concentrou
no uso de redes neurais profundas

302
00:13:03,181 --> 00:13:04,815
e aprendizado de máquina

303
00:13:04,816 --> 00:13:06,450
para decifrar a atividade cerebral dos sujeitos


304
00:13:06,451 --> 00:13:08,686
enquanto eles visualizam
fotografias muito mais complexas.

305
00:13:08,687 --> 00:13:12,756
O que você está vendo é o
resultado de uma rede neural profunda que

306
00:13:12,757 --> 00:13:15,226
processa a atividade cerebral
de um sujeito

307
00:13:15,227 --> 00:13:17,795
olhando para a fotografia.

308
00:13:17,796 --> 00:13:20,431
Isso pode ter inúmeras
aplicações no futuro,

309
00:13:20,432 --> 00:13:22,733
por exemplo,
em investigações criminais

310
00:13:22,734 --> 00:13:26,470
e
comunicação interpessoal.

311
00:13:26,471 --> 00:13:28,739
[Kamitani]
Isso está longe de ser perfeito.

312
00:13:28,740 --> 00:13:33,177
Mas eu acho que você ainda vê alguns,
você sabe, olhos e, você sabe...

313
00:13:33,178 --> 00:13:34,778
[Michael]
Bem, sim.

314
00:13:34,779 --> 00:13:36,447
E cores também.

315
00:13:36,448 --> 00:13:39,783
[Kamitani]
Sim, até certo ponto, sim.

316
00:13:39,784 --> 00:13:42,419
Seu trabalho mais atual, no entanto,
é sobre o subconsciente.

317
00:13:42,420 --> 00:13:45,256
Ele está tentando algo
extremamente ambicioso:

318
00:13:45,257 --> 00:13:46,824
registrar nossos sonhos.

319
00:13:46,825 --> 00:13:49,326
Você se chamaria de
pesquisador do sono

320
00:13:49,327 --> 00:13:50,828
ou pesquisador da visão?

321
00:13:50,829 --> 00:13:53,664
Talvez um decodificador cerebral.

322
00:13:53,665 --> 00:13:55,432
Um decodificador cerebral.

323
00:13:55,433 --> 00:13:57,534
Essa é uma
descrição de trabalho muito legal.

324
00:13:57,535 --> 00:14:01,739
Você pode me mostrar alguma coisa do
que você está fazendo com os sonhos?

325
00:14:01,740 --> 00:14:08,379
[Kamitani]
Mm-hmm, sim.

326
00:14:08,380 --> 00:14:10,514
O trabalho do Dr. Kamitani
na decodificação dos sonhos

327
00:14:10,515 --> 00:14:13,317
começa com um processo semelhante
ao do Dr. Kuhl:

328
00:14:13,318 --> 00:14:15,452
mostrar ao sujeito do teste
milhares de imagens

329
00:14:15,453 --> 00:14:17,187
enquanto ele está em um

330
00:14:17,188 --> 00:14:18,722
fMRI para aprender
como o cérebro se parece

331
00:14:18,723 --> 00:14:21,358
quando está pensando
em certas coisas.

332
00:14:21,359 --> 00:14:23,794
Uma vez que o algoritmo de aprendizado de máquina
é muito bom

333
00:14:23,795 --> 00:14:26,764
em identificar em quais imagens
o sujeito está pensando,

334
00:14:26,765 --> 00:14:29,300
o sujeito é colocado
em uma fMRI

335
00:14:29,301 --> 00:14:31,335
com uma tampa de EEG
na cabeça

336
00:14:31,336 --> 00:14:33,470
e convidado a adormecer.

337
00:14:33,471 --> 00:14:36,573
Quando as ondas de EEG indicam
que a pessoa está sonhando,

338
00:14:36,574 --> 00:14:39,243
o algoritmo prevê
que tipo de coisas

339
00:14:39,244 --> 00:14:41,645
o sujeito provavelmente está
sonhando.

340
00:14:41,646 --> 00:14:45,215
No momento, o algoritmo
procura 20 categorias.

341
00:14:45,216 --> 00:14:48,485
Coisas como prédios,
transporte

342
00:14:48,486 --> 00:14:50,621
e personagens
em um idioma.

343
00:14:50,622 --> 00:14:53,324
Os pesquisadores então despertam
o sujeito,

344
00:14:53,325 --> 00:14:55,326
perguntam com o que eles estavam
sonhando

345
00:14:55,327 --> 00:14:57,227
e verificam se a previsão do algoritmo


346
00:14:57,228 --> 00:14:59,530
e a lembrança da pessoa
combinam.

347
00:14:59,531 --> 00:15:03,367
Aqui estão os dados reais de
um dos experimentos de Kamitani.

348
00:15:03,368 --> 00:15:05,703
Abaixo está uma nuvem
de palavras de categorias.

349
00:15:05,704 --> 00:15:08,339
O nome de cada categoria
fica maior ou menor

350
00:15:08,340 --> 00:15:10,574
em tempo real com
base na probabilidade

351
00:15:10,575 --> 00:15:13,344
de estarem presentes
no sonho atual do sujeito.

352
00:15:13,345 --> 00:15:15,346
Agora, como você pode ver, a
atividade é atualmente mais forte

353
00:15:15,347 --> 00:15:18,349
para a categoria "personagem", que
significa linguagem escrita.

354
00:15:18,350 --> 00:15:20,684
Nesse momento
o sujeito foi acordado,

355
00:15:20,685 --> 00:15:29,660
e foi isso que
eles relataram.

356
00:15:29,661 --> 00:15:32,062
Isso é muito assustador.

357
00:15:32,063 --> 00:15:33,697
-[risos]
-Certo?  Quero dizer,

358
00:15:33,698 --> 00:15:36,700
você... você espiou o sonho deles.

359
00:15:36,701 --> 00:15:39,370
Sim, de certa forma.
Mas...

360
00:15:39,371 --> 00:15:42,406
a precisão
não é tão grande, então...

361
00:15:42,407 --> 00:15:44,341
Bem, a precisão
não é tão grande, mas, você sabe,

362
00:15:44,342 --> 00:15:46,677
minha precisão normal para adivinhar
os sonhos das pessoas é zero.

363
00:15:46,678 --> 00:15:48,145
Certo.

364
00:15:48,146 --> 00:15:49,580
Enquanto continua
sua pesquisa

365
00:15:49,581 --> 00:15:52,182
para prever
o conteúdo dos sonhos, o

366
00:15:52,183 --> 00:15:54,785
Dr. Kamitani está embarcando
em seu mais novo projeto

367
00:15:54,786 --> 00:15:58,389
: reconstruir imagens
de nossos sonhos.

368
00:15:58,390 --> 00:16:01,458
Então você trouxe
algumas das reconstruções

369
00:16:01,459 --> 00:16:02,659
que seu laboratório criou...

370
00:16:02,660 --> 00:16:04,061
Mm-hmm.

371
00:16:04,062 --> 00:16:17,741
...de sonhos.

372
00:16:17,742 --> 00:16:20,210
Certo, todos eles parecem sonhos
sobre bolhas.

373
00:16:20,211 --> 00:16:21,779
[Kamitani]
Sim.

374
00:16:21,780 --> 00:16:24,448
Quero dizer, quero apenas
dar um passo para trás e...

375
00:16:24,449 --> 00:16:27,785
apreciar que o que estamos
vendo nesta tela

376
00:16:27,786 --> 00:16:31,655
são, de certa forma, algumas das primeiras
fotografias de um sonho.

377
00:16:31,656 --> 00:16:33,357
Mm-hmm.

378
00:16:33,358 --> 00:16:35,759
Estamos olhando
para a fase inicial

379
00:16:35,760 --> 00:16:38,062
da pesquisa revolucionária.

380
00:16:38,063 --> 00:16:40,164
Um dia,
poderemos ter imagens,

381
00:16:40,165 --> 00:16:42,766
ou até mesmo gravar filmes,
de nossos próprios sonhos.

382
00:16:42,767 --> 00:16:45,335
E o Dr. Kamitani é a única
pessoa no mundo

383
00:16:45,336 --> 00:16:47,237
fazendo isso até agora.

384
00:16:47,238 --> 00:16:50,707
Ele é um explorador solitário viajando
em nosso subconsciente.

385
00:16:50,708 --> 00:16:53,644
Então esse trabalho ainda nem
foi publicado.

386
00:16:53,645 --> 00:16:55,345
Não.

387
00:16:55,346 --> 00:17:01,752
-Obrigado por me mostrar.
-[risos]

388
00:17:01,753 --> 00:17:06,155
Os insights que pesquisadores
como o Dr. Kuhl e o Dr. Kamitani

389
00:17:06,156 --> 00:17:09,159
podem ser capazes de alcançar
no futuro

390
00:17:09,160 --> 00:17:11,328
por causa da leitura da mente

391
00:17:11,329 --> 00:17:13,697
são difíceis
de entender completamente.

392
00:17:13,698 --> 00:17:15,399
Mas vamos desacelerar
por um segundo,

393
00:17:15,400 --> 00:17:17,233
porque estamos falando
de uma tecnologia

394
00:17:17,234 --> 00:17:21,105
que pode nos conhecer
melhor do que nós mesmos.

395
00:17:21,106 --> 00:17:23,740
Devemos realmente
estar fazendo isso?

396
00:17:23,741 --> 00:17:25,275
Bem, para responder a
essa pergunta,

397
00:17:25,276 --> 00:17:27,310
vou me encontrar
com uma especialista em ética,

398
00:17:27,311 --> 00:17:30,447
neurociência
e inteligência artificial:

399
00:17:30,448 --> 00:17:32,216
Julia Bossmann.

400
00:17:32,217 --> 00:17:34,518
Ela é diretora de estratégia
da Fathom Computing,

401
00:17:34,519 --> 00:17:37,087
membro
do conselho do Fórum Econômico Mundial

402
00:17:37,088 --> 00:17:40,424
, ex-aluna da Singularity University de Ray Kurzweil


403
00:17:40,425 --> 00:17:43,293
e ex-presidente
do Foresight Institute,

404
00:17:43,294 --> 00:17:46,530
um think tank especializado
em tecnologias futuras

405
00:17:46,531 --> 00:17:50,200
e seus impactos.

406
00:17:50,201 --> 00:17:52,669
Julia, obrigado por tirar algum
tempo para conversar.

407
00:17:52,670 --> 00:17:54,438
-Sim claro.
-Você é a pessoa perfeita

408
00:17:54,439 --> 00:17:55,739
para eu trazer
essas perguntas.

409
00:17:55,740 --> 00:17:57,274
-Mm-hmm.
-E são perguntas profundas.

410
00:17:57,275 --> 00:17:58,709
Mas acho que eles são
extremamente importantes

411
00:17:58,710 --> 00:18:00,577
e estão se tornando
cada vez mais urgentes.

412
00:18:00,578 --> 00:18:04,348
Acho que estamos vivendo em
um momento tão interessante agora,

413
00:18:04,349 --> 00:18:06,316
porque estamos neste momento em
que cérebros e máquinas

414
00:18:06,317 --> 00:18:07,751
estão se
aproximando.

415
00:18:07,752 --> 00:18:10,020
Então, quando se trata
de

416
00:18:10,021 --> 00:18:12,356
poder observar a atividade cerebral,

417
00:18:12,357 --> 00:18:15,292
onde estão
as linhas éticas aqui?

418
00:18:15,293 --> 00:18:17,327
Quão privados devem
ser meus pensamentos internos?

419
00:18:17,328 --> 00:18:19,663
Como acontece com qualquer tecnologia poderosa


420
00:18:19,664 --> 00:18:22,266
, depende das mãos
que a empunham.

421
00:18:22,267 --> 00:18:24,401
Todas essas novas tecnologias

422
00:18:24,402 --> 00:18:28,472
são coisas que podem tornar quem as
usa mais poderoso.

423
00:18:28,473 --> 00:18:32,042
Então, não queremos culpar
a tecnologia, mas queremos --

424
00:18:32,043 --> 00:18:33,477
como ela está sendo usada

425
00:18:33,478 --> 00:18:35,445
e quem está usando?

426
00:18:35,446 --> 00:18:37,748
Então, como podemos garantir
que essa tecnologia

427
00:18:37,749 --> 00:18:39,416
esteja nas mãos certas?

428
00:18:39,417 --> 00:18:41,718
Então, acho muito
importante envolver pessoas

429
00:18:41,719 --> 00:18:45,322
que atuam em políticas e leis

430
00:18:45,323 --> 00:18:48,592
para entender o que está por vir
no futuro.

431
00:18:48,593 --> 00:18:51,528
Estou esperançoso quanto
ao aspecto colaborativo disso.

432
00:18:51,529 --> 00:18:53,430
Vamos falar
das coisas boas agora.

433
00:18:53,431 --> 00:18:56,133
Quero dizer, quais são
as aplicações aqui?

434
00:18:56,134 --> 00:18:58,135
Sim, então se pensarmos

435
00:18:58,136 --> 00:18:59,803
no falecido Stephen Hawking,
por exemplo,

436
00:18:59,804 --> 00:19:04,608
se ele tivesse uma maneira mais rica de
interagir com o mundo

437
00:19:04,609 --> 00:19:06,643
ou com os computadores,
podemos apenas imaginar o

438
00:19:06,644 --> 00:19:08,645
que ele poderia ter
compartilhado conosco.

439
00:19:08,646 --> 00:19:10,647
Aqueles com síndrome do encarceramento,
certo?

440
00:19:10,648 --> 00:19:13,584
Eles estão ali.
Eles sabem que estão lá.

441
00:19:13,585 --> 00:19:15,786
Mas só precisamos de algo
para olhar em seu cérebro

442
00:19:15,787 --> 00:19:17,788
para ver o
que eles estão tentando dizer,

443
00:19:17,789 --> 00:19:20,657
ou o que estão sentindo.
-Certo, exatamente.

444
00:19:20,658 --> 00:19:22,793
Então, o que você diz
para as pessoas

445
00:19:22,794 --> 00:19:26,396
que têm esse tipo de medo
da tecnologia,

446
00:19:26,397 --> 00:19:31,802
de nós entregarmos nosso verdadeiro
eu natural à tecnologia?

447
00:19:31,803 --> 00:19:36,640
Há algo de sedutor
em chegar ao próximo nível

448
00:19:36,641 --> 00:19:40,177
do que algumas pessoas podem chamar
de evolução humana

449
00:19:40,178 --> 00:19:43,280
ou desenvolvimento de civilização,
e assim por diante.

450
00:19:43,281 --> 00:19:46,250
De certa forma, já não estamos
vivendo vidas naturais, certo?

451
00:19:46,251 --> 00:19:49,586
Porque aí a maioria de nós
morreria antes dos

452
00:19:49,587 --> 00:19:51,822
30 ou 40 anos, não sei.

453
00:19:51,823 --> 00:19:53,490
Teríamos todo tipo
de doença.

454
00:19:53,491 --> 00:19:55,492
Não usaríamos
esta roupa.

455
00:19:55,493 --> 00:19:58,161
Não teríamos óculos
ou lentes de contato.

456
00:19:58,162 --> 00:19:59,763
Não teríamos antibióticos.

457
00:19:59,764 --> 00:20:03,233
[Julia]
Já somos uma espécie

458
00:20:03,234 --> 00:20:05,335
de ciborgues futuristas
se nos compararmos

459
00:20:05,336 --> 00:20:08,805
com o humano que vivia
há 10.000 anos

460
00:20:08,806 --> 00:20:10,574
e era geneticamente
quase idêntico

461
00:20:10,575 --> 00:20:11,808
ao que somos agora.

462
00:20:11,809 --> 00:20:17,748
[Michael]
Sim, nós realmente somos.

463
00:20:17,749 --> 00:20:19,549
Para entender a
cognição,

464
00:20:19,550 --> 00:20:22,686
agora basicamente temos
que pedir

465
00:20:22,687 --> 00:20:24,321
às pessoas que falem sobre
o que estão pensando

466
00:20:24,322 --> 00:20:26,556
ou observar seu comportamento.

467
00:20:26,557 --> 00:20:30,360
Mas ler pensamentos diretamente
seria muito melhor.

468
00:20:30,361 --> 00:20:33,630
É assim que o Dr.
Kuhl estuda a memória,

469
00:20:33,631 --> 00:20:38,402
e é assim que o Dr.
Kamitani estuda o sono e os sonhos.

470
00:20:38,403 --> 00:20:40,671
Mas mesmo que a tecnologia
tenha um longo caminho a percorrer

471
00:20:40,672 --> 00:20:43,106
, é fácil ver
como as questões éticas

472
00:20:43,107 --> 00:20:44,841
podem se tornar um problema.

473
00:20:44,842 --> 00:20:47,110
Bem, é o seguinte:

474
00:20:47,111 --> 00:20:51,782
não
existe um ser humano totalmente selvagem.

475
00:20:51,783 --> 00:20:55,886
Estamos co-evoluindo
com a tecnologia.

476
00:20:55,887 --> 00:21:00,090
Humanos e tecnologia hoje
são inseparáveis.

477
00:21:00,091 --> 00:21:01,725
Agora, é verdade que
precisamos ter cuidado

478
00:21:01,726 --> 00:21:03,760
com cada coisa nova que fazemos,

479
00:21:03,761 --> 00:21:08,332
mas não podemos mudar o fato de
que elas vão acontecer.

480
00:21:08,333 --> 00:21:11,635
É uma história que vivemos de
novo e de novo.

481
00:21:11,636 --> 00:21:14,171
Você sabe, poderíamos ficar
sentados para sempre

482
00:21:14,172 --> 00:21:16,807
debatendo se deveria ou não
existir um limite de velocidade

483
00:21:16,808 --> 00:21:19,743
e quem deveria
ter autoridade para aplicá-lo.

484
00:21:19,744 --> 00:21:21,445
Mas nós não.

485
00:21:21,446 --> 00:21:24,715
Em vez disso, fomos em frente
e inventamos carros

486
00:21:24,716 --> 00:21:29,252
e descobrimos com responsabilidade
os detalhes à medida que avançávamos.

487
00:21:29,253 --> 00:21:31,254
As questões éticas
sobre as novas

488
00:21:31,255 --> 00:21:35,726
tecnologias são mais benéficas
quando facilitam a tecnologia,

489
00:21:35,727 --> 00:21:40,130
não quando impedem desnecessariamente o
progresso.

490
00:21:40,131 --> 00:21:41,498
Então siga seus sonhos.

491
00:21:41,499 --> 00:21:44,634
E, assim que puder,
mostre-as para mim.

492
00:21:44,635 --> 00:21:47,606
E, como sempre,
obrigado por assistir.

