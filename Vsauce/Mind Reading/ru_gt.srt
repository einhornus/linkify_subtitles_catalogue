1
00:00:05,237 --> 00:00:06,438
Чтение мыслей?

2
00:00:06,439 --> 00:00:08,172
Конечно нет.

3
00:00:08,173 --> 00:00:11,376
Я люблю читать.

4
00:00:11,377 --> 00:00:15,413
Послушай, чтение мыслей может
показаться псевдонаучным -

5
00:00:15,414 --> 00:00:16,614
простите за мой язык -

6
00:00:16,615 --> 00:00:18,416
буллитом.

7
00:00:18,417 --> 00:00:21,486
Но его научный аналог,
идентификация мысли,

8
00:00:21,487 --> 00:00:23,855
вполне реальная вещь.

9
00:00:23,856 --> 00:00:26,524
Он основан на нейровизуализации
и машинном обучении,

10
00:00:26,525 --> 00:00:29,861
и что действительно круто, так это
то, что эксперименты по чтению мыслей

11
00:00:29,862 --> 00:00:33,498
— это не просто слежка
за тем, что кто-то думает.

12
00:00:33,499 --> 00:00:37,602
Они о выяснении того, из
чего вообще состоят мысли.

13
00:00:37,603 --> 00:00:39,504
Я имею в виду, когда я
о чем-то думаю, на

14
00:00:39,505 --> 00:00:43,174
что на самом деле похожа эта ментальная картина
?

15
00:00:43,175 --> 00:00:44,709
В каком он разрешении?

16
00:00:44,710 --> 00:00:47,145
Насколько высока
точность воспоминаний

17
00:00:47,146 --> 00:00:49,380
и как они меняются
со временем?

18
00:00:49,381 --> 00:00:51,116
Что ж, в этом эпизоде

19
00:00:51,117 --> 00:00:52,750
�бираюсь посмотреть, как чт�
ние мыслей людей мо�

20
00:00:52,751 --> 00:00:54,719
ет помочь нам ответить на эт�
 во�

21
00:00:54,720 --> 00:00:58,490
росы.  Мое путешествие начинается прямо здесь,
в Орегонском университете.

22
00:00:58,491 --> 00:01:01,259
Я встречаюсь с доктором Брайсом Кулом
из лаборатории Кула.

23
00:01:01,260 --> 00:01:03,394
Он нейробиолог,
который использует нейровизуализацию

24
00:01:03,395 --> 00:01:06,664
и машинное обучение, чтобы
выяснить, о чем думают люди,

25
00:01:06,665 --> 00:01:31,789
не говоря ему об этом.

26
00:01:31,790 --> 00:01:33,625
Так скажи мне, что
ты здесь делаешь.

27
00:01:33,626 --> 00:01:36,794
Ну, я участвую в программе когнитивной
нейробиологии

28
00:01:36,795 --> 00:01:38,396
и изучаю человеческую память.

29
00:01:38,397 --> 00:01:41,099
В моей лаборатории в основном используются
методы нейровизуализации,

30
00:01:41,100 --> 00:01:42,567
поэтому мы много работаем с использованием

31
00:01:42,568 --> 00:01:44,169
функциональной магнитно-
резонансной томографии

32
00:01:44,170 --> 00:01:45,637
или фМРТ.

33
00:01:45,638 --> 00:01:49,340
И как вы используете
фМРТ для исследования воспоминаний?

34
00:01:49,341 --> 00:01:51,776
Мы смотрим на
модель нейронной активности.

35
00:01:51,777 --> 00:01:54,445
Когда вы формируете память,
существует определенный шаблон.

36
00:01:54,446 --> 00:01:56,548
И мы можем записать
этот паттерн,

37
00:01:56,549 --> 00:01:59,617
а затем проверить
, восстанавливается ли этот паттерн

38
00:01:59,618 --> 00:02:02,554
или повторно активируется позже,
например, когда вы его помните.

39
00:02:02,555 --> 00:02:05,823
Означает ли это, что мы можем смотреть
на закономерности мозговой активности

40
00:02:05,824 --> 00:02:10,061
и делать выводы о том, что
именно вспоминается, вспоминается

41
00:02:10,062 --> 00:02:11,262
или даже просто мыслится?

42
00:02:11,263 --> 00:02:13,631
Да, и поэтому мы называем это
декодированием.

43
00:02:13,632 --> 00:02:16,568
Таким образом, в основном
ваш входной паттерн воспринимается

44
00:02:16,569 --> 00:02:18,469
как некий паттерн активности,
который мы записываем,

45
00:02:18,470 --> 00:02:21,272
пока вы что-
то вспоминаете.

46
00:02:21,273 --> 00:02:23,441
И мы делаем прогноз
о том, что вы помните.

47
00:02:23,442 --> 00:02:27,178
Вы можете видеть, как это звучит
как чтение мыслей.

48
00:02:27,179 --> 00:02:28,713
[смеется]
Да.  Похоже на то.

49
00:02:28,714 --> 00:02:32,584
Итак, Брайс, что ты
собираешься сделать со мной сегодня?

50
00:02:32,585 --> 00:02:34,419
Итак, то, что мы
собираемся делать сегодня,

51
00:02:34,420 --> 00:02:36,354
является
для нас неизведанной территорией.

52
00:02:36,355 --> 00:02:38,623
Итак, мы собираемся опробовать на вас что-
то вроде нового

53
00:02:38,624 --> 00:02:40,258
варианта эксперимента.

54
00:02:40,259 --> 00:02:42,660
Так что я не могу гарантировать
никаких конкретных результатов.

55
00:02:42,661 --> 00:02:44,195
Но он показывает,
где находится поле

56
00:02:44,196 --> 00:02:46,664
и куда
мы пытаемся пойти.

57
00:02:46,665 --> 00:02:48,800
Сегодня вы будете
участвовать в эксперименте, в

58
00:02:48,801 --> 00:02:50,268
котором будете изучать лица.

59
00:02:50,269 --> 00:02:51,803
Итак, мы
предлагаем вам изучить

60
00:02:51,804 --> 00:02:53,404
12 фотографий знаменитостей.

61
00:02:53,405 --> 00:02:54,872
Люди, с которыми я уже
знаком.

62
00:02:54,873 --> 00:02:56,674
-Люди, которых ты знаешь, да.
-Хорошо.

63
00:02:56,675 --> 00:02:59,143
И вы
попытаетесь запомнить эти картинки.

64
00:02:59,144 --> 00:03:01,112
Затем мы отправим вас
в МРТ-сканер.

65
00:03:01,113 --> 00:03:04,249

Постарайтесь как можно ярче представить себе эту картину.

66
00:03:04,250 --> 00:03:06,417
И мы собираемся записывать
активность вашего мозга,

67
00:03:06,418 --> 00:03:08,753
пока вы пытаетесь представить
эти картинки.

68
00:03:08,754 --> 00:03:10,555
Мы попробуем
построить лицо.

69
00:03:10,556 --> 00:03:12,590
По существу, нарисуйте картину того,
что вы помните.

70
00:03:12,591 --> 00:03:14,125
-Картинка?
-Картинка.

71
00:03:14,126 --> 00:03:16,327
Настоящую картинку,
которую мы можем распечатать,

72
00:03:16,328 --> 00:03:17,729
и я мог бы
повесить ее на стену.

73
00:03:17,730 --> 00:03:19,831
[смеется]
Если бы вы хотели.

74
00:03:19,832 --> 00:03:22,634
[Майкл]Первый
шаг для меня —

75
00:03:22,635 --> 00:03:25,336
запомнить 12 конкретных
фотографий знаменитостей, о которых

76
00:03:25,337 --> 00:03:28,640
Брайс позже
попытается обнаружить мои мысли.

77
00:03:28,641 --> 00:03:33,278
Я сел делать это,
аспирант, Макс.

78
00:03:33,279 --> 00:03:35,280
Успех его предсказаний
отчасти

79
00:03:35,281 --> 00:03:37,415
зависит от моей способности как можно ярче
вспомнить эти лица,

80
00:03:37,416 --> 00:03:43,087

находясь внутри фМРТ.

81
00:03:43,088 --> 00:03:44,422
Хорошо, так что...

82
00:03:44,423 --> 00:03:46,157
[вздыхает]

83
00:03:46,158 --> 00:03:50,728
Думаю, я довольно
хорошо все это помню.

84
00:03:50,729 --> 00:03:53,698
-Большой.
- Я чувствую, что ставки высоки.

85
00:03:53,699 --> 00:03:56,701
Мы надеемся, что лица знаменитостей
запомнены,

86
00:03:56,702 --> 00:03:58,303
и пришло время для следующего шага:

87
00:03:58,304 --> 00:04:00,071
пройти
через металлоискатель

88
00:04:00,072 --> 00:04:01,706
и перейти к фМРТ,

89
00:04:01,707 --> 00:04:04,676
где Брайс будет записывать
и отслеживать активность моего мозга,

90
00:04:04,677 --> 00:04:08,746
а затем вводить ее в свой
алгоритм для восстановления лиц.

91
00:04:08,747 --> 00:04:10,448
Это будет первый раз, когда
он

92
00:04:10,449 --> 00:04:12,383
попытается восстановить лица
по долговременной памяти,

93
00:04:12,384 --> 00:04:14,385
что очень сложно,
потому что мы полагаемся

94
00:04:14,386 --> 00:04:16,720
на то, насколько четко я могу
вспомнить фотографии знаменитостей, которые

95
00:04:16,721 --> 00:04:19,090
я видел час назад.

96
00:04:19,091 --> 00:04:21,225
Я люблю его глаза.
Посмотри на это.

97
00:04:21,226 --> 00:04:24,362
[женщина]

98
00:04:24,363 --> 00:04:31,102
Разве ребенок
не сказал бы: «Он меня съест»?

99
00:04:31,103 --> 00:04:34,205
ФМРТ отслеживает активность
мозга

100
00:04:34,206 --> 00:04:36,774
, разделяя его
на тысячи маленьких кубов,

101
00:04:36,775 --> 00:04:39,744
называемых вокселями
или объемными пикселями.

102
00:04:39,745 --> 00:04:41,446
Каждый из этих вокселей содержит

103
00:04:41,447 --> 00:04:43,581
сотни
тысяч нейронов.

104
00:04:43,582 --> 00:04:46,117
Используя фМРТ,
мы можем обнаружить

105
00:04:46,118 --> 00:04:47,719
кровоток
в этих вокселах,

106
00:04:47,720 --> 00:04:50,088
что означает, что эта
часть мозга активна.

107
00:04:50,089 --> 00:04:53,124
Если мне показать несколько
фотографий людей с усами,

108
00:04:53,125 --> 00:04:56,327
мой мозг отреагирует
на особенности каждого лица.

109
00:04:56,328 --> 00:04:58,329
Но
будет общая область моего мозга

110
00:04:58,330 --> 00:05:00,164
, которая задействована
во всем.

111
00:05:00,165 --> 00:05:04,102
Это может быть область моего
мозга, которая реагирует на усы.

112
00:05:04,103 --> 00:05:07,171
Так что позже,
когда я представляю себе лицо,

113
00:05:07,172 --> 00:05:09,440
если Брайс заметит,
что эта область занята,

114
00:05:09,441 --> 00:05:11,476
он может предсказать,
что я думаю

115
00:05:11,477 --> 00:05:13,811
об усах.

116
00:05:13,812 --> 00:05:15,780
Итак, прямо сейчас Майкл находится
в сканере,

117
00:05:15,781 --> 00:05:18,282
и он видит, как слова появляются
на экране одно за другим,

118
00:05:18,283 --> 00:05:20,651
и он
пытается визуализировать лицо,

119
00:05:20,652 --> 00:05:23,187
запомнить лицо
как можно подробнее.

120
00:05:23,188 --> 00:05:25,356
Здесь вы видите
изображения, которые мы получаем.

121
00:05:25,357 --> 00:05:28,793
Мы получаем один из этих
объемов мозга каждые две секунды.

122
00:05:28,794 --> 00:05:32,797
Так что они обновляются в режиме реального
времени, когда мы собираем изображения.

123
00:05:32,798 --> 00:05:35,633
[Майкл]Первая
часть сеанса фМРТ завершена,

124
00:05:35,634 --> 00:05:38,503
пришло время для второй части,
где Брайс и его команда

125
00:05:38,504 --> 00:05:41,773
изучат
язык активности моего мозга,

126
00:05:41,774 --> 00:05:44,776
чтобы позже они могли
расшифровать его с помощью сканирования мозга.

127
00:05:44,777 --> 00:05:46,544
Привет, Майкл.
Ты все еще в порядке?

128
00:05:46,545 --> 00:05:48,312
[Майкл]
Ага.

129
00:05:48,313 --> 00:05:50,381
Они покажут мне
сотни уникальных лиц

130
00:05:50,382 --> 00:05:52,784
и запишут, как мой мозг реагирует

131
00:05:52,785 --> 00:05:54,852
на определенные черты
лица.

132
00:05:54,853 --> 00:05:57,188
Затем они будут использовать
эту информацию

133
00:05:57,189 --> 00:05:59,657
для
реконструкции лиц знаменитостей, о которых

134
00:05:59,658 --> 00:06:03,127
я думал
на первом этапе сканирования.

135
00:06:03,128 --> 00:06:05,530
Действительно, чем больше лиц
мы сможем показать Майклу, тем лучше.

136
00:06:05,531 --> 00:06:08,166
Так что мы собираемся держать
его там

137
00:06:08,167 --> 00:06:09,600
, пока ему комфортно.

138
00:06:09,601 --> 00:06:11,636
[Майкл]
Максимальное время, которое

139
00:06:11,637 --> 00:06:13,538
мы могли провести на фМРТ, — два часа.

140
00:06:13,539 --> 00:06:17,175
Но я смог
просмотреть более 400 лиц,

141
00:06:17,176 --> 00:06:18,743
чего должно быть достаточно, чтобы получить

142
00:06:18,744 --> 00:06:20,778
довольно интересные
результаты.

143
00:06:20,779 --> 00:06:22,447
Эй, Майкл, ты сделал это.
Это было здорово.

144
00:06:22,448 --> 00:06:23,681
Мы собираемся
вытащить тебя.

145
00:06:23,682 --> 00:06:33,157
[Майкл]
Хорошо.

146
00:06:33,158 --> 00:06:34,725
Да, так что здесь просто показаны
некоторые фотографии,

147
00:06:34,726 --> 00:06:36,561
которые мы делали,
пока вы были там.

148
00:06:36,562 --> 00:06:38,095
Некоторые изображения вашего мозга.

149
00:06:38,096 --> 00:06:39,764
Теперь мы
собираемся обработать некоторые цифры.

150
00:06:39,765 --> 00:06:42,200
Макс собирается проанализировать
ваши данные.

151
00:06:42,201 --> 00:06:43,701
Мы встретимся
снова завтра,

152
00:06:43,702 --> 00:06:45,369
где мы посмотрим
на результаты,

153
00:06:45,370 --> 00:06:47,638
где мы попытаемся
реконструировать изображения лиц

154
00:06:47,639 --> 00:06:49,740
из данных мозга,
которые мы только что собрали.

155
00:06:49,741 --> 00:06:51,175
Хорошо.
Что ж, увидимся завтра.

156
00:06:51,176 --> 00:06:52,577
Хорошо.
Большое спасибо.

157
00:06:52,578 --> 00:06:54,178
Макс, спасибо и тебе.
Я не могу ждать.

158
00:06:54,179 --> 00:06:55,847
Тебе лучше
тянуть всю ночь.

159
00:06:55,848 --> 00:07:04,288
Я хочу, чтобы эти
данные были идеальными.

160
00:07:04,289 --> 00:07:06,524
Итак, я снова
в лаборатории доктора Кула.

161
00:07:06,525 --> 00:07:08,693
Ночью его команда
обработала данные,

162
00:07:08,694 --> 00:07:15,500
и мне не терпится увидеть, что, по
их мнению, они увидели в моих мыслях.

163
00:07:15,501 --> 00:07:17,101
Как мои результаты?

164
00:07:17,102 --> 00:07:18,736
Я думаю, они хорошо выглядят.

165
00:07:18,737 --> 00:07:20,705
Мы собираемся
взглянуть через мгновение здесь.

166
00:07:20,706 --> 00:07:22,406
Ладно,
я не могу дождаться.

167
00:07:22,407 --> 00:07:24,342
- Так можно я просто сяду?
-Ага, присаживайся.

168
00:07:24,343 --> 00:07:26,143
Хорошо, итак... во-

169
00:07:26,144 --> 00:07:28,212
первых...

170
00:07:28,213 --> 00:07:30,081
что я вижу?
О, ладно, ну,

171
00:07:30,082 --> 00:07:32,283
это те картинки, которые
я на самом деле запомнил.

172
00:07:32,284 --> 00:07:34,252
-Вот так.
-И это то, что

173
00:07:34,253 --> 00:07:37,822
вы реконструировали
из моего воображения.

174
00:07:37,823 --> 00:07:40,091
-Вот так.
-Ух ты.  Хорошо.

175
00:07:40,092 --> 00:07:43,094
[Брайс]
Итак, это одна
из

176
00:07:43,095 --> 00:07:44,562
созданных реконструкций.

177
00:07:44,563 --> 00:07:46,063
[Майкл]
Интересно.

178
00:07:46,064 --> 00:07:47,698
[Макс]
Итак, это Джон Чо.

179
00:07:47,699 --> 00:07:50,668
[Майкл]
Неплохо.  Неплохо.

180
00:07:50,669 --> 00:07:53,337
-Можем ли мы увидеть бок о бок?
-Ага.

181
00:07:53,338 --> 00:07:55,673
[Майкл]
Я вижу, вы знаете, сходство

182
00:07:55,674 --> 00:08:00,044
в выражении лица
в целом.

183
00:08:00,045 --> 00:08:02,213
Знаешь, здесь почти можно было
увидеть совпадающую линию роста волос.

184
00:08:02,214 --> 00:08:04,682

Я также подумал, что форма лица была...

185
00:08:04,683 --> 00:08:06,684
У него
была квадратная форма.

186
00:08:06,685 --> 00:08:08,152
-Да.  Да.
-Итак, это то,

187
00:08:08,153 --> 00:08:09,387
что пришло мне в голову.

188
00:08:09,388 --> 00:08:11,289
Итак, когда я
визуализировал

189
00:08:11,290 --> 00:08:13,257
этот образ Джона Чо

190
00:08:13,258 --> 00:08:16,260
, прямоугольность лица
была первой, самой заметной вещью.

191
00:08:16,261 --> 00:08:19,697
Я просто продолжал думать, что
он был квадратным парнем.

192
00:08:19,698 --> 00:08:23,401
Отлично, хорошо.

193
00:08:23,402 --> 00:08:26,704
[Брайс]
Так это Меган Фокс.

194
00:08:26,705 --> 00:08:28,439
[Майкл]
Мм-хм.

195
00:08:28,440 --> 00:08:30,207
Ты собираешься показать нам...
бок о бок.

196
00:08:30,208 --> 00:08:31,776
[Майкл
] Бок о бок.  Верно.

197
00:08:31,777 --> 00:08:33,644
[Брайс]
Вы видите изображение
, которое видели на самом деле,

198
00:08:33,645 --> 00:08:36,547
и это воссозданная
нами реконструкция.

199
00:08:36,548 --> 00:08:39,417
Я тебе это.
Меган Фокс, у

200
00:08:39,418 --> 00:08:42,353
меня не было четкой картины
в голове.

201
00:08:42,354 --> 00:08:45,056
По какой-то причине
мне было очень трудно вспомнить этот ее образ

202
00:08:45,057 --> 00:08:47,058
.

203
00:08:47,059 --> 00:08:50,595
Строгость на лице была
чем-то, что я уловил.

204
00:08:50,596 --> 00:08:53,698
Так что я чувствовал, что это было...
Это выглядело женственно.

205
00:08:53,699 --> 00:08:55,533
И ты
подхватил суровость.

206
00:08:55,534 --> 00:08:58,769
И так вместе,
что производит совпадение.

207
00:08:58,770 --> 00:09:00,538
[Майкл]Имейте в виду,
что Брайс и его команда

208
00:09:00,539 --> 00:09:02,773
прочитали это
по моей памяти.

209
00:09:02,774 --> 00:09:04,609
Но когда я запоминаю лицо, представляю

210
00:09:04,610 --> 00:09:07,678
ли я каждую деталь
одновременно

211
00:09:07,679 --> 00:09:09,313
с фотографической точностью?

212
00:09:09,314 --> 00:09:10,748
Или я просто посещаю несколько
одновременно?

213
00:09:10,749 --> 00:09:13,417
Читая мои мысли,
они могут видеть,

214
00:09:13,418 --> 00:09:15,219
насколько плоха моя память
и как она работает.

215
00:09:15,220 --> 00:09:18,689
-Мне!  Мне!
- [Брайс смеется]

216
00:09:18,690 --> 00:09:21,525
Итак, это ваша


217
00:09:21,526 --> 00:09:24,729
реконструкция моих мыслей об
этом образе самого себя.

218
00:09:24,730 --> 00:09:26,497
[Брайс]
Верно.

219
00:09:26,498 --> 00:09:28,666
Куда делась борода?

220
00:09:28,667 --> 00:09:31,068
[Брайс] Не знаю.
Я надеялся, что ты мне скажешь.

221
00:09:31,069 --> 00:09:36,240
[Майкл]
Например, на этой
фотографии я вспоминаю собственное лицо.

222
00:09:36,241 --> 00:09:38,743
Это действительно не похоже на меня,
но вопрос в

223
00:09:38,744 --> 00:09:41,345
том, насколько хорошо
я представляю себя?

224
00:09:41,346 --> 00:09:44,048
Я не так часто думаю о своем лице
,

225
00:09:44,049 --> 00:09:45,616
поэтому
странность результата

226
00:09:45,617 --> 00:09:47,752
может быть связана как с
недостатками моей памяти

227
00:09:47,753 --> 00:09:51,288
и ментального представления о себе,
так и с недостатками технологии.

228
00:09:51,289 --> 00:09:53,691
Так что это Дженнифер Лоуренс,
я полагаю.

229
00:09:53,692 --> 00:09:55,726
[Майкл]
Это Дженнифер Лоуренс?

230
00:09:55,727 --> 00:09:59,664
Похоже, это
намного более старший дядя Дженнифер Лоуренс.

231
00:09:59,665 --> 00:10:01,365
[все смеются]

232
00:10:01,366 --> 00:10:05,069
Ничто здесь не было слишком
умопомрачительно близким.

233
00:10:05,070 --> 00:10:09,407
Но это то, что
вы только начинаете пробовать

234
00:10:09,408 --> 00:10:11,409
такие долговременные
воспоминания.

235
00:10:11,410 --> 00:10:14,679
То, что Брайс и его команда
прочитали в моем сознании,

236
00:10:14,680 --> 00:10:18,549
могло бы быть более точным,
если бы они показали мне тысячи,

237
00:10:18,550 --> 00:10:20,284
а не сотни изображений
на фМРТ,

238
00:10:20,285 --> 00:10:22,520
потому что тогда алгоритм
лучше изучил

239
00:10:22,521 --> 00:10:24,655
бы язык моего
мозга.

240
00:10:24,656 --> 00:10:27,358
Но несмотря ни
на что, качество моих воспоминаний

241
00:10:27,359 --> 00:10:29,226
все равно
было бы проблемой.

242
00:10:29,227 --> 00:10:30,661
Я имею в виду, посмотрите, что происходит,
когда память

243
00:10:30,662 --> 00:10:33,164
полностью исключается из уравнения
.

244
00:10:33,165 --> 00:10:35,166
Брайс также считывал
активность моего мозга,

245
00:10:35,167 --> 00:10:37,168
когда я смотрел
на лица на фМРТ.

246
00:10:37,169 --> 00:10:39,103
не просто воображая их.

247
00:10:39,104 --> 00:10:41,672
И эти результаты
были гораздо ближе,

248
00:10:41,673 --> 00:10:44,675
чем те, что были восстановлены
по моей памяти.

249
00:10:44,676 --> 00:10:47,111
Итак, на что я смотрю
прямо здесь?

250
00:10:47,112 --> 00:10:48,679
[Брайс]
Итак, то, что вы видите здесь,

251
00:10:48,680 --> 00:10:51,682
в верхнем ряду,
это изображения, которые вы видели

252
00:10:51,683 --> 00:10:53,584
, когда были в сканере.

253
00:10:53,585 --> 00:10:56,754
Ниже, в этом нижнем ряду,
это реконструкции,

254
00:10:56,755 --> 00:11:00,725
которые мы делаем из
собранных нами паттернов мозговой активности.

255
00:11:00,726 --> 00:11:03,828
-Это из исходного изображения.
-Верно.

256
00:11:03,829 --> 00:11:05,629
[Майкл]
Это из моего мозга.

257
00:11:05,630 --> 00:11:07,565
-[Брайс] Верно.
-[Майкл] Они довольно близко.

258
00:11:07,566 --> 00:11:09,700
Да, в целом они были
довольно близки.

259
00:11:09,701 --> 00:11:11,602
Так что не идеально.

260
00:11:11,603 --> 00:11:13,771
Это... вы можете видеть, что
в них есть некоторая изменчивость.

261
00:11:13,772 --> 00:11:16,640
Но это согласуется
с тем, что мы обнаружили ранее,

262
00:11:16,641 --> 00:11:18,409
что воссозданные
нами реконструкции,

263
00:11:18,410 --> 00:11:20,244
когда вы
просматриваете лица

264
00:11:20,245 --> 00:11:22,279
, имеют некоторое соответствие
между реальным лицом.

265
00:11:22,280 --> 00:11:23,714
Так что это своего рода
проверка здравомыслия,

266
00:11:23,715 --> 00:11:25,750
что мы действительно можем
реконструировать изображения,

267
00:11:25,751 --> 00:11:28,219
когда вы их просматриваете.
-Верно-верно.

268
00:11:28,220 --> 00:11:31,355
Они довольно хороши.

269
00:11:31,356 --> 00:11:33,190
Что ж, Брайс, Макс,
большое вам спасибо

270
00:11:33,191 --> 00:11:35,126
за то, что позволили мне
быть частью этого.

271
00:11:35,127 --> 00:11:36,660
Надеюсь, мои данные будут полезны.

272
00:11:36,661 --> 00:11:38,596
Спасибо.
Было очень весело.

273
00:11:38,597 --> 00:11:46,837
Нам всегда
полезно думать об этих вещах.

274
00:11:46,838 --> 00:11:50,808
Исследование памяти, проведенное доктором Брайсом Кулом,
показывает, что

275
00:11:50,809 --> 00:11:53,677
компьютер
может читать чьи-то мысли.

276
00:11:53,678 --> 00:11:56,313
Чтобы понять, о
чем они думают.

277
00:11:56,314 --> 00:11:58,415
Но многое
еще предстоит сделать.

278
00:11:58,416 --> 00:12:00,050
Я имею в виду, если вы хотите знать,

279
00:12:00,051 --> 00:12:01,619
что я думаю прямо сейчас,
например,

280
00:12:01,620 --> 00:12:05,189
проще просто попросить
меня рассказать вам.

281
00:12:05,190 --> 00:12:07,491
Но что, если я не
могу тебе сказать?

282
00:12:07,492 --> 00:12:10,594
Доктор Юкиясу Камитани
— исследователь,

283
00:12:10,595 --> 00:12:14,498
профессор и пионер,
изучающий границы

284
00:12:14,499 --> 00:12:17,535
за стеной сна.

285
00:12:17,536 --> 00:12:19,703
Я приехал сюда,
в Киотский университет,

286
00:12:19,704 --> 00:12:21,672
чтобы встретиться с ним и посмотреть,
каково

287
00:12:21,673 --> 00:12:24,175
это читать не то, что кто-
то думает,

288
00:12:24,176 --> 00:12:29,647
а то, что кто-
то мечтает.

289
00:12:29,648 --> 00:12:31,348
Камитани-сенсей,
я Майкл.

290
00:12:31,349 --> 00:12:33,818
-Привет, я Юки.
-Юки, приятно познакомиться.

291
00:12:33,819 --> 00:12:36,320
[Майкл]
В течение последних десяти лет

292
00:12:36,321 --> 00:12:38,455
доктор Камитани был
в

293
00:12:38,456 --> 00:12:40,124
авангарде машинного чтения мыслей.

294
00:12:40,125 --> 00:12:43,527
Субъект, как вы знаете,
готов войти.

295
00:12:43,528 --> 00:12:45,462
Подобно Брайсу Кулу,

296
00:12:45,463 --> 00:12:48,632
его ранние эксперименты изучали
реконструкцию изображений,

297
00:12:48,633 --> 00:12:52,236
показанных испытуемым на фМРТ,
на основе активности их мозга.

298
00:12:52,237 --> 00:12:53,637
В случае Камитани

299
00:12:53,638 --> 00:12:55,706
изображения были
черно-белыми,

300
00:12:55,707 --> 00:12:58,375
а реконструкция
была поразительно точной.

301
00:12:58,376 --> 00:13:03,180
В последнее время Камитани сосредоточился
на использовании глубоких нейронных сетей

302
00:13:03,181 --> 00:13:04,815
и машинного обучения

303
00:13:04,816 --> 00:13:06,450
для расшифровки мозговой активности субъектов,


304
00:13:06,451 --> 00:13:08,686
когда они просматривают
гораздо более сложные фотографии.

305
00:13:08,687 --> 00:13:12,756
То, что вы видите, —
результат работы глубокой нейронной сети,

306
00:13:12,757 --> 00:13:15,226
обрабатывающей мозговую
активность субъекта,

307
00:13:15,227 --> 00:13:17,795
смотрящего на фотографию.

308
00:13:17,796 --> 00:13:20,431
Это может иметь множество
применений в будущем,

309
00:13:20,432 --> 00:13:22,733
например,
в уголовных расследованиях

310
00:13:22,734 --> 00:13:26,470
и межличностном
общении.

311
00:13:26,471 --> 00:13:28,739
[Камитани]
Это далеко не идеально.

312
00:13:28,740 --> 00:13:33,177
Но я думаю, что вы все еще видите некоторые,
знаете, глаза и, вы знаете...

313
00:13:33,178 --> 00:13:34,778
[Майкл]
Ну, да.

314
00:13:34,779 --> 00:13:36,447
И цвета тоже.

315
00:13:36,448 --> 00:13:39,783
[Камитани]
Да, в какой-то степени да.

316
00:13:39,784 --> 00:13:42,419
Однако его самая последняя работа
посвящена подсознанию.

317
00:13:42,420 --> 00:13:45,256
Он пытается сделать что-то
очень амбициозное:

318
00:13:45,257 --> 00:13:46,824
записать наши сны.

319
00:13:46,825 --> 00:13:49,326
Вы бы назвали
себя исследователем сна

320
00:13:49,327 --> 00:13:50,828
или исследователем зрения?

321
00:13:50,829 --> 00:13:53,664
Может декодер мозга.

322
00:13:53,665 --> 00:13:55,432
Декодер мозга.

323
00:13:55,433 --> 00:13:57,534
Это довольно крутое
описание работы.

324
00:13:57,535 --> 00:14:01,739
Можешь показать мне что-нибудь из
того, что ты делаешь со снами?

325
00:14:01,740 --> 00:14:08,379
[Камитани]
Мм-хм, да.

326
00:14:08,380 --> 00:14:10,514
Работа доктора Камитани
по расшифровке снов

327
00:14:10,515 --> 00:14:13,317
начинается с того же процесса,
что и у доктора Кула: он

328
00:14:13,318 --> 00:14:15,452
показывает испытуемым
тысячи изображений,

329
00:14:15,453 --> 00:14:17,187
пока они находятся в фМРТ

330
00:14:17,188 --> 00:14:18,722
, чтобы узнать,
как выглядит мозг,

331
00:14:18,723 --> 00:14:21,358
когда он думает
об определенных вещах.

332
00:14:21,359 --> 00:14:23,794
Как только алгоритм машинного обучения
довольно

333
00:14:23,795 --> 00:14:26,764
хорошо определяет, о каких образах


334
00:14:26,765 --> 00:14:29,300
думает субъект, его помещают
в фМРТ

335
00:14:29,301 --> 00:14:31,335
с шапкой ЭЭГ
на голове

336
00:14:31,336 --> 00:14:33,470
и предлагают заснуть.

337
00:14:33,471 --> 00:14:36,573
Когда волны ЭЭГ указывают на
то, что человек спит

338
00:14:36,574 --> 00:14:39,243
, алгоритм предсказывает
, какие

339
00:14:39,244 --> 00:14:41,645
вещи ему, скорее всего,
снится.

340
00:14:41,646 --> 00:14:45,215
Сейчас алгоритм
ищет 20 категорий.

341
00:14:45,216 --> 00:14:48,485
Такие вещи, как здания,
транспорт

342
00:14:48,486 --> 00:14:50,621
и символы
на языке.

343
00:14:50,622 --> 00:14:53,324
Затем исследователи
будят испытуемого,

344
00:14:53,325 --> 00:14:55,326
спрашивают, что ему
снилось,

345
00:14:55,327 --> 00:14:57,227
и смотрят, совпадают ли предсказания алгоритма


346
00:14:57,228 --> 00:14:59,530
и
воспоминания человека.

347
00:14:59,531 --> 00:15:03,367
Вот фактические данные
одного из экспериментов Камитани.

348
00:15:03,368 --> 00:15:05,703
Ниже представлено облако
слов категорий.

349
00:15:05,704 --> 00:15:08,339
Название каждой категории
увеличивается или уменьшается

350
00:15:08,340 --> 00:15:10,574
в реальном времени в
зависимости от вероятности того,

351
00:15:10,575 --> 00:15:13,344
что они присутствуют
в текущем сне субъекта.

352
00:15:13,345 --> 00:15:15,346
Теперь, как вы можете видеть,
в настоящее время активность наиболее высока

353
00:15:15,347 --> 00:15:18,349
для категории «персонаж», то
есть письменный язык.

354
00:15:18,350 --> 00:15:20,684
В этот
момент субъект проснулся,

355
00:15:20,685 --> 00:15:29,660
и вот что
они сообщили.

356
00:15:29,661 --> 00:15:32,062
Это довольно жутко.

357
00:15:32,063 --> 00:15:33,697
-[смеется]
-Правильно?  Я имею в виду, ты...

358
00:15:33,698 --> 00:15:36,700
ты подсмотрел их сон.

359
00:15:36,701 --> 00:15:39,370
Да, в некотором роде.
Но

360
00:15:39,371 --> 00:15:42,406
... точность
не так велика, так что...

361
00:15:42,407 --> 00:15:44,341
Ну, точность
не так велика, но, знаешь,

362
00:15:44,342 --> 00:15:46,677
моя обычная точность угадывания
человеческих снов равна нулю.

363
00:15:46,678 --> 00:15:48,145
Верно.

364
00:15:48,146 --> 00:15:49,580
Продолжая
свои исследования

365
00:15:49,581 --> 00:15:52,182
в области
предсказания содержания снов,

366
00:15:52,183 --> 00:15:54,785
доктор Камитани приступает
к своему новейшему проекту:

367
00:15:54,786 --> 00:15:58,389
фактическому воссозданию изображений
из наших снов.

368
00:15:58,390 --> 00:16:01,458
Итак, вы принесли
некоторые реконструкции

369
00:16:01,459 --> 00:16:02,659
, созданные в вашей лаборатории...

370
00:16:02,660 --> 00:16:04,061
М-м-м.

371
00:16:04,062 --> 00:16:17,741
... мечтаний.

372
00:16:17,742 --> 00:16:20,210
Верно, все они похожи на сны
о каплях.

373
00:16:20,211 --> 00:16:21,779
[Камитани]
Да.

374
00:16:21,780 --> 00:16:24,448
Я имею в виду, я хочу просто
сделать шаг назад и...

375
00:16:24,449 --> 00:16:27,785
понять, что то, что мы
смотрим на этот

376
00:16:27,786 --> 00:16:31,655
экран, является в некотором роде одними из первых
фотографий сна.

377
00:16:31,656 --> 00:16:33,357
М-м-м.

378
00:16:33,358 --> 00:16:35,759
Мы смотрим
на самую раннюю

379
00:16:35,760 --> 00:16:38,062
фазу революционных исследований.

380
00:16:38,063 --> 00:16:40,164
Однажды мы сможем
получить изображения

381
00:16:40,165 --> 00:16:42,766
или даже записать
фильмы наших собственных снов.

382
00:16:42,767 --> 00:16:45,335
И доктор Камитани пока единственный
человек в мире

383
00:16:45,336 --> 00:16:47,237
, который этим занимается.

384
00:16:47,238 --> 00:16:50,707
Он одинокий исследователь, путешествующий
в наше подсознание.

385
00:16:50,708 --> 00:16:53,644
Так что эта работа еще даже
не опубликована.

386
00:16:53,645 --> 00:16:55,345
Нет.

387
00:16:55,346 --> 00:17:01,752
-Спасибо, что показал мне это.
- [смеется

388
00:17:01,753 --> 00:17:06,155
] Открытия, которые такие исследователи,
как доктор Куль и доктор Камитани,

389
00:17:06,156 --> 00:17:09,159
могли бы достичь
в будущем

390
00:17:09,160 --> 00:17:11,328
благодаря чтению мыслей

391
00:17:11,329 --> 00:17:13,697
,
трудно полностью понять.

392
00:17:13,698 --> 00:17:15,399
Но давайте притормозим
на секунду,

393
00:17:15,400 --> 00:17:17,233
потому что мы говорим
о технологии,

394
00:17:17,234 --> 00:17:21,105
которая может знать нас
лучше, чем мы сами себя знаем.

395
00:17:21,106 --> 00:17:23,740
Должны ли мы действительно
делать это?

396
00:17:23,741 --> 00:17:25,275
Что ж, чтобы ответить на
этот вопрос,

397
00:17:25,276 --> 00:17:27,310
я собираюсь встретиться
с экспертом в области этики,

398
00:17:27,311 --> 00:17:30,447
неврологии
и искусственного интеллекта:

399
00:17:30,448 --> 00:17:32,216
Джулией Боссманн.

400
00:17:32,217 --> 00:17:34,518
Она директор по стратегии
компании Fathom Computing,

401
00:17:34,519 --> 00:17:37,087
член
совета Всемирного экономического форума,

402
00:17:37,088 --> 00:17:40,424
выпускница Университета сингулярности Рэя Курцвейла


403
00:17:40,425 --> 00:17:43,293
и бывший
президент Института прогнозирования

404
00:17:43,294 --> 00:17:46,530
, аналитического центра, специализирующегося
на технологиях будущего

405
00:17:46,531 --> 00:17:50,200
и их влиянии.

406
00:17:50,201 --> 00:17:52,669
Юлия, спасибо, что нашли
время поболтать.

407
00:17:52,670 --> 00:17:54,438
-Да, конечно.
-Ты идеальный человек

408
00:17:54,439 --> 00:17:55,739
для меня, чтобы
задать эти вопросы.

409
00:17:55,740 --> 00:17:57,274
-Мм-хм.
-И это глубокие вопросы.

410
00:17:57,275 --> 00:17:58,709
Но я думаю, что они
чрезвычайно важны,

411
00:17:58,710 --> 00:18:00,577
и они становятся все
более и более актуальными.

412
00:18:00,578 --> 00:18:04,348
Я думаю, что мы живем в
такое интересное время прямо сейчас,

413
00:18:04,349 --> 00:18:06,316
потому что мы живем в то время,
когда мозг и машины

414
00:18:06,317 --> 00:18:07,751
на самом деле
сближаются.

415
00:18:07,752 --> 00:18:10,020
Итак, когда дело доходит
до

416
00:18:10,021 --> 00:18:12,356
возможности наблюдать за активностью мозга,

417
00:18:12,357 --> 00:18:15,292
где
здесь этические грани?

418
00:18:15,293 --> 00:18:17,327
Насколько приватными должны быть
мои внутренние мысли?

419
00:18:17,328 --> 00:18:19,663
Как и в случае с любой мощной
технологией,

420
00:18:19,664 --> 00:18:22,266
все зависит от рук,
которые ею владеют.

421
00:18:22,267 --> 00:18:24,401
Все эти новые технологии

422
00:18:24,402 --> 00:18:28,472
могут сделать того, кто
их использует, сильнее.

423
00:18:28,473 --> 00:18:32,042
Поэтому мы не хотим
обвинять технологию, но мы хотим...

424
00:18:32,043 --> 00:18:33,477
как она используется

425
00:18:33,478 --> 00:18:35,445
и кто ее использует?

426
00:18:35,446 --> 00:18:37,748
Так как же нам убедиться,
что эта технология

427
00:18:37,749 --> 00:18:39,416
находится в правильных руках?

428
00:18:39,417 --> 00:18:41,718
Поэтому я думаю, что очень
важно привлекать людей,

429
00:18:41,719 --> 00:18:45,322
которые действуют в соответствии с политикой и законом,

430
00:18:45,323 --> 00:18:48,592
чтобы понять, что нас ждет
в будущем.

431
00:18:48,593 --> 00:18:51,528
Я надеюсь
на совместный аспект этого.

432
00:18:51,529 --> 00:18:53,430
Давайте теперь поговорим
о хорошем.

433
00:18:53,431 --> 00:18:56,133
Я имею в виду, какие
здесь приложения?

434
00:18:56,134 --> 00:18:58,135
Да, так что если мы подумаем

435
00:18:58,136 --> 00:18:59,803
о покойном Стивене Хокинге,
например,

436
00:18:59,804 --> 00:19:04,608
если бы у него был способ более богатого
взаимодействия с миром

437
00:19:04,609 --> 00:19:06,643
или с компьютерами,
мы можем только представить,

438
00:19:06,644 --> 00:19:08,645
чем он мог бы
поделиться с нами.

439
00:19:08,646 --> 00:19:10,647
Те, у кого синдром запертого человека,
верно?

440
00:19:10,648 --> 00:19:13,584
Они там.
Они знают, что они там.

441
00:19:13,585 --> 00:19:15,786
Но нам просто нужно что-то,
чтобы заглянуть в их мозг,

442
00:19:15,787 --> 00:19:17,788
чтобы увидеть,
что они пытаются сказать

443
00:19:17,789 --> 00:19:20,657
или что чувствуют.
-Правильно, точно.

444
00:19:20,658 --> 00:19:22,793
Итак, что вы
скажете людям,

445
00:19:22,794 --> 00:19:26,396
которые испытывают такой страх
перед технологиями

446
00:19:26,397 --> 00:19:31,802
, перед тем, как мы отдаем свое истинное
естественное «я» технологиям?

447
00:19:31,803 --> 00:19:36,640
Есть что-то заманчивое
в переходе на следующий уровень

448
00:19:36,641 --> 00:19:40,177
того, что некоторые люди могут
назвать эволюцией человека

449
00:19:40,178 --> 00:19:43,280
или развитием цивилизации
и так далее.

450
00:19:43,281 --> 00:19:46,250
В каком-то смысле мы уже не
живем естественной жизнью, верно?

451
00:19:46,251 --> 00:19:49,586
Потому что тогда большинство из нас
умерло бы в возрасте,

452
00:19:49,587 --> 00:19:51,822
не знаю, 30 или 40 лет.

453
00:19:51,823 --> 00:19:53,490
У нас были бы
всевозможные болезни.

454
00:19:53,491 --> 00:19:55,492
Мы бы не стали носить
эту одежду.

455
00:19:55,493 --> 00:19:58,161
У нас не было бы ни очков,
ни контактных линз.

456
00:19:58,162 --> 00:19:59,763
У нас не было бы антибиотиков.

457
00:19:59,764 --> 00:20:03,233
[Джулия]
Мы уже своего рода

458
00:20:03,234 --> 00:20:05,335
очень футуристические киборги,
если сравнивать себя

459
00:20:05,336 --> 00:20:08,805
с человеком, который жил
10 000 лет назад

460
00:20:08,806 --> 00:20:10,574
и был генетически
почти идентичен тому,

461
00:20:10,575 --> 00:20:11,808
кем мы являемся сейчас.

462
00:20:11,809 --> 00:20:17,748
[Майкл]
Да, действительно.

463
00:20:17,749 --> 00:20:19,549
Чтобы понять
познание,

464
00:20:19,550 --> 00:20:22,686
прямо сейчас нам
нужно либо просто попросить

465
00:20:22,687 --> 00:20:24,321
людей рассказать о
том, о чем они думают,

466
00:20:24,322 --> 00:20:26,556
либо понаблюдать за их поведением.

467
00:20:26,557 --> 00:20:30,360
Но чтение мыслей напрямую
было бы намного лучше.

468
00:20:30,361 --> 00:20:33,630
Именно так доктор
Куль изучает память,

469
00:20:33,631 --> 00:20:38,402
а доктор
Камитани изучает сон и сновидения.

470
00:20:38,403 --> 00:20:40,671
Но даже несмотря на то, что технологиям
еще предстоит пройти долгий путь,

471
00:20:40,672 --> 00:20:43,106
легко понять,
как этические вопросы

472
00:20:43,107 --> 00:20:44,841
могут стать проблемой.

473
00:20:44,842 --> 00:20:47,110
Вот в чем дело:

474
00:20:47,111 --> 00:20:51,782

совершенно диких людей не бывает.

475
00:20:51,783 --> 00:20:55,886
Мы развиваемся
вместе с технологиями.

476
00:20:55,887 --> 00:21:00,090
Люди и технологии
сегодня неразделимы.

477
00:21:00,091 --> 00:21:01,725
Это правда, что нам
нужно быть осторожными

478
00:21:01,726 --> 00:21:03,760
со всеми новыми вещами, которые мы делаем,

479
00:21:03,761 --> 00:21:08,332
но мы не можем изменить тот факт,
что они будут происходить.

480
00:21:08,333 --> 00:21:11,635
Это история, которую мы переживаем
снова и снова.

481
00:21:11,636 --> 00:21:14,171
Знаете, мы могли бы
вечно

482
00:21:14,172 --> 00:21:16,807
спорить о том,
должно ли существовать ограничение скорости

483
00:21:16,808 --> 00:21:19,743
и кто должен
иметь право его обеспечивать.

484
00:21:19,744 --> 00:21:21,445
Но мы этого не сделали.

485
00:21:21,446 --> 00:21:24,715
Вместо этого мы пошли вперед
и изобрели автомобили

486
00:21:24,716 --> 00:21:29,252
и ответственно
продумывали детали по ходу дела.

487
00:21:29,253 --> 00:21:31,254
Этические вопросы
о новых технологиях

488
00:21:31,255 --> 00:21:35,726
приносят наибольшую пользу, когда
они облегчают технологию, а

489
00:21:35,727 --> 00:21:40,130
не когда они без необходимости
мешают прогрессу.

490
00:21:40,131 --> 00:21:41,498
Так следуй за своей мечтой.

491
00:21:41,499 --> 00:21:44,634
И, как только сможешь,
покажи их мне.

492
00:21:44,635 --> 00:21:47,606
И, как всегда,
спасибо за просмотр.

