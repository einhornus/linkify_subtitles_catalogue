1
00:00:05,171 --> 00:00:06,872
Чтение мыслей?

2
00:00:06,873 --> 00:00:07,973
Нет, конечно.

3
00:00:07,974 --> 00:00:10,876
Я обожаю читать.

4
00:00:10,877 --> 00:00:15,180
Дело вот в чем: чтение мыслей –
это, конечно, антинаучная,

5
00:00:15,181 --> 00:00:16,582
простите мой французский,

6
00:00:16,583 --> 00:00:18,050
фигня.

7
00:00:18,051 --> 00:00:21,387
Но есть и вполне научная
идентификация мыслей, -

8
00:00:21,388 --> 00:00:23,655
это очень даже реальное явление.

9
00:00:23,656 --> 00:00:26,592
Она основывается на нейровизуализации
и машинном обучении.

10
00:00:26,593 --> 00:00:30,095
И замечательно то, что эксперименты
с чтением мыслей заключаются

11
00:00:30,096 --> 00:00:33,399
не в том, чтобы
следить за чьими-то суждениями.

12
00:00:33,400 --> 00:00:37,403
Их цель – разобраться,
из чего состоят мысли.

13
00:00:37,404 --> 00:00:40,339
То есть как выглядит мысленный образ,

14
00:00:40,340 --> 00:00:42,841
когда человек думает.

15
00:00:42,842 --> 00:00:44,376
Какое в нем разрешение?

16
00:00:44,377 --> 00:00:46,712
Насколько высока точность памяти

17
00:00:46,713 --> 00:00:49,081
и как она меняется со временем?

18
00:00:49,082 --> 00:00:50,282
В этой серии

19
00:00:50,283 --> 00:00:52,451
я рассмотрю, как идентификация мыслей

20
00:00:52,452 --> 00:00:54,553
помогает ответить на эти вопросы.

21
00:00:54,554 --> 00:00:58,257
Мое путешествие начинается здесь,
в Университете Орегона.

22
00:00:58,258 --> 00:01:01,060
Я встречаюсь
с доктором Брайсом Кюлом из Kuhl Lab.

23
00:01:01,061 --> 00:01:03,462
Он нейроученый.

24
00:01:03,463 --> 00:01:07,499
Нейровизуализация и машинное обучение
помогают ему узнавать, о чем думают люди,

25
00:01:07,500 --> 00:01:23,248
не задавая им вопросов.

26
00:01:23,249 --> 00:01:27,953
ЧТЕНИЕ МЫСЛЕЙ

27
00:01:27,954 --> 00:01:30,823
УНИВЕРСИТЕТ ОРЕГОНА

28
00:01:30,824 --> 00:01:33,559
Расскажите, чем вы занимаетесь.

29
00:01:33,560 --> 00:01:34,693
БРАЙС КЮЛ
ДОЦЕНТ ПО ПСИХОЛОГИИ

30
00:01:34,694 --> 00:01:36,595
Я занимаюсь когнитивной нейробиологией

31
00:01:36,596 --> 00:01:38,163
и исследую человеческую память.

32
00:01:38,164 --> 00:01:40,766
В основном мы используем
методы нейровизуализации.

33
00:01:40,767 --> 00:01:42,568
Так что мы активно используем

34
00:01:42,569 --> 00:01:45,671
функциональную магнитно-
резонансную визуализацию, или ФМРВ.

35
00:01:45,672 --> 00:01:49,208
И как именно
она помогает вам исследовать память?

36
00:01:49,209 --> 00:01:51,110
Мы изучаем структуры деятельности мозга.

37
00:01:51,111 --> 00:01:55,280
Когда человек что-то запоминает,
в мозге возникает особая структура.

38
00:01:55,281 --> 00:01:58,617
Мы ее записываем, а потом,
когда человек вспоминает,

39
00:01:58,618 --> 00:02:02,254
проверяем,
восстанавливается ли эта структура.

40
00:02:02,255 --> 00:02:06,158
Значит ли это, что мы можем посмотреть
на структуры деятельности мозга

41
00:02:06,159 --> 00:02:10,996
и сделать вывод о том,
что именно мозг вспоминает и о чем думает?

42
00:02:10,997 --> 00:02:13,666
Да. И мы называем это декодированием.

43
00:02:13,667 --> 00:02:15,868
Нужно взять входную структуру –

44
00:02:15,869 --> 00:02:18,037
это определенная
структура деятельности,

45
00:02:18,038 --> 00:02:20,939
которую мы записываем,
когда вы что-то запоминаете.

46
00:02:20,940 --> 00:02:23,575
И мы предполагаем, что именно.

47
00:02:23,576 --> 00:02:26,445
Вы же понимаете, что это звучит так,
будто вы читаете мысли.

48
00:02:26,446 --> 00:02:28,947
Да. Именно так и звучит.

49
00:02:28,948 --> 00:02:32,451
Итак, Брайс,
что вы сегодня будете со мной делать?

50
00:02:32,452 --> 00:02:35,454
Это и для нас пока
неизведанная территория.

51
00:02:35,455 --> 00:02:38,290
С вами мы будем пробовать
новый вариант эксперимента.

52
00:02:38,291 --> 00:02:41,894
Я не могу гарантировать результаты.

53
00:02:41,895 --> 00:02:46,231
Но он покажет, куда мы движемся
и чего мы пытаемся добиться.

54
00:02:46,232 --> 00:02:50,235
Сегодня вы участвуете
в эксперименте по распознаванию лиц.

55
00:02:50,236 --> 00:02:53,839
Мы дадим вам изучить
12 фотографий знаменитостей.

56
00:02:53,840 --> 00:02:55,107
Знакомых мне людей.

57
00:02:55,108 --> 00:02:56,975
– Знакомых, да.
– Хорошо.

58
00:02:56,976 --> 00:02:58,877
Вы попробуете запомнить эти фото.

59
00:02:58,878 --> 00:03:00,946
Затем мы вас положим в МРТ-сканер,

60
00:03:00,947 --> 00:03:03,849
и вы попробуете
четко представить эти фото.

61
00:03:03,850 --> 00:03:08,253
А мы в это время будем
записывать деятельность мозга.

62
00:03:08,254 --> 00:03:10,089
И построим изображения лиц.

63
00:03:10,090 --> 00:03:12,257
Нарисуем то, что вы помните.

64
00:03:12,258 --> 00:03:13,992
– Картинку?
– Картинку.

65
00:03:13,993 --> 00:03:18,030
Настоящую картинку, которую можно
напечатать и повесить на стене?

66
00:03:18,031 --> 00:03:20,232
Если захотите.

67
00:03:20,233 --> 00:03:25,270
Сначала мне нужно запомнить
12 фотографий знаменитостей.

68
00:03:25,271 --> 00:03:28,674
Затем Брайс попробует понять,
о чем я думаю.

69
00:03:28,675 --> 00:03:31,543
Пока я изучал фото,
со мной был аспирант Макс.

70
00:03:31,544 --> 00:03:32,878
МАКС ДРАСКЕР
АСПИРАНТ ПО ПСИХОЛОГИИ

71
00:03:32,879 --> 00:03:37,716
Успех его предположений зависит от того,
насколько хорошо я смогу вспомнить лица,

72
00:03:37,717 --> 00:03:42,588
когда буду проходить ФМРВ-сканирование.

73
00:03:42,589 --> 00:03:45,591
Так, ладно.

74
00:03:45,592 --> 00:03:51,063
Думаю, я довольно хорошо всех запомнил.

75
00:03:51,064 --> 00:03:53,699
– Отлично.
– Ставки высоки.

76
00:03:53,700 --> 00:03:58,203
Надеясь, что я все запомнил,
мы переходим ко второму этапу –

77
00:03:58,204 --> 00:04:01,340
через металлоискатель к ФМРВ.

78
00:04:01,341 --> 00:04:04,143
Там Брайс будет записывать
деятельность моего мозга.

79
00:04:04,144 --> 00:04:07,913
А затем обработает эти данные,
чтобы воссоздать лица.

80
00:04:07,914 --> 00:04:12,084
Он впервые будет пробовать построить
лица из долговременной памяти.

81
00:04:12,085 --> 00:04:13,519
А это очень сложно,

82
00:04:13,520 --> 00:04:15,721
ведь все зависит от того,
насколько четко я запомнил

83
00:04:15,722 --> 00:04:19,058
снимки знаменитостей,
которые увидел час назад.

84
00:04:19,059 --> 00:04:20,792
О, здесь глаза нарисованы.

85
00:04:20,793 --> 00:04:22,661
Да, чтобы детям было веселее.

86
00:04:22,662 --> 00:04:24,396
У нас тут много детей.

87
00:04:24,397 --> 00:04:26,932
Они спрашивают: "Он меня съест?"

88
00:04:26,933 --> 00:04:31,236
ДЕМОНСТРАЦИЯ
ВОССТАНОВЛЕНИЕ ПАМЯТИ

89
00:04:31,237 --> 00:04:33,972
Чтобы отслеживать нервную деятельность,

90
00:04:33,973 --> 00:04:36,975
при ФМРВ мозг распределяют
на множество участков –

91
00:04:36,976 --> 00:04:39,945
вокселей, или объемных пикселей.

92
00:04:39,946 --> 00:04:43,749
В каждом из них содержатся
сотни тысяч нейронов.

93
00:04:43,750 --> 00:04:47,753
С помощью ФМРВ можно проследить
кровоток в этих вокселях –

94
00:04:47,754 --> 00:04:50,089
он отражает активность в этой части мозга.

95
00:04:50,090 --> 00:04:53,125
Если мне покажут несколько фото
людей с усами,

96
00:04:53,126 --> 00:04:56,428
мой мозг отреагирует
на особенности каждого лица.

97
00:04:56,429 --> 00:04:59,965
Но все это время будет задействована
одна часть моего мозга.

98
00:04:59,966 --> 00:05:03,936
И это будет та часть моего мозга,
которая реагирует на усы.

99
00:05:03,937 --> 00:05:09,341
А позже, когда я представлю лицо,
если Брайс заметит, что эта часть активна,

100
00:05:09,342 --> 00:05:13,779
он сможет предположить,
что я думаю об усах.

101
00:05:13,780 --> 00:05:15,814
Майкл уже в сканере.

102
00:05:15,815 --> 00:05:17,716
Перед ним на экране возникают слова.

103
00:05:17,717 --> 00:05:18,851
ДЖОН ЧО – МЕГАН ФОКС

104
00:05:18,852 --> 00:05:20,819
Он пытается визуализировать лица.

105
00:05:20,820 --> 00:05:23,255
Вспомнить их как можно детальнее.

106
00:05:23,256 --> 00:05:25,691
Вот картинка, которую мы получаем.

107
00:05:25,692 --> 00:05:29,028
Образцы поступают каждые две секунды,

108
00:05:29,029 --> 00:05:33,666
Так что изображение обновляется
по мере сбора данных.

109
00:05:33,667 --> 00:05:36,101
Этап с ФМРВ закончился.

110
00:05:36,102 --> 00:05:37,536
Теперь второй этап:

111
00:05:37,537 --> 00:05:40,472
Брайс с командой будут изучать
язык деятельности моего мозга,

112
00:05:40,473 --> 00:05:44,843
чтобы потом декодировать
результаты сканирования.

113
00:05:44,844 --> 00:05:46,545
Привет, Майкл. Все хорошо?

114
00:05:46,546 --> 00:05:48,113
Да.

115
00:05:48,114 --> 00:05:52,718
Они покажут мне сотни неповторяемых лиц
и запишут, как реагирует мой мозг

116
00:05:52,719 --> 00:05:55,020
на определенные черты лица.

117
00:05:55,021 --> 00:05:59,491
Затем, исходя из этой информации,
они воссоздадут лица знаменитостей,

118
00:05:59,492 --> 00:06:03,228
которые я представлял
на первом этапе сканирования.

119
00:06:03,229 --> 00:06:06,031
Чем больше лиц
мы покажем Майклу, тем лучше.

120
00:06:06,032 --> 00:06:09,802
Так что будем продолжать,
пока он не устанет.

121
00:06:09,803 --> 00:06:13,138
Дольше двух часов ФМРВ не проводят.

122
00:06:13,139 --> 00:06:16,442
Но за это время
я просмотрел около 400 лиц,

123
00:06:16,443 --> 00:06:21,080
а этого должно быть достаточно,
чтобы получить интересные результаты.

124
00:06:21,081 --> 00:06:22,681
Майкл, все готово.

125
00:06:22,682 --> 00:06:26,652
– Сейчас поможем вам выйти.
– Хорошо.

126
00:06:26,653 --> 00:06:28,821
Ого.

127
00:06:28,822 --> 00:06:31,390
Вот уж я насмотрелся сегодня на лица.

128
00:06:31,391 --> 00:06:32,858
Господи.

129
00:06:32,859 --> 00:06:36,328
Вот часть изображений,
которые мы получили.

130
00:06:36,329 --> 00:06:39,965
Несколько снимков вашего мозга.
Теперь мы проведем подсчеты.

131
00:06:39,966 --> 00:06:42,034
Макс будет анализировать данные.

132
00:06:42,035 --> 00:06:45,270
Завтра мы увидимся снова и посмотрим,

133
00:06:45,271 --> 00:06:47,973
удалось ли нам восстановить снимки лиц

134
00:06:47,974 --> 00:06:49,775
из собранных данных.

135
00:06:49,776 --> 00:06:51,377
Ясно. Увидимся завтра.

136
00:06:51,378 --> 00:06:54,646
– Да. Спасибо.
– Макс, спасибо. Жду не дождусь.

137
00:06:54,647 --> 00:07:04,356
Не вздумайте спать ночью.
Нам нужен идеальный результат.

138
00:07:04,357 --> 00:07:06,892
И вот я снова в лаборатории доктора Кюла.

139
00:07:06,893 --> 00:07:08,994
За ночь его команда обработала данные.

140
00:07:08,995 --> 00:07:15,701
И сейчас я узнаю, о чем,
по их мнению, я вчера думал.

141
00:07:15,702 --> 00:07:17,536
Ну что, как результаты?

142
00:07:17,537 --> 00:07:19,171
Думаю, все в порядке.

143
00:07:19,172 --> 00:07:20,773
Через минутку посмотрим.

144
00:07:20,774 --> 00:07:22,341
Хорошо, жду не дождусь.

145
00:07:22,342 --> 00:07:24,243
– Так я могу присесть?
– Да.

146
00:07:24,244 --> 00:07:26,645
Так...

147
00:07:26,646 --> 00:07:29,248
Прежде всего, что это здесь?

148
00:07:29,249 --> 00:07:32,518
А, понял. Это снимки, которые я запоминал.

149
00:07:32,519 --> 00:07:33,285
Верно.

150
00:07:33,286 --> 00:07:38,023
А это фото, созданные
вами на основе моего воображения.

151
00:07:38,024 --> 00:07:40,726
– Правильно.
– Ясно.

152
00:07:40,727 --> 00:07:44,530
Итак, это одна из созданных реконструкций.

153
00:07:44,531 --> 00:07:45,931
Интересно.

154
00:07:45,932 --> 00:07:47,966
Это Джон Чо.

155
00:07:47,967 --> 00:07:50,402
Неплохо.

156
00:07:50,403 --> 00:07:53,872
– Макс, можешь показать обе сразу?
– Да.

157
00:07:53,873 --> 00:07:59,678
Выражения лиц в целом похожи.

158
00:07:59,679 --> 00:08:02,414
Даже линия волос почти совпадает.

159
00:08:02,415 --> 00:08:04,983
Думаю, форма лица тоже...

160
00:08:04,984 --> 00:08:06,985
Она тоже будто квадратная.

161
00:08:06,986 --> 00:08:07,720
Да.

162
00:08:07,721 --> 00:08:09,421
Вот на что я обратил внимание.

163
00:08:09,422 --> 00:08:12,791
Когда я представлял себе снимок Джо Чо,

164
00:08:12,792 --> 00:08:16,328
в первую очередь думал о том,
что у него лицо квадратной формы.

165
00:08:16,329 --> 00:08:20,065
– Интересно.
– Я думал: он весь такой квадратный.

166
00:08:20,066 --> 00:08:23,335
Отлично.

167
00:08:23,336 --> 00:08:28,307
А это Меган Фокс.

168
00:08:28,308 --> 00:08:30,175
Покажи их... да, рядом.

169
00:08:30,176 --> 00:08:31,844
Рядом. Так.

170
00:08:31,845 --> 00:08:36,682
Вот фото, которое вы видели,
и созданная нами реконструкция.

171
00:08:36,683 --> 00:08:38,317
Вот что я скажу.

172
00:08:38,318 --> 00:08:42,021
Мне не удалось
четко представить себе Меган Фокс.

173
00:08:42,022 --> 00:08:46,992
Эту фотографию
почему-то было сложно запомнить.

174
00:08:46,993 --> 00:08:50,963
Но я отметил, что лицо было строгим.

175
00:08:50,964 --> 00:08:54,066
Я думал...
Оно выглядело женственным.

176
00:08:54,067 --> 00:08:58,804
И вы запомнили строгость.
Вместе получилось так.

177
00:08:58,805 --> 00:09:02,474
Не забывайте, что Брайс с командой
прочитали это в моей памяти.

178
00:09:02,475 --> 00:09:07,112
Но когда я запоминаю лицо,
представляю ли я все детали одновременно

179
00:09:07,113 --> 00:09:08,747
с фотографической точностью?

180
00:09:08,748 --> 00:09:11,016
Или несколько за раз?

181
00:09:11,017 --> 00:09:16,121
Прочитав мои мысли, они могут увидеть,
насколько плоха моя память и как работает.

182
00:09:16,122 --> 00:09:19,024
Я!

183
00:09:19,025 --> 00:09:25,330
Значит, это ваша реконструкция того,
как я представлял свою фотографию.

184
00:09:25,331 --> 00:09:27,499
Именно.

185
00:09:27,500 --> 00:09:29,435
А куда делась борода?

186
00:09:29,436 --> 00:09:32,137
Не знаю. Я думал, вы скажете.

187
00:09:32,138 --> 00:09:36,542
Например, вот снимок того,
как я помню свое лицо.

188
00:09:36,543 --> 00:09:39,244
Оно не похоже на меня, но вопрос в другом:

189
00:09:39,245 --> 00:09:41,613
насколько хорошо
я представляю, как я выгляжу.

190
00:09:41,614 --> 00:09:45,451
Я не так часто думаю о своем лице,
поэтому результат получился такой странный

191
00:09:45,452 --> 00:09:48,687
или потому, что у меня плохая память
и неточный образ самого себя,

192
00:09:48,688 --> 00:09:51,824
или из-за несовершенства технологии.

193
00:09:51,825 --> 00:09:54,460
А это Дженнифер Лоуренс, я так думаю.

194
00:09:54,461 --> 00:09:56,095
Это Дженнифер Лоуренс?

195
00:09:56,096 --> 00:10:01,800
Это скорее ее старый дядя.

196
00:10:01,801 --> 00:10:05,371
Не скажешь, чтобы
результаты были очень точными.

197
00:10:05,372 --> 00:10:09,208
Но вы только начали работать

198
00:10:09,209 --> 00:10:12,678
с долговременной памятью.

199
00:10:12,679 --> 00:10:15,214
Данные, которые Брайс с командой прочли

200
00:10:15,215 --> 00:10:19,451
в моей голове, могли бы быть точнее,
если бы в аппарате ФМРВ они показали мне

201
00:10:19,452 --> 00:10:22,054
не несколько сотен, а много тысяч снимков,

202
00:10:22,055 --> 00:10:25,057
ведь тогда алгоритм лучше бы
изучил язык моего мозга.

203
00:10:25,058 --> 00:10:29,228
Тем не менее качество моих воспоминаний
все равно было бы под вопросом.

204
00:10:29,229 --> 00:10:33,298
Посмотрите, что происходит,
если полностью исключить память.

205
00:10:33,299 --> 00:10:37,302
Брайс также считывал деятельность
моего мозга, когда я смотрел на лица в ФМРВ.

206
00:10:37,303 --> 00:10:39,238
А не просто представлял их.

207
00:10:39,239 --> 00:10:45,144
И эти результаты намного точнее,
чем те, которые созданы из моей памяти.

208
00:10:45,145 --> 00:10:47,546
Что здесь показано?

209
00:10:47,547 --> 00:10:53,919
В верхнем ряду фотографии,
которые вы видели, пока были в сканере.

210
00:10:53,920 --> 00:10:56,855
Под ними, в нижнем ряду, – реконструкции.

211
00:10:56,856 --> 00:11:00,092
Мы нарисовали их, опираясь на
структуры, собранные из вашего мозга.

212
00:11:00,093 --> 00:11:01,193
ВЕРХНИЙ РЯД: ИСХОДНОЕ ИЗОБРАЖЕНИЕ
НИЖНИЙ РЯД: РЕКОНСТРУКЦИЯ

213
00:11:01,194 --> 00:11:03,696
– Это я видел.
– Точно.

214
00:11:03,697 --> 00:11:05,464
А это я представлял.

215
00:11:05,465 --> 00:11:07,566
– Точно.
– Они довольно похожи.

216
00:11:07,567 --> 00:11:10,102
Да, в целом они очень похожи.

217
00:11:10,103 --> 00:11:11,704
Но не идеальны.

218
00:11:11,705 --> 00:11:14,239
Здесь есть небольшие различия.

219
00:11:14,240 --> 00:11:17,076
Но они согласуются с тем,
что мы уже узнали:

220
00:11:17,077 --> 00:11:19,712
когда мы реконструируем,
как вы видите фотографии,

221
00:11:19,713 --> 00:11:22,481
в полученных результатах
есть сходство с исходным снимком.

222
00:11:22,482 --> 00:11:26,552
Мы просто убедились,
что можем воссоздавать картинки,

223
00:11:26,553 --> 00:11:27,920
которые вы видите.

224
00:11:27,921 --> 00:11:29,121
Да, понятно.

225
00:11:29,122 --> 00:11:31,590
И вышло неплохо!

226
00:11:31,591 --> 00:11:35,027
Брайс, Макс, большое спасибо,
что дали возможность поучаствовать в этом.

227
00:11:35,028 --> 00:11:36,729
Надеюсь, эти данные вам помогут.

228
00:11:36,730 --> 00:11:38,597
Спасибо. Нам и самим было интересно.

229
00:11:38,598 --> 00:11:43,836
Всегда полезно подумать о таких вещах.

230
00:11:43,837 --> 00:11:47,740
КИОТО, ЯПОНИЯ

231
00:11:47,741 --> 00:11:51,443
Исследования памяти
доктора Брайса Кюла доказывают,

232
00:11:51,444 --> 00:11:54,279
что компьютер может считывать мысли людей

233
00:11:54,280 --> 00:11:56,915
и определять, о чем они думают.

234
00:11:56,916 --> 00:11:59,051
Но работы еще непочатый край.

235
00:11:59,052 --> 00:12:02,221
Например, если вы хотите узнать,
о чем я сейчас думаю,

236
00:12:02,222 --> 00:12:05,524
все еще проще спросить у меня.

237
00:12:05,525 --> 00:12:08,327
А если я не могу сказать?

238
00:12:08,328 --> 00:12:11,363
Профессор доктор Юкиясу Камитани

239
00:12:11,364 --> 00:12:15,100
занимается новаторскими исследованиями

240
00:12:15,101 --> 00:12:18,237
в области сна.

241
00:12:18,238 --> 00:12:20,472
Я приехал в Киотский университет,

242
00:12:20,473 --> 00:12:27,513
чтобы встретиться с ним и узнать,
на что похоже чтение не мыслей, а снов.

243
00:12:27,514 --> 00:12:29,548
ЛАБОРАТОРИЯ "НАУЧНЫЕ ВОЗМОЖНОСТИ"

244
00:12:29,549 --> 00:12:31,650
Камитани-сенсей, я Майкл.

245
00:12:31,651 --> 00:12:33,385
– Привет, я Юки.
– Юки, рад встрече.

246
00:12:33,386 --> 00:12:34,753
Да, очень приятно.

247
00:12:34,754 --> 00:12:36,355
Уже десять лет

248
00:12:36,356 --> 00:12:40,225
доктор Камитани продвигает науку
в сфере машинного чтения мыслей.

249
00:12:40,226 --> 00:12:44,396
Испытуемый готов.

250
00:12:44,397 --> 00:12:46,098
Как и Брайс Кюл,

251
00:12:46,099 --> 00:12:49,201
сначала он экспериментировал
с реконструкцией изображений,

252
00:12:49,202 --> 00:12:52,771
считывая деятельность
мозга с помощью ФМРВ.

253
00:12:52,772 --> 00:12:55,974
В его случае это были черно-белые фигуры,

254
00:12:55,975 --> 00:12:59,578
и реконструкции были поразительно точными.

255
00:12:59,579 --> 00:13:03,382
Но недавно Камитани занялся
расшифровкой деятельности мозга

256
00:13:03,383 --> 00:13:06,485
с помощью глубоких
нейронных сетей и машинного обучения.

257
00:13:06,486 --> 00:13:09,955
При этом испытуемым демонстрируют
более сложные изображения.

258
00:13:09,956 --> 00:13:13,726
Сейчас вы видите, как
глубокие нейронные сети

259
00:13:13,727 --> 00:13:18,097
обрабатывают деятельность мозга
испытуемого, который смотрит на фото.

260
00:13:18,098 --> 00:13:21,433
В будущем эта технология может
применяться множеством разных способов.

261
00:13:21,434 --> 00:13:26,939
Например, в уголовном розыске
и межличностном общении.

262
00:13:26,940 --> 00:13:28,941
Эта реконструкция далека от идеала.

263
00:13:28,942 --> 00:13:32,211
Но все равно можно разглядеть глаза и уши.

264
00:13:32,212 --> 00:13:33,812
Д-Р ЮКИЯСУ КАМИТАНИ
ПРОФЕССОР, ВЫСШАЯ ШКОЛА ИНФОРМАТИКИ

265
00:13:33,813 --> 00:13:35,414
Да.

266
00:13:35,415 --> 00:13:37,116
И цвета.

267
00:13:37,117 --> 00:13:39,952
Да, в какой-то мере.

268
00:13:39,953 --> 00:13:43,088
Но его самая последняя работа
касается подсознания.

269
00:13:43,089 --> 00:13:45,591
У него честолюбивый замысел –

270
00:13:45,592 --> 00:13:47,693
записывать сны.

271
00:13:47,694 --> 00:13:52,398
Вы бы называли себя
исследователем сна или образов?

272
00:13:52,399 --> 00:13:54,266
Наверное, дешифровщиком разума.

273
00:13:54,267 --> 00:13:56,001
Дешифровщик разума.

274
00:13:56,002 --> 00:13:58,303
Отличное название профессии.

275
00:13:58,304 --> 00:14:02,374
Можете показать,
что именно делаете со снами?

276
00:14:02,375 --> 00:14:03,942
Да.

277
00:14:03,943 --> 00:14:08,647
Для начала мы
одновременно записываем ЭЭГ и МРТ.

278
00:14:08,648 --> 00:14:11,150
Работа доктора Камитани
над расшифровкой снов

279
00:14:11,151 --> 00:14:13,485
начинается примерно
так же, как у доктора Кюла:

280
00:14:13,486 --> 00:14:17,389
испытуемого кладут в сканер ФМПВ
и показывают ему тысячи картинок.

281
00:14:17,390 --> 00:14:22,094
Так он изучает работу мозга в тот момент,
когда он работает с изображениями.

282
00:14:22,095 --> 00:14:25,330
Как только алгоритм
машинного обучения может определить,

283
00:14:25,331 --> 00:14:27,566
о каких картинках думает человек,

284
00:14:27,567 --> 00:14:31,837
испытуемого перемещают в ФМРВ
со шлемом для ЭЭГ на голове

285
00:14:31,838 --> 00:14:33,972
и просят уснуть.

286
00:14:33,973 --> 00:14:37,076
Когда волны ЭЭГ показывают,
что человеку снятся сны,

287
00:14:37,077 --> 00:14:42,247
алгоритм определяет,
что может сниться испытуемому.

288
00:14:42,248 --> 00:14:45,851
Прямо сейчас алгоритм
просматривает 20 категорий.

289
00:14:45,852 --> 00:14:51,423
Здания, транспорт и буквы.

290
00:14:51,424 --> 00:14:55,828
Затем исследователи будят испытуемого
и спрашивают, что ему снилось,

291
00:14:55,829 --> 00:15:00,299
чтобы проверить, совпали ли предположения
алгоритма и воспоминания человека.

292
00:15:00,300 --> 00:15:03,836
Вот фактические данные
одного из экспериментов Камитани.

293
00:15:03,837 --> 00:15:06,305
Ниже видно облако слов –
в нем показаны категории.

294
00:15:06,306 --> 00:15:08,407
Каждое слово становится больше или меньше

295
00:15:08,408 --> 00:15:10,909
в зависимости от того,
насколько высока вероятность,

296
00:15:10,910 --> 00:15:14,079
что данная категория прямо сейчас
присутствует во сне испытуемого.

297
00:15:14,080 --> 00:15:17,016
Как видите, в данный момент
активнее всего категория "Буквы",

298
00:15:17,017 --> 00:15:18,984
то есть письменной речи.

299
00:15:18,985 --> 00:15:23,822
Затем испытуемого разбудили.
Вот что он сказал.

300
00:15:23,823 --> 00:15:26,692
"Там были просто какие-то буквы.

301
00:15:26,693 --> 00:15:30,729
Что-то вроде формы для написания эссе..."

302
00:15:30,730 --> 00:15:32,998
– Жутковато.
– Да.

303
00:15:32,999 --> 00:15:37,102
Правда? Вы шпионили за их сном.

304
00:15:37,103 --> 00:15:39,938
Да, в какой-то мере.

305
00:15:39,939 --> 00:15:42,174
Но точность не настолько высока...

306
00:15:42,175 --> 00:15:43,942
Да, точность невысока,

307
00:15:43,943 --> 00:15:47,579
но лично я угадываю сны
с нулевой точностью.

308
00:15:47,580 --> 00:15:48,947
Именно.

309
00:15:48,948 --> 00:15:52,518
Продолжая свои исследования анализа снов,

310
00:15:52,519 --> 00:15:55,554
доктор Камитани
приступает к новому проекту:

311
00:15:55,555 --> 00:15:59,224
буквальной реконструкции
изображений из наших снов.

312
00:15:59,225 --> 00:16:05,831
Вы принесли несколько реконструкций снов,
созданных вашей лабораторией.

313
00:16:05,832 --> 00:16:08,467
Над этим мы еще работаем,

314
00:16:08,468 --> 00:16:11,337
но кое-что мы уже заметили.

315
00:16:11,338 --> 00:16:13,972
Что бы мы ни передавали декодеру,

316
00:16:13,973 --> 00:16:18,344
реконструкция всегда похожа
на шарик в центре.

317
00:16:18,345 --> 00:16:20,779
Да, похоже, будто все сны о шариках.

318
00:16:20,780 --> 00:16:22,014
Да.

319
00:16:22,015 --> 00:16:27,119
Я хочу сделать шаг назад
и оценить тот факт,

320
00:16:27,120 --> 00:16:34,793
что сейчас на экране
мы видим первые фотографии сна.

321
00:16:34,794 --> 00:16:38,497
Мы видим самую раннюю стадию
революционного исследования.

322
00:16:38,498 --> 00:16:43,535
Однажды мы сможем получить картинки
или даже снимать фильмы из наших снов.

323
00:16:43,536 --> 00:16:47,539
И пока во всем мире
этим занимается только доктор Камитани.

324
00:16:47,540 --> 00:16:51,643
Одинокий исследователь нашего подсознания.

325
00:16:51,644 --> 00:16:54,546
Так эту работу ещё не публиковали?

326
00:16:54,547 --> 00:16:56,015
Нет.

327
00:16:56,016 --> 00:16:59,985
Спасибо, что показали мне.

328
00:16:59,986 --> 00:17:02,888
ЛОС-АНДЖЕЛЕС, КАЛИФОРНИЯ

329
00:17:02,889 --> 00:17:06,424
Сложно в полной мере представить себе,

330
00:17:06,425 --> 00:17:09,761
какие знания смогут
получить исследователи,

331
00:17:09,762 --> 00:17:12,798
такие как доктор Кюл и доктор Камитани,

332
00:17:12,799 --> 00:17:15,034
благодаря чтению мыслей.

333
00:17:15,035 --> 00:17:18,337
Но давайте притормозим,
ведь мы говорим о технологии,

334
00:17:18,338 --> 00:17:22,174
которая может узнать нас
лучше, чем мы сами.

335
00:17:22,175 --> 00:17:24,309
Нужно ли нам ее развивать?

336
00:17:24,310 --> 00:17:25,978
Для ответа на этот вопрос

337
00:17:25,979 --> 00:17:28,247
я встречаюсь с экспертом по этике,

338
00:17:28,248 --> 00:17:32,918
нейронаукам и искусственному интеллекту,
Джулией Боссман.

339
00:17:32,919 --> 00:17:35,521
Она директор по стратегии
в Fathom Computing,

340
00:17:35,522 --> 00:17:37,990
член совета
на Всемирном экономическом форуме,

341
00:17:37,991 --> 00:17:41,393
выпускница Университета Сингулярности
Рэя Курцвейла

342
00:17:41,394 --> 00:17:44,063
и бывший президент Foresight Institute –
исследовательского центра,

343
00:17:44,064 --> 00:17:51,970
специализирующегося на будущих
технологиях и их значении для нас.

344
00:17:51,971 --> 00:17:54,239
– Спасибо, что уделили мне время.
– Без проблем.

345
00:17:54,240 --> 00:17:56,975
Вы именно тот человек,
которому нужно задавать эти вопросы.

346
00:17:56,976 --> 00:17:58,410
Это глубокие вопросы.

347
00:17:58,411 --> 00:18:01,814
Думаю, что они очень важны
и становятся все актуальнее.

348
00:18:01,815 --> 00:18:04,817
Думаю, мы живем в очень интересное время,

349
00:18:04,818 --> 00:18:06,985
потому что разум и машины работают вместе.

350
00:18:06,986 --> 00:18:08,787
ДЖУЛИЯ БОССМАН
СОВЕТНИК ПО МИРОВОМУ БУДУЩЕМУ – ВЭФ

351
00:18:08,788 --> 00:18:13,192
Если говорить
об изучении деятельности мозга,

352
00:18:13,193 --> 00:18:15,627
где здесь моральная граница?

353
00:18:15,628 --> 00:18:18,497
Насколько конфиденциальными
должны быть мои мысли?

354
00:18:18,498 --> 00:18:23,769
Как и с любой мощной технологией,
все зависит от того, в чьих она руках.

355
00:18:23,770 --> 00:18:25,070
Все новые технологии

356
00:18:25,071 --> 00:18:29,608
могут сделать своего обладателя сильнее.

357
00:18:29,609 --> 00:18:32,711
Нужно не обвинять технологию, а смотреть,

358
00:18:32,712 --> 00:18:36,181
как и кто ее использует.

359
00:18:36,182 --> 00:18:40,519
А как убедиться,
что технология в нужных руках?

360
00:18:40,520 --> 00:18:42,921
Думаю, очень важно вовлекать людей,

361
00:18:42,922 --> 00:18:49,395
которые вершат политику и законы,
чтобы они понимали, что будет в будущем.

362
00:18:49,396 --> 00:18:52,631
Я надеюсь на сотрудничество.

363
00:18:52,632 --> 00:18:54,667
Давайте поговорим о хорошем.

364
00:18:54,668 --> 00:18:57,069
Как ее можно применять?

365
00:18:57,070 --> 00:19:00,673
Можем вспомнить
о покойном Стивене Хокинге.

366
00:19:00,674 --> 00:19:05,010
Если бы у него была возможность
более широко взаимодействовать

367
00:19:05,011 --> 00:19:06,378
с миром или компьютерами,

368
00:19:06,379 --> 00:19:09,348
невозможно представить,
чем бы он с нами поделился.

369
00:19:09,349 --> 00:19:11,350
Люди с синдромом псевдокомы, да?

370
00:19:11,351 --> 00:19:14,920
Они тут. Они знают, что они тут.

371
00:19:14,921 --> 00:19:17,156
Нам нужно как-то залезть в их разум

372
00:19:17,157 --> 00:19:19,158
и увидеть, что они пытаются сказать.

373
00:19:19,159 --> 00:19:21,527
– Или что они ощущают.
– Именно.

374
00:19:21,528 --> 00:19:27,132
Так что вы говорите людям,
которые боятся технологий

375
00:19:27,133 --> 00:19:33,172
и того, что передаем себя, свою
природную сущность, во власть технологии?

376
00:19:33,173 --> 00:19:38,344
Есть что-то заманчивое в том, чтобы
перейти на новый уровень процесса,

377
00:19:38,345 --> 00:19:41,380
который некоторые люди
называют человеческой эволюцией

378
00:19:41,381 --> 00:19:43,816
или развитием цивилизации, и так далее.

379
00:19:43,817 --> 00:19:47,152
В некотором роде мы уже
отдалились от природы, так?

380
00:19:47,153 --> 00:19:52,658
Ведь иначе большинство из нас
умирали бы в возрасте 30 или 40 лет.

381
00:19:52,659 --> 00:19:55,861
Были бы всевозможные болезни.
Мы бы не носили одежду.

382
00:19:55,862 --> 00:19:57,863
У нас бы не было очков и контактных линз.

383
00:19:57,864 --> 00:19:58,831
Именно.

384
00:19:58,832 --> 00:20:00,933
У нас не было бы антибиотиков.

385
00:20:00,934 --> 00:20:04,636
Если сравнить нас с теми,
кто жил 10 000 лет назад,

386
00:20:04,637 --> 00:20:09,875
то мы уже похожи
на футуристических киборгов,

387
00:20:09,876 --> 00:20:12,878
хотя генетически
мы практически не отличаемся.

388
00:20:12,879 --> 00:20:18,517
Да, верно.

389
00:20:18,518 --> 00:20:20,753
Чтобы изучать мыслительный процесс,

390
00:20:20,754 --> 00:20:23,956
сейчас нам приходится
либо спрашивать людей,

391
00:20:23,957 --> 00:20:27,726
о чем они думают,
либо наблюдать за их поведением.

392
00:20:27,727 --> 00:20:31,530
Но непосредственное чтение мыслей
будет намного лучше.

393
00:20:31,531 --> 00:20:34,400
Вот так доктор Кюл изучает память.

394
00:20:34,401 --> 00:20:39,071
А так доктор Камитани изучает сон.

395
00:20:39,072 --> 00:20:41,340
Хотя технологиям ещё долго развиваться,

396
00:20:41,341 --> 00:20:44,009
уже сейчас очевидно,
что некоторые этические вопросы

397
00:20:44,010 --> 00:20:45,978
могут перерасти в серьезные проблемы.

398
00:20:45,979 --> 00:20:47,212
Вот в чем дело.

399
00:20:47,213 --> 00:20:53,052
Не существует такого явления,
как абсолютно естественный человек.

400
00:20:53,053 --> 00:20:56,989
Мы развиваемся вместе с технологиями.

401
00:20:56,990 --> 00:21:00,793
Сейчас люди и технологии неразделимы.

402
00:21:00,794 --> 00:21:04,630
Да, с любыми новинками нужно
быть предельно аккуратными.

403
00:21:04,631 --> 00:21:09,234
Но они будут появляться,
и этот факт не изменить.

404
00:21:09,235 --> 00:21:12,738
Мы возвращаемся к этому снова и снова.

405
00:21:12,739 --> 00:21:15,274
Можно вечно сидеть на месте и обсуждать,

406
00:21:15,275 --> 00:21:18,210
нужно ли нам ограничить скорость развития

407
00:21:18,211 --> 00:21:20,979
и кому дать право это решать.

408
00:21:20,980 --> 00:21:22,348
Но мы так не делаем.

409
00:21:22,349 --> 00:21:25,851
Наоборот, мы пошли вперед
и изобрели машины.

410
00:21:25,852 --> 00:21:30,089
И при этом со всей ответственностью
выяснили множество деталей.

411
00:21:30,090 --> 00:21:32,591
Этические вопросы о новых технологиях

412
00:21:32,592 --> 00:21:37,196
приносят больше всего пользы,
когда они способствуют развитию,

413
00:21:37,197 --> 00:21:40,699
а не препятствуют прогрессу.

414
00:21:40,700 --> 00:21:42,668
Так что следуйте за своими снами.

415
00:21:42,669 --> 00:21:46,005
И, как только сможете, покажите их мне.

416
00:21:46,006 --> 00:21:48,408
Как всегда,
спасибо вам, что были с нами.

