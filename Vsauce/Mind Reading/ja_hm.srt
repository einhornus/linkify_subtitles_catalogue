1
00:00:05,271 --> 00:00:06,872
読心術？

2
00:00:06,873 --> 00:00:10,943
無理だ　読書は好きだけど

3
00:00:10,944 --> 00:00:15,247
読心術はエセ科学のように思えます

4
00:00:15,248 --> 00:00:17,983
言葉は悪いがイカサマだ

5
00:00:17,984 --> 00:00:23,555
しかし科学的な思考の識別は
現実となっています

6
00:00:23,556 --> 00:00:26,658
神経画像と機械学習が基盤です

7
00:00:26,659 --> 00:00:33,265
面白いことに 読心術の実験は
人の心をのぞき見るだけではない

8
00:00:33,266 --> 00:00:37,436
思考の成り立ちにまで踏み込みます

9
00:00:37,437 --> 00:00:42,875
つまり何かを考える時
頭の中はどうなっているのか

10
00:00:42,876 --> 00:00:44,376
解像度は？

11
00:00:44,377 --> 00:00:49,014
記憶の忠実度は高い？
どのように書き換えを？

12
00:00:49,015 --> 00:00:54,620
読心術はこうした疑問の解消に
役立つでしょうか？

13
00:00:54,621 --> 00:00:56,021
まず訪れたのは…

14
00:00:56,022 --> 00:01:01,060
オレゴン大学の
ブライス･キュール博士です

15
00:01:01,061 --> 00:01:23,248
神経画像と機械学習を用いて
思考の解読を研究する神経科学者です

16
00:01:23,249 --> 00:01:27,986
[読心術]

17
00:01:27,987 --> 00:01:30,589
[オレゴン大学]

18
00:01:30,590 --> 00:01:33,425
研究について教えてください

19
00:01:33,426 --> 00:01:38,030
認知神経科学が専門でテーマは人間の記憶

20
00:01:38,031 --> 00:01:45,504
私の研究室では主に
fMRIという機能的磁気共鳴画像を用います

21
00:01:45,505 --> 00:01:49,308
どうやって記憶を調べるのですか？

22
00:01:49,309 --> 00:01:51,243
神経作用のパターンを見ます

23
00:01:51,244 --> 00:01:56,415
記憶を形成する時に現れるパターンを記録

24
00:01:56,416 --> 00:02:02,254
後から思い出す時に
同じ状態が再現されるのかを調べます

25
00:02:02,255 --> 00:02:06,158
脳の活動のパターンを見れば―

26
00:02:06,159 --> 00:02:10,863
記憶や思考まで推測できるということ？

27
00:02:10,864 --> 00:02:13,666
それを「解読」と呼んでいます

28
00:02:13,667 --> 00:02:18,971
記憶する時の活動パターンを
インプット･パターンと呼び―

29
00:02:18,972 --> 00:02:23,509
記憶を推測する材料にしています

30
00:02:23,510 --> 00:02:26,311
読心術のようですね

31
00:02:26,312 --> 00:02:28,747
確かに そう聞こえる

32
00:02:28,748 --> 00:02:32,418
今日は私に何をするつもりですか？

33
00:02:32,419 --> 00:02:35,921
我々も初めて試みる実験です

34
00:02:35,922 --> 00:02:41,860
新種の実験なので
成功するかどうか分からない

35
00:02:41,861 --> 00:02:46,331
我々の研究の方向性は見えるはずです

36
00:02:46,332 --> 00:02:50,102
顔認識の実験に参加してもらいます

37
00:02:50,103 --> 00:02:54,006
12人の有名人の写真を使います

38
00:02:54,007 --> 00:02:56,442
- よく知ってる人？
- そうです

39
00:02:56,443 --> 00:02:58,844
彼らの顔を覚えてから―

40
00:02:58,845 --> 00:03:03,949
MRIに入り その顔を思い出してもらいます

41
00:03:03,950 --> 00:03:08,220
その時にあなたの脳の活動を記録し―

42
00:03:08,221 --> 00:03:12,257
あなたの記憶から絵を描きます

43
00:03:12,258 --> 00:03:13,959
- 絵？
- そうです

44
00:03:13,960 --> 00:03:17,896
印刷して壁に飾れるような絵？

45
00:03:17,897 --> 00:03:20,399
お望みなら

46
00:03:20,400 --> 00:03:25,204
まず私が 有名人12名の写真を記憶します

47
00:03:25,205 --> 00:03:28,574
その後ブライスが 私の思考を検出

48
00:03:28,575 --> 00:03:31,844
院生のマックスが付き添いです

49
00:03:31,845 --> 00:03:37,816
推測の成否は
fMRIの中で私が鮮明に顔を―

50
00:03:37,817 --> 00:03:42,488
思い出せるかどうかに懸かっています

51
00:03:42,489 --> 00:03:45,591
いいでしょう

52
00:03:45,592 --> 00:03:50,963
全員の顔をしっかり覚えられたと思います

53
00:03:50,964 --> 00:03:53,666
- よかった
- 緊張するね

54
00:03:53,667 --> 00:03:58,137
顔を覚えたところで次のステップです

55
00:03:58,138 --> 00:04:01,340
金属探知機を通ってfMRIへ

56
00:04:01,341 --> 00:04:04,076
私の脳の活動を記録し―

57
00:04:04,077 --> 00:04:07,846
博士のアルゴリズムで顔を再現します

58
00:04:07,847 --> 00:04:12,084
長期記憶から再現する実験は初めてです

59
00:04:12,085 --> 00:04:16,855
１時間前に覚えた記憶が頼りなので―

60
00:04:16,856 --> 00:04:19,090
とても難しい実験です

61
00:04:19,091 --> 00:04:20,993
あの目がいいね

62
00:04:20,994 --> 00:04:24,263
子供がMRIを怖がらないように

63
00:04:24,264 --> 00:04:26,965
口に入るみたいだ

64
00:04:26,966 --> 00:04:31,170
[実験]
[記憶の再現]

65
00:04:31,171 --> 00:04:37,009
fMRIは数千もの立方体に分けて
脳の活動をモニタリングします

66
00:04:37,010 --> 00:04:40,012
この「ボクセル」の１つには―

67
00:04:40,013 --> 00:04:43,816
無数の神経細胞が含まれます

68
00:04:43,817 --> 00:04:47,720
fMRIでボクセル内の血流が検知され―

69
00:04:47,721 --> 00:04:50,089
活動の有無が分かります

70
00:04:50,090 --> 00:04:53,025
ヒゲの写真を見せられたら

71
00:04:53,026 --> 00:04:56,362
脳は顔の特徴に反応します

72
00:04:56,363 --> 00:04:59,865
その時 常に反応する領域は―

73
00:04:59,866 --> 00:05:03,836
ヒゲを認識する領域かもしれません

74
00:05:03,837 --> 00:05:09,341
私が顔を想像する時に
その領域が活動していれば―

75
00:05:09,342 --> 00:05:13,846
ヒゲを考えていると推測できます

76
00:05:13,847 --> 00:05:18,250
マイケルが画面に現れる名前を見て―

77
00:05:18,251 --> 00:05:23,188
その顔をできるだけ忠実に思い出します

78
00:05:23,189 --> 00:05:28,827
２秒に１回の速さで脳の容積を取り込みます

79
00:05:28,828 --> 00:05:33,565
リアルタイムの更新です

80
00:05:33,566 --> 00:05:37,670
パート１が終わりパート２へ

81
00:05:37,671 --> 00:05:41,240
私の脳の活動を言語として把握し―

82
00:05:41,241 --> 00:05:44,743
解読に向けた準備をします

83
00:05:44,744 --> 00:05:46,378
マイケル　順調？

84
00:05:46,379 --> 00:05:48,180
ああ

85
00:05:48,181 --> 00:05:50,749
何百枚もの顔写真を見せ―

86
00:05:50,750 --> 00:05:55,054
顔の特徴に対する脳の反応を記録します

87
00:05:55,055 --> 00:05:59,358
私がパート１で考えた有名人の顔を―

88
00:05:59,359 --> 00:06:03,295
再現する際に必要な情報です

89
00:06:03,296 --> 00:06:06,065
情報量を増やしたいので―

90
00:06:06,066 --> 00:06:09,702
できる限り長く続けてもらいます

91
00:06:09,703 --> 00:06:13,305
fMRIにいられるのは最大２時間

92
00:06:13,306 --> 00:06:17,943
400以上の顔を見られたから十分でしょう

93
00:06:17,944 --> 00:06:21,013
いい結果が期待できます

94
00:06:21,014 --> 00:06:23,782
もう出てきていいよ

95
00:06:23,783 --> 00:06:28,921
了解

96
00:06:28,922 --> 00:06:31,557
たくさんの顔を見た

97
00:06:31,558 --> 00:06:33,025
やれやれ

98
00:06:33,026 --> 00:06:37,696
MRIにいた時のあなたの脳の画像です

99
00:06:37,697 --> 00:06:42,568
高速処理してからマックスが分析します

100
00:06:42,569 --> 00:06:45,104
また明日 来てください

101
00:06:45,105 --> 00:06:49,742
収集したデータから顔の画像を再現します

102
00:06:49,743 --> 00:06:51,243
では また明日

103
00:06:51,244 --> 00:06:52,411
ありがとう

104
00:06:52,412 --> 00:06:54,646
楽しみだよ

105
00:06:54,647 --> 00:07:01,487
徹夜だね　完璧にしてほしい

106
00:07:01,488 --> 00:07:04,223
[オレゴン大学]

107
00:07:04,224 --> 00:07:06,692
再び博士の研究室です

108
00:07:06,693 --> 00:07:10,896
徹夜の作業の結果が待ち遠しい

109
00:07:10,897 --> 00:07:15,801
心は読めたのでしょうか

110
00:07:15,802 --> 00:07:17,670
どうでした？

111
00:07:17,671 --> 00:07:20,606
よさそうだ　一緒に見よう

112
00:07:20,607 --> 00:07:23,175
楽しみだ　座っていい？

113
00:07:23,176 --> 00:07:24,777
- もちろん
- どうも

114
00:07:24,778 --> 00:07:28,914
最初は何の画像を見るんですか？

115
00:07:28,915 --> 00:07:33,052
- 下が私が覚えた顔写真ですね
- そうです

116
00:07:33,053 --> 00:07:37,990
上は私の記憶から再現した画像ですか

117
00:07:37,991 --> 00:07:40,659
- そのとおり
- すごいね

118
00:07:40,660 --> 00:07:44,496
これは再現された画像の１つ

119
00:07:44,497 --> 00:07:45,998
面白い

120
00:07:45,999 --> 00:07:48,000
ジョン･チョーです

121
00:07:48,001 --> 00:07:50,402
なかなかの出来栄えだ

122
00:07:50,403 --> 00:07:51,737
並べて見せて

123
00:07:51,738 --> 00:07:53,872
はい

124
00:07:53,873 --> 00:07:59,511
全体的に表情が似ていると思います

125
00:07:59,512 --> 00:08:02,314
前髪のラインは一致してる

126
00:08:02,315 --> 00:08:06,819
顔の輪郭は両方とも四角だと思います

127
00:08:06,820 --> 00:08:08,887
- ええ
- それが僕の印象だ

128
00:08:08,888 --> 00:08:12,758
彼の顔を視覚化しようとした時―

129
00:08:12,759 --> 00:08:16,495
四角い輪郭が一番大きな特徴だった

130
00:08:16,496 --> 00:08:20,132
四角い人だと考え続けてた

131
00:08:20,133 --> 00:08:23,202
すばらしい

132
00:08:23,203 --> 00:08:28,507
ミーガン･フォックス

133
00:08:28,508 --> 00:08:31,443
- 並べて見せて
- 比較だ

134
00:08:31,444 --> 00:08:36,682
右が実際に見た写真で左が再現した画像

135
00:08:36,683 --> 00:08:42,021
彼女の顔は鮮明に思い出せなかったんです

136
00:08:42,022 --> 00:08:46,959
なぜか思い出すのに苦労してしまいました

137
00:08:46,960 --> 00:08:50,929
印象に残っていたのは表情の険しさです

138
00:08:50,930 --> 00:08:54,099
これは女性の顔に見えるし―

139
00:08:54,100 --> 00:08:58,737
険しさが加味されてる点で一致してる

140
00:08:58,738 --> 00:09:02,441
私の記憶から画像を作成しましたが―

141
00:09:02,442 --> 00:09:08,647
脳は写真並みの精度で
細部まで描いているのでしょうか？

142
00:09:08,648 --> 00:09:11,116
それとも一部だけ？

143
00:09:11,117 --> 00:09:16,121
思考が読めれば
記憶の詳細も分かるかもしれない

144
00:09:16,122 --> 00:09:18,957
私だ　私の顔だよ

145
00:09:18,958 --> 00:09:25,431
私が思う自分のイメージを
再現した画像だね

146
00:09:25,432 --> 00:09:27,466
そのとおり

147
00:09:27,467 --> 00:09:29,435
ヒゲはどこ？

148
00:09:29,436 --> 00:09:32,037
僕が聞きたいよ

149
00:09:32,038 --> 00:09:36,475
左が私の記憶から再現した画像です

150
00:09:36,476 --> 00:09:41,547
全然 似てないのは
私の能力の問題かもしれない

151
00:09:41,548 --> 00:09:45,684
自分の顔を見ることは少ないから―

152
00:09:45,685 --> 00:09:51,623
記憶力と心の自画像の欠陥が
不思議な結果を招いたかも

153
00:09:51,624 --> 00:09:54,626
ジェニファー･ローレンスだ

154
00:09:54,627 --> 00:09:56,061
これが？

155
00:09:56,062 --> 00:10:01,800
彼女のおじさんと間違えてない？

156
00:10:01,801 --> 00:10:05,337
驚くほど似ているものはないが―

157
00:10:05,338 --> 00:10:09,041
初実験としてはかなりの成果です

158
00:10:09,042 --> 00:10:12,711
長期記憶だからね

159
00:10:12,712 --> 00:10:17,850
私がfMRIで見る画像の数を増やせば―

160
00:10:17,851 --> 00:10:20,519
改善の余地はありそうです

161
00:10:20,520 --> 00:10:25,057
私の脳の「言語」を
もっと把握できるからです

162
00:10:25,058 --> 00:10:29,061
私の記憶の質にも問題があります

163
00:10:29,062 --> 00:10:33,265
見ながら再現する場合はどうか

164
00:10:33,266 --> 00:10:39,138
実際に顔写真を見ている時の
脳の活動を解読すると―

165
00:10:39,139 --> 00:10:45,077
再現した画像の出来栄えは
はるかによくなります

166
00:10:45,078 --> 00:10:47,446
これは何の画像？

167
00:10:47,447 --> 00:10:50,249
上の列にある画像は―

168
00:10:50,250 --> 00:10:53,919
MRI内で実際に見た画像です

169
00:10:53,920 --> 00:10:57,990
下は収集した脳の活動パターンから―

170
00:10:57,991 --> 00:11:01,060
我々が抽出した画像です

171
00:11:01,061 --> 00:11:06,065
- 上が元の画像で下が脳内の画像
- そうだ

172
00:11:06,066 --> 00:11:07,733
かなり似ています

173
00:11:07,734 --> 00:11:10,069
全体的に合致してる

174
00:11:10,070 --> 00:11:14,239
若干の違いがあり完璧とは言えません

175
00:11:14,240 --> 00:11:18,911
ですが写真を見ている時の脳から
再現した顔は―

176
00:11:18,912 --> 00:11:22,348
本物とかなり共通性が見られる

177
00:11:22,349 --> 00:11:27,786
これはプログラムの動作確認になりました

178
00:11:27,787 --> 00:11:29,221
なるほど

179
00:11:29,222 --> 00:11:31,590
すばらしい

180
00:11:31,591 --> 00:11:35,260
参加させてくれてありがとう

181
00:11:35,261 --> 00:11:36,929
役立つといいね

182
00:11:36,930 --> 00:11:43,836
とても有益な実験になりました

183
00:11:43,837 --> 00:11:47,873
[日本　京都]

184
00:11:47,874 --> 00:11:54,279
研究からコンピュータで
人の心を読めることが分かりました

185
00:11:54,280 --> 00:11:56,982
思考を解読するカギです

186
00:11:56,983 --> 00:12:02,054
だが例えば今 私が考えていることを
知りたければ―

187
00:12:02,055 --> 00:12:05,624
私に聞くほうが簡単です

188
00:12:05,625 --> 00:12:08,260
でも私が話せなかったら？

189
00:12:08,261 --> 00:12:13,265
神谷之康教授は眠りの壁に挑む研究者で―

190
00:12:13,266 --> 00:12:18,203
この分野の最先端領域を探求しています

191
00:12:18,204 --> 00:12:22,841
京都大学の研究室を訪ねて話を聞きましょう

192
00:12:22,842 --> 00:12:29,581
人の考えではなく夢をのぞくのです

193
00:12:29,582 --> 00:12:31,650
神谷先生　マイケルです

194
00:12:31,651 --> 00:12:32,785
ユキです

195
00:12:32,786 --> 00:12:34,887
- よろしく
- こちらこそ

196
00:12:34,888 --> 00:12:40,292
神谷博士はこの10年
機械読心の最先端にいます

197
00:12:40,293 --> 00:12:44,363
これから被験者が中に入ります

198
00:12:44,364 --> 00:12:47,299
当初は彼もfMRIを使って

199
00:12:47,300 --> 00:12:52,705
脳の活動から画像を再現する
実験をしていました

200
00:12:52,706 --> 00:12:55,774
彼の画像は白黒ですが―

201
00:12:55,775 --> 00:12:59,578
驚くほど精巧に再現されます

202
00:12:59,579 --> 00:13:04,216
最近は神経回路網と機械学習を駆使して―

203
00:13:04,217 --> 00:13:09,955
より複雑な写真を見た時の
解読を試みています

204
00:13:09,956 --> 00:13:13,692
こちらは 写真を見た時の脳の活動を―

205
00:13:13,693 --> 00:13:18,097
神経回路網で処理した結果です

206
00:13:18,098 --> 00:13:26,872
犯罪捜査や対人コミュニケーション
などへの応用が期待されます

207
00:13:26,873 --> 00:13:30,642
完璧とは言えませんが―

208
00:13:30,643 --> 00:13:33,712
目は判別できますよね

209
00:13:33,713 --> 00:13:35,347
- ええ
- 耳も

210
00:13:35,348 --> 00:13:37,049
色もです

211
00:13:37,050 --> 00:13:39,885
ある程度はね

212
00:13:39,886 --> 00:13:43,088
しかし直近の研究対象は無意識

213
00:13:43,089 --> 00:13:47,559
大胆にも夢を記録しようと試みています

214
00:13:47,560 --> 00:13:52,498
あなたは睡眠の研究者？
ビジョンの研究者？

215
00:13:52,499 --> 00:13:55,901
- 脳解読者かな
- 脳解読者？

216
00:13:55,902 --> 00:13:58,237
カッコいいですね

217
00:13:58,238 --> 00:14:02,307
夢の研究について説明してください

218
00:14:02,308 --> 00:14:03,909
分かりました

219
00:14:03,910 --> 00:14:08,647
脳波とMRI画像を同時に記録します

220
00:14:08,648 --> 00:14:13,452
夢の解読の導入部分は
キュール博士と同じ

221
00:14:13,453 --> 00:14:17,389
fMRIの中で被験者に画像を見せ

222
00:14:17,390 --> 00:14:22,227
思考中の脳の様子を把握します

223
00:14:22,228 --> 00:14:27,366
機械学習アルゴリズムの
画像認識の準備を整え

224
00:14:27,367 --> 00:14:33,939
被験者は脳波計用帽子をかぶり
fMRI内で眠ります

225
00:14:33,940 --> 00:14:37,109
夢を見ている脳波が検知されたら―

226
00:14:37,110 --> 00:14:42,247
アルゴリズムが夢の内容を
おおまかに推測します

227
00:14:42,248 --> 00:14:45,884
現段階のアルゴリズムでは―

228
00:14:45,885 --> 00:14:51,423
建物 交通手段 文字など
20のカテゴリがあります

229
00:14:51,424 --> 00:14:55,794
目覚めた被験者に夢の内容を確認

230
00:14:55,795 --> 00:15:00,332
アルゴリズムの推測と一致するか確かめます

231
00:15:00,333 --> 00:15:03,769
実際に行った実験のデータです

232
00:15:03,770 --> 00:15:06,305
下にあるのはカテゴリ名

233
00:15:06,306 --> 00:15:11,076
該当する可能性が高いカテゴリ名が―

234
00:15:11,077 --> 00:15:13,712
リアルタイムで大きくなります

235
00:15:13,713 --> 00:15:18,951
ご覧のとおり
今 最も強力なのは「文字」

236
00:15:18,952 --> 00:15:23,489
この時点で
目覚めさせた被験者の口述は―

237
00:15:23,490 --> 00:15:30,929
「夢で見たのは文字で
エッセイのようなものでした」

238
00:15:30,930 --> 00:15:32,965
薄気味悪い

239
00:15:32,966 --> 00:15:37,236
夢をのぞき見してるんだから

240
00:15:37,237 --> 00:15:40,005
ある意味 そうだが…

241
00:15:40,006 --> 00:15:42,074
それほど正確じゃない

242
00:15:42,075 --> 00:15:44,677
正確性は低いといっても―

243
00:15:44,678 --> 00:15:48,847
普通なら人の夢は想像もつかない

244
00:15:48,848 --> 00:15:52,651
彼は夢を推測する研究を続ける一方で―

245
00:15:52,652 --> 00:15:55,487
新プロジェクトも始めています

246
00:15:55,488 --> 00:15:59,124
夢から画像を再現する試みです

247
00:15:59,125 --> 00:16:06,165
これがあなたの研究室で
夢を再生した画像ですか？

248
00:16:06,166 --> 00:16:08,667
まだ開発途上です

249
00:16:08,668 --> 00:16:11,470
ある傾向があります

250
00:16:11,471 --> 00:16:13,972
この解読機では―

251
00:16:13,973 --> 00:16:18,344
再生画像は中央にぼんやり固まっています

252
00:16:18,345 --> 00:16:20,779
シミみたいですね

253
00:16:20,780 --> 00:16:22,014
ええ

254
00:16:22,015 --> 00:16:25,150
でも非常にありがたい

255
00:16:25,151 --> 00:16:28,520
この画面に見えるものは―

256
00:16:28,521 --> 00:16:34,693
初めて夢を捉えた画像と言えますね

257
00:16:34,694 --> 00:16:38,364
革新的研究の初期段階です

258
00:16:38,365 --> 00:16:43,669
いつか夢を画像や
動画にできるかもしれません

259
00:16:43,670 --> 00:16:47,373
現在 この種の研究者は神谷博士だけ

260
00:16:47,374 --> 00:16:51,543
無意識を旅する孤独な探検者です

261
00:16:51,544 --> 00:16:54,780
この研究は発表前ですね

262
00:16:54,781 --> 00:16:56,048
まだです

263
00:16:56,049 --> 00:16:59,718
見られて感激だ

264
00:16:59,719 --> 00:17:02,788
[カリフォルニア州ロサンゼルス]

265
00:17:02,789 --> 00:17:07,026
キュール博士や神谷博士らの研究は―

266
00:17:07,027 --> 00:17:10,062
今後 実を結ぶかもしれません

267
00:17:10,063 --> 00:17:15,034
完全に心を読むのは非常に難しいことです

268
00:17:15,035 --> 00:17:19,704
とはいえ 技術によって自分が知る以上に―

269
00:17:19,705 --> 00:17:24,543
我々を知られることは望ましいでしょうか？

270
00:17:24,544 --> 00:17:27,279
その疑問に取り組むため―

271
00:17:27,280 --> 00:17:32,851
倫理学と神経科学と人工知能の専門家
ジュリア･ボスマンに会います

272
00:17:32,852 --> 00:17:37,956
Fathom Computing社の戦略部長
世界経済フォーラムの理事で

273
00:17:37,957 --> 00:17:41,226
シンギュラリティ大学卒業生

274
00:17:41,227 --> 00:17:45,064
次世代技術とその影響を研究する―

275
00:17:45,065 --> 00:17:51,537
シンクタンクの会長も務めました

276
00:17:51,538 --> 00:17:53,539
ご多忙中 申し訳ない

277
00:17:53,540 --> 00:17:54,707
とんでもない

278
00:17:54,708 --> 00:17:57,209
お話を聞きたいんです

279
00:17:57,210 --> 00:18:01,814
厄介だが今後さらに重要性を増す問題です

280
00:18:01,815 --> 00:18:04,883
我々は面白い時代に生きてます

281
00:18:04,884 --> 00:18:08,587
脳と機械が近づいてきているのです

282
00:18:08,588 --> 00:18:13,158
脳の活動を見られるようになると―

283
00:18:13,159 --> 00:18:18,530
思考のプライバシーにおける
倫理上の境界線は？

284
00:18:18,531 --> 00:18:23,669
どんなに強力な技術も
それを操る人次第です

285
00:18:23,670 --> 00:18:29,341
新しい技術を使う人間が
力を得ることになります

286
00:18:29,342 --> 00:18:32,644
だから技術を責めるのではなく―

287
00:18:32,645 --> 00:18:36,148
使い方と誰が使うかを考えるべきです

288
00:18:36,149 --> 00:18:40,386
正しく使われているか確かめる方法は？

289
00:18:40,387 --> 00:18:46,291
政策と法律の担当者と関わり
将来の動きについて―

290
00:18:46,292 --> 00:18:49,328
理解することが重要です

291
00:18:49,329 --> 00:18:52,631
協力が成果を生むはずです

292
00:18:52,632 --> 00:18:56,902
ここではどういった研究を？

293
00:18:56,903 --> 00:19:00,606
例えば今は亡きホーキング博士

294
00:19:00,607 --> 00:19:06,412
彼が世界あるいはコンピュータと
もっと交信できたら―

295
00:19:06,413 --> 00:19:09,448
何を共有できたかなどです

296
00:19:09,449 --> 00:19:14,987
閉じ込め症候群患者は
アウトプットができないから―

297
00:19:14,988 --> 00:19:21,493
彼らの頭の中を知る手段が
必要だということですね

298
00:19:21,494 --> 00:19:27,299
自分の本性を
技術に明け渡してしまうことに―

299
00:19:27,300 --> 00:19:33,305
恐れを抱いている人に言いたいことは？

300
00:19:33,306 --> 00:19:39,778
人類の進化や文明の発展が次のレベルに進む

301
00:19:39,779 --> 00:19:43,916
これが魅力的であることは否めません

302
00:19:43,917 --> 00:19:47,019
人間はもう自然の状態にない

303
00:19:47,020 --> 00:19:52,624
原始時代なら人間の寿命は30～40歳でしょう

304
00:19:52,625 --> 00:19:56,195
病気にかかるし 衣類もなかった

305
00:19:56,196 --> 00:19:58,931
メガネやコンタクトレンズも

306
00:19:58,932 --> 00:20:00,933
抗生物質もない

307
00:20:00,934 --> 00:20:06,138
１万年前の人類からすれば今の私たちは―

308
00:20:06,139 --> 00:20:09,775
サイボーグみたいなものです

309
00:20:09,776 --> 00:20:12,811
遺伝子的には ほぼ同じなのに

310
00:20:12,812 --> 00:20:18,484
そうですね

311
00:20:18,485 --> 00:20:23,589
現時点では他人の考えを理解したければ―

312
00:20:23,590 --> 00:20:27,760
本人に聞くか行動を観察します

313
00:20:27,761 --> 00:20:31,397
でも直接 見るほうが便利です

314
00:20:31,398 --> 00:20:34,500
キュール博士が記憶を研究し―

315
00:20:34,501 --> 00:20:39,138
神谷博士が睡眠と夢を研究するゆえんです

316
00:20:39,139 --> 00:20:46,045
技術の進歩には時間を要しますが
倫理問題が生じるのは明らか

317
00:20:46,046 --> 00:20:47,713
忘れてはいけません

318
00:20:47,714 --> 00:20:53,052
完全に野生の人間はいないのです

319
00:20:53,053 --> 00:20:56,855
我々は技術と共に進化しています

320
00:20:56,856 --> 00:21:00,826
今や人間と技術は切り離せません

321
00:21:00,827 --> 00:21:04,630
新しいことは慎重にやるべきだが―

322
00:21:04,631 --> 00:21:09,268
起きる事実を変えることはできない

323
00:21:09,269 --> 00:21:12,805
何度も経験したことです

324
00:21:12,806 --> 00:21:18,344
速度制限を設けるか否か
誰がその施行権限を持つか―

325
00:21:18,345 --> 00:21:21,080
議論を続けることもできた

326
00:21:21,081 --> 00:21:25,918
だが私たちは先に進み車を発明しました

327
00:21:25,919 --> 00:21:30,055
進みながら詳細を定めていった

328
00:21:30,056 --> 00:21:37,129
新技術の倫理的議論は
その技術を促すなら非常に有益です

329
00:21:37,130 --> 00:21:40,733
むやみに進化を阻むのはよくない

330
00:21:40,734 --> 00:21:42,701
夢を追いかけよう

331
00:21:42,702 --> 00:21:45,971
なるべく早く 見せてほしい

332
00:21:45,972 --> 00:21:48,675
今回もご視聴ありがとう

