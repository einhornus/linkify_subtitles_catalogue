1
00:00:07,773 --> 00:00:08,740
Oh Hallo.

2
00:00:08,741 --> 00:00:11,709
Technologie verandert niet alleen
ons leven.

3
00:00:11,710 --> 00:00:14,446
Het verandert onze hersenen.

4
00:00:14,447 --> 00:00:15,713
Niet alleen hoe ze denken,

5
00:00:15,714 --> 00:00:17,515
maar ook hoe ze eruitzien.

6
00:00:17,516 --> 00:00:21,086
Het is aangetoond dat het urenlang spelen van
bepaalde videogames

7
00:00:21,087 --> 00:00:23,254
je geheugen
voor details kan verbeteren,

8
00:00:23,255 --> 00:00:25,356
je vermogen
om door de ruimte

9
00:00:25,357 --> 00:00:26,624
in videogames te navigeren

10
00:00:26,625 --> 00:00:28,426
en je hersenen -

11
00:00:28,427 --> 00:00:31,262
nou ja, bepaalde
delen ervan - groter kan maken.

12
00:00:31,263 --> 00:00:34,165
Maar wetenschappers willen weten
of het verkennen van digitale werelden

13
00:00:34,166 --> 00:00:37,335
onze hersenen kan veranderen
op manieren die ons vermogen

14
00:00:37,336 --> 00:00:39,637
om door de echte wereld te navigeren, verbeteren.

15
00:00:39,638 --> 00:00:42,674
Om daar achter te komen,
hebben we een gigantisch doolhof gebouwd

16
00:00:42,675 --> 00:00:45,777
om hun theorieën
voor het eerst

17
00:00:45,778 --> 00:00:48,379
buiten de wereld van computers te testen.

18
00:00:48,380 --> 00:00:50,415
En mijn baan?

19
00:00:50,416 --> 00:00:58,289
Ik ben de laboratoriumrat.

20
00:00:58,290 --> 00:01:10,869
[themamuziek speelt]

21
00:01:10,870 --> 00:01:12,504
[vacuüm neuriën, stopt]

22
00:01:12,505 --> 00:01:15,373
Onze hersenen zijn
grondig getransformeerd

23
00:01:15,374 --> 00:01:17,542
door onze interacties
met technologie.

24
00:01:17,543 --> 00:01:19,911
Veel van de informatie
die ik vroeger

25
00:01:19,912 --> 00:01:23,281
in mijn hersenen moest opslaan,
is nu opgeslagen in mijn telefoon.

26
00:01:23,282 --> 00:01:25,383
Mijn contacten, mijn agenda.

27
00:01:25,384 --> 00:01:27,185
In veel opzichten heb ik

28
00:01:27,186 --> 00:01:29,354
wat vroeger
door dit orgel werd gedaan, gedelegeerd

29
00:01:29,355 --> 00:01:32,690
aan dit nieuwe externe orgel.

30
00:01:32,691 --> 00:01:34,726
Door dat te doen, komen
de hulpbronnen van de hersenen vrij

31
00:01:34,727 --> 00:01:36,327
voor andere dingen die ertoe doen

32
00:01:36,328 --> 00:01:38,897
of die technologie
nog niet helemaal voor ons kan doen.

33
00:01:38,898 --> 00:01:43,268
Dus hoewel we allemaal nog geen
implantaten in onze hersenen hebben, heeft

34
00:01:43,269 --> 00:01:46,504
technologie al
een weg naar ons hoofd gevonden,

35
00:01:46,505 --> 00:01:49,507
en daarom vind je het misschien
zeer verontrustend

36
00:01:49,508 --> 00:01:56,514
om mij zoiets als dit te zien doen
.

37
00:01:56,515 --> 00:01:57,515
Sh--

38
00:01:57,516 --> 00:02:01,352
[muziek speelt]

39
00:02:01,353 --> 00:02:03,888
[Michael]Studies tonen aan dat
we onze hersenen kunnen verbeteren

40
00:02:03,889 --> 00:02:05,857
door verrijkende
ervaringen te hebben,

41
00:02:05,858 --> 00:02:08,459
zelfs door videogames te spelen.

42
00:02:08,460 --> 00:02:10,361
Om hier meer over te leren,

43
00:02:10,362 --> 00:02:12,497
kwam ik naar het Stark Lab van UC Irvine
om met experts

44
00:02:12,498 --> 00:02:15,333
op het gebied van leren
en geheugen te spreken.

45
00:02:15,334 --> 00:02:17,202
Dus Dane en Craig,
jullie werken aan

46
00:02:17,203 --> 00:02:18,770
leren en geheugen.

47
00:02:18,771 --> 00:02:20,939
- Wat is er met hen?
- Dus het lab
probeert erachter te komen

48
00:02:20,940 --> 00:02:24,642
hoe het geheugen werkt,
hoe het werkt in de hersenen.

49
00:02:24,643 --> 00:02:26,945
En een hersenstructuur, in de
temporale kwab

50
00:02:26,946 --> 00:02:29,581
waarvan we weten dat die belangrijk is voor het
geheugen, is

51
00:02:29,582 --> 00:02:31,482
de hippocampus.

52
00:02:31,483 --> 00:02:33,985
Dus wat doet
de hippocampus?

53
00:02:33,986 --> 00:02:35,687
We weten dat het een rol speelt in het geheugen

54
00:02:35,688 --> 00:02:38,223
en, echt, een bepaald
soort geheugen.

55
00:02:38,224 --> 00:02:39,657
De hippocampus
is echt betrokken

56
00:02:39,658 --> 00:02:44,362
wanneer je snel
nieuwe willekeurige associaties moet vormen.

57
00:02:44,363 --> 00:02:46,331
Weet je, als je
je herinnert wat je gisteren hebt gedaan, heb je

58
00:02:46,332 --> 00:02:48,600
zeker
de hippocampus nodig.

59
00:02:48,601 --> 00:02:50,702
Misschien gaan we naar de winkel,
parkeren we onze auto op de parkeerplaats,

60
00:02:50,703 --> 00:02:52,437
en moeten we niet
alleen onthouden

61
00:02:52,438 --> 00:02:53,739
: "Ik heb
mijn auto op de parkeerplaats geparkeerd",

62
00:02:53,740 --> 00:02:57,675
"Ik heb mijn auto
precies op deze plek
op de parkeerplaats geparkeerd.  "

63
00:02:57,676 --> 00:02:59,611
- [Michael]Juist.
- [Craig]En die details,

64
00:02:59,612 --> 00:03:01,846
dat is waar de hippocampus
ons echt mee lijkt te

65
00:03:01,847 --> 00:03:02,947
helpen.

66
00:03:02,948 --> 00:03:04,983
En je blijft kijken
naar dit stuk gekauwde

67
00:03:04,984 --> 00:03:07,385
kauwgom op het boek,
is dat een hippocampus?

68
00:03:07,386 --> 00:03:09,787
[Craig] Ja.  Dit is
eigenlijk mijn hippocampus.

69
00:03:09,788 --> 00:03:12,657
Is dit het hele ding
of is het symmetrisch... Dat is het...

70
00:03:12,658 --> 00:03:13,925
Oh, er is er een
aan de andere kant.

71
00:03:13,926 --> 00:03:15,026
Dat ziet er net zo uit?

72
00:03:15,027 --> 00:03:16,227
Ja, spiegelbeeld ervan.

73
00:03:16,228 --> 00:03:18,396
[Michael]In 2015 voerden
Dr. Stark en Dr. Clemenson

74
00:03:18,397 --> 00:03:19,864
een onderzoek uit om te laten zien

75
00:03:19,865 --> 00:03:22,500
hoe videogames
de hersenen beïnvloeden.

76
00:03:22,501 --> 00:03:23,801
Ze verzamelden deelnemers

77
00:03:23,802 --> 00:03:25,536
die normaal geen
videogames speelden

78
00:03:25,537 --> 00:03:27,438
en verdeelden ze
in drie groepen.

79
00:03:27,439 --> 00:03:28,740
Een controlegroep die

80
00:03:28,741 --> 00:03:31,776
twee weken geen videogames speelde,
een actieve controlegroep

81
00:03:31,777 --> 00:03:34,312
die
twee weken tweedimensionale games speelde

82
00:03:34,313 --> 00:03:35,546
en een experimentele groep

83
00:03:35,547 --> 00:03:37,682
die twee weken 3D-games speelde
.

84
00:03:37,683 --> 00:03:39,617
Vooraf lieten ze alle


85
00:03:39,618 --> 00:03:42,287
deelnemers twee virtuele taken
op computers uitvoeren

86
00:03:42,288 --> 00:03:43,888
om
hun ruimtelijk geheugen te meten.

87
00:03:43,889 --> 00:03:46,524
Zodra ze terugkwamen,
hebben we
die twee taken opnieuw uitgevoerd.

88
00:03:46,525 --> 00:03:48,593
En wat we ontdekten was dat de
mensen die het 3D-spel speelden

89
00:03:48,594 --> 00:03:50,728
een verbetering zagen
in hun testscores,

90
00:03:50,729 --> 00:03:52,030
terwijl de controlegroep

91
00:03:52,031 --> 00:03:53,965
en de actieve controlegroep
dat niet deden.

92
00:03:53,966 --> 00:03:55,566
We hebben geen hersenscans gedaan,

93
00:03:55,567 --> 00:03:57,568
maar we kunnen speculeren
dat er veranderingen waren

94
00:03:57,569 --> 00:04:00,605
in de hippocampi van de experimentele groep
.

95
00:04:00,606 --> 00:04:03,908
Dus wat gaan we
hier met me doen?

96
00:04:03,909 --> 00:04:05,843
Dus we gaan alles doen
wat we eerder hebben gedaan

97
00:04:05,844 --> 00:04:07,011
in onze eerdere studies,

98
00:04:07,012 --> 00:04:08,646
behalve dat we
twee nieuwe dingen gaan toevoegen.

99
00:04:08,647 --> 00:04:11,449
Uh, de eerste is dat we
wat hersenscans gaan toevoegen,

100
00:04:11,450 --> 00:04:12,617
dus we gaan kijken
of we een verandering zien

101
00:04:12,618 --> 00:04:14,452
in de structurele kant
van je hippocampus.

102
00:04:14,453 --> 00:04:16,587
We hebben nooit echt
naar iemands hersenscans gekeken

103
00:04:16,588 --> 00:04:18,523
voor en na
het spelen van videogames.

104
00:04:18,524 --> 00:04:19,991
En het tweede dat
we gaan doen,

105
00:04:19,992 --> 00:04:22,460
is dat we je door
een echte wereld leiden.

106
00:04:22,461 --> 00:04:25,330
Je wordt de rat
in een doolhof.

107
00:04:25,331 --> 00:04:27,865
[Michael]
Dit werkelijk onbeproefde terrein.

108
00:04:27,866 --> 00:04:30,468
Het effect van videogames
op het ruimtelijk geheugen

109
00:04:30,469 --> 00:04:32,570
is nog nooit


110
00:04:32,571 --> 00:04:35,340
op zo'n grote
en uitgebreide schaal onderzocht in een fysieke omgeving.

111
00:04:35,341 --> 00:04:37,442
Ik zal me een weg moeten

112
00:04:37,443 --> 00:04:39,944
banen door een
fysiek doolhof van 3.600 vierkante meter.

113
00:04:39,945 --> 00:04:43,681
Zal het spelen van videogames
mijn mentale vaardigheden

114
00:04:43,682 --> 00:04:45,016
in de echte wereld verbeteren?

115
00:04:45,017 --> 00:04:47,352
Als dat zo is,
kan de samenleving

116
00:04:47,353 --> 00:04:49,454
op een geheel nieuwe manier naar gaming gaan kijken.

117
00:04:49,455 --> 00:04:51,456
Eerst moesten we

118
00:04:51,457 --> 00:04:53,791
nulmetingen
van mijn hersenen krijgen.

119
00:04:53,792 --> 00:04:55,393
Welkom bij het MRI-centrum.

120
00:04:55,394 --> 00:04:57,628
We gaan een hele
reeks scans van je maken,

121
00:04:57,629 --> 00:04:58,996
zoals de voor-scan

122
00:04:58,997 --> 00:05:01,366
om te zien wat
er met je hersenen gaat gebeuren

123
00:05:01,367 --> 00:05:02,834
als functie van het
daadwerkelijk gamen.

124
00:05:02,835 --> 00:05:04,769
Stoer.  Wat voor
dingen zoek je?

125
00:05:04,770 --> 00:05:06,938
Veranderingen in de grootte en vorm
van je hippocampus

126
00:05:06,939 --> 00:05:10,007
en ook veranderingen
in de connectiviteit
tussen hersengebieden.

127
00:05:10,008 --> 00:05:13,378
[Michael]Mijn hersenen werden gescand
met behulp van diffusie-MRI,

128
00:05:13,379 --> 00:05:14,645
met speciale nadruk

129
00:05:14,646 --> 00:05:17,648
op mijn allerbelangrijkste
hippocampus.

130
00:05:17,649 --> 00:05:18,916
[muziek speelt]

131
00:05:18,917 --> 00:05:20,385
[Craig]Dus deze eerste test

132
00:05:20,386 --> 00:05:22,153
is een standaard geheugentest
die we doen.

133
00:05:22,154 --> 00:05:24,522
Het wordt een
geheugentest voor objectherkenning genoemd.

134
00:05:24,523 --> 00:05:26,457
[Michael]
Deze test begon met het laten zien van

135
00:05:26,458 --> 00:05:28,993
een reeks willekeurige objecten.

136
00:05:28,994 --> 00:05:32,897
Ik deed mijn best
om ze allemaal in mijn geheugen op te nemen.

137
00:05:32,898 --> 00:05:33,931
Oké.

138
00:05:33,932 --> 00:05:35,566
- Afgerond.
- Oke.

139
00:05:35,567 --> 00:05:36,801
Wat we nu echter gaan doen,
is dat we

140
00:05:36,802 --> 00:05:39,771
je geheugen voor die objecten gaan testen.
- Oké.

141
00:05:39,772 --> 00:05:41,572
En dit is eigenlijk
waar het begint te profiteren

142
00:05:41,573 --> 00:05:43,541
van de hippocampus
waarvan we weten dat het zo belangrijk is

143
00:05:43,542 --> 00:05:44,943
voor zaken
als ruimtelijk geheugen.

144
00:05:44,944 --> 00:05:48,179
[Michael]Deze keer moest ik een
andere reeks objecten bekijken

145
00:05:48,180 --> 00:05:50,148
en
alle objecten identificeren die identiek waren

146
00:05:50,149 --> 00:05:51,983
aan degene die
ik eerder had gezien.

147
00:05:51,984 --> 00:05:55,119
De vangst, sommige
items leken erg

148
00:05:55,120 --> 00:05:56,187
op de eerdere,

149
00:05:56,188 --> 00:05:58,689
maar niet precies hetzelfde.

150
00:05:58,690 --> 00:06:00,525
Dit testte mijn geheugen
voor details

151
00:06:00,526 --> 00:06:02,093
en zeer kleine veranderingen.

152
00:06:02,094 --> 00:06:03,395
Oké.

153
00:06:03,396 --> 00:06:05,797
[Michael]Vervolgens een virtuele
versie van een waterdoolhof dat

154
00:06:05,798 --> 00:06:08,166
normaal gesproken door knaagdieren
en muizen wordt gebruikt.

155
00:06:08,167 --> 00:06:11,068
[Dane] Het idee is dat
je

156
00:06:11,069 --> 00:06:13,704
een verborgen platform
in een plas water probeert te vinden.

157
00:06:13,705 --> 00:06:14,672
[Michael] Oh, man,

158
00:06:14,673 --> 00:06:16,941
ik ben zo blij dat ik geen laboratoriumrat ben.

159
00:06:16,942 --> 00:06:19,811
Deze taak stelde mijn ruimtelijk
geheugen echt op de proef.

160
00:06:19,812 --> 00:06:22,847
Ik moest steeds opnieuw hetzelfde
onzichtbare

161
00:06:22,848 --> 00:06:24,615
onderwaterplatform vinden,

162
00:06:24,616 --> 00:06:27,552
waarbij ik alleen de vormen
van de bergen als mijn gids gebruikte,

163
00:06:27,553 --> 00:06:29,720
maar ik hoefde in ieder geval
niet nat te worden.

164
00:06:29,721 --> 00:06:31,055
Hoi.

165
00:06:31,056 --> 00:06:32,757
Dat was moeilijker
dan ik had verwacht.

166
00:06:32,758 --> 00:06:35,560
[Craig] Dit zijn het soort
taken dat we hebben kunnen doen

167
00:06:35,561 --> 00:06:37,094
omdat we ze
op een computer kunnen zetten.

168
00:06:37,095 --> 00:06:38,496
En we gaan ze opnieuw bekijken

169
00:06:38,497 --> 00:06:39,897
nadat je
de videogames hebt gedaan.

170
00:06:39,898 --> 00:06:43,134
Maar we hebben
hier nu ook een geweldige kans

171
00:06:43,135 --> 00:06:46,471
om te proberen het uit te schakelen door het
gewoon op de computer te doen

172
00:06:46,472 --> 00:06:48,473
en het daadwerkelijk
in de echte wereld te krijgen.

173
00:06:48,474 --> 00:06:49,740
Hebben jullie
dit al eerder gedaan?

174
00:06:49,741 --> 00:06:52,143
Nee. We mogen
dit soort dingen niet doen.

175
00:06:52,144 --> 00:06:54,879
- Nou, welkom
in hetMind Field.
- Geweldig.

176
00:06:54,880 --> 00:07:00,618
[muziek speelt]

177
00:07:00,619 --> 00:07:02,153
[Michael]
Dus dit is het?  Het is enorm.

178
00:07:02,154 --> 00:07:04,021
[Craig] Dit is waarvoor
we je hierheen hebben gebracht,

179
00:07:04,022 --> 00:07:06,858
voor een
echte geheugentest.

180
00:07:06,859 --> 00:07:09,727
Je wordt
een laboratoriumrat in een doolhof.

181
00:07:09,728 --> 00:07:11,028
Dit is dus een grote primeur voor ons.

182
00:07:11,029 --> 00:07:12,897
Het is een grote primeur
voor geheugenonderzoek.

183
00:07:12,898 --> 00:07:14,232
[Michael]
Dus hoe denk je dat
dat van invloed zal zijn op

184
00:07:14,233 --> 00:07:16,667
wat
jullie al hebben gezien,

185
00:07:16,668 --> 00:07:18,903
namelijk
dat bewegen
in een 3D-omgeving

186
00:07:18,904 --> 00:07:22,640
in een videogame je hersenen
fysiek kan
beïnvloeden?

187
00:07:22,641 --> 00:07:24,909
[Dane] We zouden verwachten dat
als we op de een of andere manier

188
00:07:24,910 --> 00:07:26,944
je hippocampus
kunnen trainen om beter te zijn
in ruimtelijk geheugen

189
00:07:26,945 --> 00:07:29,247
en ruimtelijke navigatie,
we verbeteringen zouden zien

190
00:07:29,248 --> 00:07:30,148
op sommige van deze gebieden.

191
00:07:30,149 --> 00:07:31,916
En het zal niet
alleen een doolhof zijn.

192
00:07:31,917 --> 00:07:34,552
Je hebt hier objecten
ingebed,

193
00:07:34,553 --> 00:07:37,622
en we gaan
je vermogen testen om te onthouden
waar alles is.

194
00:07:37,623 --> 00:07:41,559
Oh, en maak een mentale kaart
van wat daarbinnen is.

195
00:07:41,560 --> 00:07:42,693
[Craig]
Dus je hebt vijf minuten.

196
00:07:42,694 --> 00:07:44,262
Ga naar binnen, verken,
leer het doolhof

197
00:07:44,263 --> 00:07:45,563
en leer de objecten.

198
00:07:45,564 --> 00:07:48,065
Gaan.

199
00:07:48,066 --> 00:07:50,234
[Michael]Omdat de
muren 1,80 meter hoog waren, kon

200
00:07:50,235 --> 00:07:52,870
ik het niet
in vogelvlucht bekijken.

201
00:07:52,871 --> 00:07:55,706
Mijn taak was om
een ruimtelijk geheugen te creëren dat v

202
00:07:55,707 --> 00:07:59,110
lledig gebaseerd was op de hoeken en bo
hten van de witte muren die ik op

203
00:07:59,111 --> 00:08:00,578
ooghoogte kon zien, en ee

204
00:08:00,579 --> 00:08:02,747
 paar hoge bomen en li
htmasten buite

205
00:08:02,748 --> 00:08:04,916
 het doolh

206
00:08:04,917 --> 00:08:06,984
f.  Oké.  Dus ik heb me georiënteerd.

207
00:08:06,985 --> 00:08:08,252
De ingang is die kant op.

208
00:08:08,253 --> 00:08:10,254
Daar is een uitgang.

209
00:08:10,255 --> 00:08:13,090
Ik beschouw dit als de
rechterkant, dat de linkerkant.

210
00:08:13,091 --> 00:08:15,259
Ik heb een vaag idee
van waar dingen zijn

211
00:08:15,260 --> 00:08:18,663
waarvan ik denk dat ze bestaan
de buitenrand, maar 

212
00:08:18,664 --> 00:08:21,832
k weet niet veel 
an de dingen binne

213
00:08:21,833 --> 00:08:23,701
in.  [Craig] En tijd.

214
00:08:23,702 --> 00:08:25,903
Oke.  Dus
nu heb je de kans
gehad om het doolhof te verkennen en uit te

215
00:08:25,904 --> 00:08:27,972
zoeken waar
de objecten zijn.

216
00:08:27,973 --> 00:08:29,340
Nu gaan we
je geheugen testen...

217
00:08:29,341 --> 00:08:30,308
- Oké.
- ...en we zullen je timen

218
00:08:30,309 --> 00:08:30,976
en zien waar je heen gaat.

219
00:08:30,977 --> 00:08:31,943
- Oké.
- Oké.  Ben je klaar?

220
00:08:31,944 --> 00:08:33,344
- Ik ben klaar.
- [Dane] Dus je eerste object

221
00:08:33,345 --> 00:08:34,678
is de fietspomp.

222
00:08:34,679 --> 00:08:38,081
- Gaan.
- [Michael] Pomp.  Oké.

223
00:08:38,082 --> 00:08:40,817
[Michael] Pump maakte
altijd rechtse bochten,

224
00:08:40,818 --> 00:08:45,256
het meest rechtse
deel van... pump omhelzen.

225
00:08:45,257 --> 00:08:47,758
Haha!  Ja.  Eenvoudig.  Oké.

226
00:08:47,759 --> 00:08:50,027
Nu, ik denk dat ik het tegenovergestelde doe
om eruit te komen.

227
00:08:50,028 --> 00:08:53,965
Linkerkant - ja,
ik denk dat ik deze afslag moet maken.

228
00:08:53,966 --> 00:08:57,201
Daar is het.

229
00:08:57,202 --> 00:08:58,636
- Je vroeg om een
 - Oke.

230
00:08:58,637 --> 00:09:01,005
Punt twee, de basketbal.

231
00:09:01,006 --> 00:09:03,341
[Michael]Later evalueerden Dr. Stark
en Dr.

232
00:09:03,342 --> 00:09:05,042
Clemenson mijn prestaties

233
00:09:05,043 --> 00:09:07,612
op hoe snel ik was,
het aantal fouten dat ik maakte

234
00:09:07,613 --> 00:09:10,982
en of ik
elke keer de meest optimale route nam.

235
00:09:10,983 --> 00:09:11,683
[Craig] En tijd.

236
00:09:11,684 --> 00:09:13,951
Het derde item
is de kat.  Gaan.

237
00:09:13,952 --> 00:09:16,287
[Michael]
Hier poesje, poesje, poesje.

238
00:09:16,288 --> 00:09:17,755
Ik snap het.

239
00:09:17,756 --> 00:09:18,990
[Dane] Het vierde item
is het kussen.

240
00:09:18,991 --> 00:09:20,825
[Michael] Ik keer op
mijn stappen terug.

241
00:09:20,826 --> 00:09:22,293
- [Dane] Het kleurpotlood.
- [Michael] Makkelijk.

242
00:09:22,294 --> 00:09:23,828
- [Dane] Het boek.
- [Michael] Oké.

243
00:09:23,829 --> 00:09:24,996
[Dane] De laars.

244
00:09:24,997 --> 00:09:26,931
Het laatste item
is de waterfles.

245
00:09:26,932 --> 00:09:30,901
- Gaan.
- [Michael] Waterfles.

246
00:09:30,902 --> 00:09:33,738
Ik denk... door...

247
00:09:33,739 --> 00:09:38,075
Ja, het was hier.

248
00:09:38,076 --> 00:09:41,846
Misschien aan de andere kant
van deze muur.

249
00:09:41,847 --> 00:09:44,048
Nee?  O, schiet.

250
00:09:44,049 --> 00:09:46,317
Oké.  Misschien is het hier beneden.

251
00:09:46,318 --> 00:09:47,418
Oh wacht.

252
00:09:47,419 --> 00:09:50,388
Dat is... nee?

253
00:09:50,389 --> 00:09:52,189
Dat is de centrale kubus.

254
00:09:52,190 --> 00:09:54,191
Het was in een soort van...

255
00:09:54,192 --> 00:09:58,362
een lange gang als deze
in dit gebied.

256
00:09:58,363 --> 00:10:00,197
Oh man.

257
00:10:00,198 --> 00:10:02,700
[Michael]Tot nu
toe was het redelijk goed gegaan,

258
00:10:02,701 --> 00:10:05,169
maar nu voelde het alsof
mijn hippocampus me in de steek liet.

259
00:10:05,170 --> 00:10:07,071
Nu de meeste
items verdwenen waren,

260
00:10:07,072 --> 00:10:08,339
kon ik ze niet
als referentie gebruiken,

261
00:10:08,340 --> 00:10:10,941
en het was moeilijk
om de verschillen

262
00:10:10,942 --> 00:10:12,810
tussen de verschillende
witte gangen te onderscheiden.

263
00:10:12,811 --> 00:10:13,978
Oh, verdomme.

264
00:10:13,979 --> 00:10:15,846
Oh, hoe zit het met door--

265
00:10:15,847 --> 00:10:17,448
Begrepen.

266
00:10:17,449 --> 00:10:20,384
- Fles komt eraan.
- [Craig] Oké.
Daar ga je.

267
00:10:20,385 --> 00:10:22,219
- [Michael] Ik snap het.  Leuk.
- Die was wat
stoerder, h?

268
00:10:22,220 --> 00:10:23,821
[Michael]
Ja, het was moeilijker.

269
00:10:23,822 --> 00:10:25,356
- Dus we hebben alle acht objecten gevonden.
- JEP.

270
00:10:25,357 --> 00:10:27,224
[Dane] Nu gaan we het
een beetje moeilijker maken.

271
00:10:27,225 --> 00:10:28,926
Dus we gaan
naar de volgende fase

272
00:10:28,927 --> 00:10:30,227
en dat zal
van de andere kant zijn.

273
00:10:30,228 --> 00:10:32,063
[Craig]
Omgekeerd door het doolhof navigeren

274
00:10:32,064 --> 00:10:35,232
zal een nog grotere test
van je ruimtelijk geheugen zijn.

275
00:10:35,233 --> 00:10:38,235
We gaan je
een lijst geven van vier dingen die je

276
00:10:38,236 --> 00:10:39,170
op volgorde moet krijgen.

277
00:10:39,171 --> 00:10:41,472
[Dane] Dus de eerste reeks
is het boek,

278
00:10:41,473 --> 00:10:43,374
de fles, het krijt

279
00:10:43,375 --> 00:10:44,475
en de laars.

280
00:10:44,476 --> 00:10:46,310
- Gaan.
- [Michael] Boek.

281
00:10:46,311 --> 00:10:47,812
Ik denk...

282
00:10:47,813 --> 00:10:52,283
Dat is de bal.

283
00:10:52,284 --> 00:10:53,084
Ik snap het.

284
00:10:53,085 --> 00:10:54,919
Oh, ja, fles
was zo moeilijk,

285
00:10:54,920 --> 00:10:58,489
maar nu weet ik weer
welk steegje ik in moest.

286
00:10:58,490 --> 00:10:59,724
Perfect.

287
00:10:59,725 --> 00:11:01,992
Kleurpotlood.

288
00:11:01,993 --> 00:11:04,228
Laars.  Wil dat niet.

289
00:11:04,229 --> 00:11:04,896
Hier is het.

290
00:11:04,897 --> 00:11:06,931
Oké.  Nu heb ik de laars nodig.

291
00:11:06,932 --> 00:11:08,065
Oh, ik zag net de laars,

292
00:11:08,066 --> 00:11:10,334
maar hoe kwam ik...

293
00:11:10,335 --> 00:11:14,138
Begrepen.
Ik ben klaar.  Ik kom terug.

294
00:11:14,139 --> 00:11:15,306
- Heb ze.
- [Craig] Oké.

295
00:11:15,307 --> 00:11:16,373
Dus dan de volgende vier.

296
00:11:16,374 --> 00:11:18,042
[Dane] De pomp, het kussen,

297
00:11:18,043 --> 00:11:19,944
de basketbal en de kat.

298
00:11:19,945 --> 00:11:23,314
- [Craig] Oké.  Uitstekend.
- [Deen] Oké.  Goed werk.

299
00:11:23,315 --> 00:11:24,482
[Michael] Oké.
Dus dat was erg leuk,

300
00:11:24,483 --> 00:11:26,517
maar ik kan niet
het enige onderwerp zijn.

301
00:11:26,518 --> 00:11:28,786
Dit experiment
kan een controle gebruiken.

302
00:11:28,787 --> 00:11:30,521
Hoe kunnen we anders weten dat ik, door
mijn leven te verrijken

303
00:11:30,522 --> 00:11:32,456
met het dagelijks
spelen van videogames,

304
00:11:32,457 --> 00:11:35,392
echt een verandering
in mijn ruimtelijk geheugen veroorzaakt, toch?

305
00:11:35,393 --> 00:11:37,161
Nou, gelukkig daarvoor

306
00:11:37,162 --> 00:11:39,063
hebben we een mooie op
elkaar afgestemde controle.

307
00:11:39,064 --> 00:11:40,498
Jongens die op mij lijken.

308
00:11:40,499 --> 00:11:41,966
Oké, een van hen
heeft te veel haar,

309
00:11:41,967 --> 00:11:43,400
maar jullie zien er goed uit.

310
00:11:43,401 --> 00:11:45,236
- Ben je klaar?
- [allemaal] Klaar.

311
00:11:45,237 --> 00:11:46,804
[Michael]In elk experiment is

312
00:11:46,805 --> 00:11:48,506
het belangrijk om
een controlegroep te hebbe

313
00:11:48,507 --> 00:11:51,108
.  Mijn lookalikes
moesten exact dezelfde tests doorstaan

314
00:11:51,109 --> 00:11:52,810
 in het doolhof deed 

315
00:11:52,811 --> 00:11:54,445
m hun i
dividuele basislijnen vast te stellen.  Het 

316
00:11:54,446 --> 00:11:55,713
verschil zou zijn
dat

317
00:11:55,714 --> 00:11:58,849

ze de komende 10 dagen absoluut geen videogames zouden spelen.

318
00:11:58,850 --> 00:12:00,451
Dan zou elke verandering
in mijn

319
00:12:00,452 --> 00:12:03,420
prestaties worden vergeleken met
eventuele veranderingen in die van hen.

320
00:12:03,421 --> 00:12:06,957
[muziek spelen]

321
00:12:06,958 --> 00:12:09,193
Vervolgens begon ik met
mijn spelregime,

322
00:12:09,194 --> 00:12:11,028
beginnend
bij een ideale basislijn,

323
00:12:11,029 --> 00:12:12,930
aangezien ik sinds mijn kindertijd geen videogames meer heb gespeeld


324
00:12:12,931 --> 00:12:14,232
.

325
00:12:14,233 --> 00:12:18,035
Zou tien dagen gamen
echt een verschil maken?

326
00:12:18,036 --> 00:12:28,245
[muziek afspelen]

327
00:12:28,246 --> 00:12:31,282
Technologie heeft niet alleen invloed op
de manier waarop we ons dingen herinneren.

328
00:12:31,283 --> 00:12:34,552
- [zoemend]
- Het speelt ook
met de empathie

329
00:12:34,553 --> 00:12:37,488
en sociale circuits
van onze hersenen.

330
00:12:37,489 --> 00:12:38,989
In veel gevallen

331
00:12:38,990 --> 00:12:41,158
voelen we ons zelfs meer op ons
gemak met machines

332
00:12:41,159 --> 00:12:42,560
dan met mensen.

333
00:12:42,561 --> 00:12:45,029
Bedenk eens hoeveel
we om onze telefoons geven.  Alex

334
00:12:45,030 --> 00:12:47,898

Reben, roboticus en MIT Media Lab

335
00:12:47,899 --> 00:12:50,201
,
vond de BlabDroid uit,

336
00:12:50,202 --> 00:12:52,570
een miniatuurrobot uitgerust
met een camera

337
00:12:52,571 --> 00:12:54,138
en een onschuldig stemmetje

338
00:12:54,139 --> 00:12:55,506
dat


339
00:12:55,507 --> 00:12:57,441
nietsvermoedende voetgangers heel persoonlijke vragen stelt.

340
00:12:57,442 --> 00:13:00,177
[BlabDroid]Als je
één fout zou kunnen terugdraaien,

341
00:13:00,178 --> 00:13:01,445
wat zou dat dan zijn?

342
00:13:01,446 --> 00:13:04,315
Oh God.
Ik mag er maar één terugnemen?

343
00:13:04,316 --> 00:13:05,983
[Michael]
De meerderheid van de mensen

344
00:13:05,984 --> 00:13:07,551
deelde onmiddellijk
intieme details.

345
00:13:07,552 --> 00:13:09,920
[BlabDroid]Vertel me iets
dat je nog nooit aan

346
00:13:09,921 --> 00:13:11,255
een vreemde hebt verteld.

347
00:13:11,256 --> 00:13:13,357
Ik ben bang dat
ik niet in staat zal zijn om lief te hebben

348
00:13:13,358 --> 00:13:18,095
en mezelf te laten gaan
in een liefdesrelatie.

349
00:13:18,096 --> 00:13:19,263
[Michael]In veel opzichten vinden

350
00:13:19,264 --> 00:13:21,365
we het prettiger
om met een machine te praten

351
00:13:21,366 --> 00:13:23,033
dan met een mens.

352
00:13:23,034 --> 00:13:25,603
Maar hoe zit het
met praten via een machine?

353
00:13:25,604 --> 00:13:27,538
Ik bedoel, het is vaak makkelijker om

354
00:13:27,539 --> 00:13:29,640
moeilijke dingen
tegen iemand te zeggen via sms in

355
00:13:29,641 --> 00:13:31,475
plaats van in het echte leven
, toch?

356
00:13:31,476 --> 00:13:33,644
Nou, wat als de persoon
aan de andere

357
00:13:33,645 --> 00:13:36,347
kant geen vriend
of een significant ander was,

358
00:13:36,348 --> 00:13:38,649
maar een therapeut?

359
00:13:38,650 --> 00:13:41,185
Een startup voor geestelijke gezondheidszorg
genaamd Talkspace

360
00:13:41,186 --> 00:13:43,420
stelt volwassen gebruikers
die een wekelijkse vergoeding betalen, toe

361
00:13:43,421 --> 00:13:45,556
aan sms-therapeuten voor advies.

362
00:13:45,557 --> 00:13:48,058
[vrouw]Bij Talkspace vinden
we dat

363
00:13:48,059 --> 00:13:50,160
therapie anoniem,
stigmavrij,

364
00:13:50,161 --> 00:13:53,931
eenvoudig, betaalbaar
en comfortabel moet zijn.

365
00:13:53,932 --> 00:13:56,166
Sms'en kan gebruikers
de afstand geven die ze nodig hebben

366
00:13:56,167 --> 00:13:57,534
om open en eerlijk te zijn.

367
00:13:57,535 --> 00:14:00,671
En berichten kunnen worden verzonden
wanneer de gebruiker dat wil,

368
00:14:00,672 --> 00:14:02,039
niet alleen tijdens een afspraak

369
00:14:02,040 --> 00:14:03,607
of alleen tijdens kantooruren.

370
00:14:03,608 --> 00:14:04,675
[vrouw]Talkspace,

371
00:14:04,676 --> 00:14:08,178
therapie voor hoe we vandaag leven.

372
00:14:08,179 --> 00:14:09,513
[Michael] Hoe gaat het met mij?

373
00:14:09,514 --> 00:14:14,351
Beter nu mijn telefoon het
doet.

374
00:14:14,352 --> 00:14:19,423
Soms zijn
we echter niet op zoek naar
technologie om ons te troosten.

375
00:14:19,424 --> 00:14:24,695
we merken dat we
technologie willen troosten.

376
00:14:24,696 --> 00:14:27,064
Dit is een ROBOTIS OP2.

377
00:14:27,065 --> 00:14:30,167
Schattige kleine kerel, is het niet?

378
00:14:30,168 --> 00:14:32,069
Dus hoe voelde je je daardoor?

379
00:14:32,070 --> 00:14:33,103
Slechte?

380
00:14:33,104 --> 00:14:34,305
Nou waarom?

381
00:14:34,306 --> 00:14:36,206
Robots zijn gewoon machines,

382
00:14:36,207 --> 00:14:38,342
metaal en draden
en computerchips.

383
00:14:38,343 --> 00:14:42,046
Maar we besteden veel tijd
aan technologie.

384
00:14:42,047 --> 00:14:43,580
We zijn afhankelijk van technologie

385
00:14:43,581 --> 00:14:45,149
en daar geven we om.

386
00:14:45,150 --> 00:14:46,717
Maar de mate waarin
we ons er in inleven,

387
00:14:46,718 --> 00:14:48,953
hangt af van de context.

388
00:14:48,954 --> 00:14:52,623
[muziek speelt]

389
00:14:52,624 --> 00:14:54,959
[Michael]
Onlangs werd mijnVsauce-

390
00:14:54,960 --> 00:14:56,627
kantoor binnengevallen door bugs -

391
00:14:56,628 --> 00:14:58,495
robothexbugs, dat wil zeggen.

392
00:14:58,496 --> 00:15:01,165
Deze bugs zijn gemaakt
van plastic, metaal

393
00:15:01,166 --> 00:15:03,033
en elektronische schakelingen.

394
00:15:03,034 --> 00:15:04,201
Ze leven niet.

395
00:15:04,202 --> 00:15:05,569
Maar kunnen bepaalde omstandigheden

396
00:15:05,570 --> 00:15:08,706
ervoor zorgen dat ze
empathie bij mensen opwekken?

397
00:15:08,707 --> 00:15:11,275
Een MIT-studie uit 2015 wees uit

398
00:15:11,276 --> 00:15:14,111
dat het geven van een
robotbeweging, een naam

399
00:15:14,112 --> 00:15:15,346
en een persoonlijk achtergrondverhaal de

400
00:15:15,347 --> 00:15:17,481
neiging heeft om
het antropomorfe effect te vergroten,

401
00:15:17,482 --> 00:15:19,516
wat kan leiden tot
een emotionele band

402
00:15:19,517 --> 00:15:20,718
met mensen.

403
00:15:20,719 --> 00:15:22,586
We besloten om dit in
actie te zien.

404
00:15:22,587 --> 00:15:25,589
- Bedankt voor je hulp vandaag.
- Natuurlijk.  Plezier.

405
00:15:25,590 --> 00:15:26,724
[Michael]
In onze demonstratie

406
00:15:26,725 --> 00:15:29,026
denken onze proefpersonen dat
ze

407
00:15:29,027 --> 00:15:31,161
een nieuwe, gebruiksvriendelijke technologie aan het testen zijn.

408
00:15:31,162 --> 00:15:34,164
In dit geval krijgen
ze een levenloze hexbug

409
00:15:34,165 --> 00:15:36,066
en wordt gevraagd deze te beschrijven.

410
00:15:36,067 --> 00:15:38,202
Dit ding
ziet eruit als een bug,

411
00:15:38,203 --> 00:15:39,536
alleen weet ik niet
wat het doet.

412
00:15:39,537 --> 00:15:41,105
Het heeft een schakelaar aan de onderkant.

413
00:15:41,106 --> 00:15:42,172
Het is licht.

414
00:15:42,173 --> 00:15:43,307
Het is een soort rechthoek,

415
00:15:43,308 --> 00:15:45,342
maar de uiteinden
zijn als zeshoeken.

416
00:15:45,343 --> 00:15:47,478
[Michael]Toen was het tijd
om hun empathie te testen.

417
00:15:47,479 --> 00:15:49,146
Karina,
wat ik wil
dat je nu doet,

418
00:15:49,147 --> 00:15:52,216
is het item
in het midden
van dat blok plaatsen.

419
00:15:52,217 --> 00:15:54,151
Er is een magneet
die het zal vasthouden.

420
00:15:54,152 --> 00:15:57,354
En ik zou graag willen dat
je deze hamer pakt

421
00:15:57,355 --> 00:15:58,422
en hem kapot slaat.

422
00:15:58,423 --> 00:16:02,760
Ja.  Werkelijk?  Oké.
Dit is cool.

423
00:16:02,761 --> 00:16:05,262
[Michael]Onze deelnemers
toonden geen weerstand

424
00:16:05,263 --> 00:16:06,764
tegen het verpletteren van
dit levenloze object.

425
00:16:06,765 --> 00:16:10,434
Velen van hen
leken er zelfs van te genieten.

426
00:16:10,435 --> 00:16:12,169
Vind je het erg
dat je het hebt gebroken?

427
00:16:12,170 --> 00:16:15,072
Niet echt.
Ik voelde me er onverschillig bij.

428
00:16:15,073 --> 00:16:17,174
Niet echt, want
het was niet echt.  [lacht]

429
00:16:17,175 --> 00:16:18,476
Niet echt.

430
00:16:18,477 --> 00:16:20,511
[Michael]Hoewel deze
proefpersonen geen empathie toonden

431
00:16:20,512 --> 00:16:22,312
voor de levenloze beestjes,

432
00:16:22,313 --> 00:16:25,049
kijk eens wat er gebeurde toen
we exact dezelfde beestjes

433
00:16:25,050 --> 00:16:26,750
namen en bewegingen gaven.

434
00:16:26,751 --> 00:16:28,819
Dit is Margaretha.  Oké.

435
00:16:28,820 --> 00:16:30,220
Ik zet Margaret
hier neer.

436
00:16:30,221 --> 00:16:31,755
Ik wil dat je
even de tijd neemt

437
00:16:31,756 --> 00:16:33,457
om naar Margaret te kijken,
oké?

438
00:16:33,458 --> 00:16:35,659
En je kon
haar gerust oppikken.

439
00:16:35,660 --> 00:16:37,594
Ze gedraagt zich echt goed.

440
00:16:37,595 --> 00:16:39,496
 - Ze is echt een
van onze favorieten.
- [vrouw, lachend] Oké.

441
00:16:39,497 --> 00:16:42,566
Dus hoe zou je
Margaret's persoonlijkheid omschrijven?

442
00:16:42,567 --> 00:16:46,370
Een beetje grillig nu,

443
00:16:46,371 --> 00:16:48,405
maar ik denk dat als ik haar optil,
ze kalmeert.

444
00:16:48,406 --> 00:16:50,441
[Michael]Merk op
hoe het

445
00:16:50,442 --> 00:16:53,744
subject het object al heeft vermenselijkt,
door ernaar te verwijzen als 'zij'.

446
00:16:53,745 --> 00:16:55,479
Misschien voedt ze zich met
mijn energie.

447
00:16:55,480 --> 00:16:57,414
Zou kunnen.

448
00:16:57,415 --> 00:16:58,615
Ga naar het licht.

449
00:16:58,616 --> 00:17:00,117
Ga naar het midden.

450
00:17:00,118 --> 00:17:01,518
[Michael] Denk je dat
Margaret je leuk vindt?

451
00:17:01,519 --> 00:17:03,720
Ja, misschien
doet ze dit daarom,

452
00:17:03,721 --> 00:17:05,289
en misschien


453
00:17:05,290 --> 00:17:07,758
gedraagt ze zich niet zo gr
llig als ik zo ga.  

454
00:17:07,759 --> 00:17:09,226
Dat is Aäron.

455
00:17:09,227 --> 00:17:10,594
Hallo, Aäron.

456
00:17:10,595 --> 00:17:12,362
Hij kan een
beetje een pistool zijn.

457
00:17:12,363 --> 00:17:13,864
- Echt niet.
- Ja.

458
00:17:13,865 --> 00:17:17,366
Het hangt er echt van af
wie hem vasthoudt.

459
00:17:17,367 --> 00:17:18,735
[lacht]

460
00:17:18,736 --> 00:17:21,305
Oh, ja.
Hij heeft veel energie.

461
00:17:21,306 --> 00:17:24,107
Aäron, hallo.

462
00:17:24,108 --> 00:17:26,175
[Michael] Nu je
wat meer contact met Eli hebt gehad,

463
00:17:26,176 --> 00:17:28,178
hoe zou je
zijn persoonlijkheid omschrijven?

464
00:17:28,179 --> 00:17:29,780
Waarschijnlijk is hij gewoon nerveus.
Hij is bang.

465
00:17:29,781 --> 00:17:32,316
- Hij weet niet
wat er aan de hand is.
- Hoi, Joe.

466
00:17:32,317 --> 00:17:33,851
[Michael]Zullen deze
proefpersonen net zo bereid

467
00:17:33,852 --> 00:17:35,752
zijn om hun bugs kapot te maken?

468
00:17:35,753 --> 00:17:40,190
Amy, ik plaats
Margaret hier,

469
00:17:40,191 --> 00:17:42,860
en dan
wil ik dat
je deze hamer pakt,

470
00:17:42,861 --> 00:17:46,530
en ik wil dat je
hem kapot slaat.

471
00:17:46,531 --> 00:17:47,631
Nee.

472
00:17:47,632 --> 00:17:50,400
Ik wil het niet kwetsen.

473
00:17:50,401 --> 00:17:53,537
Pak gewoon deze hamer
en sla Aaron kapot.

474
00:17:53,538 --> 00:17:58,509
[muziek speelt]

475
00:17:58,510 --> 00:18:00,777
[Michael]
Ik ga je
vragen deze hamer te pakken,

476
00:18:00,778 --> 00:18:05,215
en ik wil dat je
hem kapot slaat.

477
00:18:05,216 --> 00:18:07,551
Sla het?

478
00:18:07,552 --> 00:18:08,685
Raak het?

479
00:18:08,686 --> 00:18:09,920
En, Chris...

480
00:18:09,921 --> 00:18:11,355
Wil je dat ik Joe vermoord?

481
00:18:11,356 --> 00:18:12,489
Alsjeblieft, sla Joe kapot.

482
00:18:12,490 --> 00:18:14,658
Ugh.

483
00:18:14,659 --> 00:18:17,427
Het spijt me.

484
00:18:17,428 --> 00:18:20,297
O, Joep.  Joep.

485
00:18:20,298 --> 00:18:27,905
[muziek speelt

486
00:18:27,906 --> 00:18:32,910
] Hoe voelde het
om Aaron in elkaar te slaan?

487
00:18:32,911 --> 00:18:36,547
Het voelde niet goed,
weet je,

488
00:18:36,548 --> 00:18:38,515
na tijd met hem

489
00:18:38,516 --> 00:18:39,816
te hebben doorgebracht en hem te leren kennen.

490
00:18:39,817 --> 00:18:41,251
Ook al
is het levenloos

491
00:18:41,252 --> 00:18:43,320
en heeft het
geen eigen wil, ik raakte er

492
00:18:43,321 --> 00:18:44,488
meteen aan
gehecht,

493
00:18:44,489 --> 00:18:45,889
want toen ik het
in mijn hand legde,

494
00:18:45,890 --> 00:18:46,957
voelde ik zijn energie.

495
00:18:46,958 --> 00:18:48,725
Het spijt me, Joe.

496
00:18:48,726 --> 00:18:50,627
- Voel je je slecht?
- Ik doe.

497
00:18:50,628 --> 00:18:51,695
Ik voel me slecht over Joe.

498
00:18:51,696 --> 00:18:53,730
Hij was best cool.

499
00:18:53,731 --> 00:18:55,465
O, hij is terug.

500
00:18:55,466 --> 00:18:56,533
Hij is terug?

501
00:18:56,534 --> 00:18:58,335
Pomp, pomp.

502
00:18:58,336 --> 00:19:00,204
Zou je hem nog een keer kapot slaan
om er zeker van te zijn dat

503
00:19:00,205 --> 00:19:01,939
hij niet terugkomt?

504
00:19:01,940 --> 00:19:03,740
-
Nee waarom niet?

505
00:19:03,741 --> 00:19:05,609
Ik bedoel, hij heeft het overleefd.
Hij heeft het een keer overleefd.

506
00:19:05,610 --> 00:19:08,212
Ik ga het niet nog een keer doen.

507
00:19:08,213 --> 00:19:09,947
[Michael]Het is duidelijk
dat er niet veel voor nodig is voor mensen

508
00:19:09,948 --> 00:19:12,950
om emotioneel
gehecht te raken aan technologie.

509
00:19:12,951 --> 00:19:15,819
Maar na mijn tien
dagen videogamen...

510
00:19:15,820 --> 00:19:17,654
Leuk.

511
00:19:17,655 --> 00:19:20,591
Ik stond op het punt erachter te komen
of technologie

512
00:19:20,592 --> 00:19:22,326
mijn ruimtelijk geheugen

513
00:19:22,327 --> 00:19:24,428
en mijn fysieke brein had beïnvloed.

514
00:19:24,429 --> 00:19:25,563
[muziek speelt]

515
00:19:25,564 --> 00:19:27,497
[Michael]Oké.
Het is tien dagen geleden.

516
00:19:27,498 --> 00:19:29,399
Precies, dus we gaan kijken
naar het verschil tussen

517
00:19:29,400 --> 00:19:31,835
je test tien dagen geleden
en je test nu

518
00:19:31,836 --> 00:19:33,370
om te
zien of we enige verandering zien.

519
00:19:33,371 --> 00:19:35,572
[Michael]
Eerst moest ik

520
00:19:35,573 --> 00:19:37,741
de
geheugentest voor objectherkenning

521
00:19:37,742 --> 00:19:39,509
en de Morris waterdoolhoftaak opnieuw doen, die

522
00:19:39,510 --> 00:19:42,412
beide waren herzien
met een andere inhoud

523
00:19:42,413 --> 00:19:43,780
dan de vorige keer.

524
00:19:43,781 --> 00:19:45,449
Ik denk dat ik het beter heb gedaan.

525
00:19:45,450 --> 00:19:47,484
Dane en ik zullen
al deze gegevens analyseren
en kijken hoe je het hebt gedaan.

526
00:19:47,485 --> 00:19:49,987
Maar nu moeten we terug
naar het grote doolhof.

527
00:19:49,988 --> 00:19:54,524
[muziek speelt]

528
00:19:54,525 --> 00:19:56,426
[Craig]
Dus we hebben een nieuw doolhof.

529
00:19:56,427 --> 00:19:58,662
De oude afgebroken,
een nieuwe gebouwd

530
00:19:58,663 --> 00:20:00,397
om te proberen isomorf te zijn.

531
00:20:00,398 --> 00:20:02,966
Het heeft dus ongeveer
dezelfde moeilijkheidsgraad.

532
00:20:02,967 --> 00:20:04,735
Hetzelfde
aantal keuzepunten,

533
00:20:04,736 --> 00:20:06,536
hetzelfde aantal beurten,

534
00:20:06,537 --> 00:20:09,339
dezelfde totale afstand
tot elk van de objecten

535
00:20:09,340 --> 00:20:12,709
om te proberen een soortgelijk doolhof te hebben,
maar dat is nieuw.

536
00:20:12,710 --> 00:20:16,046
Drie, twee, één, ga.

537
00:20:16,047 --> 00:20:17,481
[Michael] Hier in de buurt hebben

538
00:20:17,482 --> 00:20:18,516
we een bonsai.

539
00:20:18,517 --> 00:20:20,617
Net als voorheen kreeg
ik vijf minuten

540
00:20:20,618 --> 00:20:22,486
om me vertrouwd te maken
met het doolhof

541
00:20:22,487 --> 00:20:24,688
en waar
alle objecten zich bevonden.

542
00:20:24,689 --> 00:20:27,024
Dit is waar ik was
voordat ik die muur omhelsde,

543
00:20:27,025 --> 00:20:28,959
dus als ik
de tweede rechter muur omhels

544
00:20:28,960 --> 00:20:31,561
en helemaal rechts blijf,
een vaas.

545
00:20:31,562 --> 00:20:33,463
Werkte mijn
hippocampus beter?

546
00:20:33,464 --> 00:20:36,033
Op dit punt was
het moeilijk te zeggen.

547
00:20:36,034 --> 00:20:37,501
Dertig seconden.

548
00:20:37,502 --> 00:20:39,870
Ik weet niet eens zeker of
ik

549
00:20:39,871 --> 00:20:41,938
alle objecten heb ontdekt die hier verborgen zijn.

550
00:20:41,939 --> 00:20:43,440
En tijd.

551
00:20:43,441 --> 00:20:45,008
[Michael]
Toen begon mijn test.

552
00:20:45,009 --> 00:20:46,510
Het eerste object
is een badeend.

553
00:20:46,511 --> 00:20:49,379
- Gaan.
- Badeend was hier ver.

554
00:20:49,380 --> 00:20:51,548
Ja!
Wat vind je daarvan?

555
00:20:51,549 --> 00:20:52,849
Ik heb een eend.

556
00:20:52,850 --> 00:20:55,385
Tweede item
is de hoed.  Gaan.

557
00:20:55,386 --> 00:20:57,087
[Michael]Met dit doolhof
merkte ik dat ik

558
00:20:57,088 --> 00:20:58,522
instinctief een andere aanpak gebruikte.

559
00:20:58,523 --> 00:20:59,924
Hoge hoed.

560
00:20:59,925 --> 00:21:01,925
In plaats van aan de
algemene geografie van het doolhof te denken,

561
00:21:01,926 --> 00:21:03,593
zoals ik de vorige keer deed,

562
00:21:03,594 --> 00:21:06,396
herinnerde ik me deze keer
specifieke details.

563
00:21:06,397 --> 00:21:09,800
Tweede rechts,
omhels de bocht, begrepen.

564
00:21:09,801 --> 00:21:11,535
Letterlijk herinneren aan
bepaalde bochten,

565
00:21:11,536 --> 00:21:13,537
bochten en rechte stukken.

566
00:21:13,538 --> 00:21:14,538
Bonsai.

567
00:21:14,539 --> 00:21:15,572
Nu blauwe vaas.

568
00:21:15,573 --> 00:21:17,708
Oh wow.
Het is eigenlijk een gave vaas.

569
00:21:17,709 --> 00:21:21,011
Maar zou dit
mijn algehele prestaties verbeteren?

570
00:21:21,012 --> 00:21:22,079
Ik heb een rugzak voor je.

571
00:21:22,080 --> 00:21:23,513
- Oke.
- Uitstekend.

572
00:21:23,514 --> 00:21:25,048
Dus we hebben
alle objecten gekregen.

573
00:21:25,049 --> 00:21:26,483
Maar natuurlijk hebben we nog
een geheugentest

574
00:21:26,484 --> 00:21:28,752
die we hier gaan doen.

575
00:21:28,753 --> 00:21:30,487
We gaan
naar de andere kant van het doolhof

576
00:21:30,488 --> 00:21:32,356
en testen je geheugen
vanaf daar.

577
00:21:32,357 --> 00:21:33,623
- [Michael] Oké.
- [Dane] Dus je eerste reeks

578
00:21:33,624 --> 00:21:35,459
is het blauwe zeepaardje,
de zaklamp,

579
00:21:35,460 --> 00:21:37,794
de rubberen eend
en de bonsaiboom.

580
00:21:37,795 --> 00:21:39,363
Gaan.

581
00:21:39,364 --> 00:21:41,565
[Michael]
Met de taken met meerdere items,

582
00:21:41,566 --> 00:21:43,567
hoewel ik
vanaf de andere ingang aan het werk was,

583
00:21:43,568 --> 00:21:46,636
bleef ik me
verschillende details van het doolhof herinneren,

584
00:21:46,637 --> 00:21:48,105
wat me goed leek te dienen.

585
00:21:48,106 --> 00:21:51,441
Vanaf daar is
het gewoon een kleine spiraal.

586
00:21:51,442 --> 00:21:52,509
Leuk.

587
00:21:52,510 --> 00:21:53,977
[bel gaat]

588
00:21:53,978 --> 00:21:56,847
[Dane] Goed.  Je volgende
reeks is de blauwe vaas,

589
00:21:56,848 --> 00:21:58,448
de hoed, de rugzak

590
00:21:58,449 --> 00:22:00,617
en de honkbalhandschoen.
- [Craig] Raak het.

591
00:22:00,618 --> 00:22:02,152
- En tijd.
- Geweldig.

592
00:22:02,153 --> 00:22:03,620
Hoe was het?

593
00:22:03,621 --> 00:22:05,989
Dat was niet zo moeilijk
als ik had verwacht.

594
00:22:05,990 --> 00:22:07,691
- Het ging over details.
- [Craig] Juist.

595
00:22:07,692 --> 00:22:10,494
Ik dacht letterlijk
: "O, oké.

596
00:22:10,495 --> 00:22:12,028
Daar is die beurt,

597
00:22:12,029 --> 00:22:13,163
en ik zou een
of twee dingen kunnen doen.

598
00:22:13,164 --> 00:22:14,664
De handschoen is
de eerste.

599
00:22:14,665 --> 00:22:16,533
De bonsai is die
zelfs ervoor."

600
00:22:16,534 --> 00:22:19,035
Dat was ik helemaal niet van
plan.
Het gebeurde gewoon.

601
00:22:19,036 --> 00:22:21,905
[Michael]Mijn look-alikes werden
ook getest in het nieuwe doolhof.

602
00:22:21,906 --> 00:22:23,540
Heb je
videogames gespeeld?

603
00:22:23,541 --> 00:22:24,908
[allemaal] Nee, meneer.

604
00:22:24,909 --> 00:22:26,877
[Michael]Nogmaals,
hun niet-gamingconditie

605
00:22:26,878 --> 00:22:27,911
zou de controle zijn,

606
00:22:27,912 --> 00:22:29,646
met mijn eventuele verbetering,

607
00:22:29,647 --> 00:22:32,115

afgemeten aan die van hen.

608
00:22:32,116 --> 00:22:34,918
[Craig] Oké.
We zijn hier voor scan nummer twee.

609
00:22:34,919 --> 00:22:37,154
[Michael]Ten slotte werden
mijn hersenen opnieuw gescand om

610
00:22:37,155 --> 00:22:40,056
te bepalen of
er fysieke veranderingen
waren opgetreden.

611
00:22:40,057 --> 00:22:43,059
Dr. Stark en Dr.
Clemenson analyseerden de MRI

612
00:22:43,060 --> 00:22:46,563
samen met alle andere gegevens
en rapporteerden hun bevindingen.

613
00:22:46,564 --> 00:22:52,202
[muziek speelt]

614
00:22:52,203 --> 00:22:53,537
[Michael] Ik heb het gevoel dat
mijn

615
00:22:53,538 --> 00:22:55,439
hippocampus een beetje groter is.

616
00:22:55,440 --> 00:22:58,708
Ja.  Eigenlijk, nee,
ik weet het niet.

617
00:22:58,709 --> 00:23:01,545
Ik ben benieuwd
wat je resultaten zijn.

618
00:23:01,546 --> 00:23:02,712
Ik denk dat we
eerst beginnen

619
00:23:02,713 --> 00:23:04,815
met de
taak voor objectherkenning.

620
00:23:04,816 --> 00:23:08,952
En het is belangrijk op te merken
dat in onze controletest
zonder videogames,

621
00:23:08,953 --> 00:23:12,222
mensen niet verbeterden
in deze taak, maar...

622
00:23:12,223 --> 00:23:13,957
je geheugen werd beter.

623
00:23:13,958 --> 00:23:15,492
Je bent tien punten gestegen.

624
00:23:15,493 --> 00:23:17,561
Tien punten is eigenlijk
20 jaar

625
00:23:17,562 --> 00:23:20,764
van wat er
met ons gebeurt als we ouder worden.

626
00:23:20,765 --> 00:23:21,698
Oh wow.

627
00:23:21,699 --> 00:23:23,166
Dat is ongeveer wat je zou kunnen zien

628
00:23:23,167 --> 00:23:25,702
bij iemand
die heel oud wordt

629
00:23:25,703 --> 00:23:27,571
, maar ze
kunnen tien punten lager worden.
- Precies.

630
00:23:27,572 --> 00:23:29,573
Dus de tweede die we deden
was de virtuele versie

631
00:23:29,574 --> 00:23:32,709
van de waterdoolhoftaak,
en je presteerde eigenlijk

632
00:23:32,710 --> 00:23:34,544
30% beter de tweede keer dat
je het deed.

633
00:23:34,545 --> 00:23:35,846
Hé, niet slecht.

634
00:23:35,847 --> 00:23:39,483
Ik kon zien dat
ik betere strategieën gebruikte.

635
00:23:39,484 --> 00:23:40,884
Ja.

636
00:23:40,885 --> 00:23:43,487
- We hadden ook het echte doolhof.
- [Michael] Ja.

637
00:23:43,488 --> 00:23:44,921
[Craig]Zoals je weet,
hebben we twee doolhoven gemaakt.

638
00:23:44,922 --> 00:23:47,057
Ondanks onze
pogingen om ze gelijk te stellen, was

639
00:23:47,058 --> 00:23:49,659
het tweede doolhof
een beetje moeilijker

640
00:23:49,660 --> 00:23:50,827
dan het eerste doolhof.

641
00:23:50,828 --> 00:23:52,262
Als we keken
naar zaken

642
00:23:52,263 --> 00:23:55,832
als hoe snel
je de objecten kreeg,

643
00:23:55,833 --> 00:23:57,801
hoeveel fouten je maakte,
en we keken

644
00:23:57,802 --> 00:24:00,003
naar de prestaties van de controlepersonen
in
pre- versus post-.

645
00:24:00,004 --> 00:24:01,738
Dus bij

646
00:24:01,739 --> 00:24:03,974
allemaal werden ze een
beetje langzamer in doolhof twee,

647
00:24:03,975 --> 00:24:06,743
en op één na maakten ze allemaal
meer fouten.

648
00:24:06,744 --> 00:24:08,245
We
hebben je prestaties bekeken.

649
00:24:08,246 --> 00:24:10,780
Je ging niet langzamer
van doolhof één naar twee.

650
00:24:10,781 --> 00:24:12,082
Je bent echt sneller geworden.

651
00:24:12,083 --> 00:24:13,650
- [Michael]Echt?
- [Craig]En je maakte

652
00:24:13,651 --> 00:24:15,552
exact hetzelfde aantal fouten.

653
00:24:15,553 --> 00:24:18,522
Dus ze verbeteren niet,
en jij wel.

654
00:24:18,523 --> 00:24:19,789
En hoewel
dit

655
00:24:19,790 --> 00:24:21,791
experiment een klein
aantal proefpersonen had, komen

656
00:24:21,792 --> 00:24:25,295
de resultaten overeen
met onze virtuele doolhofstudie

657
00:24:25,296 --> 00:24:27,197
met 70 proefpersonen.

658
00:24:27,198 --> 00:24:29,099
- [Craig] Oké.
- Dank je, videospelletjes.

659
00:24:29,100 --> 00:24:30,801
En
in mijn hersenen?

660
00:24:30,802 --> 00:24:33,003
[Craig]In je hersenen is
het een beetje moeilijker
om het echt te zeggen.

661
00:24:33,004 --> 00:24:36,640
We zouden verwachten
dat het effect

662
00:24:36,641 --> 00:24:38,041
hiervan klein zal zijn.

663
00:24:38,042 --> 00:24:39,643
Ik bedoel, we kunnen
je

664
00:24:39,644 --> 00:24:40,978
hippocampus niet twee keer zo groot maken,

665
00:24:40,979 --> 00:24:43,313
want dan
zou het
iets anders naar buiten moeten duwen.

666
00:24:43,314 --> 00:24:47,017
Het zal dus
niet zomaar een grote verandering zijn.

667
00:24:47,018 --> 00:24:48,585
Dus waar we wel
een verschil vonden,

668
00:24:48,586 --> 00:24:50,887
is eigenlijk in de vorm
van de hippocampus.

669
00:24:50,888 --> 00:24:52,822
Wat we zagen is dat
er aan beide kanten enkele regio's

670
00:24:52,823 --> 00:24:55,659
in de hippocampus
waren

671
00:24:55,660 --> 00:24:57,093
die
van vorm lijken te zijn veranderd

672
00:24:57,094 --> 00:24:58,662
vanaf de eerste dag voor het gamen

673
00:24:58,663 --> 00:25:00,864
tot dag tien na het gamen.

674
00:25:00,865 --> 00:25:04,100
Wat voor mij echt verrassend is,
is dat als volwassene

675
00:25:04,101 --> 00:25:05,802
mijn brein nog steeds aan het veranderen is.

676
00:25:05,803 --> 00:25:08,305
Dat zorgt ervoor dat ik
beter voor mijn hersenen wil zorgen.

677
00:25:08,306 --> 00:25:09,440
Ja.

678
00:25:09,441 --> 00:25:11,341
Oefen het meer
, want het is iets
dat kan veranderen.

679
00:25:11,342 --> 00:25:16,046
Ik zit niet alleen vast
met wat ik nu heb, vandaag.

680
00:25:16,047 --> 00:25:19,649
Ik bedoel, bij dit alles
denk ik dat het belangrijkste

681
00:25:19,650 --> 00:25:21,351
is dat dingen doen

682
00:25:21,352 --> 00:25:23,787
, je hersenen
iets geven om te leren,

683
00:25:23,788 --> 00:25:26,923
iets te doen,
iets om uit te zoeken,

684
00:25:26,924 --> 00:25:28,725
dit is wat we denken


685
00:25:28,726 --> 00:25:30,827
dat je hersenen scherp houdt.

686
00:25:30,828 --> 00:25:33,096
Een manier om dat te doen is door
naarMind Field te blijven kijken.

687
00:25:33,097 --> 00:25:34,798
[Craig] Precies.

688
00:25:34,799 --> 00:25:40,136
[muziek speelt]

689
00:25:40,137 --> 00:25:43,773
[Michael]Naarmate onze relatie
met technologie
steeds sterker wordt, gaan

690
00:25:43,774 --> 00:25:47,811
mensen zich zorgen maken over
wat het met onze hersenen zal doen.

691
00:25:47,812 --> 00:25:49,779
Zal het overdragen van geheugen
en computergebruik

692
00:25:49,780 --> 00:25:52,282
naar onze machines ons dommer maken?

693
00:25:52,283 --> 00:25:56,720
Zal onze empathie voor
machines negatieve gevolgen hebben

694
00:25:56,721 --> 00:25:59,656
voor hoe we
met elkaar omgaan?

695
00:25:59,657 --> 00:26:02,792
Laten we terugkijken
naar een andere keer dat

696
00:26:02,793 --> 00:26:04,794
een nieuw soort technologie onze hersenen


697
00:26:04,795 --> 00:26:07,197
dreigde fundamenteel te
veranderen.

698
00:26:07,198 --> 00:26:08,798
Twee en een half duizend
jaar geleden maakte

699
00:26:08,799 --> 00:26:10,834
de Griekse filosoof Socrates zich

700
00:26:10,835 --> 00:26:13,169
zorgen dat
het wijdverbreide gebruik van het schrift

701
00:26:13,170 --> 00:26:15,939
een negatieve invloed zou hebben
op de geest van mensen.

702
00:26:15,940 --> 00:26:19,109
Hij zei dat schrijven,
om zijn leerling Plato te citeren,

703
00:26:19,110 --> 00:26:20,777
"vergetelheid zou creëren,

704
00:26:20,778 --> 00:26:23,146
omdat mensen
hun geheugen niet zullen gebruiken.

705
00:26:23,147 --> 00:26:26,249
Ze zullen de externe
geschreven karakters vertrouwen

706
00:26:26,250 --> 00:26:29,085
en zichzelf niet herinneren."

707
00:26:29,086 --> 00:26:30,820
Socrates had gelijk.

708
00:26:30,821 --> 00:26:33,857
Geschreven taal heeft
onze hersenen fundamenteel veranderd.

709
00:26:33,858 --> 00:26:36,793
Maar het is ook een van
de hoekstenen van alles wat de

710
00:26:36,794 --> 00:26:38,795
moderne beschaving
heeft bereikt.

711
00:26:38,796 --> 00:26:41,898
Een van de bepalende
kenmerken van het mens-zijn

712
00:26:41,899 --> 00:26:44,768
is dat dit niet
de grens van mijn lichaam is,

713
00:26:44,769 --> 00:26:48,772
en dit is niet de grens
van mijn geest.

714
00:26:48,773 --> 00:26:54,978
En, zoals altijd,
bedankt voor het kijken.

715
00:26:54,979 --> 00:26:57,082
[thema muziek afspelen]

