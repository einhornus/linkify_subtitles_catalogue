1
00:00:07,773 --> 00:00:08,740
Oh, hello.

2
00:00:08,741 --> 00:00:11,709
Technology isn't just
changing our lives.

3
00:00:11,710 --> 00:00:14,446
It's changing our brains.

4
00:00:14,447 --> 00:00:15,713
Not just how they think,

5
00:00:15,714 --> 00:00:17,515
but how they look.

6
00:00:17,516 --> 00:00:21,086
It's been shown that playing
certain video games for hours

7
00:00:21,087 --> 00:00:23,254
can improve your memory
for details,

8
00:00:23,255 --> 00:00:25,356
your ability
to navigate space

9
00:00:25,357 --> 00:00:26,624
in video games,

10
00:00:26,625 --> 00:00:28,426
and can make your brain--

11
00:00:28,427 --> 00:00:31,262
well, certain parts
of it-- bigger.

12
00:00:31,263 --> 00:00:34,165
But scientists want to know
if exploring digital worlds

13
00:00:34,166 --> 00:00:37,335
can change our brains
in ways that improve our ability

14
00:00:37,336 --> 00:00:39,637
to navigate the real world.

15
00:00:39,638 --> 00:00:42,674
To find out,
we've built a giant maze

16
00:00:42,675 --> 00:00:45,777
to test their theories
for the first time ever

17
00:00:45,778 --> 00:00:48,379
outside the world of computers.

18
00:00:48,380 --> 00:00:50,415
And my job?

19
00:00:50,416 --> 00:00:58,289
I'm the lab rat.

20
00:00:58,290 --> 00:01:10,869
[theme music playing]

21
00:01:10,870 --> 00:01:12,504
[vacuum humming, stops]

22
00:01:12,505 --> 00:01:15,373
Our brains have been
profoundly transformed

23
00:01:15,374 --> 00:01:17,542
by our interactions
with technology.

24
00:01:17,543 --> 00:01:19,911
A lot of the information
that I used to have to store

25
00:01:19,912 --> 00:01:23,281
in my brain
is now stored in my phone.

26
00:01:23,282 --> 00:01:25,383
My contacts, my schedule.

27
00:01:25,384 --> 00:01:27,185
In many ways, I've delegated

28
00:01:27,186 --> 00:01:29,354
what used to be done
by this organ

29
00:01:29,355 --> 00:01:32,690
to this new external organ.

30
00:01:32,691 --> 00:01:34,726
Doing that frees up
by brain's resources

31
00:01:34,727 --> 00:01:36,327
for other things that matter

32
00:01:36,328 --> 00:01:38,897
or that technology
can't quite do for us yet.

33
00:01:38,898 --> 00:01:43,268
So while we all don't have
implants in our brains yet,

34
00:01:43,269 --> 00:01:46,504
technology has already found
a way into our heads,

35
00:01:46,505 --> 00:01:49,507
which is why you may find it
deeply disturbing

36
00:01:49,508 --> 00:01:56,514
to see me do something
like this.

37
00:01:56,515 --> 00:01:57,515
Sh--

38
00:01:57,516 --> 00:02:01,352
[music playing]

39
00:02:01,353 --> 00:02:03,888
[Michael] Studies show
 we can improve our brains

40
00:02:03,889 --> 00:02:05,857
 by having enriching
 experiences,

41
00:02:05,858 --> 00:02:08,459
 even by playing video games.

42
00:02:08,460 --> 00:02:10,361
 To learn more about this,

43
00:02:10,362 --> 00:02:12,497
I came to UC Irvine's Stark Lab
 to speak with experts

44
00:02:12,498 --> 00:02:15,333
 in the field of learning
 and memory.

45
00:02:15,334 --> 00:02:17,202
So Dane and Craig,
you guys work on

46
00:02:17,203 --> 00:02:18,770
learning and memory.

47
00:02:18,771 --> 00:02:20,939
- What about them?
- So the lab is trying
to figure out

48
00:02:20,940 --> 00:02:24,642
how memory works,
how it works in the brain.

49
00:02:24,643 --> 00:02:26,945
And one brain structure, in the
temporal lobe

50
00:02:26,946 --> 00:02:29,581
that we know is important to
memory is

51
00:02:29,582 --> 00:02:31,482
the hippocampus.

52
00:02:31,483 --> 00:02:33,985
So what does
the hippocampus do?

53
00:02:33,986 --> 00:02:35,687
We know it has a role in memory

54
00:02:35,688 --> 00:02:38,223
and, really, a certain
kind of memory.

55
00:02:38,224 --> 00:02:39,657
The hippocampus
is really involved

56
00:02:39,658 --> 00:02:44,362
when you need to rapidly form
new arbitrary associations.

57
00:02:44,363 --> 00:02:46,331
You know, remembering
what you did yesterday

58
00:02:46,332 --> 00:02:48,600
definitely needs
the hippocampus.

59
00:02:48,601 --> 00:02:50,702
 Maybe we'll go the store,
 we park our car in the lot,

60
00:02:50,703 --> 00:02:52,437
 and we need to be able
 to remember

61
00:02:52,438 --> 00:02:53,739
 not just, "I parked
 my car in the lot,"

62
00:02:53,740 --> 00:02:57,675
 "I parked my car
 in this exact spot
 in the lot."

63
00:02:57,676 --> 00:02:59,611
- [Michael] Right. 
- [Craig] And those details,

64
00:02:59,612 --> 00:03:01,846
 that's what the hippocampus
 seems to be really be

65
00:03:01,847 --> 00:03:02,947
 helping us out on.

66
00:03:02,948 --> 00:03:04,983
And you keep looking down
at this piece of chewed

67
00:03:04,984 --> 00:03:07,385
bubblegum on the book,
is that a hippocampus?

68
00:03:07,386 --> 00:03:09,787
[Craig] Yes. This actually
is my hippocampus.

69
00:03:09,788 --> 00:03:11,522
Is this the whole thing
or is it symmetric...

70
00:03:11,523 --> 00:03:12,657
That's it--

71
00:03:12,658 --> 00:03:13,925
Oh, there's one
on the other side.

72
00:03:13,926 --> 00:03:15,026
That looks just like this?

73
00:03:15,027 --> 00:03:16,227
Yeah, mirror image of it.

74
00:03:16,228 --> 00:03:18,396
[Michael] In 2015,
 Dr. Stark and Dr. Clemenson,

75
00:03:18,397 --> 00:03:19,864
 conducted a study to show

76
00:03:19,865 --> 00:03:22,500
 how video games
 affect the brain.

77
00:03:22,501 --> 00:03:23,801
 They gathered participants

78
00:03:23,802 --> 00:03:25,536
 who normally didn't play
 video games

79
00:03:25,537 --> 00:03:27,438
 and split them up
 into three groups.

80
00:03:27,439 --> 00:03:28,740
A control group who didn't play

81
00:03:28,741 --> 00:03:31,776
 any video games for two weeks,
 an active control group

82
00:03:31,777 --> 00:03:34,312
 who played two-dimensional
 games for two weeks,

83
00:03:34,313 --> 00:03:35,546
 and an experimental group

84
00:03:35,547 --> 00:03:37,682
 who played 3D games
 for two weeks.

85
00:03:37,683 --> 00:03:39,617
 Beforehand, they had all
 the participants

86
00:03:39,618 --> 00:03:42,287
 perform two virtual tasks
 on computers

87
00:03:42,288 --> 00:03:43,888
 to measure
 their spatial memory.

88
00:03:43,889 --> 00:03:46,524
As soon as they came back,
we re-administered
those two tasks.

89
00:03:46,525 --> 00:03:48,593
 And what we found was that the
 people who played the 3D game

90
00:03:48,594 --> 00:03:50,728
 saw an improving
 in their test scores,

91
00:03:50,729 --> 00:03:52,030
 whereas the control group

92
00:03:52,031 --> 00:03:53,965
 and active control group
 did not.

93
00:03:53,966 --> 00:03:55,566
 We didn't do brain scans,

94
00:03:55,567 --> 00:03:57,568
 but we can speculate
 that there were changes

95
00:03:57,569 --> 00:04:00,605
 to the experimental group's
 hippocampi.

96
00:04:00,606 --> 00:04:03,908
So what are we going to be
doing to me here?

97
00:04:03,909 --> 00:04:05,843
So we're gonna do everything
that we've done before

98
00:04:05,844 --> 00:04:07,011
in our past studies,

99
00:04:07,012 --> 00:04:08,646
except we're gonna add
two new things.

100
00:04:08,647 --> 00:04:11,449
Uh, the first is we're gonna
add some brain scans,

101
00:04:11,450 --> 00:04:12,617
so we're gonna see
if we see a change

102
00:04:12,618 --> 00:04:14,452
in the structural side
of your hippocampus.

103
00:04:14,453 --> 00:04:16,587
We've never actually looked
at somebody's brain scans

104
00:04:16,588 --> 00:04:18,523
before and after
they played video games.

105
00:04:18,524 --> 00:04:19,991
And the second thing
we're actually gonna do

106
00:04:19,992 --> 00:04:22,460
is we're gonna put you through
a real-world space.

107
00:04:22,461 --> 00:04:25,330
You're gonna be the rat
in a maze.

108
00:04:25,331 --> 00:04:27,865
[Michael]
 This truly untested territory.

109
00:04:27,866 --> 00:04:30,468
 The effect of video-gaming
 on spatial memory

110
00:04:30,469 --> 00:04:32,570
 has never been studied
 in a physical environment

111
00:04:32,571 --> 00:04:35,340
 on a scale this big
 and comprehensive.

112
00:04:35,341 --> 00:04:37,442
 I will have to navigate my way

113
00:04:37,443 --> 00:04:39,944
 through a 3,600-square-foot
 physical maze.

114
00:04:39,945 --> 00:04:43,681
 Will playing video games
 improve my mental skills

115
00:04:43,682 --> 00:04:45,016
 in the real world?

116
00:04:45,017 --> 00:04:47,352
 If so, society
 may start looking

117
00:04:47,353 --> 00:04:49,454
 at gaming in a whole new way.

118
00:04:49,455 --> 00:04:51,456
 First, we had to get

119
00:04:51,457 --> 00:04:53,791
 baseline measurements
 of my brain.

120
00:04:53,792 --> 00:04:55,393
Welcome to the MRI Center.

121
00:04:55,394 --> 00:04:57,628
We're gonna be taking a whole
series of scans of you,

122
00:04:57,629 --> 00:04:58,996
as the before scan

123
00:04:58,997 --> 00:05:01,366
to then see what's gonna be
happening to your brain

124
00:05:01,367 --> 00:05:02,834
as a function of actually
doing the gaming.

125
00:05:02,835 --> 00:05:04,769
Cool. What kind of things
are you looking for?

126
00:05:04,770 --> 00:05:06,938
Changes in the size and shape
of your hippocampus

127
00:05:06,939 --> 00:05:10,007
and also changes
in the connectivity
between brain regions.

128
00:05:10,008 --> 00:05:13,378
[Michael] My brain was scanned
 using diffusion MRI,

129
00:05:13,379 --> 00:05:14,645
 with a special emphasis

130
00:05:14,646 --> 00:05:17,648
 on my all-important
 hippocampus.

131
00:05:17,649 --> 00:05:18,916
[music playing]

132
00:05:18,917 --> 00:05:20,385
[Craig] So this first test

133
00:05:20,386 --> 00:05:22,153
is a standard memory test
that we do.

134
00:05:22,154 --> 00:05:24,522
It's called an object
recognition memory test.

135
00:05:24,523 --> 00:05:26,457
[Michael]
 This test began by showing me

136
00:05:26,458 --> 00:05:28,993
 a series of random objects.

137
00:05:28,994 --> 00:05:32,897
 I did my best to commit
 every one of them to memory.

138
00:05:32,898 --> 00:05:33,931
Okay.

139
00:05:33,932 --> 00:05:35,566
- Finished.
- All right.

140
00:05:35,567 --> 00:05:36,801
What we're gonna do now though,
is we're gonna test

141
00:05:36,802 --> 00:05:39,771
- your memory for those objects.
- Okay.

142
00:05:39,772 --> 00:05:41,572
And this is actually
where it starts to tap

143
00:05:41,573 --> 00:05:43,541
into the hippocampus
that we know is so important

144
00:05:43,542 --> 00:05:44,943
for things
like spatial memory.

145
00:05:44,944 --> 00:05:48,179
 [Michael] This time, I had to
 view another series of objects

146
00:05:48,180 --> 00:05:50,148
 and identify
 any that were identical

147
00:05:50,149 --> 00:05:51,983
 to the ones
 I'd seen previously.

148
00:05:51,984 --> 00:05:55,119
 The catch, some of the items
 were very similar

149
00:05:55,120 --> 00:05:56,187
 to the earlier ones,

150
00:05:56,188 --> 00:05:58,689
 but not exactly the same.

151
00:05:58,690 --> 00:06:00,525
 This tested my memory
 for details

152
00:06:00,526 --> 00:06:02,093
 and very slight changes.

153
00:06:02,094 --> 00:06:03,395
Okay.

154
00:06:03,396 --> 00:06:05,797
[Michael] Next up, a virtual
 version of a water maze

155
00:06:05,798 --> 00:06:08,166
 normally used by rodents
 and mice.

156
00:06:08,167 --> 00:06:11,068
[Dane] The idea is that
you are trying to locate

157
00:06:11,069 --> 00:06:13,704
a hidden platform
in a pool of water.

158
00:06:13,705 --> 00:06:14,672
[Michael] Oh, man,

159
00:06:14,673 --> 00:06:16,941
I'm so glad I'm not a lab rat.

160
00:06:16,942 --> 00:06:19,811
This task really put my spatial
 memory to the test.

161
00:06:19,812 --> 00:06:22,847
 I had to find the same
 invisible underwater platform

162
00:06:22,848 --> 00:06:24,615
 over and over again,

163
00:06:24,616 --> 00:06:27,552
 using only the shapes
 of the mountains as my guide,

164
00:06:27,553 --> 00:06:29,720
 but at least I didn't have
 to get wet.

165
00:06:29,721 --> 00:06:31,055
Hey.

166
00:06:31,056 --> 00:06:32,757
That was more difficult
than I expected.

167
00:06:32,758 --> 00:06:35,560
[Craig] These are the sorts of
tasks that we've been able to do

168
00:06:35,561 --> 00:06:37,094
because we can put them
on a computer.

169
00:06:37,095 --> 00:06:38,496
And we're gonna revisit them

170
00:06:38,497 --> 00:06:39,897
after you've done
the video games.

171
00:06:39,898 --> 00:06:43,134
But we also have a really
great opportunity here now

172
00:06:43,135 --> 00:06:46,471
to be able to try to take it out
of just doing it on the computer

173
00:06:46,472 --> 00:06:48,473
and actually get it
into the real world.

174
00:06:48,474 --> 00:06:49,740
Have you guys done
this before?

175
00:06:49,741 --> 00:06:52,143
No. We don't get to do
this kind of thing.

176
00:06:52,144 --> 00:06:54,879
- Well, welcome
to the Mind Field. 
- Awesome.

177
00:06:54,880 --> 00:07:00,618
[music playing]

178
00:07:00,619 --> 00:07:02,153
[Michael]
So this is it? It's huge.

179
00:07:02,154 --> 00:07:04,021
[Craig] This is what
we brought you here for,

180
00:07:04,022 --> 00:07:06,858
to have a real-world test
of memory.

181
00:07:06,859 --> 00:07:09,727
You're gonna be
a lab rat in a maze.

182
00:07:09,728 --> 00:07:11,028
So this is a big first for us.

183
00:07:11,029 --> 00:07:12,897
It's a big first really
for memory research.

184
00:07:12,898 --> 00:07:14,232
[Michael]
So how do you think
that'll effect

185
00:07:14,233 --> 00:07:16,667
what you guys
have already seen,

186
00:07:16,668 --> 00:07:18,903
which is
that moving around
in a 3D environment

187
00:07:18,904 --> 00:07:22,640
in a video game can
actually physically
affect your brain?

188
00:07:22,641 --> 00:07:24,909
[Dane] We would expect that
if we can somehow, kind of,

189
00:07:24,910 --> 00:07:26,944
train your hippocampus
to be better
at spatial memory

190
00:07:26,945 --> 00:07:29,247
and spatial navigation,
we would see improvements

191
00:07:29,248 --> 00:07:30,148
in some of these areas.

192
00:07:30,149 --> 00:07:31,916
And it's not just
gonna be running a maze.

193
00:07:31,917 --> 00:07:34,552
You've got objects
embedded inside here,

194
00:07:34,553 --> 00:07:37,622
and we're gonna be testing
your ability to remember
where everything is.

195
00:07:37,623 --> 00:07:41,559
Oh, and build a mental map
of whatever's inside there.

196
00:07:41,560 --> 00:07:42,693
[Craig]
So you have five minutes.

197
00:07:42,694 --> 00:07:44,262
Go on in, explore,
learn the maze,

198
00:07:44,263 --> 00:07:45,563
and learn the objects.

199
00:07:45,564 --> 00:07:48,065
Go.

200
00:07:48,066 --> 00:07:50,234
[Michael] Because the walls
 were six feet tall,

201
00:07:50,235 --> 00:07:52,870
 I was unable to get
 a bird's-eye view.

202
00:07:52,871 --> 00:07:55,706
 My task was to create
 a spatial memory

203
00:07:55,707 --> 00:07:59,110
 based entirely on the angles
 and turns of the white walls

204
00:07:59,111 --> 00:08:00,578
 I could see at eye level,

205
00:08:00,579 --> 00:08:02,747
 and a few tall trees
 and light poles

206
00:08:02,748 --> 00:08:04,916
 outside the maze.

207
00:08:04,917 --> 00:08:06,984
Okay. So I've oriented myself.

208
00:08:06,985 --> 00:08:08,252
The entrance is that way.

209
00:08:08,253 --> 00:08:10,254
There's an exit over there.

210
00:08:10,255 --> 00:08:13,090
I'm considering this the right
side, that the left side.

211
00:08:13,091 --> 00:08:15,259
I've got a vague idea
of where things are

212
00:08:15,260 --> 00:08:18,663
that I feel like exist
along the outside edge,

213
00:08:18,664 --> 00:08:21,832
but I don't know about
a lot of the stuff inside.

214
00:08:21,833 --> 00:08:23,701
[Craig] And time.

215
00:08:23,702 --> 00:08:25,903
All right. So
now you've had a chance
to explore the maze,

216
00:08:25,904 --> 00:08:27,972
find out where
the objects are.

217
00:08:27,973 --> 00:08:29,340
Now we're gonna test
your memory...

218
00:08:29,341 --> 00:08:30,308
- Okay.
- ...and we'll be timing you

219
00:08:30,309 --> 00:08:30,976
and seeing where you go.

220
00:08:30,977 --> 00:08:31,943
- Okay.
- Okay. You ready?

221
00:08:31,944 --> 00:08:33,344
- I'm ready.
- [Dane] So your first object

222
00:08:33,345 --> 00:08:34,678
is the bicycle pump.

223
00:08:34,679 --> 00:08:38,081
- Go.
- [Michael] Pump. Okay.

224
00:08:38,082 --> 00:08:40,817
[Michael] Pump was just
always making right turns,

225
00:08:40,818 --> 00:08:45,256
hugging the rightmost
part of-- pump.

226
00:08:45,257 --> 00:08:47,758
Ha ha! Yes. Easy. Okay.

227
00:08:47,759 --> 00:08:50,027
Now, I guess I do the opposite
to get out.

228
00:08:50,028 --> 00:08:53,965
Left side-- yup,
I think I should make this turn.

229
00:08:53,966 --> 00:08:57,201
There it is.

230
00:08:57,202 --> 00:08:58,636
- You asked for a pump?
- All right.

231
00:08:58,637 --> 00:09:01,005
Item two, the basketball.

232
00:09:01,006 --> 00:09:03,341
[Michael] Later, Dr. Stark
 and Dr. Clemenson

233
00:09:03,342 --> 00:09:05,042
 would evaluate my performance

234
00:09:05,043 --> 00:09:07,612
 on how fast I was,
 the number of errors I made,

235
00:09:07,613 --> 00:09:10,982
 and whether I took the most
 optimal route each time.

236
00:09:10,983 --> 00:09:11,683
[Craig] And time.

237
00:09:11,684 --> 00:09:13,951
Third item
is the cat. Go.

238
00:09:13,952 --> 00:09:16,287
[Michael]
Here kitty, kitty, kitty.

239
00:09:16,288 --> 00:09:17,755
Got it.

240
00:09:17,756 --> 00:09:18,990
[Dane] The fourth item
is the pillow.

241
00:09:18,991 --> 00:09:20,825
[Michael]
Retracing my steps.

242
00:09:20,826 --> 00:09:22,293
- [Dane] The crayon. 
- [Michael] Easy.

243
00:09:22,294 --> 00:09:23,828
- [Dane] The book. 
- [Michael] Okay.

244
00:09:23,829 --> 00:09:24,996
[Dane] The boot.

245
00:09:24,997 --> 00:09:26,931
Last item
is the water bottle.

246
00:09:26,932 --> 00:09:30,901
- Go.
- [Michael] Water bottle.

247
00:09:30,902 --> 00:09:32,737
I think--

248
00:09:32,738 --> 00:09:33,738
by--

249
00:09:33,739 --> 00:09:38,075
Yeah, it was back here.

250
00:09:38,076 --> 00:09:41,846
Maybe on the other side
of this wall.

251
00:09:41,847 --> 00:09:44,048
No? Oh, shoot.

252
00:09:44,049 --> 00:09:46,317
Okay. Maybe it's down here.

253
00:09:46,318 --> 00:09:47,418
Oh, wait.

254
00:09:47,419 --> 00:09:50,388
That's-- no?

255
00:09:50,389 --> 00:09:52,189
That's the central cube.

256
00:09:52,190 --> 00:09:54,191
It was down some sort of...

257
00:09:54,192 --> 00:09:58,362
a long corridor like this
in this area.

258
00:09:58,363 --> 00:10:00,197
Oh, man.

259
00:10:00,198 --> 00:10:02,700
[Michael] Until this point,
 things had gone pretty well,

260
00:10:02,701 --> 00:10:05,169
 but now it felt like
 my hippocampus was failing me.

261
00:10:05,170 --> 00:10:07,071
 With most of the items
 now gone,

262
00:10:07,072 --> 00:10:08,339
 I couldn't use them
 for reference,

263
00:10:08,340 --> 00:10:10,941
 and it was difficult
 to distinguish the differences

264
00:10:10,942 --> 00:10:12,810
 between the various
 white corridors.

265
00:10:12,811 --> 00:10:13,978
Oh, dang it.

266
00:10:13,979 --> 00:10:15,846
Oh, what about through--

267
00:10:15,847 --> 00:10:17,448
Got it.

268
00:10:17,449 --> 00:10:20,384
- Bottle coming up.
- [Craig] All right.
There you go.

269
00:10:20,385 --> 00:10:22,219
- [Michael] Got it. Nice.
- That one was a little
tougher, huh?

270
00:10:22,220 --> 00:10:23,821
[Michael]
Yeah, it was tougher.

271
00:10:23,822 --> 00:10:25,356
- So we found all eight objects.
- Yup.

272
00:10:25,357 --> 00:10:27,224
[Dane] Now, we're gonna make it
a little bit more difficult.

273
00:10:27,225 --> 00:10:28,926
So we're gonna move
onto the next phase

274
00:10:28,927 --> 00:10:30,227
and that's gonna be
from the other side.

275
00:10:30,228 --> 00:10:32,063
[Craig] Navigating
the maze in reverse

276
00:10:32,064 --> 00:10:35,232
will be an even bigger test
of your spatial memory.

277
00:10:35,233 --> 00:10:38,235
We're gonna give you
a list of four things to get,

278
00:10:38,236 --> 00:10:39,170
in order.

279
00:10:39,171 --> 00:10:41,472
[Dane] So the first sequence
is the book,

280
00:10:41,473 --> 00:10:43,374
the bottle, the crayon,

281
00:10:43,375 --> 00:10:44,475
and the boot.

282
00:10:44,476 --> 00:10:46,310
- Go.
- [Michael] Book.

283
00:10:46,311 --> 00:10:47,812
I think--

284
00:10:47,813 --> 00:10:52,283
That's the ball.

285
00:10:52,284 --> 00:10:53,084
Got it.

286
00:10:53,085 --> 00:10:54,919
Oh, yeah, bottle
was that hard one,

287
00:10:54,920 --> 00:10:58,489
but now I remember
which alley to go down.

288
00:10:58,490 --> 00:10:59,724
Perfect.

289
00:10:59,725 --> 00:11:01,992
Crayon.

290
00:11:01,993 --> 00:11:04,228
Boot. Don't want that.

291
00:11:04,229 --> 00:11:04,896
Here it is.

292
00:11:04,897 --> 00:11:06,931
Okay. Now, I need the boot.

293
00:11:06,932 --> 00:11:08,065
Oh, I just saw the boot,

294
00:11:08,066 --> 00:11:10,334
but how did I--

295
00:11:10,335 --> 00:11:14,138
Got it.
I'm done. I'm coming back.

296
00:11:14,139 --> 00:11:15,306
- Got them.
- [Craig] All right.

297
00:11:15,307 --> 00:11:16,373
So then the next four.

298
00:11:16,374 --> 00:11:18,042
[Dane] The pump, the pillow,

299
00:11:18,043 --> 00:11:19,944
the basketball, and the cat.

300
00:11:19,945 --> 00:11:23,314
- [Craig] All right. Excellent.
- [Dane] All right. Nice job.

301
00:11:23,315 --> 00:11:24,482
[Michael] Okay.
So that was really fun,

302
00:11:24,483 --> 00:11:26,517
but I can't be
the only subject.

303
00:11:26,518 --> 00:11:28,786
This experiment
could use a control.

304
00:11:28,787 --> 00:11:30,521
How else will we know that me,
enriching my life

305
00:11:30,522 --> 00:11:32,456
with daily
video game playing,

306
00:11:32,457 --> 00:11:35,392
really causes a change
in my spatial memory, right?

307
00:11:35,393 --> 00:11:37,161
Well, luckily for that,

308
00:11:37,162 --> 00:11:39,063
we've got a nice
matched control.

309
00:11:39,064 --> 00:11:40,498
Guys similar to me.

310
00:11:40,499 --> 00:11:41,966
Okay, one of them
has too much hair,

311
00:11:41,967 --> 00:11:43,400
but you guys look good.

312
00:11:43,401 --> 00:11:45,236
- You ready?
- [all] Ready.

313
00:11:45,237 --> 00:11:46,804
[Michael] In every experiment,

314
00:11:46,805 --> 00:11:48,506
 it's important to have
 a control group.

315
00:11:48,507 --> 00:11:51,108
 My look-alikes had to go
 through the exact same tests

316
00:11:51,109 --> 00:11:52,810
 as I did in the maze

317
00:11:52,811 --> 00:11:54,445
 to establish
 their individual baselines.

318
00:11:54,446 --> 00:11:55,713
 The difference would be
 that they would play

319
00:11:55,714 --> 00:11:58,849
 absolutely no video games
 for the next 10 days.

320
00:11:58,850 --> 00:12:00,451
 Then any change
 in my performance

321
00:12:00,452 --> 00:12:03,420
 would be compared against
 any changes in theirs.

322
00:12:03,421 --> 00:12:06,957
[music playing]

323
00:12:06,958 --> 00:12:09,193
 Next, I began
 my gaming regimen,

324
00:12:09,194 --> 00:12:11,028
 starting
 from an ideal baseline,

325
00:12:11,029 --> 00:12:12,930
 since I haven't played
 video games

326
00:12:12,931 --> 00:12:14,232
 since I was a kid.

327
00:12:14,233 --> 00:12:18,035
 Would ten days of gaming
 really make a difference?

328
00:12:18,036 --> 00:12:28,245
[music playing]

329
00:12:28,246 --> 00:12:31,282
Technology isn't just affecting
the way we remember things.

330
00:12:31,283 --> 00:12:34,552
- [whirring]
- It's also playing
with the empathy

331
00:12:34,553 --> 00:12:37,488
and social circuits
of our brains.

332
00:12:37,489 --> 00:12:38,989
In fact, in many cases,

333
00:12:38,990 --> 00:12:41,158
we are more comfortable
relating to machines

334
00:12:41,159 --> 00:12:42,560
than we are to people.

335
00:12:42,561 --> 00:12:45,029
Just think about how much
we care about our phones.

336
00:12:45,030 --> 00:12:47,898
Roboticist
and MIT Media Lab alum,

337
00:12:47,899 --> 00:12:50,201
Alex Reben,
invented the BlabDroid,

338
00:12:50,202 --> 00:12:52,570
 a miniature robot equipped
 with a camera

339
00:12:52,571 --> 00:12:54,138
 and an innocent little voice

340
00:12:54,139 --> 00:12:55,506
 that asks
 very personal questions

341
00:12:55,507 --> 00:12:57,441
 of unsuspecting pedestrians.

342
00:12:57,442 --> 00:13:00,177
 [BlabDroid] If you could
 take back one mistake,

343
00:13:00,178 --> 00:13:01,445
 what would it be?

344
00:13:01,446 --> 00:13:04,315
Oh, gosh.
I only get to take back one?

345
00:13:04,316 --> 00:13:05,983
[Michael]
 The majority of people

346
00:13:05,984 --> 00:13:07,551
 instantly shared
 intimate details.

347
00:13:07,552 --> 00:13:09,920
[BlabDroid] Tell me something
 that you've never told

348
00:13:09,921 --> 00:13:11,255
 a stranger before.

349
00:13:11,256 --> 00:13:13,357
I'm scared
I won't be able to love

350
00:13:13,358 --> 00:13:18,095
and to let myself go
in a love relationship.

351
00:13:18,096 --> 00:13:19,263
[Michael] In many ways,

352
00:13:19,264 --> 00:13:21,365
 we are more comfortable
 talking to a machine

353
00:13:21,366 --> 00:13:23,033
 than to a human.

354
00:13:23,034 --> 00:13:25,603
But what about talking
through a machine?

355
00:13:25,604 --> 00:13:27,538
I mean, it's often easier to say

356
00:13:27,539 --> 00:13:29,640
difficult things
to a person via text

357
00:13:29,641 --> 00:13:31,475
instead of in real life,
isn't it?

358
00:13:31,476 --> 00:13:33,644
Well, what if the person
on the other end

359
00:13:33,645 --> 00:13:36,347
wasn't a friend
or a significant other,

360
00:13:36,348 --> 00:13:38,649
but was a therapist?

361
00:13:38,650 --> 00:13:41,185
 A mental healthcare startup
 called Talkspace

362
00:13:41,186 --> 00:13:43,420
 allows adult users
 who pay a weekly fee

363
00:13:43,421 --> 00:13:45,556
 to text therapists for advice.

364
00:13:45,557 --> 00:13:48,058
[woman] At Talkspace,
 we believe that therapy

365
00:13:48,059 --> 00:13:50,160
 should be anonymous,
 stigma-free,

366
00:13:50,161 --> 00:13:53,931
 simple, affordable,
 and comfortable.

367
00:13:53,932 --> 00:13:56,166
Texting can give users
the distance they need

368
00:13:56,167 --> 00:13:57,534
to be open and honest.

369
00:13:57,535 --> 00:14:00,671
And messages can be sent
when the user wants,

370
00:14:00,672 --> 00:14:02,039
 not during an appointment

371
00:14:02,040 --> 00:14:03,607
 or business hours only.

372
00:14:03,608 --> 00:14:04,675
[woman] Talkspace,

373
00:14:04,676 --> 00:14:08,178
 therapy for how we live today.

374
00:14:08,179 --> 00:14:09,513
[Michael] How am I?

375
00:14:09,514 --> 00:14:14,351
Better now that my phone
is working.

376
00:14:14,352 --> 00:14:19,423
Sometimes, however,
we aren't looking for
technology to comfort us.

377
00:14:19,424 --> 00:14:24,695
we're finding ourselves
wanting to comfort technology.

378
00:14:24,696 --> 00:14:27,064
This is a ROBOTIS OP2.

379
00:14:27,065 --> 00:14:30,167
Cute little fellow, isn't he?

380
00:14:30,168 --> 00:14:32,069
So how did that make you feel?

381
00:14:32,070 --> 00:14:33,103
Bad?

382
00:14:33,104 --> 00:14:34,305
Well, why?

383
00:14:34,306 --> 00:14:36,206
Robots are just machines,

384
00:14:36,207 --> 00:14:38,342
metal and wires
and computer chips.

385
00:14:38,343 --> 00:14:42,046
But we spend a lot of time
with technology.

386
00:14:42,047 --> 00:14:43,580
We depend on technology,

387
00:14:43,581 --> 00:14:45,149
and we care about it.

388
00:14:45,150 --> 00:14:46,717
But the degree to which
we empathize with it

389
00:14:46,718 --> 00:14:48,953
depends on context.

390
00:14:48,954 --> 00:14:52,623
[music playing]

391
00:14:52,624 --> 00:14:54,959
[Michael]
 Recently, my Vsauce office

392
00:14:54,960 --> 00:14:56,627
 was invaded by bugs--

393
00:14:56,628 --> 00:14:58,495
 robot hexbugs, that is.

394
00:14:58,496 --> 00:15:01,165
 These bugs are made
 of plastic, metal,

395
00:15:01,166 --> 00:15:03,033
 and electronic circuitry.

396
00:15:03,034 --> 00:15:04,201
 They aren't alive.

397
00:15:04,202 --> 00:15:05,569
 But could certain conditions

398
00:15:05,570 --> 00:15:08,706
 cause them to inspire
 empathy in humans?

399
00:15:08,707 --> 00:15:11,275
 A 2015 MIT study

400
00:15:11,276 --> 00:15:14,111
 found that giving a robot
 movement, a name,

401
00:15:14,112 --> 00:15:15,346
 and a personal backstory

402
00:15:15,347 --> 00:15:17,481
 tends to increase
 its anthropomorphic effect,

403
00:15:17,482 --> 00:15:19,516
 which can lead to
 an emotional connection

404
00:15:19,517 --> 00:15:20,718
 with humans.

405
00:15:20,719 --> 00:15:22,586
 We decided to see this in
 action.

406
00:15:22,587 --> 00:15:25,589
- Thank you for your help today.
- Of course. Pleasure.

407
00:15:25,590 --> 00:15:26,724
[Michael]
 In our demonstration,

408
00:15:26,725 --> 00:15:29,026
 our subjects think
 they're focus testing

409
00:15:29,027 --> 00:15:31,161
a new user-friendly technology.

410
00:15:31,162 --> 00:15:34,164
 In this case,
they're given a lifeless hexbug

411
00:15:34,165 --> 00:15:36,066
 and asked to describe it.

412
00:15:36,067 --> 00:15:38,202
This thing kind of
looks like a bug,

413
00:15:38,203 --> 00:15:39,536
only I don't know
what it does.

414
00:15:39,537 --> 00:15:41,105
It has a switch on the bottom.

415
00:15:41,106 --> 00:15:42,172
It's light.

416
00:15:42,173 --> 00:15:43,307
It's sort of a rectangle,

417
00:15:43,308 --> 00:15:45,342
but the ends
are like hexagons.

418
00:15:45,343 --> 00:15:47,478
[Michael] Then it was time
 to test their empathy.

419
00:15:47,479 --> 00:15:49,146
Now, Karina,
what I would
like you to do now

420
00:15:49,147 --> 00:15:52,216
is place the item
in the middle
of that block.

421
00:15:52,217 --> 00:15:54,151
There's a magnet
that will hold it.

422
00:15:54,152 --> 00:15:57,354
And I would like for you
to take this mallet

423
00:15:57,355 --> 00:15:58,422
and please smash it.

424
00:15:58,423 --> 00:16:02,760
Yeah. Really? Okay.
This is cool.

425
00:16:02,761 --> 00:16:05,262
[Michael] Our participants
 demonstrated no resistance

426
00:16:05,263 --> 00:16:06,764
 to smashing
 this lifeless object.

427
00:16:06,765 --> 00:16:10,434
 Many of them
 even seemed to enjoy it.

428
00:16:10,435 --> 00:16:12,169
Do you feel bad
for breaking it?

429
00:16:12,170 --> 00:16:15,072
Not really.
I felt indifferent to it.

430
00:16:15,073 --> 00:16:17,174
Not really 'cause
it wasn't real. [laughing]

431
00:16:17,175 --> 00:16:18,476
Not really.

432
00:16:18,477 --> 00:16:20,511
[Michael] While these subjects
 exhibited no empathy

433
00:16:20,512 --> 00:16:22,312
 to the inanimate bugs,

434
00:16:22,313 --> 00:16:25,049
look what happened when we gave
 the exact same bugs

435
00:16:25,050 --> 00:16:26,750
 names and movement.

436
00:16:26,751 --> 00:16:28,819
This is Margaret. Okay.

437
00:16:28,820 --> 00:16:30,220
I'm gonna place Margaret
down here.

438
00:16:30,221 --> 00:16:31,755
I just want you
to take a moment

439
00:16:31,756 --> 00:16:33,457
to watch Margaret,
all right?

440
00:16:33,458 --> 00:16:35,659
And you could feel free
to pick her up.

441
00:16:35,660 --> 00:16:37,594
She's really well-behaved.

442
00:16:37,595 --> 00:16:39,496
- She's honestly one
of our favorites.
- [woman, laughing] Okay.

443
00:16:39,497 --> 00:16:42,566
So how would you describe
Margaret's personality?

444
00:16:42,567 --> 00:16:46,370
A little erratic right now,

445
00:16:46,371 --> 00:16:48,405
but I think if I pick her up,
she calms down.

446
00:16:48,406 --> 00:16:50,441
[Michael] Notice
 how the subject has already

447
00:16:50,442 --> 00:16:53,744
 anthropomorphized the object,
 referring to it as "she."

448
00:16:53,745 --> 00:16:55,479
Maybe she feeds off
my energy.

449
00:16:55,480 --> 00:16:57,414
Could be.

450
00:16:57,415 --> 00:16:58,615
Go towards the light.

451
00:16:58,616 --> 00:17:00,117
Go towards the middle.

452
00:17:00,118 --> 00:17:01,518
[Michael] Do you think
Margaret likes you?

453
00:17:01,519 --> 00:17:03,720
Yeah, maybe that's why
she's doing this,

454
00:17:03,721 --> 00:17:05,289
and maybe when I go
like that,

455
00:17:05,290 --> 00:17:07,758
she doesn't act
all erratic.

456
00:17:07,759 --> 00:17:09,226
That's Aaron.

457
00:17:09,227 --> 00:17:10,594
Hi, Aaron.

458
00:17:10,595 --> 00:17:12,362
He can be a bit
of a pistol.

459
00:17:12,363 --> 00:17:13,864
- No way.
- Yes.

460
00:17:13,865 --> 00:17:17,366
It really depends on
who's holding him.

461
00:17:17,367 --> 00:17:18,735
[laughing]

462
00:17:18,736 --> 00:17:21,305
Oh, yeah.
He's got a lot of energy.

463
00:17:21,306 --> 00:17:24,107
Aaron, hi.

464
00:17:24,108 --> 00:17:26,175
[Michael] Now that you've
interacted with Eli a bit more,

465
00:17:26,176 --> 00:17:28,178
how would you describe
his personality?

466
00:17:28,179 --> 00:17:29,780
Probably he's just nervous.
He's scared.

467
00:17:29,781 --> 00:17:32,316
- He doesn't know
what's going on.
- Hey, Joe.

468
00:17:32,317 --> 00:17:33,851
[Michael] Will these subjects
 be just as willing

469
00:17:33,852 --> 00:17:35,752
 to smash their bugs?

470
00:17:35,753 --> 00:17:40,190
Amy, I'm gonna place
Margaret right here,

471
00:17:40,191 --> 00:17:42,860
and then I
would like for you
to take this mallet,

472
00:17:42,861 --> 00:17:46,530
and I'd like you
to smash it.

473
00:17:46,531 --> 00:17:47,631
No.

474
00:17:47,632 --> 00:17:50,400
I don't wanna hurt it.

475
00:17:50,401 --> 00:17:53,537
Just take this mallet
and smash Aaron.

476
00:17:53,538 --> 00:17:58,509
[music playing]

477
00:17:58,510 --> 00:18:00,777
[Michael]
I'm gonna ask you
to take this mallet,

478
00:18:00,778 --> 00:18:05,215
and I'd like for you
to smash it.

479
00:18:05,216 --> 00:18:07,551
Smash it?

480
00:18:07,552 --> 00:18:08,685
Hit it?

481
00:18:08,686 --> 00:18:09,920
And, Chris...

482
00:18:09,921 --> 00:18:11,355
You want me to kill Joe?

483
00:18:11,356 --> 00:18:12,489
Please smash Joe.

484
00:18:12,490 --> 00:18:14,658
Ugh.

485
00:18:14,659 --> 00:18:17,427
Joe, I'm sorry.

486
00:18:17,428 --> 00:18:20,297
Oh, Joe. Joe.

487
00:18:20,298 --> 00:18:27,905
[music playing]

488
00:18:27,906 --> 00:18:32,910
Now, how did it feel
to smash Aaron?

489
00:18:32,911 --> 00:18:36,547
It didn't feel good,
you know,

490
00:18:36,548 --> 00:18:38,515
after spending time with him

491
00:18:38,516 --> 00:18:39,816
and getting to know him.

492
00:18:39,817 --> 00:18:41,251
Even though
it's lifeless

493
00:18:41,252 --> 00:18:43,320
and doesn't have a mind
of its own,

494
00:18:43,321 --> 00:18:44,488
instantly,
I grew attached to it,

495
00:18:44,489 --> 00:18:45,889
because when I put it
in my hand,

496
00:18:45,890 --> 00:18:46,957
I felt its energy.

497
00:18:46,958 --> 00:18:48,725
I'm sorry, Joe.

498
00:18:48,726 --> 00:18:50,627
- Do you feel bad?
- I do.

499
00:18:50,628 --> 00:18:51,695
I do feel bad about Joe.

500
00:18:51,696 --> 00:18:53,730
He was pretty cool.

501
00:18:53,731 --> 00:18:55,465
Oh, he's back.

502
00:18:55,466 --> 00:18:56,533
He's back?

503
00:18:56,534 --> 00:18:58,335
Pump, pump.

504
00:18:58,336 --> 00:19:00,204
Would you smash him again
to make sure

505
00:19:00,205 --> 00:19:01,939
he doesn't come back?

506
00:19:01,940 --> 00:19:03,740
- No.
- Why not?

507
00:19:03,741 --> 00:19:05,609
I mean, he survived it.
He survived it once.

508
00:19:05,610 --> 00:19:08,212
I'm not gonna do it again.

509
00:19:08,213 --> 00:19:09,947
[Michael] Clearly,
it doesn't take much for humans

510
00:19:09,948 --> 00:19:12,950
 to become emotionally
 attached to technology.

511
00:19:12,951 --> 00:19:15,819
 But after my ten days
 of video-gaming--

512
00:19:15,820 --> 00:19:17,654
Nice.

513
00:19:17,655 --> 00:19:20,591
 I was about to find out
 if technology had

514
00:19:20,592 --> 00:19:22,326
 affected my spatial memory

515
00:19:22,327 --> 00:19:24,428
 and my physical brain.

516
00:19:24,429 --> 00:19:25,563
[music playing]

517
00:19:25,564 --> 00:19:27,497
 [Michael] All right.
 It's been ten days.

518
00:19:27,498 --> 00:19:29,399
Exactly, so we're gonna look
at the difference between

519
00:19:29,400 --> 00:19:31,835
your test ten days ago
and your test now

520
00:19:31,836 --> 00:19:33,370
to see
do we see any change.

521
00:19:33,371 --> 00:19:35,572
[Michael]
 First, I had to retake

522
00:19:35,573 --> 00:19:37,741
 the object recognition
 memory test

523
00:19:37,742 --> 00:19:39,509
and the Morris water maze task,

524
00:19:39,510 --> 00:19:42,412
 both of which had been revised
 with different content

525
00:19:42,413 --> 00:19:43,780
 than they had the last time.

526
00:19:43,781 --> 00:19:45,449
I think I did better.

527
00:19:45,450 --> 00:19:47,484
Dane and I will
analyze all this data
and see how you did.

528
00:19:47,485 --> 00:19:49,987
But now we got to go back
to the full-size maze.

529
00:19:49,988 --> 00:19:54,524
[music playing]

530
00:19:54,525 --> 00:19:56,426
[Craig]
So we've got a new maze.

531
00:19:56,427 --> 00:19:58,662
 Tore down the old one,
 built a new one

532
00:19:58,663 --> 00:20:00,397
 to try to be isomorphic.

533
00:20:00,398 --> 00:20:02,966
 So it has sort of the same
 level of difficulty.

534
00:20:02,967 --> 00:20:04,735
 The same number
 of choice points,

535
00:20:04,736 --> 00:20:06,536
 the same number of turns,

536
00:20:06,537 --> 00:20:09,339
 the same total distance
 to each of one the objects

537
00:20:09,340 --> 00:20:12,709
 to try to have a similar maze,
 but that's new.

538
00:20:12,710 --> 00:20:16,046
Three, two, one, go.

539
00:20:16,047 --> 00:20:17,481
[Michael] Right around here,

540
00:20:17,482 --> 00:20:18,516
we got a bonsai.

541
00:20:18,517 --> 00:20:20,617
 As before,
 I was given five minutes

542
00:20:20,618 --> 00:20:22,486
 to familiarize myself
 with the maze

543
00:20:22,487 --> 00:20:24,688
 and where all
 of the objects were.

544
00:20:24,689 --> 00:20:27,024
Now, this is where I was
before I hugged that wall,

545
00:20:27,025 --> 00:20:28,959
so if I hug
the second right wall

546
00:20:28,960 --> 00:20:31,561
and stay all the way right,
a vase.

547
00:20:31,562 --> 00:20:33,463
 Was my hippocampus
 working better?

548
00:20:33,464 --> 00:20:36,033
 At this point,
 it was hard to tell.

549
00:20:36,034 --> 00:20:37,501
Thirty seconds.

550
00:20:37,502 --> 00:20:39,870
I'm not even sure
I've discovered

551
00:20:39,871 --> 00:20:41,938
all the objects hidden here.

552
00:20:41,939 --> 00:20:43,440
And time.

553
00:20:43,441 --> 00:20:45,008
[Michael]
 Then my test began.

554
00:20:45,009 --> 00:20:46,510
First object
is a rubber duck.

555
00:20:46,511 --> 00:20:49,379
- Go.
- Rubber duck was way over here.

556
00:20:49,380 --> 00:20:51,548
Yeah!
How do you like that?

557
00:20:51,549 --> 00:20:52,849
I got a duck.

558
00:20:52,850 --> 00:20:55,385
Second item
is the hat. Go.

559
00:20:55,386 --> 00:20:57,087
[Michael] With this maze,
 I found myself instinctively

560
00:20:57,088 --> 00:20:58,522
 using a different approach.

561
00:20:58,523 --> 00:20:59,924
Top hat.

562
00:20:59,925 --> 00:21:01,925
 Instead of thinking of the
 overall geography of the maze

563
00:21:01,926 --> 00:21:03,593
 like I did last time,

564
00:21:03,594 --> 00:21:06,396
 this time I was remembering
 specific details.

565
00:21:06,397 --> 00:21:09,800
Second right,
hug the turn, got it.

566
00:21:09,801 --> 00:21:11,535
 Literally recalling
 certain corners,

567
00:21:11,536 --> 00:21:13,537
 turns, and straightaways.

568
00:21:13,538 --> 00:21:14,538
Bonsai.

569
00:21:14,539 --> 00:21:15,572
Now blue vase.

570
00:21:15,573 --> 00:21:17,708
Oh, wow.
It's actually a cool vase.

571
00:21:17,709 --> 00:21:21,011
 But would this improve
 my overall performance?

572
00:21:21,012 --> 00:21:22,079
I got you a backpack.

573
00:21:22,080 --> 00:21:23,513
- All right.
- Excellent.

574
00:21:23,514 --> 00:21:25,048
So we've gotten
all the objects.

575
00:21:25,049 --> 00:21:26,483
But, of course, we have
another memory test

576
00:21:26,484 --> 00:21:28,752
that we're gonna do here.

577
00:21:28,753 --> 00:21:30,487
We're gonna go around
to the other side of the maze

578
00:21:30,488 --> 00:21:32,356
and test your memory
from there.

579
00:21:32,357 --> 00:21:33,623
- [Michael] All right. 
- [Dane] So your first sequence

580
00:21:33,624 --> 00:21:35,459
is the blue seahorse
the flashlight,

581
00:21:35,460 --> 00:21:37,794
the rubber duck,
and the bonsai tree.

582
00:21:37,795 --> 00:21:39,363
Go.

583
00:21:39,364 --> 00:21:41,565
[Michael]
 With the multiple item tasks,

584
00:21:41,566 --> 00:21:43,567
 even though I was working
 from the opposite entrance,

585
00:21:43,568 --> 00:21:46,636
 I continued to recall
 various details of the maze,

586
00:21:46,637 --> 00:21:48,105
 which seemed to serve me well.

587
00:21:48,106 --> 00:21:51,441
From there,
it's just a little spiral.

588
00:21:51,442 --> 00:21:52,509
Nice.

589
00:21:52,510 --> 00:21:53,977
[bell dings]

590
00:21:53,978 --> 00:21:56,847
[Dane] All right. Your next
sequence is the blue vase,

591
00:21:56,848 --> 00:21:58,448
the hat, the backpack,

592
00:21:58,449 --> 00:22:00,617
and the baseball glove. 
- [Craig] Hit it.

593
00:22:00,618 --> 00:22:02,152
- And time.
- Awesome.

594
00:22:02,153 --> 00:22:03,620
So how was it?

595
00:22:03,621 --> 00:22:05,989
That was not as hard
as I expected.

596
00:22:05,990 --> 00:22:07,691
- It was about details.
- [Craig] Right.

597
00:22:07,692 --> 00:22:10,494
I was literally
thinking, "Oh, okay.

598
00:22:10,495 --> 00:22:12,028
There's that turn,

599
00:22:12,029 --> 00:22:13,163
and I could do one
or two things.

600
00:22:13,164 --> 00:22:14,664
The glove's
the first one.

601
00:22:14,665 --> 00:22:16,533
The bonsai's the one
even before."

602
00:22:16,534 --> 00:22:19,035
I didn't even
plan that at all.
It just kind of happened.

603
00:22:19,036 --> 00:22:21,905
 [Michael] My look-alikes were
 also tested in the new maze.

604
00:22:21,906 --> 00:22:23,540
Have you been playing
video games?

605
00:22:23,541 --> 00:22:24,908
[all] No, sir.

606
00:22:24,909 --> 00:22:26,877
[Michael] Again,
 their non-gaming condition

607
00:22:26,878 --> 00:22:27,911
 would be the control,

608
00:22:27,912 --> 00:22:29,646
 with my amount of improvement,

609
00:22:29,647 --> 00:22:32,115
 if any,
 measured against theirs.

610
00:22:32,116 --> 00:22:34,918
[Craig] All right.
We're here for scan number two.

611
00:22:34,919 --> 00:22:37,154
[Michael] Finally,
my brain was scanned once again

612
00:22:37,155 --> 00:22:40,056
 to determine whether
 any physical changes
 had occurred.

613
00:22:40,057 --> 00:22:43,059
 Dr. Stark and Dr. Clemenson
 would analyze the MRI

614
00:22:43,060 --> 00:22:46,563
 along with all the other data
 and report their findings.

615
00:22:46,564 --> 00:22:52,202
[music playing]

616
00:22:52,203 --> 00:22:53,537
[Michael] I feel like
my hippocampus

617
00:22:53,538 --> 00:22:55,439
is a little bit bigger.

618
00:22:55,440 --> 00:22:58,708
Yep. Actually, no,
I don't know.

619
00:22:58,709 --> 00:23:01,545
I'm anxious to see
what your results are.

620
00:23:01,546 --> 00:23:02,712
I guess let's start
off first

621
00:23:02,713 --> 00:23:04,815
with the object
recognition task.

622
00:23:04,816 --> 00:23:08,952
And it's important to note
that in our control test
without video-gaming,

623
00:23:08,953 --> 00:23:12,222
 people did not improve
 in this task, but...

624
00:23:12,223 --> 00:23:13,957
your memory got better.

625
00:23:13,958 --> 00:23:15,492
You went up by ten points.

626
00:23:15,493 --> 00:23:17,561
Ten points is actually
20 years' worth

627
00:23:17,562 --> 00:23:20,764
of what happens
to us as we age.

628
00:23:20,765 --> 00:23:21,698
Oh, wow.

629
00:23:21,699 --> 00:23:23,166
That's about what you might see

630
00:23:23,167 --> 00:23:25,702
in someone
who's getting really old,

631
00:23:25,703 --> 00:23:27,571
- but they might go down
by ten points.
- Exactly.

632
00:23:27,572 --> 00:23:29,573
So the second one we did
was the virtual version

633
00:23:29,574 --> 00:23:32,709
of the water maze task,
and you actually performed

634
00:23:32,710 --> 00:23:34,544
30% better the second time
you did it.

635
00:23:34,545 --> 00:23:35,846
Hey, not bad.

636
00:23:35,847 --> 00:23:39,483
I could tell that I was
using better strategies.

637
00:23:39,484 --> 00:23:40,884
Yeah.

638
00:23:40,885 --> 00:23:43,487
- We also had the real maze.
- [Michael] Yeah.

639
00:23:43,488 --> 00:23:44,921
[Craig] As you know,
 we made two mazes.

640
00:23:44,922 --> 00:23:47,057
 Despite our efforts
 to try to equate them,

641
00:23:47,058 --> 00:23:49,659
the second maze was
a little bit more difficult

642
00:23:49,660 --> 00:23:50,827
than the first maze.

643
00:23:50,828 --> 00:23:52,262
If we took a look
at things

644
00:23:52,263 --> 00:23:55,832
like how quickly you
got the objects,

645
00:23:55,833 --> 00:23:57,801
how many errors you made,
and we looked

646
00:23:57,802 --> 00:24:00,003
at the control subjects'
performance in
pre- versus post-.

647
00:24:00,004 --> 00:24:01,738
So on all of them,

648
00:24:01,739 --> 00:24:03,974
 they actually got a little
 bit slower in maze two,

649
00:24:03,975 --> 00:24:06,743
and all but one of them
made more errors.

650
00:24:06,744 --> 00:24:08,245
We took a look
at your performance.

651
00:24:08,246 --> 00:24:10,780
 You didn't get slower
 from maze one to two.

652
00:24:10,781 --> 00:24:12,082
 You actually got faster.

653
00:24:12,083 --> 00:24:13,650
- [Michael] Really? 
- [Craig] And you made the same

654
00:24:13,651 --> 00:24:15,552
exact number of errors.

655
00:24:15,553 --> 00:24:18,522
So they don't improve,
and you did.

656
00:24:18,523 --> 00:24:19,789
 And even though
 this experiment

657
00:24:19,790 --> 00:24:21,791
 had a small number
 of subjects,

658
00:24:21,792 --> 00:24:25,295
 the results are consistent
 with our virtual maze study

659
00:24:25,296 --> 00:24:27,197
 with 70 test subjects.

660
00:24:27,198 --> 00:24:29,099
- [Craig] All right.
- Thank you, video games.

661
00:24:29,100 --> 00:24:30,801
What about
inside my brain?

662
00:24:30,802 --> 00:24:33,003
 [Craig] Inside your brain,
 it's a little tougher
 to really tell.

663
00:24:33,004 --> 00:24:36,640
 We would expect
 that any effect of this

664
00:24:36,641 --> 00:24:38,041
 is going to be small.

665
00:24:38,042 --> 00:24:39,643
 I mean, we couldn't take
 your hippocampus

666
00:24:39,644 --> 00:24:40,978
and make it twice as big

667
00:24:40,979 --> 00:24:43,313
because then it would
have to be pushing
something else out.

668
00:24:43,314 --> 00:24:47,017
So it's just not going
to be a large change.

669
00:24:47,018 --> 00:24:48,585
So where we did find
a difference

670
00:24:48,586 --> 00:24:50,887
is actually in the shape
of the hippocampus.

671
00:24:50,888 --> 00:24:52,822
What we saw is
there were some regions

672
00:24:52,823 --> 00:24:55,659
in the hippocampus
on both sides

673
00:24:55,660 --> 00:24:57,093
 that appear
 to have changed shape

674
00:24:57,094 --> 00:24:58,662
 from day one before gaming

675
00:24:58,663 --> 00:25:00,864
 to day ten after gaming.

676
00:25:00,865 --> 00:25:04,100
What's really surprising to me
is that as an adult,

677
00:25:04,101 --> 00:25:05,802
my brain is still changing.

678
00:25:05,803 --> 00:25:08,305
That makes me wanna take
better care of my brain.

679
00:25:08,306 --> 00:25:09,440
Yes.

680
00:25:09,441 --> 00:25:11,341
Exercise it more,
'cause it is a thing
that can change.

681
00:25:11,342 --> 00:25:16,046
I'm not just stuck
with what I have now, today.

682
00:25:16,047 --> 00:25:19,649
I mean, in all of this,
I think that the big takeaway

683
00:25:19,650 --> 00:25:21,351
is that doing things,

684
00:25:21,352 --> 00:25:23,787
giving your brain
something to learn,

685
00:25:23,788 --> 00:25:26,923
something to do,
something to figure out,

686
00:25:26,924 --> 00:25:28,725
this is what we think
is actually

687
00:25:28,726 --> 00:25:30,827
keeping your brain sharp.

688
00:25:30,828 --> 00:25:33,096
One way to do that is to keep
watching Mind Field.

689
00:25:33,097 --> 00:25:34,798
[Craig] Exactly.

690
00:25:34,799 --> 00:25:40,136
[music playing]

691
00:25:40,137 --> 00:25:43,773
 [Michael] As our relationship
 with technology becomes
 ever stronger,

692
00:25:43,774 --> 00:25:47,811
people are bound to worry about
what it will do to our brains.

693
00:25:47,812 --> 00:25:49,779
Will offloading memory
and computing

694
00:25:49,780 --> 00:25:52,282
to our machines make us dumber?

695
00:25:52,283 --> 00:25:56,720
Will our empathy for machines
have negative consequences

696
00:25:56,721 --> 00:25:59,656
for how we interact
with each other?

697
00:25:59,657 --> 00:26:02,792
Well, let's look back
to another time

698
00:26:02,793 --> 00:26:04,794
a new kind of technology
threatened

699
00:26:04,795 --> 00:26:07,197
to fundamentally
change our brains.

700
00:26:07,198 --> 00:26:08,798
Two and a half thousand
years ago,

701
00:26:08,799 --> 00:26:10,834
the Greek philosopher, Socrates,

702
00:26:10,835 --> 00:26:13,169
worried that
the wide use of writing

703
00:26:13,170 --> 00:26:15,939
would have a negative impact
on people's minds.

704
00:26:15,940 --> 00:26:19,109
He said that writing would,
to quote his student, Plato,

705
00:26:19,110 --> 00:26:20,777
"Create forgetfulness,

706
00:26:20,778 --> 00:26:23,146
because people will
not use their memories.

707
00:26:23,147 --> 00:26:26,249
They will trust the external
written characters

708
00:26:26,250 --> 00:26:29,085
and not remember themselves."

709
00:26:29,086 --> 00:26:30,820
Socrates was right.

710
00:26:30,821 --> 00:26:33,857
Written language did
fundamentally change our brains.

711
00:26:33,858 --> 00:26:36,793
But it's also one of
the cornerstones of everything

712
00:26:36,794 --> 00:26:38,795
modern civilization
has accomplished.

713
00:26:38,796 --> 00:26:41,898
One of the defining
characteristics of being human

714
00:26:41,899 --> 00:26:44,768
is that this is not
the boundary of my body,

715
00:26:44,769 --> 00:26:48,772
and this is not the boundary
of my mind.

716
00:26:48,773 --> 00:26:54,978
And, as always,
thanks for watching.

717
00:26:54,979 --> 00:26:57,082
[theme music playing]

