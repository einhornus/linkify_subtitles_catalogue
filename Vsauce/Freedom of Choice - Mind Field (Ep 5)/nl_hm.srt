1
00:00:11,255 --> 00:00:14,113
Er gaat niets boven
bacon en ei in de ochtend.

2
00:00:14,114 --> 00:00:17,316
Een hartig ontbijt
dat je de hele dag overeind houdt.

3
00:00:17,317 --> 00:00:20,119
De combinatie is zo goed,
dat het al zolang bestaat

4
00:00:20,120 --> 00:00:22,421
als de ingrediënten zelf.

5
00:00:22,422 --> 00:00:25,692
Mensen hielden overduidelijk
van deze voedselcombinatie,

6
00:00:25,693 --> 00:00:29,495
dus ze werden het basisontbijt.

7
00:00:29,496 --> 00:00:31,732
Of is dat niet zo?

8
00:00:31,733 --> 00:00:34,535
Wat als ik je vertel dat de
traditionele combinatie

9
00:00:34,536 --> 00:00:37,470
van bacon en ei
geen onderdeel is van onze geschiedenis,

10
00:00:37,471 --> 00:00:40,172
maar een samenzwering

11
00:00:40,173 --> 00:00:43,175
van de machtigste bedrijven
in onze samenleving?

12
00:00:43,176 --> 00:00:45,612
Het is geen kampioenenontbijt.

13
00:00:45,613 --> 00:01:02,863
Het is een ontbijt voor de kudde.

14
00:01:02,864 --> 00:01:05,497
We denken dat een hoop gewone dingen

15
00:01:05,498 --> 00:01:08,835
zo zijn door onze gezamenlijke vrije keuze

16
00:01:08,836 --> 00:01:10,837
terwijl soms

17
00:01:10,838 --> 00:01:13,607
slechts één of twee mensen

18
00:01:13,608 --> 00:01:16,275
een beslissing namen en zo iets creëerden

19
00:01:16,276 --> 00:01:19,713
wat wordt gezien
als onderdeel van de samenleving,

20
00:01:19,714 --> 00:01:21,682
onderdeel van het leven.

21
00:01:21,683 --> 00:01:24,551
Dit is het ware verhaal
achter bacon en eieren.

22
00:01:24,552 --> 00:01:27,721
En het begint allemaal met Sigmund Freud.

23
00:01:27,722 --> 00:01:31,592
Of eigenlijk, zijn neef Edward Bernays.

24
00:01:31,593 --> 00:01:35,762
Bernays staat bekend als
'de vader van public relations'

25
00:01:35,763 --> 00:01:37,931
een product in een tijd waarin de wereld

26
00:01:37,932 --> 00:01:40,266
klein genoeg was geworden

27
00:01:40,267 --> 00:01:43,469
zodat je een hoop mensen
tegelijk kon manipuleren,

28
00:01:43,470 --> 00:01:45,672
omdat reclame, nieuws

29
00:01:45,673 --> 00:01:49,442
en radio een grote groep mensen
in korte tijd kon bereiken.

30
00:01:49,443 --> 00:01:51,712
Bernays maakte gebruik van de massamedia,

31
00:01:51,713 --> 00:01:54,413
niet om mensen te informeren,

32
00:01:54,414 --> 00:01:57,584
maar om ze te manipuleren.

33
00:01:57,585 --> 00:02:01,454
In de jaren 20 van de vorige eeuw

34
00:02:01,455 --> 00:02:04,591
vroeg Ed Bernays een dokter,
die bij zijn bedrijf werkte,

35
00:02:04,592 --> 00:02:07,961
of een ontbijt zwaar of licht moet zijn,
en de dokter zei:

36
00:02:07,962 --> 00:02:09,930
"Ik denk dat zwaar beter zou zijn."

37
00:02:09,931 --> 00:02:12,331
Bernays zorgde dat die dokter

38
00:02:12,332 --> 00:02:15,502
dit liet bevestigen
door 4.500 andere dokters.

39
00:02:15,503 --> 00:02:18,572
Ze zeiden allemaal dat een zwaar ontbijt

40
00:02:18,573 --> 00:02:21,875
beter was voor de gezondheid
van het Amerikaanse volk.

41
00:02:21,876 --> 00:02:24,343
Vervolgens zorgde Bernays dat kranten

42
00:02:24,344 --> 00:02:27,279
de woorden van deze dokters publiceerden:

43
00:02:27,280 --> 00:02:29,415
dat je dit traditionele ontbijt moet eten.

44
00:02:29,416 --> 00:02:32,251
Hij deed dit echter niet
om de gezondheid te verbeteren.

45
00:02:32,252 --> 00:02:35,756
Hij deed dit omdat
Beech-Nut Packing Company,

46
00:02:35,757 --> 00:02:37,958
een bedrijf dat handelde in bacon,

47
00:02:37,959 --> 00:02:40,794
hem betaalde dit te doen.

48
00:02:40,795 --> 00:02:43,262
De verkoop van bacon steeg

49
00:02:43,263 --> 00:02:46,298
en ik heb nog steeds een brief

50
00:02:46,299 --> 00:02:48,367
van Bartlett Arkell,

51
00:02:48,368 --> 00:02:50,837
directeur van Beech-Nut Packing Company,

52
00:02:50,838 --> 00:02:52,839
om me dat te vertellen.

53
00:02:52,840 --> 00:02:55,307
Wij besloten collectief als land,

54
00:02:55,308 --> 00:02:58,444
dat bacon onze vleeskeuze
was voor het ontbijt.

55
00:02:58,445 --> 00:03:01,731
Maar die keuze hebben we
eigenlijk niet gemaakt.

56
00:03:01,732 --> 00:03:03,282
En dat is slechts ontbijt.

57
00:03:03,283 --> 00:03:06,164
Onze levens zitten vol
met beslissingen waarvan we denken

58
00:03:06,165 --> 00:03:07,654
dat we ze zelf gemaakt hebben.

59
00:03:07,655 --> 00:03:09,074
Maar is dat zo?

60
00:03:09,075 --> 00:03:11,457
Keuzevrijheid

61
00:03:11,458 --> 00:03:13,927
Onze winkels staan tegenwoordig vol

62
00:03:13,928 --> 00:03:16,697
met producten en keuzes.

63
00:03:16,698 --> 00:03:21,035
Is een grote keuze hebben goed of slecht?

64
00:03:21,036 --> 00:03:25,605
[Demonstratie #1 - te veel keuze]

65
00:03:25,606 --> 00:03:28,407
De meeste mensen zeggen
dat ze graag veel keuze hebben.

66
00:03:28,408 --> 00:03:30,276
Maar is dat echt zo?

67
00:03:30,277 --> 00:03:33,199
Wij namen onze camera's
en enkele kilo's jelly beans

68
00:03:33,200 --> 00:03:35,571
naar Venice Beach om dat uit te testen.

69
00:03:35,572 --> 00:03:37,192
Eerst nodigden we mensen uit

70
00:03:37,193 --> 00:03:39,786
een van de twee smaken te kiezen.

71
00:03:39,787 --> 00:03:42,324
Ja, lekker.

72
00:03:42,325 --> 00:03:45,324
Ben je tevreden met je keuze?

73
00:03:45,325 --> 00:03:48,762
Ik ben blij met mijn keuze, ja.

74
00:03:48,763 --> 00:03:49,896
Dankjewel.

75
00:03:49,897 --> 00:03:51,732
Het was een makkelijke keuze.

76
00:03:51,733 --> 00:03:58,839
Ik koos het omdat ik iets fris wilde.

77
00:03:58,840 --> 00:04:03,009
Ik vind het lekker, ik houd van
smaken als citroen en citrus.

78
00:04:03,010 --> 00:04:05,545
Smaakt goed, ik ben blij met mijn keuze.

79
00:04:05,546 --> 00:04:08,048
De meeste mensen waren blij met hun keuze

80
00:04:08,049 --> 00:04:10,684
wanneer ze twee opties hadden.

81
00:04:10,685 --> 00:04:13,587
Maar wat gebeurt er
als we meer keuzes geven?

82
00:04:13,588 --> 00:04:16,388
Zullen ze net zo blij zijn met hun keuze?

83
00:04:16,389 --> 00:04:19,693
Oké.

84
00:04:19,694 --> 00:04:21,727
Geen drop...

85
00:04:21,728 --> 00:04:24,330
Mag ik er meer, of alleen eentje?

86
00:04:24,331 --> 00:04:31,738
Oh mijn god.

87
00:04:31,739 --> 00:04:35,709
Ik heb een beetje spijt
dat ik niet voor fruit ben gegaan.

88
00:04:35,710 --> 00:04:37,644
Want met jelly beans...

89
00:04:37,645 --> 00:04:39,946
fruit smaakt natuurlijker.

90
00:04:39,947 --> 00:04:41,413
Ik had waarschijnlijk

91
00:04:41,414 --> 00:04:44,050
voor mijn eerste keuze moeten gaan,
framboos.

92
00:04:44,051 --> 00:04:46,787
Dat zou beter zijn geweest.

93
00:04:46,788 --> 00:04:48,922
Er is een hoop om uit te kiezen.

94
00:04:48,923 --> 00:04:50,657
Mag ik er alleen een proberen?

95
00:04:50,658 --> 00:04:53,563
Oké, marshmallow.

96
00:04:53,564 --> 00:04:56,563
Ben je tevreden met je keuze?

97
00:04:56,564 --> 00:04:57,998
Ik weet het niet...

98
00:04:57,999 --> 00:04:59,415
Je vraagt jezelf altijd af:

99
00:04:59,416 --> 00:05:00,994
"Heb ik de juiste keuze gemaakt?"

100
00:05:00,995 --> 00:05:03,369
Als eerst wilde ik ananas proberen,

101
00:05:03,370 --> 00:05:04,945
en toen dacht ik aan marshmallow,

102
00:05:04,946 --> 00:05:07,406
en dat ik die niet mislopen, of perzik,

103
00:05:07,407 --> 00:05:10,811
of bosbes zelfs.

104
00:05:10,812 --> 00:05:14,748
Als ik opnieuw mocht kiezen,
zou ik denk ik voor perzik gaan.

105
00:05:14,749 --> 00:05:17,584
Oké.

106
00:05:17,585 --> 00:05:18,919
Ananas.

107
00:05:18,920 --> 00:05:20,486
Lekker, mijn favoriete fruit.

108
00:05:20,487 --> 00:05:22,022
Oh, ik had bosbes kunnen nemen,

109
00:05:22,023 --> 00:05:23,772
wat ook een favoriet is.

110
00:05:23,773 --> 00:05:25,892
Goed gekozen?

111
00:05:25,893 --> 00:05:27,727
Het was een impulsieve beslissing.

112
00:05:27,728 --> 00:05:30,711
Ik had nu gewild dat ik alles had bekeken.

113
00:05:30,712 --> 00:05:32,859
Ik had denk ik
een betere smaak gekozen dan.

114
00:05:32,860 --> 00:05:34,167
Dus misschien zijn we soms

115
00:05:34,168 --> 00:05:36,719
blijer met minder keuzes?

116
00:05:36,720 --> 00:05:40,040
Wetenschappers hebben dit idee
jarenlang onderzocht.

117
00:05:40,041 --> 00:05:42,776
En volgens het bekende jam-experiment,

118
00:05:42,777 --> 00:05:46,780
gepubliceerd door
Sheena Iyengar en Mark Lepper in 2000,

119
00:05:46,781 --> 00:05:49,716
zorgen teveel gelijkwaardige opties ervoor

120
00:05:49,717 --> 00:05:51,885
dat we helemaal geen keuze maken.

121
00:05:51,886 --> 00:05:54,420
Het onderzoek vergeleek
twee productuitstallingen:

122
00:05:54,421 --> 00:05:58,992
een met 6 varianten jam, en eentje met 24.

123
00:05:58,993 --> 00:06:01,695
Minder consumenten stopten
om jam te proeven

124
00:06:01,696 --> 00:06:03,797
bij de stal met zes keuzes,

125
00:06:03,798 --> 00:06:07,033
maar 30% van hen kocht een pot.

126
00:06:07,034 --> 00:06:10,036
Ter vergelijking:
slechts 3% van de consumenten

127
00:06:10,037 --> 00:06:12,072
die de stal met 24 keuzes bezochten,

128
00:06:12,073 --> 00:06:14,774
kochten een pot jam.

129
00:06:14,775 --> 00:06:17,911
Dit heet 'keuzeverlamming'.

130
00:06:17,912 --> 00:06:20,881
Maar alles in het leven draait om keuzes.

131
00:06:20,882 --> 00:06:24,050
We hebben graag keuzes.

132
00:06:24,051 --> 00:06:26,868
Of niet? Of liever geen keuze?

133
00:06:26,869 --> 00:06:31,958
[Demonstratie #2 - keuze of geen keuze?]

134
00:06:31,959 --> 00:06:35,061
Hallo! Welkom bij Tea Time Word Scrambles,

135
00:06:35,062 --> 00:06:38,198
het spel waarbij de strijd fel is

136
00:06:38,199 --> 00:06:40,767
en problemen borrelen?

137
00:06:40,768 --> 00:06:42,903
Enkele van onze deelnemers krijgen de keuze

138
00:06:42,904 --> 00:06:46,156
tussen opzwepende zwarte thee
of kalmerende kruidenthee.

139
00:06:46,157 --> 00:06:49,102
Anderen krijgen geen keuze.

140
00:06:49,103 --> 00:06:50,840
Als de werking van de thee intreedt,

141
00:06:50,841 --> 00:06:53,466
moeten ze woorden ontwarren.

142
00:06:53,467 --> 00:06:56,059
Welke deelnemers zijn
meer tevreden met hun resultaten?

143
00:06:56,060 --> 00:06:59,219
Degenen die een keuze hadden,
of degenen zonder keuze?

144
00:06:59,220 --> 00:07:02,555
Daar komen we snel achter, het is Tea Time.

145
00:07:02,556 --> 00:07:04,724
Ik ben Michael Stevens, de presentator.

146
00:07:04,725 --> 00:07:07,027
En dit is onze deelnemer Gisele.

147
00:07:07,028 --> 00:07:08,494
Leuk je te ontmoeten, Gisele.

148
00:07:08,495 --> 00:07:09,796
Leuk om jou te ontmoeten.

149
00:07:09,797 --> 00:07:11,497
Vertel eens iets over jezelf.

150
00:07:11,498 --> 00:07:14,441
Ik kom uit New York en woon nu in LA...

151
00:07:14,442 --> 00:07:16,396
Gisele, je weet wat dat geluid betekent.

152
00:07:16,397 --> 00:07:18,238
Het is Tea Time.

153
00:07:18,239 --> 00:07:21,463
Neem plaats aan de tafel.

154
00:07:21,464 --> 00:07:22,208
Oké.

155
00:07:22,209 --> 00:07:23,673
Ik hou van thee.

156
00:07:23,674 --> 00:07:25,512
Dan ben je op de juiste plaats.

157
00:07:25,513 --> 00:07:28,748
- Oké.
- Want vandaag ga jij woorden ontwarren.

158
00:07:28,749 --> 00:07:30,984
Een taak die energie vraagt,

159
00:07:30,985 --> 00:07:34,287
want er is een tijdslimiet,
maar je moet je ook focussen.

160
00:07:34,288 --> 00:07:36,720
- Oké.
- Stalen zenuwen.

161
00:07:36,721 --> 00:07:38,024
- Ik snap het.
- En geduld.

162
00:07:38,025 --> 00:07:39,059
Dus,

163
00:07:39,060 --> 00:07:42,128
de keuze is aan jou.

164
00:07:42,129 --> 00:07:44,297
Je kunt kiezen voor

165
00:07:44,298 --> 00:07:48,635
kruidenthee, die je helpt
kalm te blijven en te focussen...

166
00:07:48,636 --> 00:07:50,637
- Oké.
- Of je kunt kiezen voor

167
00:07:50,638 --> 00:07:52,806
zwarte thee met cafeïne,

168
00:07:52,807 --> 00:07:56,843
wat je energie zal geven.

169
00:07:56,844 --> 00:07:58,801
- Ik ga voor zwarte thee.
- Zwarte thee?

170
00:07:58,802 --> 00:07:59,779
- Ja.
- Oké.

171
00:07:59,780 --> 00:08:02,115
Geef haar een kopje zwarte thee.

172
00:08:02,116 --> 00:08:04,184
Weet je wat? Ik neem ook een kopje.

173
00:08:04,185 --> 00:08:06,086
Lekker.

174
00:08:06,087 --> 00:08:08,722
Waarom koos je zwarte thee?

175
00:08:08,723 --> 00:08:11,658
Ik wil energie krijgen.

176
00:08:11,659 --> 00:08:13,026
- Oké.
- Ja.

177
00:08:13,027 --> 00:08:14,861
- Op jou.
- Proost.

178
00:08:14,862 --> 00:08:18,798
Proost.

179
00:08:18,799 --> 00:08:20,767
Je weet wat dat geluid betekent.

180
00:08:20,768 --> 00:08:23,003
Tijd om woorden te ontwarren.

181
00:08:23,004 --> 00:08:25,972
Onthoud, deze deelnemer had vrije keuze

182
00:08:25,973 --> 00:08:27,807
in haar opties voor thee.

183
00:08:27,808 --> 00:08:29,642
Zal keuzevrijheid haar

184
00:08:29,643 --> 00:08:31,745
geluk en tevredenheid brengen?

185
00:08:31,746 --> 00:08:34,913
Gisele, dit zijn jouw woorden.

186
00:08:34,914 --> 00:08:36,716
O god. Wanneer mag ik beginnen?

187
00:08:36,717 --> 00:08:38,493
We zetten drie minuten op de klok.

188
00:08:38,494 --> 00:08:39,686
- Oké.
- Kom hier.

189
00:08:39,687 --> 00:08:41,154
Je kunt deze trapjes gebruiken

190
00:08:41,155 --> 00:08:42,512
om bij de letters te komen.

191
00:08:42,513 --> 00:08:44,124
Het doel is

192
00:08:44,125 --> 00:08:47,093
om zoveel mogelijk
woorden te maken in drie minuten.

193
00:08:47,094 --> 00:08:54,934
- Ik snap het.
- En ... start!

194
00:08:54,935 --> 00:09:00,040
Ze begint met nummer vijf.

195
00:09:00,041 --> 00:09:01,608
Gisele heeft kitten.

196
00:09:01,609 --> 00:09:10,083
Ziet eruit als het goede antwoord.

197
00:09:10,084 --> 00:09:16,256
Vacuum.

198
00:09:16,257 --> 00:09:18,858
Hearth.

199
00:09:18,859 --> 00:09:20,693
Ziet er goed uit.

200
00:09:20,694 --> 00:09:26,066
Ik weet niet wat dit is.

201
00:09:26,067 --> 00:09:28,968
De tijd is om, Gisele.
Kom maar naar beneden.

202
00:09:28,969 --> 00:09:31,905
En laten we kijken hoe je het gedaan hebt.

203
00:09:31,906 --> 00:09:34,908
Oh nee.

204
00:09:34,909 --> 00:09:36,943
Bij nummer één heb je vacuum

205
00:09:36,944 --> 00:09:38,912
en dat is goed, gefeliciteerd.

206
00:09:38,913 --> 00:09:41,681
Goed gedaan. Nummer twee: hearth.

207
00:09:41,682 --> 00:09:43,383
Opnieuw correct, gefeliciteerd.

208
00:09:43,384 --> 00:09:46,820
Bij nummer drie heb je taffrid.

209
00:09:46,821 --> 00:09:49,289
Een leuk woord, maar het bestaat niet.

210
00:09:49,290 --> 00:09:51,825
We zochten adrift.

211
00:09:51,826 --> 00:09:53,960
Ja, ik zat vast met dat woord.

212
00:09:53,961 --> 00:09:55,962
Bij vijf heb je kitten.

213
00:09:55,963 --> 00:09:58,264
Dat was de eerste die je had
en die is correct.

214
00:09:58,265 --> 00:09:59,833
Gefeliciteerd.

215
00:09:59,834 --> 00:10:01,835
Hier beneden,

216
00:10:01,836 --> 00:10:04,337
zochten we naar lounge.

217
00:10:04,338 --> 00:10:06,272
Jij hebt lougne.

218
00:10:06,273 --> 00:10:08,108
Oh nee, ik heb het verkeerd gespeld.

219
00:10:08,109 --> 00:10:10,977
Helaas kunnen we lougne niet goedkeuren.

220
00:10:10,978 --> 00:10:16,216
Oké Gisele, je hebt één, twee, drie punten.

221
00:10:16,217 --> 00:10:17,667
Hoe vond je het gaan?

222
00:10:17,668 --> 00:10:20,898
Ik had de andere thee moeten nemen,
het had mijn zenuwen gekalmeerd.

223
00:10:20,899 --> 00:10:22,055
Ja, de andere thee.

224
00:10:22,056 --> 00:10:24,630
Deze deelnemer heeft
duidelijk spijt van haar keuze.

225
00:10:24,631 --> 00:10:26,586
Het feit dat ze zelf haar thee kon kiezen

226
00:10:26,587 --> 00:10:29,639
geeft haar de mogelijkheid
haar beslissing in twijfel te trekken.

227
00:10:29,640 --> 00:10:31,504
Hoe ging het met de andere deelnemers

228
00:10:31,505 --> 00:10:32,732
die keuzevrijheid hadden?

229
00:10:32,733 --> 00:10:36,703
Noric. We zochten ironic.

230
00:10:36,704 --> 00:10:39,139
- Is dat niet ironisch?
- Nee, dat is het niet.

231
00:10:39,140 --> 00:10:41,407
We zochten naar hearth.

232
00:10:41,408 --> 00:10:43,176
- Hearth?
- Adrift.

233
00:10:43,177 --> 00:10:45,745
- Shroud.
- Bestaan die woorden?

234
00:10:45,746 --> 00:10:48,081
Ja, ze bestaan.

235
00:10:48,082 --> 00:10:50,116
Zo, Heather, hoe vind je dat je het deed?

236
00:10:50,117 --> 00:10:52,051
Niet zo goed als ik had gehoopt.

237
00:10:52,052 --> 00:10:54,750
Zou je een andere thee kiezen
als je het over mocht doen?

238
00:10:54,751 --> 00:10:56,180
Ja, het kan alleen maar beter.

239
00:10:56,181 --> 00:10:57,795
Het kan niet slechter dan dit.

240
00:10:57,796 --> 00:10:59,419
Als ik de andere thee had gekozen,

241
00:10:59,420 --> 00:11:01,427
had ik waarschijnlijk alles correct gehad.

242
00:11:01,428 --> 00:11:02,929
Geen enkele deelnemer

243
00:11:02,930 --> 00:11:04,864
was blij met de gemaakte keuze.

244
00:11:04,865 --> 00:11:06,199
Maar wat gebeurt als

245
00:11:06,200 --> 00:11:08,502
de keuzevrijheid wordt weggenomen?

246
00:11:08,503 --> 00:11:10,803
Trin, welke thee is vandaag

247
00:11:10,804 --> 00:11:13,173
toegewezen aan Athena?

248
00:11:13,174 --> 00:11:15,808
Athena is zwarte thee toegewezen.

249
00:11:15,809 --> 00:11:19,078
Zwarte thee met cafeïne, voor energie.

250
00:11:19,079 --> 00:11:21,781
Op jou, en veel geluk.

251
00:11:21,782 --> 00:11:27,053
Dankjewel.

252
00:11:27,054 --> 00:11:29,022
Dit is goede thee.

253
00:11:29,023 --> 00:11:32,225
Athena, jij hebt thee toegewezen gekregen.

254
00:11:32,226 --> 00:11:33,960
Zwarte thee. Met cafeïne.

255
00:11:33,961 --> 00:11:37,197
Laten we kijken hoe dat voor jou werkt.

256
00:11:37,198 --> 00:11:41,401
Hier zijn jouw woorden!

257
00:11:41,402 --> 00:11:47,473
Je drie minuten gaan ... nu in!

258
00:11:47,474 --> 00:11:51,177
Veel keuzes.

259
00:11:51,178 --> 00:11:55,348
- Kitten.
- Eindelijk.

260
00:11:55,349 --> 00:11:57,921
Maak je geen zorgen Athena,
we hebben erger gezien.

261
00:11:57,922 --> 00:11:59,285
Twee minuten.

262
00:11:59,286 --> 00:12:02,055
- Twee minuten op de klok.
- Ik krijg geen ingevingen.

263
00:12:02,056 --> 00:12:05,191
Het zijn geen makkelijke woorden.

264
00:12:05,192 --> 00:12:06,993
Lounge.

265
00:12:06,994 --> 00:12:08,962
- Ja.

266
00:12:08,963 --> 00:12:10,096
En je tijd is om.

267
00:12:10,097 --> 00:12:11,497
Athena, kom naar beneden.

268
00:12:11,498 --> 00:12:13,833
En laten we je resultaten bekijken.

269
00:12:13,834 --> 00:12:16,202
- Oké.
- Bij woord nummer vijf

270
00:12:16,203 --> 00:12:18,972
heb jij kitten en dat is correct.

271
00:12:18,973 --> 00:12:20,473
Goed gedaan.

272
00:12:20,474 --> 00:12:23,810
Bij het laatste woord heb je lounge.

273
00:12:23,811 --> 00:12:26,513
En het antwoord is lounge.

274
00:12:26,514 --> 00:12:28,081
Erg goed gedaan.

275
00:12:28,082 --> 00:12:29,882
- Je hebt er 2 uit 12.
- Oh man.

276
00:12:29,883 --> 00:12:31,150
Hoe vond je het gaan?

277
00:12:31,151 --> 00:12:33,052
Ik ben blij dat ik er twee goed heb.

278
00:12:33,053 --> 00:12:34,781
Denk je dat je er meer goed had

279
00:12:34,782 --> 00:12:37,558
als je kalmerende thee had?

280
00:12:37,559 --> 00:12:39,325
Ik denk het niet, je hebt iets nodig

281
00:12:39,326 --> 00:12:41,327
dat je hersenen een impuls geeft.

282
00:12:41,328 --> 00:12:43,564
Deze deelnemer, die geen keuze had,

283
00:12:43,565 --> 00:12:46,032
was blij met de thee
die haar toegewezen was,

284
00:12:46,033 --> 00:12:48,101
terwijl ze maar twee woorden goed had.

285
00:12:48,102 --> 00:12:50,270
En ze was niet de enige.

286
00:12:50,271 --> 00:12:51,437
Hoe vond je het gaan?

287
00:12:51,438 --> 00:12:53,502
Ik denk dat het vrij goed ging.

288
00:12:53,503 --> 00:12:54,928
Als je het opnieuw kon doen,

289
00:12:54,929 --> 00:12:57,680
zou je dan een andere thee willen
dan degene die je kreeg?

290
00:12:57,681 --> 00:12:59,279
- Nee.
- Studies laten zien

291
00:12:59,280 --> 00:13:02,181
dat we soms gelukkiger zijn
als we geen keuze hebben.

292
00:13:02,182 --> 00:13:04,551
Met twee punten

293
00:13:04,552 --> 00:13:07,487
heb je niets gewonnen.

294
00:13:07,488 --> 00:13:10,223
Dit spel gaat namelijk meer
om het onderzoeken

295
00:13:10,224 --> 00:13:12,325
van het brein,

296
00:13:12,326 --> 00:13:16,029
dus eigenlijk is iedereen een winnaar.

297
00:13:16,030 --> 00:13:18,264
Bedankt voor het meedoen, en onthoud:

298
00:13:18,265 --> 00:13:20,534
het maakt niet uit waar je woont
of wie je bent,

299
00:13:20,535 --> 00:13:25,371
het is altijd... Tea Time!

300
00:13:25,372 --> 00:13:35,315
Verdomme, ik zie net een nieuw woord.

301
00:13:35,316 --> 00:13:37,383
Oké, het heeft dus niet altijd de voorkeur

302
00:13:37,384 --> 00:13:39,653
om controle over je leven te hebben.

303
00:13:39,654 --> 00:13:42,388
De druk om een keuze te maken

304
00:13:42,389 --> 00:13:45,958
kan ervoor zorgen dat je spijt hebt
van wat je niet gekozen hebt

305
00:13:45,959 --> 00:13:48,061
en je prestaties belemmeren.

306
00:13:48,062 --> 00:13:50,363
Maar wat als er een verschil is

307
00:13:50,364 --> 00:13:53,634
tussen het fysieke proces
bij het maken van een keuze

308
00:13:53,635 --> 00:13:56,402
en je bewustzijn dat weet

309
00:13:56,403 --> 00:13:58,338
dat er een keuze is gemaakt?

310
00:13:58,339 --> 00:14:02,008
Wat als al je beslissingen
gemaakt worden door iemand...

311
00:14:02,009 --> 00:14:04,645
nee, iets anders...

312
00:14:04,646 --> 00:14:09,068
een fractie van een seconde
voordat jij weet dat je ze gemaakt hebt?

313
00:14:09,069 --> 00:14:23,196
[Demonstratie #3 - De machine]

314
00:14:23,197 --> 00:14:25,465
Deze taak lijkt simpel.

315
00:14:25,466 --> 00:14:32,639
Druk op een van de twee knoppen
voor het lampje brandt.

316
00:14:32,640 --> 00:14:35,074
Waarom is dit zo moeilijk?

317
00:14:35,075 --> 00:14:37,549
Het is moeilijk omdat deze machine

318
00:14:37,550 --> 00:14:39,495
mijn gedachten leest.

319
00:14:39,496 --> 00:14:41,804
Het weet wanneer ik beslis
op een knop te drukken

320
00:14:41,805 --> 00:14:44,583
en laat het lampje branden
voor ik op een knop kan drukken.

321
00:14:44,584 --> 00:14:46,445
Hoe voelt het wanneer dat gebeurt?

322
00:14:46,446 --> 00:14:48,388
Het voelt alsof...

323
00:14:48,389 --> 00:14:50,957
Kijk, zoals nu.

324
00:14:50,958 --> 00:14:53,359
Het wist het al.

325
00:14:53,360 --> 00:14:57,598
Ik probeer mijn gedachten
niet te laten lezen.

326
00:14:57,599 --> 00:14:59,098
Dit is hoe de machine werkt.

327
00:14:59,099 --> 00:15:03,436
Mijn beslissing om op een knop te duwen,
begint eerder dan ik denk.

328
00:15:03,437 --> 00:15:07,574
Het leest mijn onbewuste activiteit,
waar ik me nog niet van bewust ben,

329
00:15:07,575 --> 00:15:09,676
maar die de machine wel kan lezen.

330
00:15:09,677 --> 00:15:13,179
De machine voorspelt niet
welke knop ik zal indrukken,

331
00:15:13,180 --> 00:15:18,151
het stelt vast wanneer ik dit zal doen,
voordat ik het weet.

332
00:15:18,152 --> 00:15:20,420
Gedurende enkele minuten
drukte ik op knoppen,

333
00:15:20,421 --> 00:15:22,816
terwijl de machine
mijn breinactiviteit registreert

334
00:15:22,817 --> 00:15:27,427
en zo leert welk gedrag op
bepaalde onbewuste processen volgt.

335
00:15:27,428 --> 00:15:30,731
Uiteindelijk weet de machine
wat ik ga doen,

336
00:15:30,732 --> 00:15:32,733
voordat ik dat weet.

337
00:15:32,734 --> 00:15:35,736
In andere woorden:
het kan mijn onderbewustzijn lezen

338
00:15:35,737 --> 00:15:37,571
en me vertellen wat ik ga doen

339
00:15:37,572 --> 00:15:40,173
voordat ik weet dat ik het zou gaan doen.

340
00:15:40,174 --> 00:15:42,475
Dat is het gedeelte dat me beangstigd.

341
00:15:42,476 --> 00:15:45,211
Dit heet een vrije wil-experiment

342
00:15:45,212 --> 00:15:49,516
want het behandelt
wat vrije wil eigenlijk is.

343
00:15:49,517 --> 00:15:51,652
Als het onderbewustzijn weet wat je doet

344
00:15:51,653 --> 00:15:54,655
voordat jij het doet,
is het dan echt jouw beslissing,

345
00:15:54,656 --> 00:16:00,326
of denk je slechts
dat het jouw beslissing is?

346
00:16:00,327 --> 00:16:03,730
Ik probeer het te verrassen.

347
00:16:03,731 --> 00:16:06,332
Het is interessant om te merken dat

348
00:16:06,333 --> 00:16:09,168
je je meer betrokken voelt

349
00:16:09,169 --> 00:16:11,137
en je het tempo opvoert.

350
00:16:11,138 --> 00:16:12,338
Ik voel me competitief.

351
00:16:12,339 --> 00:16:14,240
Ik wil mijn gedachten niet laten lezen.

352
00:16:14,241 --> 00:16:17,143
Ik vind dit proces frustrerend.

353
00:16:17,144 --> 00:16:19,078
Terwijl ik weet hoe de machine werkt.

354
00:16:19,079 --> 00:16:21,981
Maar wat als je niet weet
hoe de machine werkt

355
00:16:21,982 --> 00:16:23,382
voordat je het zou proberen?

356
00:16:23,383 --> 00:16:24,904
Ik wil je voorstellen aan Moran,

357
00:16:24,905 --> 00:16:27,313
dit is Diana van het
YouTube-kanaal Physics Girl,

358
00:16:27,314 --> 00:16:29,288
een van mijn favoriete YouTube-kanalen.

359
00:16:29,289 --> 00:16:30,824
Michael, stop.

360
00:16:30,825 --> 00:16:32,759
Derek, dank je dat je hier bent.

361
00:16:32,760 --> 00:16:36,009
Ik introduceer je
met Moran Cerf van Northwester.

362
00:16:36,010 --> 00:16:37,363
Leuk je te ontmoeten.

363
00:16:37,364 --> 00:16:39,766
En hij heeft deze machine meegenomen.

364
00:16:39,767 --> 00:16:42,503
Diana en Derek hebben
een wetenschappelijk brein.

365
00:16:42,504 --> 00:16:45,539
Maar hen is niet verteld
wat de machine doet.

366
00:16:45,540 --> 00:16:49,549
Moran legt hen een
misleidend makkelijk spel uit.

367
00:16:49,550 --> 00:16:52,569
Het is een simpel experiment.
Je krijgt dit op je hoofd

368
00:16:52,570 --> 00:16:55,624
en daarmee meten we je hersenactiviteit.

369
00:16:55,625 --> 00:16:58,494
We vragen je een simpele keuze te maken:

370
00:16:58,495 --> 00:16:59,544
op een knop drukken.

371
00:16:59,545 --> 00:17:01,782
Als het lampje aan is, druk je nergens op.

372
00:17:01,783 --> 00:17:03,752
- Dus we kunnen...
- De lampjes zijn aan,

373
00:17:03,753 --> 00:17:05,075
dus je raakt niets aan.

374
00:17:05,076 --> 00:17:07,182
Hebben zij door
wat er gebeurt als de machine

375
00:17:07,183 --> 00:17:11,364
hun actieve beslissingsproces herkent?

376
00:17:11,365 --> 00:17:13,266
Zie ik eruit als een kwal?

377
00:17:13,267 --> 00:17:15,434
- Voel je je goed?
- Ik voel me geweldig.

378
00:17:15,435 --> 00:17:21,240
Oké, je kunt beginnen.

379
00:17:21,241 --> 00:17:24,174
Gedurende de eerste 15 minuten
kalibreert de machine

380
00:17:24,175 --> 00:17:26,555
en leert het hoe het brein
van de deelnemers werkt

381
00:17:26,556 --> 00:17:29,148
voordat het een beslissing maakt.

382
00:17:29,149 --> 00:17:37,735
Dan begint het leuke gedeelte.

383
00:17:37,736 --> 00:17:39,565
Zorg dat het lampje nog niet aan is.

384
00:17:39,566 --> 00:17:40,359
Nog niet?

385
00:17:40,360 --> 00:17:43,864
Ja.

386
00:17:43,865 --> 00:17:46,600
Allebei de deelnemers lijken in de war

387
00:17:46,601 --> 00:17:50,469
en gefrustreerd.

388
00:17:50,470 --> 00:17:56,209
Ik weet precies hoe ze zich voelen.

389
00:17:56,210 --> 00:17:58,427
Het is moeilijk, want soms
gaan de lampjes aan

390
00:17:58,428 --> 00:18:00,045
terwijl ik er net op wil drukken.

391
00:18:00,046 --> 00:18:00,974
Het is alsof...

392
00:18:00,975 --> 00:18:02,381
Moran, wil je het vertellen?

393
00:18:02,382 --> 00:18:05,619
De machine

394
00:18:05,620 --> 00:18:07,521
leest je hersenactiviteit

395
00:18:07,522 --> 00:18:10,266
en probeert niet te voorspellen
welke knop je indrukt,

396
00:18:10,267 --> 00:18:12,769
maar wanneer, om vervolgens
de lampjes op te lichten

397
00:18:12,770 --> 00:18:14,570
net voordat jij erop wilt drukken.

398
00:18:14,571 --> 00:18:17,196
Dit voorspelt
wanneer ik een beslissing maak.

399
00:18:17,197 --> 00:18:18,699
- Wat?
- Ja.

400
00:18:18,700 --> 00:18:20,433
Dit is geweldig.

401
00:18:20,434 --> 00:18:22,603
Ik zag inderdaad dat de lampjes aangingen

402
00:18:22,604 --> 00:18:24,437
net als ik op de knop wilde drukken.

403
00:18:24,438 --> 00:18:25,939
Maar er waren ook momenten

404
00:18:25,940 --> 00:18:27,908
wanneer ik geen keuze had gemaakt

405
00:18:27,909 --> 00:18:29,876
en ze toch aangingen, dus ik dacht,...

406
00:18:29,877 --> 00:18:31,945
- Waarom? Hoe weet je dat?
- Oké.

407
00:18:31,946 --> 00:18:33,437
- Wat?
- Hoe weet je dat?

408
00:18:33,438 --> 00:18:35,591
Misschien stopten de lichtjes
je hersenen van

409
00:18:35,592 --> 00:18:37,736
het laten weten dat je een
keuze ging maken.

410
00:18:37,737 --> 00:18:40,243
Het detecteert niet alleen
'hij gaat erop drukken',

411
00:18:40,244 --> 00:18:43,389
maar juist ook 'hij komt tot de beslissing

412
00:18:43,390 --> 00:18:46,352
dat hij kiest erop te drukken.'

413
00:18:46,353 --> 00:18:48,641
Ik probeer te denken,
ik probeer jou te verslaan.

414
00:18:48,642 --> 00:18:49,630
Zoals "Oh, ik ga

415
00:18:49,631 --> 00:18:50,844
op de linkerknop drukken,

416
00:18:50,845 --> 00:18:52,348
nee, wacht, ik doe de rechter."

417
00:18:52,349 --> 00:18:54,074
Interessant dat je het zo verwoordt.

418
00:18:54,075 --> 00:18:56,402
Want het gaat er niet om
om ons te verslaan,

419
00:18:56,403 --> 00:19:00,674
maar om je eigen brein te verslaan.

420
00:19:00,675 --> 00:19:05,211
Wat dit impliceert, is eng.

421
00:19:05,212 --> 00:19:07,413
Wij kunnen dingen over jou ontdekken

422
00:19:07,414 --> 00:19:09,886
die je zelf niet eens wist,
of niet wilde toegeven.

423
00:19:09,887 --> 00:19:11,764
Wij kunnen je dingen vertellen, zoals

424
00:19:11,765 --> 00:19:14,220
'Welke van deze
schilderingen vind je mooier?'

425
00:19:14,221 --> 00:19:16,037
'Wat denk je echt van iemand?'

426
00:19:16,038 --> 00:19:17,323
Of, stel je voor,

427
00:19:17,324 --> 00:19:18,959
om dit voor dating te gebruiken.

428
00:19:18,960 --> 00:19:21,460
Want het leest je onderbewustzijn...

429
00:19:21,461 --> 00:19:23,396
We kunnen je wellicht vertellen

430
00:19:23,397 --> 00:19:28,702
dat je voorkeur naar iemand uitgaat,
waarvan je het niet had verwacht.

431
00:19:28,703 --> 00:19:32,839
Dat klinkt eng.

432
00:19:32,840 --> 00:19:34,775
Maar tegelijkertijd,

433
00:19:34,776 --> 00:19:36,977
voelt het alsof... ik weet het niet.

434
00:19:36,978 --> 00:19:39,245
Ik ben zo menselijk, Michael, ik voel alsof

435
00:19:39,246 --> 00:19:40,747
mijn menselijke reactie dit is:

436
00:19:40,748 --> 00:19:42,716
"Oké, mijn brein gaat door een proces.

437
00:19:42,717 --> 00:19:44,383
Ik snap het. Jij weet het.

438
00:19:44,384 --> 00:19:48,354
Maar het is nog steeds mijn brein
en mijn proces."

439
00:19:48,355 --> 00:19:50,694
- Ik denk waar je nu doorheen gaat...
- Ontkenning.

440
00:19:50,695 --> 00:19:52,124
Ik zou een ander woord kiezen.

441
00:19:52,125 --> 00:19:54,367
Het is een proces waar
we allemaal doorheen gaan

442
00:19:54,368 --> 00:19:56,997
als we de breekbaarheid
van de vrije wil ervaren.

443
00:19:56,998 --> 00:20:00,567
Ik noem het liever
'de limiet' van de vrije wil.

444
00:20:00,568 --> 00:20:02,035
Oh trouwens, je weet dat je

445
00:20:02,036 --> 00:20:03,670
morgenavond kipsalade eet?

446
00:20:03,671 --> 00:20:05,038
Ja, dat is duidelijk.

447
00:20:05,039 --> 00:20:07,143
Het is goed in het voorspellen daarvan.

448
00:20:07,144 --> 00:20:13,547
Ja.

449
00:20:13,548 --> 00:20:15,849
Als vallende dominostenen,

450
00:20:15,850 --> 00:20:18,317
heeft een keten van dingen

451
00:20:18,318 --> 00:20:20,020
geleid tot nu, dit moment.

452
00:20:20,021 --> 00:20:22,622
De dominostenen
in jouw leven kunnen bestaan uit

453
00:20:22,623 --> 00:20:26,026
je ouders, je jeugd,
de boeken die je gelezen hebt,

454
00:20:26,027 --> 00:20:28,327
je vrienden,
dingen die je hebben beïnvloed,

455
00:20:28,328 --> 00:20:29,663
wat je als ontbijt had,

456
00:20:29,664 --> 00:20:32,833
hoe je je vanmiddag voelde.

457
00:20:32,834 --> 00:20:36,302
Alles heeft geleid tot nu,
de laatste domino,

458
00:20:36,303 --> 00:20:40,006
maar hoe het valt, dat is jouw keuze.

459
00:20:40,007 --> 00:20:42,042
Of toch niet?

460
00:20:42,043 --> 00:20:45,478
Morans machine stelt
dit soort dingen in vraag.

461
00:20:45,479 --> 00:20:49,716
Als je brein ons kan vertellen
wat je gaat doen

462
00:20:49,717 --> 00:20:52,451
voordat jij weet dat je het gaat doen,

463
00:20:52,452 --> 00:20:54,748
is je bewustzijn dan eigenlijk

464
00:20:54,749 --> 00:20:56,623
onder controle van je onderbewustzijn?

465
00:20:56,624 --> 00:20:59,960
En als we je onderbewustzijn
voor de gek kunnen houden,

466
00:20:59,961 --> 00:21:01,995
wie is dan eigenlijk de baas?

467
00:21:01,996 --> 00:21:04,497
Heb je echt een vrije wil?

468
00:21:04,498 --> 00:21:06,967
Of ben je niet meer dan...

469
00:21:06,968 --> 00:21:09,803
een marionet?

470
00:21:09,804 --> 00:21:12,773
Een marionet die denkt

471
00:21:12,774 --> 00:21:15,341
niet aan touwtjes vast te zitten?

472
00:21:15,342 --> 00:21:17,409
Neemt je bewustzijn

473
00:21:17,410 --> 00:21:19,478
erkenning voor dingen

474
00:21:19,479 --> 00:21:22,015
waar je onderbewustzijn

475
00:21:22,016 --> 00:21:23,683
allang tot besloten had?

476
00:21:23,684 --> 00:21:26,520
Er is duidelijk meer onderzoek nodig.

477
00:21:26,521 --> 00:21:28,088
Maar wat we weten is dat

478
00:21:28,089 --> 00:21:32,626
dingen die je normaal niet
als onderdeel van jezelf beschouwt,

479
00:21:32,627 --> 00:21:36,062
een gigantisch deel van je zijn.

480
00:21:36,063 --> 00:21:39,933
Ik denk dat Kermit de Kikker
het het best zei:

481
00:21:39,934 --> 00:21:43,703
"Al ben ik niet compleet zeker
wat Jim Henson deed,

482
00:21:43,704 --> 00:21:47,642
maar wat het was, het bewoog me."

