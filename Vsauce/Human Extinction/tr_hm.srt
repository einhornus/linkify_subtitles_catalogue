1
00:00:00,329 --> 00:00:04,838
Hey, Vsauce, ben Michael. Evinden çıkmadan veya

2
00:00:04,839 --> 00:00:08,369
diğer insanlarla uğraşmadan Ebola'ya yakalanmak ister miydin?

3
00:00:08,370 --> 00:00:13,669
O zaman şanslı günündesin. Ebola virüsünün genomunu

4
00:00:13,670 --> 00:00:14,379
zaten indirebilirsin.

5
00:00:14,380 --> 00:00:17,769
Tam şu anda, tam da buradan, internetten. Eğer 3D biyo-yazıcı

6
00:00:17,770 --> 00:00:21,948
teknolojisinin gelişmesi için birkaç yıl bekleyebilirsen,

7
00:00:21,949 --> 00:00:26,719
işte o zaman bir yazıcı alıp genomu ona yükleyebilirsin,

8
00:00:26,720 --> 00:00:30,249
ve ta da! İstediğin kadar Ebola yazdır!

9
00:00:30,250 --> 00:00:35,599
Veya şarbon virüsü. Veya insanlığı yeryüzünden silmek için

10
00:00:35,600 --> 00:00:40,679
evinde seri üretime geçmek istediğin herhangi bir virüs.

11
00:00:40,680 --> 00:00:43,639
Yakında insanların nesli tükenecek mi?

12
00:00:43,640 --> 00:00:46,519
İnsanların neslinin tükenmesi...

13
00:00:46,520 --> 00:00:49,988
antropojenik mi olacak? Yani, insan eliyle, insan

14
00:00:49,989 --> 00:00:53,549
müdahalesiyle mi? Yoksa bu dünya tarihinin çok iyi bildiği, güzel,

15
00:00:53,550 --> 00:00:57,448
eski moda "yok olma"lardan mı olacak?

16
00:00:57,449 --> 00:01:02,358
Oxford Üniversitesi'nin İnsanlık Geleceği Enstitüsü tarafından yapılan

17
00:01:02,359 --> 00:01:06,469
Küresel Katastrofik Riskler İncelemesine göre,

18
00:01:06,470 --> 00:01:10,949
2100 yılından önce neslimizin tükenme ihtimalı %19.

19
00:01:10,950 --> 00:01:15,969
Şimdi, "blah blah blah, dünyanın sonu geliyor" diye konuştuğumu düşünüyor olabilirsiniz.

20
00:01:15,970 --> 00:01:19,399
"Hiçbir şey olmayacak, insanlar soylarının tükenmesi

21
00:01:19,400 --> 00:01:22,859
için fazla zekiler." Belki de haklısınız.

22
00:01:22,860 --> 00:01:25,569
Ama uzak geleceği katiyetle tahmin

23
00:01:25,570 --> 00:01:28,999
etmek zordur. Bunun hakkında havalı olan şeyse şu,

24
00:01:29,000 --> 00:01:32,979
eğer belirsizliği benimserseniz, basit bir iddia,

25
00:01:32,980 --> 00:01:37,329
insan soyunun yakında tükenmesi

26
00:01:37,330 --> 00:01:42,399
aslında daha muhtemel olduğunu gösterebilir. Buna "Kıyamet iddiası" denir.

27
00:01:42,400 --> 00:01:45,299
Devasa bir testi hayal edin.

28
00:01:45,300 --> 00:01:47,539
İçinde ya 1'den 10'a kadar numaralandırılmış

29
00:01:47,540 --> 00:01:51,258
10 tane top var. Ya da 1'den bir milyona kadar numaralandırılmış

30
00:01:51,259 --> 00:01:55,799
bir milyon tane top var. Hangisi olduğunu bilmiyorsunuz,

31
00:01:55,800 --> 00:01:59,399
ama testiden bir tane top çekme hakkınız var.

32
00:01:59,400 --> 00:02:01,288
Topu çekiyorsunuz,

33
00:02:01,289 --> 00:02:05,769
ve çıkan top 4 numaralı top.

34
00:02:05,770 --> 00:02:09,999
Bu testide 10 top olduğuna dair baya kuvvetli bir delildir.

35
00:02:10,000 --> 00:02:13,749
Çünkü, 1'den 10'a kadar numaralı toplardan 4 numarasını çekme olasılığı

36
00:02:13,750 --> 00:02:18,369
10'da 1'dir. Ama bir milyon numaranın içinden 4 numarasını çekme olasılığı

37
00:02:18,370 --> 00:02:21,649
ise 1 milyonda 1'dir.

38
00:02:21,650 --> 00:02:25,109
Bir benzerlik kurarsak, sen de aslında numaralandırılmış

39
00:02:25,110 --> 00:02:28,469
bir topsun. Sen, aşağı yukarı "doğum sıranın"

40
00:02:28,470 --> 00:02:31,789
kaç olduğunu bilen bir insansın.

41
00:02:31,790 --> 00:02:35,999
Büyük ihtimalle 100 milyar falandır.

42
00:02:36,000 --> 00:02:38,119
Sen doğmadan önce doğmuş olan

43
00:02:38,120 --> 00:02:41,539
insanların sayısı, büyük ihtimalle bu kadar.

44
00:02:41,540 --> 00:02:45,039
Daha önemlisi, sen kaçıncı "doğum sırasına"

45
00:02:45,040 --> 00:02:49,169
sahip olacağını seçmedin. Yani, bir topun üstündeki sayı gibi,

46
00:02:49,170 --> 00:02:53,419
yaşayıp yaşayacak bütün insanların içinde

47
00:02:53,420 --> 00:02:57,548
rastgele bir örneksin. "Kıyamet Günü İddiası"na göre

48
00:02:57,549 --> 00:03:02,518
200 milyar insan arasında rastgele seçilen bir insanın, mesela senin,

49
00:03:02,519 --> 00:03:06,809
ilk 100 milyar içerisinde olmasının olasılığı, yaklaşık %50'dir.

50
00:03:06,810 --> 00:03:09,869
Halbuki eğer gelecekte 10 trilyon insan olacaksa,

51
00:03:09,870 --> 00:03:19,199
herhangi bir insanın, mesela senin, ilk 100 milyarda olma olasılığı sadece %1'dir.

52
00:03:19,200 --> 00:03:27,049
Ya sen insanlığın hikayesinin umulmadık derecede başlarında doğduğun için inanılmaz şanslı ve özelsin,

53
00:03:27,050 --> 00:03:30,389
ya da doğum sıranın çok da özel bir tarafı yok,

54
00:03:30,390 --> 00:03:33,839
çünkü hiçbir zaman onlarca trilyon insan olmayacak.

55
00:03:33,840 --> 00:03:40,299
İnsanlığın neslinin tükenmesi geç değil, erken olacak.

56
00:03:40,300 --> 00:03:43,999
Ama sonumuzun yakın olduğuna kendimizi çok da inandırmadan önce,

57
00:03:44,000 --> 00:03:48,799
Kıyamet İddiasının tamamen tartışılmaz olmadığını da unutmayalım.

58
00:03:48,800 --> 00:03:50,729
Problem olabilecek şeylerden biri,

59
00:03:50,730 --> 00:03:54,559
referans sınıfı problemidir. Sen, gerçekten de

60
00:03:54,560 --> 00:03:57,919
doğup doğacak bütün insanların içinde tamamen rastgele

61
00:03:57,920 --> 00:04:03,019
bir örnek misin? Eğer çok da uzak olmayan bir gelecekte insanların,

62
00:04:03,020 --> 00:04:06,419
şu anki halinden baya bir farklı olacağına inanıyorsak,

63
00:04:06,420 --> 00:04:09,459
mesela, hepsinin 3 boyutlu yazıcıdan çıkarılmış

64
00:04:09,460 --> 00:04:13,799
organları olacağına, şu anda etrafta bu özelliğe sahip çok fazla insan bulunmaması,

65
00:04:13,800 --> 00:04:18,919
senin de bütün insanlar arasından rastgele bir örnek olmadığının kanıtı olabilir.

66
00:04:18,920 --> 00:04:24,799
Belki de sadece senin gibi, senin etrafındakiler gibi insanlar arasında rastgele bir örneksindir.

67
00:04:24,800 --> 00:04:25,959
İnsanlık tarihinde

68
00:04:25,960 --> 00:04:29,319
çok erken doğmuş insanların arasında.

69
00:04:29,320 --> 00:04:34,539
Ayrıca, Kıyamet İddiası gelecekte olabilecek asıl tehlikelerin olasılığını veya bu tehlikelere karşı

70
00:04:34,540 --> 00:04:38,199
insanların avantajlarını da göz önünde bulundurmaz.

71
00:04:38,200 --> 00:04:43,179
Sadece bu dengenin hangi tarafa doğru yöneleceğini bilemeyeceğimizi farz eder.

72
00:04:43,180 --> 00:04:50,079
İnsanlığın sonunun yakında veya daha sonra gelmesinin olasılığının eşit olduğunu var sayar.

73
00:04:50,080 --> 00:04:52,519
Ama belki de sen buna inanmazsın.

74
00:04:52,520 --> 00:05:00,439
Belki de sen, insan becerisinin, bütün felaketlerden her zaman bir adım önde olacağına inanıyorsundur.

75
00:05:00,440 --> 00:05:02,149
Belki de haklısındır.

76
00:05:02,150 --> 00:05:05,699
Ama bu optimizmden şüphe duymak için nedenlerimiz var.

77
00:05:05,700 --> 00:05:09,899
Örneğin, Fermi paradoksu.

78
00:05:09,900 --> 00:05:18,359
Eğer evrenimizde milyarlarca yıl boyunca yaşama kabiliyetinde olan zeki yaşam formları varsa,

79
00:05:18,360 --> 00:05:20,199
neredeler?

80
00:05:20,200 --> 00:05:23,459
Neden gökyüzü bu kadar sessiz?

81
00:05:23,460 --> 00:05:28,239
Belki de, nesil tükenmesine yol açabilecek tehditler,

82
00:05:28,240 --> 00:05:33,679
herhangi bir yerdeki yaşam formlarının bize ulaşmasına izin vermeyecek kadar yaygındır.

83
00:05:33,680 --> 00:05:35,399
Yani,

84
00:05:35,400 --> 00:05:38,929
bu, sadece pes etmemiz gerektiği anlamına mı geliyor?

85
00:05:38,930 --> 00:05:42,029
"Gönüllü İnsan Yok Olması Hareketi" böyle düşünüyor.

86
00:05:42,030 --> 00:05:50,519
1991'de kurulan bu hareketin destekçileri, insanların dünya üzerinde negatif bir tesiri olduğunu,

87
00:05:50,520 --> 00:05:53,139
ve her zaman da böyle olacağını düşünüyor.

88
00:05:53,140 --> 00:06:00,099
Bu yüzden, üremeyi bırakıp, sönüp gitmenin bizim için ahlaki bir zorunluluk olduğuna inanıyorlar.

89
00:06:00,100 --> 00:06:02,939
Ama bu durumda bir bilgisayar ne yapardı?

90
00:06:02,940 --> 00:06:10,039
Bir bakıma, bu Tom 7'nin yaptığı şey. Video oyunları oynayan bir program yarattı.

91
00:06:10,040 --> 00:06:14,899
Program, oyunları oynamak için yaratıcı teknikler ve stratejiler geliştirdi,

92
00:06:14,900 --> 00:06:21,439
hatta, oyunlarda insanların bile bilmediği, veya en azından ona bahsetmediği aksaklıklar keşfetti.

93
00:06:21,440 --> 00:06:24,239
Tom programa başka oyunlar da oynattı,

94
00:06:24,240 --> 00:06:29,139
Tetris gibi. Ki, bu bence sorumuza daha uygun.

95
00:06:29,140 --> 00:06:32,559
Bilgisayar ne yapması gerektiğini bilemedi.

96
00:06:32,560 --> 00:06:37,879
Bilgisayar, Tetris bloklarını belli şekillerde dizmenin gelecekte büyük farklılıklar yaratacağını

97
00:06:37,880 --> 00:06:44,079
fark edecek kadar, gelecekteki tepkileri hesaplayabilme becerisiyle programlanmamıştı.

98
00:06:44,080 --> 00:06:48,719
Oyunlardan birinde, yine yenilgi çok yakındayken,

99
00:06:48,720 --> 00:06:52,439
bilgisayar biraz ürkütücü bir şey yaptı.

100
00:06:52,440 --> 00:07:01,079
Kaybedip, "oyun bitti" cevabını almak yerine, bilgisayar oyunu duraklattı.

101
00:07:01,080 --> 00:07:02,279
Sonsuza kadar.

102
00:07:02,280 --> 00:07:06,919
Tom 7 bilgisayarın bu hareketinin arkasındaki mantığı şöyle açıkladı,

103
00:07:06,920 --> 00:07:11,919
"Şu anda kaybetmeyi engelleyecek tek hareket, oynamayı bırakmak."

104
00:07:11,920 --> 00:07:13,059
Ve bu doğru da.

105
00:07:13,060 --> 00:07:20,299
Eğer bir oyunu sonsuza kadar durdurursanız, o oyunu asla kaybetmezsiniz.

106
00:07:20,300 --> 00:07:25,459
Ama aynı zamanda o oyunu asla kazanamaz veya en yüksek puana ulaşamazsınız.

107
00:07:25,460 --> 00:07:33,179
Şu anda, bu evrende yaşamın "en yüksek puanınaa" ulaşmanın ne demek olduğunu,

108
00:07:33,180 --> 00:07:36,739
veya buna ulaşıp ulaşamayacağımızı bilmiyor olabiliriz.

109
00:07:36,740 --> 00:07:41,679
Gelecek umutsuz gözüktüğünde bazen panik de yapabiliriz.

110
00:07:41,680 --> 00:07:45,399
Ama eğer oynamaya ve oynadıkça öğrenmeye devam edersek,

111
00:07:45,400 --> 00:07:53,459
belki de eninde sonunda, bazı şeyleri anlayıp, gerçekten de iyi oynamaya başlama şansımız olabilir.

112
00:07:53,460 --> 00:07:57,499
Yani, burada olduğunuz ve oynamaya devam ettiğiniz için teşekkürler.

113
00:07:57,500 --> 00:07:58,879
Ve her zamanki gibi,

114
00:07:58,880 --> 00:08:00,880
izlediğiniz için teşekkürler.

