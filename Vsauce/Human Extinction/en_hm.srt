1
00:00:00,329 --> 00:00:04,838
Hey Vsauce, Michael here. Do you want to be infected with Ebola

2
00:00:04,839 --> 00:00:08,369
without having to leave  your own home or deal with other people?

3
00:00:08,370 --> 00:00:13,669
Well, you might be in luck. You cal already download an Ebola virus

4
00:00:13,670 --> 00:00:14,379
genome.

5
00:00:14,380 --> 00:00:17,769
Right here on the Internet, right now. And if you're willing to wait

6
00:00:17,770 --> 00:00:21,948
a few years for 3D bioprinting technology to progress

7
00:00:21,949 --> 00:00:26,719
a little bit, you can just acquire one then, submit the genome to it

8
00:00:26,720 --> 00:00:30,249
and ta da! All you can print Ebola.

9
00:00:30,250 --> 00:00:35,939
Or anthrax or whatever it is you wish to mass-produce at home

10
00:00:35,940 --> 00:00:40,679
to wipe out humanity.

11
00:00:40,680 --> 00:00:42,519
Are humans going to go extinct

12
00:00:42,520 --> 00:00:46,529
soon? Will human extinction be

13
00:00:46,530 --> 00:00:49,988
anthropogenic? That is the result of human

14
00:00:49,989 --> 00:00:53,549
action. Or will it be one of the good old-fashioned kinds

15
00:00:53,550 --> 00:00:57,448
of extinction Earth's history knows pretty well?

16
00:00:57,449 --> 00:01:02,358
The Global Catastrophic Risks Survey, issued by Oxford University's

17
00:01:02,359 --> 00:01:06,469
Future of Humanity Institute placed our risk of extinction

18
00:01:06,470 --> 00:01:10,949
before the year 2100 at 19%.

19
00:01:10,950 --> 00:01:15,969
Now, you might be thinking "whatever, blah blah blah armageddon".

20
00:01:15,970 --> 00:01:19,399
"It'll be okay, humans are too smart

21
00:01:19,400 --> 00:01:22,859
to go extinct." Maybe you're right.

22
00:01:22,860 --> 00:01:25,569
But it's difficult to predict the distant future

23
00:01:25,570 --> 00:01:29,009
with a lot of certainty. Whats really cool though

24
00:01:29,010 --> 00:01:32,989
is that if you embrace that uncertainty, a simple argument

25
00:01:32,990 --> 00:01:37,329
can show that human extinction soon is actually

26
00:01:37,330 --> 00:01:41,359
more probable. It's called the Doomsday

27
00:01:41,360 --> 00:01:44,379
argument. Imagine a giant

28
00:01:44,380 --> 00:01:47,539
urn that contains either 10 balls

29
00:01:47,540 --> 00:01:51,258
numbered 1 to 10 , or a million balls

30
00:01:51,259 --> 00:01:54,398
numbered 1 to a million. Now, you don't know

31
00:01:54,399 --> 00:01:57,999
which is the case, but you are allowed to pull out

32
00:01:58,000 --> 00:02:01,288
one ball. You go ahead and do that

33
00:02:01,289 --> 00:02:05,769
and it is ball number 4.

34
00:02:05,770 --> 00:02:09,999
That's pretty strong evidence in favour of the 10 ball condition

35
00:02:10,000 --> 00:02:13,749
because drawing a four from a set of 1 through 10

36
00:02:13,750 --> 00:02:18,369
is a one in 10 chance. But drawing four from a million different numbers

37
00:02:18,370 --> 00:02:21,649
is a one in a million chance.

38
00:02:21,650 --> 00:02:25,109
By analogy you are also a numbered

39
00:02:25,110 --> 00:02:28,469
ball. You are a human who knows

40
00:02:28,470 --> 00:02:31,789
approximately what your birth number is.

41
00:02:31,790 --> 00:02:35,048
It's probably somewhere around 100

42
00:02:35,049 --> 00:02:38,119
billion. That's how many other humans

43
00:02:38,120 --> 00:02:41,539
were most likely born before you were.

44
00:02:41,540 --> 00:02:45,039
Importantly, you didn't get to decide which birth number

45
00:02:45,040 --> 00:02:49,169
you would have. So, just like the number for a ball,

46
00:02:49,170 --> 00:02:53,419
you are a random sample from the set of all humans

47
00:02:53,420 --> 00:02:57,548
who will ever live. The Doomsday argument points out

48
00:02:57,549 --> 00:03:02,518
that from 200 billion people there's a 50 percent chance that a randomly chosen

49
00:03:02,519 --> 00:03:03,539
person,

50
00:03:03,540 --> 00:03:06,809
like you, would be born in the first one hundred billion.

51
00:03:06,810 --> 00:03:09,869
Whereas is there will be 10 trillion humans,

52
00:03:09,870 --> 00:03:13,949
there's only a one percent chance that any given human,

53
00:03:13,950 --> 00:03:17,208
say you, would happen to be born withing the first

54
00:03:17,209 --> 00:03:21,439
100 billion. Either you are special

55
00:03:21,440 --> 00:03:27,049
and lucky to be born so improbably early in the story of humanity

56
00:03:27,050 --> 00:03:30,389
or your birth number is to be expected

57
00:03:30,390 --> 00:03:33,839
because there will not be tens of trillions of humans.

58
00:03:33,840 --> 00:03:37,389
Human extinction will be sooner

59
00:03:37,390 --> 00:03:41,729
rather than later. But before you become

60
00:03:41,730 --> 00:03:46,439
too convinced that the end is nigh, keep in mind that the Doomsday argument is

61
00:03:46,440 --> 00:03:47,239
not

62
00:03:47,240 --> 00:03:50,729
uncontroversial. One problem it might have

63
00:03:50,730 --> 00:03:54,559
is a reference class problem. Are you really a

64
00:03:54,560 --> 00:03:57,919
random sample from the set of all humans who will ever

65
00:03:57,920 --> 00:04:03,019
be born? Well, if you believe that in the not so distant future

66
00:04:03,020 --> 00:04:06,419
humans will be quite different than they are today.

67
00:04:06,420 --> 00:04:09,459
For instance, there'll be full of more 3D printed

68
00:04:09,460 --> 00:04:13,799
organs. The mere fact that right now there aren't very many humans

69
00:04:13,800 --> 00:04:17,659
with that trait could be evidence that you aren't a random sample from the

70
00:04:17,660 --> 00:04:18,919
set of all humans,

71
00:04:18,920 --> 00:04:22,149
just from the set of all humans like

72
00:04:22,150 --> 00:04:25,959
you, like those around you. Those born

73
00:04:25,960 --> 00:04:29,649
earlier in human history. Also

74
00:04:29,650 --> 00:04:32,909
the Doomsday argument doesn't consider the likelihoods

75
00:04:32,910 --> 00:04:36,059
of actual threats or human advantages

76
00:04:36,060 --> 00:04:39,629
over those threats in the future. It just assumes that

77
00:04:39,630 --> 00:04:43,179
we don't know which way the balance will lie; that

78
00:04:43,180 --> 00:04:46,609
human extinction soon and human extinction

79
00:04:46,610 --> 00:04:52,529
later are equally likely. Buy maybe you don't believe that.

80
00:04:52,530 --> 00:04:55,539
Maybe you are convinced that human ingenuity will

81
00:04:55,540 --> 00:04:58,959
always stay one step ahead of any extinction event

82
00:04:58,960 --> 00:05:02,149
thrown at it. You could be right,

83
00:05:02,150 --> 00:05:05,699
but there's reason to doubt that optimism.

84
00:05:05,700 --> 00:05:09,899
For example, the Fermi paradox.

85
00:05:09,900 --> 00:05:13,909
If it is likely that intelligent life forms in our universe are capable

86
00:05:13,910 --> 00:05:15,529
of living for billions

87
00:05:15,530 --> 00:05:20,198
and billions of years, where are they?

88
00:05:20,199 --> 00:05:24,249
Why are the skies so silent? Perhaps

89
00:05:24,250 --> 00:05:28,249
it is because extinction level threat events are just

90
00:05:28,250 --> 00:05:31,859
too common for intelligent life anywhere

91
00:05:31,860 --> 00:05:33,679
to ever catch up.

92
00:05:33,680 --> 00:05:35,399
So,

93
00:05:35,400 --> 00:05:38,929
does this mean we should just give up?

94
00:05:38,930 --> 00:05:42,029
The Voluntary Human Extinction Movement thinks so.

95
00:05:42,030 --> 00:05:46,439
Founded in 1991, it's supporters believe that

96
00:05:46,440 --> 00:05:49,439
humans are a negative influence

97
00:05:49,440 --> 00:05:53,359
on Earth and always will be. Thus

98
00:05:53,360 --> 00:05:57,259
we have a moral obligation to just stop reproducing

99
00:05:57,260 --> 00:06:00,769
right now and fade away. Buy what would

100
00:06:00,770 --> 00:06:04,109
a computer do? In a way, that's

101
00:06:04,110 --> 00:06:10,049
kind of what Tom 7 did. He created a program that plays video games.

102
00:06:10,050 --> 00:06:14,209
The program came up with novel techniques and strategies for playing

103
00:06:14,210 --> 00:06:16,509
games and even exploited glitches

104
00:06:16,510 --> 00:06:19,698
humans didn't know about, or at least

105
00:06:19,699 --> 00:06:24,239
hadn't told it about. He also had the program play other games,

106
00:06:24,240 --> 00:06:27,719
like Tetris, which I think is relavant

107
00:06:27,720 --> 00:06:32,559
to our question. The computer struggled to figure what to do.

108
00:06:32,560 --> 00:06:36,918
You see, the computer wasn't programmed to consider future repercussions far

109
00:06:36,919 --> 00:06:37,879
enough ahead

110
00:06:37,880 --> 00:06:41,819
to notice that stacking Tetriminos in certain ways

111
00:06:41,820 --> 00:06:46,769
made a big difference. On one run, when faced with

112
00:06:46,770 --> 00:06:50,749
imminent demise, the computer did something

113
00:06:50,750 --> 00:06:53,819
eerie. Rather than

114
00:06:53,820 --> 00:06:56,969
lose, and receive a 'game over'

115
00:06:56,970 --> 00:07:01,339
it just paused the game. For

116
00:07:01,340 --> 00:07:05,279
ever. Tom 7 describes the computer's reasoning

117
00:07:05,280 --> 00:07:08,449
like this: "The only winning move

118
00:07:08,450 --> 00:07:12,869
is to not play." And that's right.

119
00:07:12,870 --> 00:07:15,989
If you pause a game for ever

120
00:07:15,990 --> 00:07:22,239
you will never lose that game. But you'll also never

121
00:07:22,240 --> 00:07:25,469
win that game or achieve a high score.

122
00:07:25,470 --> 00:07:29,429
Now, we might no know what achieving a

123
00:07:29,430 --> 00:07:32,489
sentient life high score in this universe

124
00:07:32,490 --> 00:07:35,749
means or whether or not we're capable of achieving one.

125
00:07:35,750 --> 00:07:39,089
We might also sometimes panic

126
00:07:39,090 --> 00:07:42,839
when the future looks bleak. But if we  keep playing

127
00:07:42,840 --> 00:07:47,509
and keep learning, chances are we could eventually

128
00:07:47,510 --> 00:07:50,749
figure it out and start playing

129
00:07:50,750 --> 00:07:53,459
really well.

130
00:07:53,460 --> 00:07:57,499
So thanks for continuing to play, for being here.

131
00:07:57,500 --> 00:07:58,879
And as always,

132
00:07:58,880 --> 00:08:00,880
thanks for watching.

