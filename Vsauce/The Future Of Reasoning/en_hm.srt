1
00:00:01,050 --> 00:00:03,309
The Future of Reasoning

2
00:00:03,310 --> 00:00:04,439
Hey Vsauce!

3
00:00:04,440 --> 00:00:05,839
Michael here.

4
00:00:05,840 --> 00:00:07,888
Where is your mind?

5
00:00:07,889 --> 00:00:10,199
Is it in your head?

6
00:00:10,200 --> 00:00:17,419
I mean, that’s where your brain is — and
your brain remembers, plans, makes judgements,

7
00:00:17,420 --> 00:00:25,028
solves problems … but you also remember
and plan with things like these and this.

8
00:00:25,029 --> 00:00:33,319
And you solve problems and make judgements
with all sorts of other stuff, too.

9
00:00:33,320 --> 00:00:40,988
The more you think about it, the more you
realize that while the brain is a wet lump

10
00:00:40,989 --> 00:00:48,259
of fat and protein, no firmer than a glob
of tofu, the MIND is something much larger:

11
00:00:48,260 --> 00:00:53,839
it’s an ever-expanding organ of tissue AND
wood and stone and steel.

12
00:00:53,840 --> 00:00:55,398
And people.

13
00:00:55,399 --> 00:01:02,768
Because of communication we can even make
OTHER PEOPLE extensions of our minds.

14
00:01:02,769 --> 00:01:07,619
We can access their memories and perceptions
and knowledge by simply asking.

15
00:01:07,620 --> 00:01:09,199
Or not.

16
00:01:09,200 --> 00:01:14,679
I don’t need to learn how to fix a car AND
practice medicine AND vulcanize rubber OR

17
00:01:14,680 --> 00:01:20,749
remember everything … other people are doing
that for me just as I do things for them.

18
00:01:20,750 --> 00:01:27,399
We are a species of individuals that is also
one big interdependent lumbering growth.

19
00:01:27,400 --> 00:01:31,089
A frantic blur of flesh and concrete.

20
00:01:31,090 --> 00:01:38,019
A ‘techno sapien’ powered by imaginations
and passions made real by a hallowed faculty

21
00:01:38,020 --> 00:01:39,299
we call REASON.

22
00:01:39,300 --> 00:01:44,999
Reason, it is said, guides us to truer knowledge
and better decisions.

23
00:01:45,000 --> 00:01:51,119
It’s allowed us to increase life-expectancy,
suffer less, work together better, and it’s

24
00:01:51,120 --> 00:01:56,099
bound to take us further and higher until
the end of time.

25
00:01:56,100 --> 00:01:58,849
Or is it?

26
00:01:58,850 --> 00:02:05,359
The organ we USE to reason takes millions
of years to evolve, but the fruits of reason

27
00:02:05,360 --> 00:02:08,179
grow rapidly and are ever accelerating.

28
00:02:08,180 --> 00:02:13,559
In the next four decades, we’re expected
to build the equivalent of another new york

29
00:02:13,560 --> 00:02:15,979
city every month

30
00:02:15,980 --> 00:02:22,199
More concrete was installed in the last two
decades outside the US than the US installed

31
00:02:22,200 --> 00:02:25,109
during the entire 20th century.

32
00:02:25,110 --> 00:02:29,499
This growth means that quality of life around
the world is rising.

33
00:02:29,500 --> 00:02:35,499
It means that electricity, manufactured goods,
food, comfort and transportation are all becoming

34
00:02:35,500 --> 00:02:38,109
more common and accessible.

35
00:02:38,110 --> 00:02:44,459
But there are hints that reason and logic
are struggling aginst the complexity of it

36
00:02:44,460 --> 00:02:50,179
all; against our growing dependence on the
things we’ve built and their unintended

37
00:02:50,180 --> 00:02:52,749
consequences.

38
00:02:52,750 --> 00:02:59,219
Nearly every part of life as we know it today
involves or relies on a process that releases

39
00:02:59,220 --> 00:03:02,639
molecules with lopsided electrical charges.

40
00:03:02,640 --> 00:03:08,379
This property causes them to absorb and re-emit
thermal radiation, pinging it around so that

41
00:03:08,380 --> 00:03:11,539
it escapes into space more slowly.

42
00:03:11,540 --> 00:03:15,899
Having more warmer parcels of air means stronger
weather events.

43
00:03:15,900 --> 00:03:21,729
They can’t be pinned on any particular extreme
storm, but they make extreme storms in general

44
00:03:21,730 --> 00:03:23,909
more extreme and frequent.

45
00:03:23,910 --> 00:03:29,549
What’s a stake isn’t just ‘bad weather’
it’s disaster: it’s more lives lost, more

46
00:03:29,550 --> 00:03:34,409
property lost, it’s more droughts, more
hunger, more famine, more people needing refuge,

47
00:03:34,410 --> 00:03:40,669
and a even greater reliance on the very things
that caused the problems in the first place.

48
00:03:40,670 --> 00:03:48,389
In total, we release about 51 billion tons
of such gases every year and we need to release

49
00:03:48,390 --> 00:03:50,809
zero.

50
00:03:50,810 --> 00:03:56,039
But how do you re-think … everything?

51
00:03:56,040 --> 00:04:00,019
Who gets to direct the costs and tradeoffs?

52
00:04:00,020 --> 00:04:05,979
How do you achieve collaboration between nearly
every local and national government when what

53
00:04:05,980 --> 00:04:11,259
works in one place won’t work everywhere,
when decisions effect jobs in one place and

54
00:04:11,260 --> 00:04:12,738
food in another.

55
00:04:12,739 --> 00:04:19,508
When not just things need to be re-thought,
but also habits and traditions and values.

56
00:04:19,509 --> 00:04:25,379
How do you achieve consensus when a problem
isn’t obvious to the senses, is far away

57
00:04:25,380 --> 00:04:30,929
in space and time, requires solutions that
affect people in different ways, and as a

58
00:04:30,930 --> 00:04:36,399
product of science, always carries some uncertainty?

59
00:04:36,400 --> 00:04:42,968
The philosopher Timothy Morton calls something
so massively distributed in time and space

60
00:04:42,969 --> 00:04:50,278
and so viscous — so STICKY that it adheres
to all that touch it, a HYPEROBJECT.

61
00:04:50,279 --> 00:04:56,228
Every civilizations that grows at the speed
of reason must at some point face hyperobjects.

62
00:04:56,229 --> 00:05:02,288
In fact, the fact that we still haven’t
found evidence of intelligent life beyond

63
00:05:02,289 --> 00:05:07,998
Earth has been brought up as evidence that
some sort of GREAT FILTER, might exist that

64
00:05:07,999 --> 00:05:12,859
few civilizations manage to get past.

65
00:05:12,860 --> 00:05:19,329
That a hyperobject like our impact on the
planet might be such a great filter is not

66
00:05:19,330 --> 00:05:20,329
a new idea.

67
00:05:20,330 --> 00:05:26,568
What it’ll take to solve it is the topic
of Bill Gate’s HOW TO AVOID A CLIMATE DISASTER.

68
00:05:26,569 --> 00:05:31,619
And I decided to do this video in partnership
with him and his team because the way we deal

69
00:05:31,620 --> 00:05:35,859
with hyperobjects reveals a lot about the
mind.

70
00:05:35,860 --> 00:05:40,318
It’s easy — and common! — to think that
we would all be better off if everyone was

71
00:05:40,319 --> 00:05:43,709
just more rational.

72
00:05:43,710 --> 00:05:48,908
But what if reasoning wasn’t built for what
we’ve become?

73
00:05:48,909 --> 00:05:53,459
Let’s begin by looking at behavioral inertia.

74
00:05:53,460 --> 00:05:57,739
Behavioral inertia is the tendency to keep
doing what you’re already doing.

75
00:05:57,740 --> 00:05:59,159
Status quo bias.

76
00:05:59,160 --> 00:06:04,929
It can be a frustrating bias if you desire
change, but its origin isn’t a flaw.

77
00:06:04,930 --> 00:06:10,409
If an organism has managed to survive long
enough to reproduce and provide and care for

78
00:06:10,410 --> 00:06:16,269
its offspring, then the state of its world,
was sufficient for its genes to spread.

79
00:06:16,270 --> 00:06:18,288
That’s all it takes to persist.

80
00:06:18,289 --> 00:06:24,158
The types of organisms we see around us will
naturally be those that managed to persist

81
00:06:24,159 --> 00:06:27,718
and didn’t, after reaching the point at
which they could persist, rock the boat too

82
00:06:27,719 --> 00:06:29,758
much.

83
00:06:29,759 --> 00:06:35,158
Behavioral inertia can help slow down the
accumulation of unintended consequences and

84
00:06:35,159 --> 00:06:42,568
the loss of ideas that work, but it can also
slow down innovation and adaptation.

85
00:06:42,569 --> 00:06:49,538
If the environmental impacts of our society
were more immediate and un-ignorable, it wouldn’t

86
00:06:49,539 --> 00:06:52,788
be so tempting to apply this inertial brake.

87
00:06:52,789 --> 00:06:59,219
But emissions are invisible and their consequences
aren’t immediate or local.

88
00:06:59,220 --> 00:07:02,989
They impact future people and people far away.

89
00:07:02,990 --> 00:07:07,989
Those who are different from us, poorer than
us, people we will never meet.

90
00:07:07,990 --> 00:07:13,609
This may be one of the first challenges advancing
civilizations face: weilding not just the

91
00:07:13,610 --> 00:07:19,989
power of technology and distributed cognition,
but also the responsibilities.

92
00:07:19,990 --> 00:07:28,718
Extending not just the mind but also EMPATHY
could certainly be a great filter.

93
00:07:28,719 --> 00:07:34,918
Our lower instincts may bias us, but surely,
REASON can help us navigate towards the future

94
00:07:34,919 --> 00:07:36,638
we want, right?

95
00:07:36,639 --> 00:07:38,679
Well, what IS reason?

96
00:07:38,680 --> 00:07:41,188
It’s a way of making inferences.

97
00:07:41,189 --> 00:07:48,189
An inference is any new information extracted
from the information you already have.

98
00:07:48,190 --> 00:07:54,098
We make inferences all the time — every
living thing does.

99
00:07:54,099 --> 00:07:59,688
We don’t have measuring-tape tentacles that
shoot from our eyes, and what actually enters

100
00:07:59,689 --> 00:08:06,188
our brain is just a 2D image, but our brains
nonetheless INFER depth by attending to cues

101
00:08:06,189 --> 00:08:10,838
like stereopsis, occultation, perspective,
parallax, size…

102
00:08:10,839 --> 00:08:15,258
When this happens, we accept it as reality.

103
00:08:15,259 --> 00:08:20,239
We aren’t aware of the visual processing
that made it possible and don’t have to

104
00:08:20,240 --> 00:08:21,239
be.

105
00:08:21,240 --> 00:08:27,409
If, however, we do consciously consider WHY
a certain conclusion was reached, then BOOM

106
00:08:27,410 --> 00:08:28,769
that’s REASONING.

107
00:08:28,770 --> 00:08:34,219
Reasoning is the process of making inferences
not automatically and instrinctively, but

108
00:08:34,220 --> 00:08:39,058
by looking at facts and seeing what conclusion
they support.

109
00:08:39,059 --> 00:08:43,598
When Eratosthenes calculated the circumference
of the Earth to within a percentage or two

110
00:08:43,599 --> 00:08:48,989
of the value accepted today, he didn’t do
it by MEASURING the Earth and he didn’t

111
00:08:48,990 --> 00:08:55,328
just percieve it as self-evident, he INFERRED
it from what he knew about shadows and how

112
00:08:55,329 --> 00:08:57,619
long it took camels to move.

113
00:08:57,620 --> 00:09:02,869
Stories like that make it easy to believe
that reasoning evolved because it supercharged

114
00:09:02,870 --> 00:09:09,919
our abilities; it clearly moves us towards
truer conclusions, better decisions, and knowledge

115
00:09:09,920 --> 00:09:12,489
no other species could infer.

116
00:09:12,490 --> 00:09:19,539
Attempts to describe the rules of good, orderly
reason, became logic and mathematics, concepts

117
00:09:19,540 --> 00:09:26,429
so general and abstract that while we were
still animals, armed with them, we were no

118
00:09:26,430 --> 00:09:27,659
longer beasts.

119
00:09:27,660 --> 00:09:31,549
But that’s the rub, isn’t it?

120
00:09:31,550 --> 00:09:37,679
If reasoning is so great, why are we the only
species with such a sophisticated grasp of

121
00:09:37,680 --> 00:09:38,679
it?

122
00:09:38,680 --> 00:09:44,710
And if its purpose is truth and good judgement,
why don’t we all agree on everything?

123
00:09:44,711 --> 00:09:46,698
These questions make up what Hugo Mercier
and Dan Sperber call the Enigma of Reason.

124
00:09:46,699 --> 00:09:52,578
It’s tempting to think that disagreements
happen because while I’M being rational,

125
00:09:52,579 --> 00:09:54,929
those who disagree with me are being irrational.

126
00:09:54,930 --> 00:09:55,929
Urgh!

127
00:09:55,930 --> 00:09:58,789
If only people would use reason and logic.

128
00:09:58,790 --> 00:10:00,299
What’s happened to the world!

129
00:10:00,300 --> 00:10:07,559
That’s a fair complaint if you’re arguing
over logic puzzles, but the world is not a

130
00:10:07,560 --> 00:10:09,179
logic puzzle.

131
00:10:09,180 --> 00:10:11,648
this, however, is:

132
00:10:11,649 --> 00:10:14,018
Paul is looking at Mary.

133
00:10:14,019 --> 00:10:16,259
Mary is looking at Peter.

134
00:10:16,260 --> 00:10:18,109
Paul is married.

135
00:10:18,110 --> 00:10:19,599
Peter is unmarried.

136
00:10:19,600 --> 00:10:24,559
Is a married person looking at an unmarried
person?

137
00:10:24,560 --> 00:10:25,559
Yes.

138
00:10:25,560 --> 00:10:26,559
No.

139
00:10:26,560 --> 00:10:29,888
Or not enough information to decide?

140
00:10:29,889 --> 00:10:32,239
think about it.

141
00:10:32,240 --> 00:10:35,119
The answer is YES.

142
00:10:35,120 --> 00:10:40,659
You may have thought there’s no way to know,
because we don’t know if Mary is married.

143
00:10:40,660 --> 00:10:43,809
But she either is or she isn’t.

144
00:10:43,810 --> 00:10:49,489
And if she IS, then she, a married person,
is looking at Peter, an unmarried person.

145
00:10:49,490 --> 00:10:56,769
If she ISN’T then Paul, a married person,
is looking at her, an unmarried person.

146
00:10:56,770 --> 00:11:01,198
No matter what Mary’s deal is, the answer
will be YES.

147
00:11:01,199 --> 00:11:05,528
When people get this puzzle wrong and the
correct answer is explained to them, they

148
00:11:05,529 --> 00:11:11,349
almost always immedaitely see why it’s right
and change their mind.

149
00:11:11,350 --> 00:11:13,959
Life is not usually like that.

150
00:11:13,960 --> 00:11:17,659
Now, take a look at this logical syllogism:

151
00:11:17,660 --> 00:11:20,419
All elephants are awesome.

152
00:11:20,420 --> 00:11:23,119
Michael is an elephant.

153
00:11:23,120 --> 00:11:25,768
Therefore, Michael is awesome.

154
00:11:25,769 --> 00:11:27,628
This conclusion is logically valid.

155
00:11:27,629 --> 00:11:28,628
But it’s not SOUND.

156
00:11:28,629 --> 00:11:32,398
The conclusion follows from these assumptions,
but are these assumptions true?

157
00:11:32,399 --> 00:11:33,409
No.

158
00:11:33,410 --> 00:11:37,489
I am NOT an elephant.

159
00:11:37,490 --> 00:11:40,709
Also, this premise … is subjective.

160
00:11:40,710 --> 00:11:42,588
What does it MEAN to be awesome?

161
00:11:42,589 --> 00:11:45,268
Can you measure it with an awesome-ometer?

162
00:11:45,269 --> 00:11:50,989
So you can see why, when analyzing something
like our impact on the planet, logic can only

163
00:11:50,990 --> 00:11:53,559
be a partial tool.

164
00:11:53,560 --> 00:11:59,318
If some people have more to lose than others,
who gets to decide which are fair?

165
00:11:59,319 --> 00:12:04,398
Still, though, it would seem that reasoning
should be able help out here.

166
00:12:04,399 --> 00:12:12,438
If each of us would just attend to ONLY the
facts, surely we’d all recognize the same,

167
00:12:12,439 --> 00:12:13,438
reasonable approach.

168
00:12:13,439 --> 00:12:18,239
Problem is, that’s not how reasoning works.

169
00:12:18,240 --> 00:12:23,179
Since the scientific study of human reasoning
began about a hundred years ago, it’s been

170
00:12:23,180 --> 00:12:31,039
found again and again that we’re not only
BAD at reasoning, lazy and biased, but almost

171
00:12:31,040 --> 00:12:34,148
seem PROGRAMMED to be bad.

172
00:12:34,149 --> 00:12:36,829
Like the flaws are intentional…

173
00:12:36,830 --> 00:12:42,909
In an episode of Mind Field I once used a
magician to pull off a little experiment.

174
00:12:42,910 --> 00:12:48,119
He asked people to look at two faces and choose
which of the two they would prefer to work

175
00:12:48,120 --> 00:12:53,648
with, placing their preferences in one pile,
and those they rejected into another.

176
00:12:53,649 --> 00:12:59,369
Then, the pile of people they picked were
shown again and each person was asked to provide

177
00:12:59,370 --> 00:13:02,829
a REASON for why they chose that person.

178
00:13:02,830 --> 00:13:07,109
But with a little slight of hand, the magician
managed to sneak in some of the faces they

179
00:13:07,110 --> 00:13:08,669
had just rejected.

180
00:13:08,670 --> 00:13:13,138
Amazingly, the majority of people didn’t
even notice the trick.

181
00:13:13,139 --> 00:13:19,419
Not only that, they were able to effortlessly
explain the reasons behind their choice — a

182
00:13:19,420 --> 00:13:23,809
choice they never actually made.

183
00:13:23,810 --> 00:13:27,679
Remembering faces you’ve only seen briefly
isn’t the easiest thing to do, but other

184
00:13:27,680 --> 00:13:32,888
studies have shown that even if the task involves
answering questions about one’s political

185
00:13:32,889 --> 00:13:37,898
beliefs — things we would seemingly have
a firmer grasp on — still nearly half of

186
00:13:37,899 --> 00:13:43,078
participants will fail to notice that answers
they gave have been reversed when they’re

187
00:13:43,079 --> 00:13:46,188
later asked to explain them.

188
00:13:46,189 --> 00:13:52,638
Point is, we seem practically BUILT to give
reasons for whatever we think we must, and

189
00:13:52,639 --> 00:13:56,278
NOT the reasons we actually used to reach
a conclusion.

190
00:13:56,279 --> 00:14:01,999
What if we don’t even USE reasons to form
our beliefs?

191
00:14:02,000 --> 00:14:05,109
Let’s talk about INTUITIONS.

192
00:14:05,110 --> 00:14:10,099
Our brains have evolved over millions of years
to react to the world around us in brilliant

193
00:14:10,100 --> 00:14:12,829
ways with little to no input from us.

194
00:14:12,830 --> 00:14:18,109
For example, when you notice that someone
is upset, you’ve don’t consciously think,

195
00:14:18,110 --> 00:14:24,828
“ok, so their eyebrows and oriented like
that, their speaking is curt, their posture

196
00:14:24,829 --> 00:14:29,588
… hmmmm … ah ha! those are reasons to
conclude that they are upset!”

197
00:14:29,589 --> 00:14:34,679
Instead, the belief that they may be upset
was just apparent.

198
00:14:34,680 --> 00:14:36,398
You intuited it.

199
00:14:36,399 --> 00:14:41,309
You ‘know’ it without exactly know HOW
you exactly you came to know it.

200
00:14:41,310 --> 00:14:47,948
The mood recognizing parts of your brain operate
in a way that is opaque to your awareness.

201
00:14:47,949 --> 00:14:54,018
BUT if someone asks you, why you think they’re
upset, you can nonetheless produce all sorts

202
00:14:54,019 --> 00:14:58,508
of reasons — some may have been the ones
your brain actually attended to.

203
00:14:58,509 --> 00:15:01,448
But they’re all just guesses.

204
00:15:01,449 --> 00:15:09,438
Instead of using reasoning to COME to conclusions,
we use conclusions to come to reasons.

205
00:15:09,439 --> 00:15:11,609
To be fair, we CAN go the other way.

206
00:15:11,610 --> 00:15:15,849
We love puzzles and when we don’t have a
strong intuition either way, we can sit down

207
00:15:15,850 --> 00:15:19,669
and mull over various reason to think one
thing or another.

208
00:15:19,670 --> 00:15:24,429
Our love of puzzles suggests that reasoning
has a survival value.

209
00:15:24,430 --> 00:15:27,929
Organisms that found it pleasurable would
be more likely to use it.

210
00:15:27,930 --> 00:15:33,679
But when we reason alone, even when we have
no motivation to reach any particular conclusion,

211
00:15:33,680 --> 00:15:40,119
we STILL exhibit deep biases that seem less
like mistakes and more like features.

212
00:15:40,120 --> 00:15:45,369
For example, it’s been shown that between
two otherwise similar products, people will

213
00:15:45,370 --> 00:15:50,758
prefer to buy the one with more features — even
if they don’t want those features, never

214
00:15:50,759 --> 00:15:54,248
plan to use them, and think they’re all
pointless and over complicated.

215
00:15:54,249 --> 00:15:55,558
Why?

216
00:15:55,559 --> 00:16:02,878
Well it might be that we find such decisions
easier to justify … to OTHERS.

217
00:16:02,879 --> 00:16:08,648
We won’t feel embarrassed if someone criticizes
us for getting fewer features.

218
00:16:08,649 --> 00:16:14,188
After decades of findings like this, Hugo
Mercier and Dan Sperber began to hypothesize

219
00:16:14,189 --> 00:16:22,628
that reasoning to help us make better decisions,
but instead, to help us make social decisions.

220
00:16:22,629 --> 00:16:25,409
Humans inhabit a cognitive niche on this planet.

221
00:16:25,410 --> 00:16:32,209
We aren’t strong or sharp or hidden or venomous,
instead, our advantage comes from cognition:

222
00:16:32,210 --> 00:16:34,159
reasoning and cooperation.

223
00:16:34,160 --> 00:16:39,818
We can plan hunt, build traps, and engage
in coordinated strategies that can be tested

224
00:16:39,819 --> 00:16:44,198
and modified on the fly, not by millennia
of evolution.

225
00:16:44,199 --> 00:16:47,338
Reasons allow us to so those things.

226
00:16:47,339 --> 00:16:50,319
It’s hard to convince people that your intuitions
are true.

227
00:16:50,320 --> 00:16:54,588
But if you can give REASONS for them, its
a whole heck of a lot easier to convince other

228
00:16:54,589 --> 00:16:59,909
people that you’re right.

229
00:16:59,910 --> 00:17:06,029
Reason also allows us to justify ourselves
in the eyes of others.

230
00:17:06,030 --> 00:17:11,160
To explain who we are and express the kinds
of reasons we like, what other people can

231
00:17:11,161 --> 00:17:15,879
expect from us, and what we will likely expect
from them.

232
00:17:15,880 --> 00:17:22,149
This social theory of reasoning helps explain
why two people can earnestly and rationally

233
00:17:22,150 --> 00:17:23,899
arrive at different views.

234
00:17:23,900 --> 00:17:29,149
They each have their own unique brain and
values and dispositions and experiences and

235
00:17:29,150 --> 00:17:31,579
THAT’S what drove their thinking.

236
00:17:31,580 --> 00:17:36,649
The reasons they give may or may not be the
REAL reasons they came to their conclusions,

237
00:17:36,650 --> 00:17:39,729
but it’s the best anyone can do.

238
00:17:39,730 --> 00:17:45,269
The social theory also explains why people
tend to give such weak reasons for their beliefs

239
00:17:45,270 --> 00:17:49,949
at first or when their intended audience doesn’t
need much convincing.

240
00:17:49,950 --> 00:17:55,149
It would be a waste of time and cognitive
reasources to construct grand slam reasons

241
00:17:55,150 --> 00:18:00,279
for everything I said and did and thought
when it wasn’t necessary.

242
00:18:00,280 --> 00:18:04,539
Instead, I can off-load some of the work to
other people.

243
00:18:04,540 --> 00:18:12,699
If I say, “I want to have lunch at ABC Burgers”
my friend might say, “ah, no thanks, I had

244
00:18:12,700 --> 00:18:17,779
burgers yesterday” and I might reply back,
“oh well that’s no problem, they also

245
00:18:17,780 --> 00:18:20,649
have hot dogs and great salads”

246
00:18:20,650 --> 00:18:25,909
But if my friend said “ah, no thanks, I’m
trying to spend less money eating out this

247
00:18:25,910 --> 00:18:32,589
month” I might reply, “oh well ABC Burgers
is really cheap and I;ve got a coupon!”

248
00:18:32,590 --> 00:18:37,779
What’s going on there is that I’m providing
reasons only as my interlocutor presses for

249
00:18:37,780 --> 00:18:38,779
them.

250
00:18:38,780 --> 00:18:42,129
If they press harder and harder, my reasons
will become better and better until either

251
00:18:42,130 --> 00:18:47,559
I win them over, or we come to some different,
more harmonious decision.

252
00:18:47,560 --> 00:18:54,269
So when people appear to be lazy reasoners
or to have bad reasons or none at all, it’s

253
00:18:54,270 --> 00:19:00,399
usually just the case that they’re using
reason as it evolved to function; socially.

254
00:19:00,400 --> 00:19:06,449
It starts off weak, improving if others push
it and always tailoring its work to an intended

255
00:19:06,450 --> 00:19:08,229
audience.

256
00:19:08,230 --> 00:19:14,109
the social theory of reasons can even explain
the existence of biases that otherwise make

257
00:19:14,110 --> 00:19:15,109
little sense.

258
00:19:15,110 --> 00:19:20,159
For example, it would seem that in coming
to conclusions about the world, it would behoove

259
00:19:20,160 --> 00:19:25,639
an organism to pay particular attention to
information that went against what it believed.

260
00:19:25,640 --> 00:19:30,979
That way, they would be able to adjust their
beliefs making them truer, more general, and

261
00:19:30,980 --> 00:19:32,339
more complete.

262
00:19:32,340 --> 00:19:35,909
To a certain extent, that IS what happens
… but not always.

263
00:19:35,910 --> 00:19:41,449
When someone “does their own research”
they often come to the very conclusion they

264
00:19:41,450 --> 00:19:42,449
wanted after all.

265
00:19:42,450 --> 00:19:43,449
When a person strongly believes that our impact
on the planet isn’t a problem, they tend

266
00:19:43,450 --> 00:19:44,449
to gravitate towards reasons it might not
be and see such reasons in all kinds of data.

267
00:19:44,450 --> 00:19:50,309
This is called the CONFIRMATION BIAS: our
tendency to look for, prefer, and interpret

268
00:19:50,310 --> 00:19:54,369
information so that it confirms what we already
think.

269
00:19:54,370 --> 00:20:01,119
It frustrates our ability to accept new, inconvienent
data and is a problem for the intellectualist

270
00:20:01,120 --> 00:20:03,029
view of reason.

271
00:20:03,030 --> 00:20:08,929
If reason is for finding truth and making
better decisions, why would it have this major

272
00:20:08,930 --> 00:20:10,059
weakness?

273
00:20:10,060 --> 00:20:16,069
Because, the social theory says, reasoning
is a GROUP ACTIVITY.

274
00:20:16,070 --> 00:20:24,259
If I think that option A is true and the best,
and you think option B is true and the best,

275
00:20:24,260 --> 00:20:30,309
if we both researched BOTH options and sifted
through reasons in support of BOTH options,

276
00:20:30,310 --> 00:20:35,999
we would both have twice the work to do than
we would if, instead, I simply came up with

277
00:20:36,000 --> 00:20:41,169
reason for why I was right, and you attended
to reasons for why YOU were right.

278
00:20:41,170 --> 00:20:46,919
The confirmation bias at least HALVES the
cognitive work that must be done.

279
00:20:46,920 --> 00:20:52,549
Now sometimes a lone reasoner will have a
bad idea.

280
00:20:52,550 --> 00:20:55,259
Or a decent idea with some bad parts.

281
00:20:55,260 --> 00:21:01,249
The reasons they have to justify and argue
for it will be suffiencent for them and those

282
00:21:01,250 --> 00:21:04,029
who intuitively agree but may be weak.

283
00:21:04,030 --> 00:21:09,569
But subjected to deliberation, put forth into
the machine of collective thought, it can

284
00:21:09,570 --> 00:21:16,089
be evaulated and judged not by one mind or
a group of minds thinking alike, but by something

285
00:21:16,090 --> 00:21:20,279
special … the crowd.

286
00:21:20,280 --> 00:21:25,329
Humans have long known of the WISDOM OF THE
CROWDS: the phenomenon by which a collection

287
00:21:25,330 --> 00:21:30,889
of many people can process information into
a conclusion better than any one person could

288
00:21:30,890 --> 00:21:31,889
do alone.

289
00:21:31,890 --> 00:21:36,799
It’s why we don’t trust big decisions
to a single person, no matter how educated

290
00:21:36,800 --> 00:21:38,429
or powerful they are.

291
00:21:38,430 --> 00:21:42,879
Instead, we ask a group of to deliberate.

292
00:21:42,880 --> 00:21:44,969
To reason together.

293
00:21:44,970 --> 00:21:49,609
In this way, the biases and errors of each
is smoothed out and the decision wiser.

294
00:21:49,610 --> 00:21:54,519
In a famous example, it’s been repeatedly
shown that if you ask a bunch of people to

295
00:21:54,520 --> 00:22:00,099
guess how many jelly beans are in a jar, you’ll
find that the average of all of their answers

296
00:22:00,100 --> 00:22:04,289
is CLOSER TO THE REAL NUMBER than any one
individual was alone.

297
00:22:04,290 --> 00:22:05,639
Even the smartest individual.

298
00:22:05,640 --> 00:22:11,379
What happens is that although some people
may guess a number way too big, that mistake

299
00:22:11,380 --> 00:22:17,939
is balanced out by the fact that others will
inevitably guess a number way too small.

300
00:22:17,940 --> 00:22:24,479
All together, their disagreement evens out
into spectacular accuracy.

301
00:22:24,480 --> 00:22:28,709
We have now arrived at the problem.

302
00:22:28,710 --> 00:22:34,899
Reasoning evolved to be used socially where
many different perspectives had to all deliberate

303
00:22:34,900 --> 00:22:37,299
towards a common conclusion.

304
00:22:37,300 --> 00:22:40,769
Such contexts are becoming less and less common.

305
00:22:40,770 --> 00:22:46,959
And it is becoming easier and easier to simply
be a lone reasoner, justifying only a particular

306
00:22:46,960 --> 00:22:52,229
viewpoint without doing the harder work of
deliberating and acting.

307
00:22:52,230 --> 00:22:57,569
The internet gives voices to more perspectives
than ever before in our history, but it also

308
00:22:57,570 --> 00:23:03,039
makes it easy to disengage from accountability
and find places where everyone believes what

309
00:23:03,040 --> 00:23:04,409
you do.

310
00:23:04,410 --> 00:23:10,659
Furthermore, because of technology, we confront
more issues more rapidly than ever before

311
00:23:10,660 --> 00:23:13,239
that we’re expected to have opinions about.

312
00:23:13,240 --> 00:23:18,169
And the growing complexity and specialization
of the modern world makes it difficult for

313
00:23:18,170 --> 00:23:23,349
each of us to have well-informed prepared
reasons for the acceleraeting accretion of

314
00:23:23,350 --> 00:23:24,769
intutions we must form.

315
00:23:24,770 --> 00:23:29,369
in response, we look for lone reasoners who
can defend our intuitions for us.

316
00:23:29,370 --> 00:23:34,519
They reasons they give don’t need to be
good, just good ENOUGH that we can feel like

317
00:23:34,520 --> 00:23:36,969
justification exists.

318
00:23:36,970 --> 00:23:42,299
In the past, unconvincing reasons had to be
painted on sandwich boards.

319
00:23:42,300 --> 00:23:48,599
But now, the democritization of communication
means that even unpopular, unconvincing, nonsensical

320
00:23:48,600 --> 00:23:55,669
ideas can be presented with the same trust-inducing
typefaces and professional look as common

321
00:23:55,670 --> 00:23:56,669
ones.

322
00:23:56,670 --> 00:24:00,379
Those who disagree may challenge the reasons
you’ve been given, show them to be contradictory,

323
00:24:00,380 --> 00:24:04,489
and produce betters ones for THEIR side, but
to what end?

324
00:24:04,490 --> 00:24:08,799
It’s all preparation for a debate that never
comes.

325
00:24:08,800 --> 00:24:13,679
You play a very small role in deciding how
society is run.

326
00:24:13,680 --> 00:24:18,649
Even if a good faith discussion between a
representative slice of America came to a

327
00:24:18,650 --> 00:24:24,969
resolution, if nothing can come of it, why
not just throw shade and sick burns or revel

328
00:24:24,970 --> 00:24:29,419
in the pleasure of reasoning by treating everything
like a big giant puzzle?

329
00:24:29,420 --> 00:24:35,569
It's easy to think that it doesn’t matter,
because after all, those in charge, the brilliant

330
00:24:35,570 --> 00:24:40,969
scientists and powerful billionaires, will
surely come to our rescue.

331
00:24:40,970 --> 00:24:46,739
Some giant TECHNOSALVATION is surely on the
horizon.

332
00:24:46,740 --> 00:24:48,169
Perhaps it is.

333
00:24:48,170 --> 00:24:53,409
But everything we know about reason suggets
that those implementing it should be held

334
00:24:53,410 --> 00:24:58,389
accountable by as many different perspectives
as possible.

335
00:24:58,390 --> 00:25:04,359
Leaders could lead deliberations and be elected
for their ability to moderate social reasoning,

336
00:25:04,360 --> 00:25:05,419
but that’s boring!

337
00:25:05,420 --> 00:25:10,589
Why lead when you could follow: look at what
some people believe and generate reasons for

338
00:25:10,590 --> 00:25:13,459
why they’re right, and they’ll love it!

339
00:25:13,460 --> 00:25:18,889
Of course, the hard work — the REAL work
— the work that truly elevates us on this

340
00:25:18,890 --> 00:25:24,279
planet, is not in telling poeple that they’re
right, but in trying to convince others and

341
00:25:24,280 --> 00:25:29,029
in so doing, use reason as it evolved to be
used.

342
00:25:29,030 --> 00:25:35,459
The future of reason may in fact be the past
of reason.

343
00:25:35,460 --> 00:25:38,939
In practice, what does all this look like?

344
00:25:38,940 --> 00:25:44,199
Some researchers have gone so far as to recommend
national deliberation days where citizens

345
00:25:44,200 --> 00:25:49,469
celebrate by literally joining small groups
and talking through their opinions and comparing

346
00:25:49,470 --> 00:25:51,419
reasons.

347
00:25:51,420 --> 00:25:56,719
Tests of such strategies have shown that a
return to the small, targeted discussions

348
00:25:56,720 --> 00:26:02,529
our reasoning abilities evolved to excel in
leaves all participants with a greater understanding

349
00:26:02,530 --> 00:26:07,439
of not just what they believe and why, but
about decisions that could actually be made

350
00:26:07,440 --> 00:26:10,569
and actions that could be taken.

351
00:26:10,570 --> 00:26:16,209
Others have gone even further, recommending
that the true future of reason at its best

352
00:26:16,210 --> 00:26:19,269
is the construction of a lottocracy.

353
00:26:19,270 --> 00:26:26,269
A form of government where decisions are made
not by elected leaders, but by people literally

354
00:26:26,270 --> 00:26:28,629
chosen at random.

355
00:26:28,630 --> 00:26:34,459
We decide the fate of a person this way, why
not the fate of the people?

356
00:26:34,460 --> 00:26:40,009
What IF decisions were made not by politicians
alone, but at least occasionally by groups

357
00:26:40,010 --> 00:26:45,609
of actual citizens representing differences
in thought, not just geography, who were brought

358
00:26:45,610 --> 00:26:51,109
together and paid for their time to learn
from experts and then deliberate on an assigned

359
00:26:51,110 --> 00:26:56,319
issue until a conclusion was reached or, at
the least, a recommendation?

360
00:26:56,320 --> 00:27:02,029
Instead of being motivated by re-election,
money, attention, and power, individuals chosen

361
00:27:02,030 --> 00:27:06,819
at random would have only their conscious
to guide them.

362
00:27:06,820 --> 00:27:11,059
Special interests and corporations wouldn’t
be able to cozy up to those likely to be elected

363
00:27:11,060 --> 00:27:19,229
— if any one of us could some day serve,
they’d have cozy up to and protect … all

364
00:27:19,230 --> 00:27:20,289
of us.

365
00:27:20,290 --> 00:27:25,519
Instead of the learning and deliberation being
done by people you never meet with offices

366
00:27:25,520 --> 00:27:30,509
in buildings you can’t access, gradually,
over time, more and more of your very own

367
00:27:30,510 --> 00:27:33,199
neighbors would have had the honor.

368
00:27:33,200 --> 00:27:39,089
People chosen at random would obviously lack
the same celebrity status and mandate that

369
00:27:39,090 --> 00:27:46,079
elected leaders cultivate and achieve — and
iconic figures we relate to aren’t bad — but

370
00:27:46,080 --> 00:27:50,889
our understanding of reasoning is making it
more and more clear that we evolved not to

371
00:27:50,890 --> 00:27:57,279
be leave thinking up to a few great minds,
but to the authorty of THE great mind.

372
00:27:57,280 --> 00:28:03,829
The lumbering organ of thought that is everyone
and everything.

373
00:28:03,830 --> 00:28:08,699
This is, in fact, how democracy first worked:
lotteries were used to fill many political

374
00:28:08,700 --> 00:28:10,729
positions in Anceint Athens.

375
00:28:10,730 --> 00:28:12,229
Aristotle explained that

376
00:28:12,230 --> 00:28:17,689
“the appointment of magistrates by lot is
thought to be democratic, and the election

377
00:28:17,690 --> 00:28:19,319
of them is oligrchic”

378
00:28:19,320 --> 00:28:25,019
where an oligrachy is government by only a
small number of people.

379
00:28:25,020 --> 00:28:30,689
Regardless of HOW reason is brought back to
its social roots, if we can build more and

380
00:28:30,690 --> 00:28:36,459
better areanas for deliberation and use them
to apply reason properly to hyperobjects like

381
00:28:36,460 --> 00:28:41,819
the impact of emissions on the planet, we’ll
have taught one heck of a lesson to people

382
00:28:41,820 --> 00:28:44,859
a hundred, a thousand years into the future.

383
00:28:44,860 --> 00:28:51,659
I like to think that although widening participation
will be difficult, it might provide us all

384
00:28:51,660 --> 00:28:54,869
with a kind of existential security.

385
00:28:54,870 --> 00:29:00,099
The impact of emission on our planet is not
going to be the last hyperproblem we face.

386
00:29:00,100 --> 00:29:05,159
If we can do a good job with it, maybe far
in the future, when our civilization has advanced

387
00:29:05,160 --> 00:29:09,929
to the point at which people can be quantumly
re-recreated or something, they’ll look

388
00:29:09,930 --> 00:29:16,019
back at our time and say, hey, let’s bring
them all back to life.

389
00:29:16,020 --> 00:29:19,449
We could use the cooperative abilities they
had then.

390
00:29:19,450 --> 00:29:26,029
Ultimately, the old saying that “history
is the great teacher” isn’t a bad guide.

391
00:29:26,030 --> 00:29:32,979
We will all some day be teachers ourselves
because some day we will all be history, too.

392
00:29:32,980 --> 00:29:37,499
we will some day be the ancients.

393
00:29:37,500 --> 00:29:40,449
And we can choose what that will mean.

394
00:29:40,450 --> 00:29:43,320
And as always, thanks for watching.

