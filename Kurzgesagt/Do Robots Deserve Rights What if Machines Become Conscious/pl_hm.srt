1
00:00:00,000 --> 00:00:04,048
Wyobraź sobie przyszłość w której twój toster

2
00:00:04,049 --> 00:00:06,419
przewiduje na jaki rodzaj tosta masz ochotę.

3
00:00:06,420 --> 00:00:08,129
Podczas dnia

4
00:00:08,130 --> 00:00:09,659
przeszukuje Internet pod kątem nowych

5
00:00:09,660 --> 00:00:12,479
i ekscytujących rodzajów tostów.
Może pyta cię

6
00:00:12,480 --> 00:00:14,189
o twój dzień, a może chce pogadać

7
00:00:14,190 --> 00:00:15,899
o nowych osiągnięciach w technologii opiekania

8
00:00:15,900 --> 00:00:18,538
W którym momencie stałby się osobą?

9
00:00:18,539 --> 00:00:21,389
W którym momencie zaczniesz się

10
00:00:21,390 --> 00:00:24,299
zastanawiać czy twój toster ma uczucia?

11
00:00:24,300 --> 00:00:26,969
Czy jeśli by je miał, to czy wypięcie go z gniazdka byłoby morderstwem?

12
00:00:26,970 --> 00:00:29,848
I czy nadal byłby twoją własnością?

13
00:00:29,849 --> 00:00:31,919
Czy pewnego dnia będziemy zmuszeni
przyznać naszym maszynom

14
00:00:31,920 --> 00:00:43,139
prawa?

15
00:00:43,140 --> 00:00:45,599
Sztuczna inteligencja już jest wokół ciebie.

16
00:00:45,600 --> 00:00:47,369
Dba o uzupełnianie maszyn

17
00:00:47,370 --> 00:00:48,389
odpowiednimi przekąskami,

18
00:00:48,390 --> 00:00:50,319
wybiera dla ciebie odpowiednią reklamę w internecie,

19
00:00:50,320 --> 00:00:51,839
a może nawet przeczytałeś

20
00:00:51,840 --> 00:00:54,639
artykuł napisany w całości przez maszynę.

21
00:00:54,640 --> 00:00:57,569
Teraz patrzymy na czaty jak na przykład Siri

22
00:00:57,570 --> 00:00:59,698
i śmiejemy się z ich prymitywnych symulowanych emocji.

23
00:00:59,699 --> 00:01:02,339
Ale jest prawdopodobne

24
00:01:02,340 --> 00:01:04,018
że będziemy mieli do czynienia z bytami

25
00:01:04,019 --> 00:01:06,209
które utrudniają wyznaczenie granicy

26
00:01:06,210 --> 00:01:08,039
pomiędzy prawdziwym a symulowanym człowieczeństwem.

27
00:01:08,040 --> 00:01:10,829
Czy istnieją maszyny które

28
00:01:10,830 --> 00:01:11,969
zasługują na swoje prawa?

29
00:01:11,970 --> 00:01:15,929
Prawdopodobnie jeszcze nie.
Ale jeśli się pojawią,

30
00:01:15,930 --> 00:01:18,959
nie jesteśmy na to przygotowani.

31
00:01:18,960 --> 00:01:20,908
Znaczna część filozofii prawa w ogóle nie jest przygotowana

32
00:01:20,909 --> 00:01:22,529
do radzenia sobie z przypadkami sztucznej inteligencji

33
00:01:22,530 --> 00:01:25,228
Większość przywilejów należnych

34
00:01:25,229 --> 00:01:27,239
człowiekowi lub zwierzętom skupia się wokół

35
00:01:27,240 --> 00:01:29,519
kwestii świadomości.

36
00:01:29,520 --> 00:01:31,499
Niestety nikt nie wie

37
00:01:31,500 --> 00:01:33,868
czym jest świadomość.
Niektórzy sądzą że jest

38
00:01:33,869 --> 00:01:36,089
niematerialna, inni twierdzą że jest stanem materii

39
00:01:36,090 --> 00:01:38,749
jak gaz lub ciecz

40
00:01:38,750 --> 00:01:41,389
Niezależnie od dokładnej definicji

41
00:01:41,390 --> 00:01:42,979
Mamy intuicyjną wiedzę o świadomości,

42
00:01:42,980 --> 00:01:45,879
bo jej doświadczamy.

43
00:01:45,880 --> 00:01:47,389
Jesteśmy świadomi siebie i naszego otoczenia

44
00:01:47,390 --> 00:01:49,009
 

45
00:01:49,010 --> 00:01:52,369
I wiemy jakim uczuciem jest nieświadomość

46
00:01:52,370 --> 00:01:54,139
Niektórzy neurologowie wierzą że każdy

47
00:01:54,140 --> 00:01:56,179
wystarczająco złożony układ może wytworzyć świadomość

48
00:01:56,180 --> 00:01:58,669
Więc gdyby sprzęt twojego tostera

49
00:01:58,670 --> 00:02:00,618
był wystarczająco mocny, to

50
00:02:00,619 --> 00:02:04,099
mógłby zyskać samoświadomość.
Czy gdyby tak zrobił

51
00:02:04,100 --> 00:02:05,519
to czy zasługiwałby na prawa?

52
00:02:05,520 --> 00:02:07,619
Nie tak szybko

53
00:02:07,620 --> 00:02:11,389
Czy to co uważamy za prawa miałoby dla niego sens?

54
00:02:11,390 --> 00:02:13,759
Świadomość nadaje bytom potrzebę praw

55
00:02:13,760 --> 00:02:15,559
bo daje im możliwość cierpienia.

56
00:02:15,560 --> 00:02:17,899
To oznacza zarówno

57
00:02:17,900 --> 00:02:21,499
odczuwanie bólu, jak i bycie jego świadomym

58
00:02:21,500 --> 00:02:24,289
Roboty nie cierpią i prawdopodobnie nie będą,

59
00:02:24,290 --> 00:02:27,279
chyba że tak je zaprogramujemy.

60
00:02:27,280 --> 00:02:29,499
Bez cierpienia lub przyjemności

61
00:02:29,500 --> 00:02:33,129
nie ma preferencji i prawa są bez znaczenia.

62
00:02:33,130 --> 00:02:35,619
Nasze prawa człowieka są głęboko związane

63
00:02:35,620 --> 00:02:38,409
z naszym własnym oprogramowaniem.
Na przykład nie lubimy bólu

64
00:02:38,410 --> 00:02:40,659
bo nasze mózgi ewoluowały by przetrwać.

65
00:02:40,660 --> 00:02:43,119
By powstrzymać nas przed dotykaniem gorącego ognia

66
00:02:43,120 --> 00:02:45,189
lub by zmusić nas do ucieczki przed drapieżnikami

67
00:02:45,190 --> 00:02:48,279
Więc wynaleźliśmy prawo które

68
00:02:48,280 --> 00:02:50,318
chroni nas przed nadużyciami powodującymi ból.

69
00:02:50,319 --> 00:02:53,409
Nawet bardziej abstrakcyjne prawa, jak wolność

70
00:02:53,410 --> 00:02:55,659
są zakorzenione w sposobie w jaki nasze mózgi

71
00:02:55,660 --> 00:02:58,059
są skonstruowane by wykrywać co jest sprawiedliwe

72
00:02:58,060 --> 00:03:01,839
a co nie.
Czy toster bez możliwości ruchu

73
00:03:01,840 --> 00:03:04,029
miałby coś przeciwko zamknięciu go w klatce?

74
00:03:04,030 --> 00:03:07,119
Czy miałby coś przeciwko demontażowi, gdyby

75
00:03:07,120 --> 00:03:09,939
nie bał się śmierci?

76
00:03:09,940 --> 00:03:11,859
Czy nie lubiłby obelg jeśli nie potrzebowałby samowartości?

77
00:03:11,860 --> 00:03:15,009
Ale co by było gdybyśmy zaprogramowali

78
00:03:15,010 --> 00:03:17,459
robota tak by czuł ból i emocje?

79
00:03:17,460 --> 00:03:20,379
By wybierał sprawiedliwość nad niesprawiedliwość,

80
00:03:20,380 --> 00:03:22,958
przyjemność nad cierpienie i był ich świadom.

81
00:03:22,959 --> 00:03:25,479
Czy to czyniłoby go wystarczająco ludzkim?

82
00:03:25,480 --> 00:03:27,429
Wielu technologów uważa że

83
00:03:27,430 --> 00:03:29,889
nastąpi eksplozja technologii gdy

84
00:03:29,890 --> 00:03:32,319
sztuczna inteligencja będzie się uczyć i tworzyć

85
00:03:32,320 --> 00:03:34,509
własne maszyny, mądrzejsze nawet

86
00:03:34,510 --> 00:03:37,539
od nich samych.

87
00:03:37,540 --> 00:03:39,219
Wtedy kwestia programowania

88
00:03:39,220 --> 00:03:40,959
będzie w większości

89
00:03:40,960 --> 00:03:42,459
poza naszą kontrolą.

90
00:03:42,460 --> 00:03:44,649
Co jeśli sztuczna inteligencja uzna za konieczne

91
00:03:44,650 --> 00:03:46,539
zaprogramowanie sobie odczuwania bólu,

92
00:03:46,540 --> 00:03:49,029
dokładnie tak jak biologia ewolucyjnie

93
00:03:49,030 --> 00:03:50,828
uznała to za konieczne w większości żywych organizmów

94
00:03:50,829 --> 00:03:54,779
Czy roboty zasługują na te prawa?

95
00:03:54,780 --> 00:03:56,909
Jednak może mniej powinniśmy się martwić

96
00:03:56,910 --> 00:03:58,289
ryzykiem którym superinteligentne roboty

97
00:03:58,290 --> 00:04:00,509
są dla nas, a zamiast tego spojrzeć

98
00:04:00,510 --> 00:04:03,509
na niebezpieczeństwo którym my jesteśmy dla nich.

99
00:04:03,510 --> 00:04:05,759
Cała nasza ludzka tożsamość opiera się na idei

100
00:04:05,760 --> 00:04:08,399
ludzkiej unikalności:
że jesteśmy tymi specjalnymi,

101
00:04:08,400 --> 00:04:10,699
niepowtarzalnymi płatkami śniegu, którym należna jest dominacja

102
00:04:10,700 --> 00:04:13,799
nad naturalnym światem.
Ludzie mają długą historię

103
00:04:13,800 --> 00:04:15,839
odmawiania innym bytom odczuwania

104
00:04:15,840 --> 00:04:18,509
cierpienia jak ludzkość.

105
00:04:18,510 --> 00:04:20,638
Podczas rewolucji naukowej, Rene Descartes

106
00:04:20,639 --> 00:04:23,579
twierdził że zwierzęta to jedynie automatony,

107
00:04:23,580 --> 00:04:26,789
roboty, jeśli tak wolisz.
W takim razie zranienie królika

108
00:04:26,790 --> 00:04:28,469
jest tak samo moralnie niewłaściwe

109
00:04:28,470 --> 00:04:31,019
jak uderzenie wypchanego zwierzaka

110
00:04:31,020 --> 00:04:32,729
I wiele z największych zbrodni wobec ludzkości

111
00:04:32,730 --> 00:04:35,399
było usprawiedliwione przez sprawców

112
00:04:35,400 --> 00:04:37,019
twierdząc że ofiary są bardziej

113
00:04:37,020 --> 00:04:40,559
zwierzętami niż cywilizowanymi ludźmi.

114
00:04:40,560 --> 00:04:42,389
Nawet bardziej problematyczne jest to, że mamy perspektywę zysku,

115
00:04:42,390 --> 00:04:45,659
odmawiając robotom ich praw

116
00:04:45,660 --> 00:04:48,029
Jeśli możemy zmusić rozumną sztuczną inteligencję

117
00:04:48,030 --> 00:04:50,069
na przykład poprzez programowanie lub tortury

118
00:04:50,070 --> 00:04:50,999
do spełniania naszych poleceń,

119
00:04:51,000 --> 00:04:53,668
potencjał ekonomiczny jest nieskończony.

120
00:04:53,669 --> 00:04:56,668
W końcu już tak robiliśmy.

121
00:04:56,669 --> 00:04:58,769
Przemoc była używana by zmusić innych ludzi do pracy

122
00:04:58,770 --> 00:05:00,839
i nigdy nie mieliśmy problemów

123
00:05:00,840 --> 00:05:02,429
ze znalezieniem

124
00:05:02,430 --> 00:05:04,568
ideologicznej wymówki.

125
00:05:04,569 --> 00:05:07,418
Właściciele niewolników twierdzą, że niewolnictwo

126
00:05:07,419 --> 00:05:09,848
było korzystne dla niewolników.
Dało im dach nad głową

127
00:05:09,849 --> 00:05:12,579
i nauczyło chrześcijaństwa.

128
00:05:12,580 --> 00:05:14,648
Mężczyźni odmawiający kobietom prawa głosu twierdzą, że

129
00:05:14,649 --> 00:05:16,508
dla własnych korzyści kobiety powinny

130
00:05:16,509 --> 00:05:20,318
zostawić podejmowanie trudnych decyzji mężczyznom.

131
00:05:20,319 --> 00:05:22,028
Hodowcy twierdzą że opieka nad zwierzętami i karmienie ich

132
00:05:22,029 --> 00:05:24,068
usprawiedliwia ich wczesną śmierć

133
00:05:24,069 --> 00:05:28,628
w imię naszej diety

134
00:05:28,629 --> 00:05:29,558
Jeśli roboty staną się rozumne

135
00:05:29,559 --> 00:05:31,269
będzie bardzo wiele argumentów

136
00:05:31,270 --> 00:05:32,528
przekonujących że

137
00:05:32,529 --> 00:05:34,688
powinny pozostać bez praw.

138
00:05:34,689 --> 00:05:36,758
Szczególnie wśród tych, którzy na tym zyskają.

139
00:05:36,759 --> 00:05:39,668
Sztuczna inteligencja wysuwa poważne pytania

140
00:05:39,669 --> 00:05:41,918
o filozoficzne granice

141
00:05:41,919 --> 00:05:44,739
Można spytać, co jeśli rozumne roboty

142
00:05:44,740 --> 00:05:46,778
są świadome lub zasługujące na prawa

143
00:05:46,779 --> 00:05:48,938
Zmusza nas to do bardziej podstawowych pytań

144
00:05:48,939 --> 00:05:51,638
jak "Co czyni nas ludźmi?"

145
00:05:51,639 --> 00:05:54,419
"Co sprawia że zasługujemy na prawa?"

146
00:05:54,420 --> 00:05:56,909
Niezależnie jak uważamy, pytania te

147
00:05:56,910 --> 00:05:58,379
mogą potrzebować odpowiedzi w niedalekiej przyszłości

148
00:05:58,380 --> 00:05:59,189
 

149
00:05:59,190 --> 00:06:01,379
Co zrobimy gdy roboty

150
00:06:01,380 --> 00:06:06,879
zaczną domagać się swych praw?

151
00:06:06,880 --> 00:06:08,669
Czego roboty domagające się praw

152
00:06:08,670 --> 00:06:11,369
mogą nas nauczyć o nas samych?

153
00:06:11,370 --> 00:06:13,169
Nasi przyjaciele z Wisecrack nakręcili film

154
00:06:13,170 --> 00:06:15,269
zgłębiający właśnie to pytanie, korzystając z filozofii świata Zachodu.

155
00:06:15,270 --> 00:06:18,929
Wisecrack robi rozkłada i bada popkulturę

156
00:06:18,930 --> 00:06:21,239
w unikalny i filozoficzny sposób.

157
00:06:21,240 --> 00:06:22,979
Kliknij tu by zobaczyć ten film

158
00:06:22,980 --> 00:06:25,000
i subskrybować ich kanał

