1
00:00:02,160 --> 00:00:07,259
ลองนึกภาพอนาคตที่เครื่องปิ้งขนมปังของคุณคาดการณ์ว่าคุณต้องการขนมปังประเภทใด

2
00:00:07,260 --> 00:00:11,559
ในระหว่างวัน มันจะสแกนอินเทอร์เน็ตเพื่อหาขนมปังปิ้งประเภทใหม่และน่าตื่นเต้น

3
00:00:11,560 --> 00:00:17,539
บางทีมันอาจจะถามคุณเกี่ยวกับวันของคุณ และต้องการพูดคุยเกี่ยวกับความสำเร็จใหม่ๆ ในเทคโนโลยีขนมปังปิ้ง

4
00:00:17,540 --> 00:00:20,159
มันจะกลายเป็นคนระดับไหน?

5
00:00:20,160 --> 00:00:24,239
เมื่อถึงจุดใดที่คุณจะถามตัวเองว่าเครื่องปิ้งขนมปังของคุณมีความรู้สึกหรือไม่?

6
00:00:24,240 --> 00:00:27,259
ถ้าเป็นเช่นนั้น การถอดปลั๊กจะเป็นการฆาตกรรมหรือไม่?

7
00:00:27,260 --> 00:00:43,179
แล้วคุณยังจะเป็นเจ้าของมันอยู่ไหม?
สักวันหนึ่งเราจะถูกบังคับให้ให้สิทธิ์เครื่องจักรของเราหรือไม่?

8
00:00:43,180 --> 00:00:45,599
AI อยู่รอบตัวคุณแล้ว

9
00:00:45,600 --> 00:00:48,379
ทำให้แน่ใจว่าผู้ลดราคามีของว่างเพียงพอ

10
00:00:48,380 --> 00:00:55,399
ให้บริการคุณด้วยโฆษณาทางอินเทอร์เน็ตที่เหมาะสม และคุณอาจเคยอ่านเรื่องใหม่ที่เขียนด้วยเครื่องจักรทั้งหมด

11
00:00:55,400 --> 00:01:01,179
ตอนนี้เราดูแชทบอทอย่าง Siri และหัวเราะเยาะอารมณ์จำลองดั้งเดิมของพวกเขา

12
00:01:01,180 --> 00:01:05,199
แต่มีแนวโน้มว่าเราจะต้องจัดการกับสิ่งมีชีวิตที่ทำให้ยากต่อการขีดเส้นแบ่ง

13
00:01:05,200 --> 00:01:08,719
ระหว่างมนุษย์จริงและมนุษย์จำลอง

14
00:01:08,720 --> 00:01:12,539
มีเครื่องจักรใดบ้างที่สมควรได้รับสิทธิ์?

15
00:01:12,540 --> 00:01:18,459
เป็นไปได้มากว่าจะยังไม่ใช่
แต่ถ้ามาเราไม่พร้อม

16
00:01:18,460 --> 00:01:23,859
ปรัชญาสิทธิส่วนใหญ่ไม่พร้อมที่จะจัดการกับกรณีของปัญญาประดิษฐ์

17
00:01:23,860 --> 00:01:29,859
การเรียกร้องสิทธิส่วนใหญ่ของมนุษย์หรือสัตว์มีศูนย์กลางอยู่ที่คำถามเรื่องจิตสำนึก

18
00:01:29,860 --> 00:01:33,159
น่าเสียดายที่ไม่มีใครรู้ว่าจิตสำนึกคืออะไร

19
00:01:33,160 --> 00:01:39,099
บางคนคิดว่ามันไม่มีสาระสำคัญ บางคนบอกว่ามันเป็นสถานะของสสาร เช่น แก๊สหรือของเหลว

20
00:01:39,100 --> 00:01:45,899
โดยไม่คำนึงถึงคำจำกัดความที่ชัดเจน เรามีความรู้โดยสัญชาตญาณของจิตสำนึกเพราะเราประสบกับมัน

21
00:01:45,900 --> 00:01:51,759
เราตระหนักรู้ในตนเองและสิ่งแวดล้อมรอบข้าง และรู้ว่าการหมดสติรู้สึกอย่างไร

22
00:01:51,760 --> 00:01:57,499
นักประสาทวิทยาบางคนเชื่อว่าระบบที่ก้าวหน้าเพียงพอสามารถสร้างจิตสำนึกได้

23
00:01:57,500 --> 00:02:02,879
ดังนั้น หากฮาร์ดแวร์ของเครื่องปิ้งขนมปังของคุณมีประสิทธิภาพเพียงพอ ก็อาจสามารถรับรู้ได้เอง

24
00:02:02,880 --> 00:02:05,779
ถ้าทำได้ สมควรได้รับสิทธิหรือไม่?

25
00:02:05,780 --> 00:02:11,679
ดีไม่เร็วนัก
สิ่งที่เรากำหนดเป็น "สิทธิ" จะสมเหตุสมผลหรือไม่?

26
00:02:11,680 --> 00:02:17,199
สติให้สิทธิแก่สัตว์ทั้งหลาย เพราะมันทำให้สัตว์มีความสามารถในการทนทุกข์

27
00:02:17,200 --> 00:02:22,159
หมายถึงความสามารถที่ไม่เพียงแต่รู้สึกเจ็บปวดเท่านั้นแต่ยังรับรู้ถึงความเจ็บปวดอีกด้วย

28
00:02:22,160 --> 00:02:27,539
หุ่นยนต์ไม่ต้องทนทุกข์ทรมาน และพวกมันก็อาจจะไม่เป็นเช่นนั้น เว้นแต่ว่าเราตั้งโปรแกรมไว้

29
00:02:27,540 --> 00:02:32,899
หากปราศจากความเจ็บปวดหรือความเพลิดเพลิน ย่อมไม่มีความพึงใจ และสิทธิก็ไม่มีความหมาย

30
00:02:32,900 --> 00:02:38,779
สิทธิมนุษยชนของเราเชื่อมโยงอย่างแนบแน่นกับแผนงานของเราเอง เช่น เราไม่ชอบความเจ็บปวด

31
00:02:38,780 --> 00:02:41,699
เพราะสมองของเรามีวิวัฒนาการเพื่อให้เรามีชีวิตอยู่

32
00:02:41,700 --> 00:02:46,639
เพื่อไม่ให้เราโดนไฟที่ร้อนจัด หรือเพื่อให้เราวิ่งหนีจากผู้ล่า

33
00:02:46,640 --> 00:02:51,739
ดังนั้นเราจึงคิดสิทธิที่ปกป้องเราจากการละเมิดที่ทำให้เราเจ็บปวด

34
00:02:51,740 --> 00:02:56,539
สิทธิที่เป็นนามธรรมมากขึ้น เช่น เสรีภาพ มีรากฐานมาจากวิธีที่สมองของเราเชื่อมต่อ

35
00:02:56,540 --> 00:03:00,099
เพื่อตรวจหาสิ่งที่ยุติธรรมและไม่ยุติธรรม

36
00:03:00,100 --> 00:03:04,779
เครื่องปิ้งขนมปังที่ขยับไม่ได้ ใจจะถูกขังอยู่ในกรงหรือไม่?

37
00:03:04,780 --> 00:03:08,919
ถ้าไม่กลัวตายจะรังเกียจไหม?

38
00:03:08,920 --> 00:03:13,879
จะรังเกียจไหมที่จะถูกดูหมิ่นถ้าไม่ต้องการเห็นคุณค่าในตนเอง?

39
00:03:13,880 --> 00:03:17,479
แต่ถ้าเราตั้งโปรแกรมให้หุ่นยนต์รู้สึกเจ็บปวดและอารมณ์ล่ะ

40
00:03:17,480 --> 00:03:22,459
ชอบความยุติธรรมมากกว่าความอยุติธรรม ความสุขมากกว่าความเจ็บปวด และตระหนักถึงมัน?

41
00:03:22,460 --> 00:03:25,239
นั่นจะทำให้พวกเขาเป็นมนุษย์เพียงพอหรือไม่?

42
00:03:25,240 --> 00:03:29,299
นักเทคโนโลยีหลายคนเชื่อว่าการระเบิดของเทคโนโลยีจะเกิดขึ้น

43
00:03:29,300 --> 00:03:34,279
เมื่อปัญญาประดิษฐ์สามารถเรียนรู้และสร้างปัญญาประดิษฐ์ของตนเอง

44
00:03:34,280 --> 00:03:36,879
ได้ แม้จะฉลาดกว่าตัวเองก็ตาม

45
00:03:36,880 --> 00:03:42,519
ณ จุดนี้ คำถามเกี่ยวกับวิธีการตั้งโปรแกรมหุ่นยนต์ของเรานั้นส่วนใหญ่อยู่นอกเหนือการควบคุมของเรา

46
00:03:42,520 --> 00:03:47,439
จะเกิดอะไรขึ้นถ้าปัญญาประดิษฐ์พบว่าจำเป็นต้องตั้งโปรแกรมความสามารถในการรู้สึกเจ็บปวด

47
00:03:47,440 --> 00:03:52,059
เช่นเดียวกับที่ชีววิทยาวิวัฒนาการพบว่าจำเป็นในสิ่งมีชีวิตส่วนใหญ่

48
00:03:52,060 --> 00:03:54,779
หุ่นยนต์สมควรได้รับสิทธิ์เหล่านั้นหรือไม่?

49
00:03:54,780 --> 00:03:59,719
แต่บางทีเราควรกังวลน้อยลงเกี่ยวกับความเสี่ยงที่หุ่นยนต์อัจฉริยะขั้นสูงจะก่อขึ้นกับเรา

50
00:03:59,720 --> 00:04:03,059
และกังวลมากขึ้นเกี่ยวกับอันตรายที่เราก่อขึ้นกับพวกมัน

51
00:04:03,060 --> 00:04:07,559
อัตลักษณ์มนุษย์ทั้งหมดของเรามีพื้นฐานมาจากแนวคิดเกี่ยวกับความพิเศษของมนุษย์

52
00:04:07,560 --> 00:04:12,939
ว่าเราเป็นเกล็ดหิมะที่มีลักษณะพิเศษเฉพาะตัว มีสิทธิที่จะครองโลกธรรมชาติ

53
00:04:12,940 --> 00:04:17,898
มนุษย์มีประวัติที่ปฏิเสธว่าสิ่งมีชีวิตอื่นสามารถทนทุกข์ได้เช่นเดียวกับพวกเขา

54
00:04:17,899 --> 00:04:25,119
ท่ามกลางการปฏิวัติทางวิทยาศาสตร์ René Descartes โต้แย้งว่าสัตว์เป็นเพียงออโตมาตา ― หุ่นยนต์ ถ้าคุณต้องการ

55
00:04:25,120 --> 00:04:30,239
ดังนั้น การทำร้ายกระต่ายจึงเป็นเรื่องที่น่ารังเกียจพอๆ กับการต่อยตุ๊กตาสัตว์

56
00:04:30,240 --> 00:04:35,299
และอาชญากรรมที่ยิ่งใหญ่ที่สุดต่อมนุษยชาติจำนวนมากได้รับการพิสูจน์โดยผู้กระทำความผิด

57
00:04:35,300 --> 00:04:40,179
โดยอ้างว่าเหยื่อเป็นสัตว์มากกว่ามนุษย์ที่มีอารยะธรรม

58
00:04:40,180 --> 00:04:45,499
ปัญหาที่หนักกว่านั้นคือเรามีผลประโยชน์ทางเศรษฐกิจในการปฏิเสธสิทธิ์ของหุ่นยนต์

59
00:04:45,500 --> 00:04:51,039
หากสามารถบังคับ AI ที่มีความรู้สึก—อาจผ่านการทรมานตามโปรแกรม—ให้ทำในสิ่งที่เราพอใจ

60
00:04:51,040 --> 00:04:53,659
ศักยภาพทางเศรษฐกิจนั้นไม่มีขีดจำกัด

61
00:04:53,660 --> 00:04:56,279
เราเคยทำมาแล้ว

62
00:04:56,280 --> 00:04:59,759
มีการใช้ความรุนแรงเพื่อบังคับให้เพื่อนมนุษย์ของเราทำงาน

63
00:04:59,760 --> 00:05:04,959
และเราไม่เคยมีปัญหาในการหาเหตุผลทางอุดมการณ์

64
00:05:04,960 --> 00:05:12,159
เจ้าของทาสแย้งว่าการเป็นทาสเป็นประโยชน์ต่อทาส: มันเอาหลังคาคลุมศีรษะของพวกเขาและสอนให้พวกเขานับถือศาสนาคริสต์

65
00:05:12,160 --> 00:05:19,479
ผู้ชายที่ต่อต้านการลงคะแนนเสียงกับผู้หญิงแย้งว่าผู้หญิงเองก็สนใจที่จะมอบการตัดสินใจที่ยากลำบากให้กับผู้ชาย

66
00:05:19,480 --> 00:05:27,699
เกษตรกรให้เหตุผลว่าการดูแลสัตว์และการให้อาหารเป็นการสมควรที่พวกมันจะตายก่อนกำหนดตามความชอบด้านอาหารของเรา

67
00:05:27,700 --> 00:05:32,139
หากหุ่นยนต์มีสติสัมปชัญญะ ก็จะไม่มีปัญหาการโต้แย้งสำหรับผู้ที่กล่าว

68
00:05:32,140 --> 00:05:37,759
ว่าพวกเขาควรจะอยู่โดยไม่มีสิทธิ์ โดยเฉพาะอย่างยิ่งจากผู้ที่ยืนหยัดเพื่อผลประโยชน์จากมัน

69
00:05:37,760 --> 00:05:42,659
ปัญญาประดิษฐ์ทำให้เกิดคำถามจริงจังเกี่ยวกับขอบเขตทางปรัชญา

70
00:05:42,660 --> 00:05:46,799
สิ่งที่เราอาจถามว่าหุ่นยนต์รู้สึกมีสติหรือสมควรได้รับสิทธิ

71
00:05:46,800 --> 00:05:54,799
มันบังคับให้เราตั้งคำถามพื้นฐานเช่นอะไรทำให้เราเป็นมนุษย์?  อะไรที่ทำให้เราคู่ควรกับสิทธิ?

72
00:05:54,800 --> 00:05:59,719
ไม่ว่าเราจะคิดอย่างไร คำถามอาจต้องได้รับการแก้ไขในอนาคตอันใกล้นี้

73
00:05:59,720 --> 00:06:07,279
เราจะทำอย่างไรถ้าหุ่นยนต์เริ่มเรียกร้องสิทธิของตนเอง?

74
00:06:07,280 --> 00:06:10,779
หุ่นยนต์ที่เรียกร้องสิทธิสามารถสอนอะไรเราเกี่ยวกับตัวเราได้บ้าง?

75
00:06:10,780 --> 00:06:16,859
เพื่อนของเราที่ Wisecrack ได้สร้างวิดีโอที่สำรวจคำถามนี้โดยใช้ปรัชญาของ Westworld

76
00:06:16,860 --> 00:06:21,419
Wisecrack วิเคราะห์วัฒนธรรมป๊อปด้วยวิธีที่มีเอกลักษณ์และปรัชญา

77
00:06:21,420 --> 00:06:25,140
คลิกที่นี่เพื่อดูวิดีโอและสมัครรับข้อมูลจากช่องของพวกเขา

