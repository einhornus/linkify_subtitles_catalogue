1
00:00:02,160 --> 00:00:07,259
토스터가 당신이 원하는 토스트의 종류를 예상하는 미래를 상상해보십시오.

2
00:00:07,260 --> 00:00:11,559
낮에는 새롭고 흥미로운 유형의 토스트를 찾기 위해 인터넷을 검색합니다.

3
00:00:11,560 --> 00:00:17,539
어쩌면 그것은 당신에게 당신의 하루에 대해 묻고 토스트 기술의 새로운 성취에 대해 이야기하고 싶어할 것입니다.

4
00:00:17,540 --> 00:00:20,159
어떤 수준에서 사람이 될까요?

5
00:00:20,160 --> 00:00:24,239
토스터에 감정이 있는지 어느 시점에서 스스로에게 물어볼 것입니까?

6
00:00:24,240 --> 00:00:27,259
그렇다면 플러그를 뽑으면 살인이 될까요?

7
00:00:27,260 --> 00:00:43,179
그리고 당신은 여전히 그것을 소유할 것�
가?  언젠가는 기계에 권리를 부여해야 합니까?

8
00:00:43,180 --> 00:00:45,599
AI는 이미 당신 주위에 있습니다.

9
00:00:45,600 --> 00:00:48,379
그것은 할인점에 충분한 간식이 있는지 확인

10
00:00:48,380 --> 00:00:55,399
하고 올바른 인터넷 광고를 제공하며 완전히 기계로 작성된 새로운 이야기를 읽었을 수도 있습니다.

11
00:00:55,400 --> 00:01:01,179
지금 우리는 Siri와 같은 챗봇을 보고 그들의 원시적인 시뮬레이션된 감정을 비웃지

12
00:01:01,180 --> 00:01:05,199
만 실제 인간과 시뮬레이션된 인간의 경계를 긋기 어렵게 만드는 존재를 처리해야 할 가능성이 높습니다

13
00:01:05,200 --> 00:01:08,719
.

14
00:01:08,720 --> 00:01:12,539
권리를 받을 자격이 있는 기계가 존재합니까?

15
00:01:12,540 --> 00:01:18,459
아직까지는 아닐 가능성이 높습니다.
그러나 그들이 오면 우리는 그것에 대한 준비가 되어 있지 않습니다.

16
00:01:18,460 --> 00:01:23,859
권리 철학의 대부분은 인공 지능의 경우를 다루기에 충분하지 않습니다.

17
00:01:23,860 --> 00:01:29,859
인간이나 동물의 권리에 대한 대부분의 주장은 의식의 문제를 중심으로 이루어집니다.

18
00:01:29,860 --> 00:01:33,159
불행히도 의식이 무엇인지는 아무도 모릅니다.

19
00:01:33,160 --> 00:01:39,099
어떤 사람들은 그것이 비물질적이라고 생각하고 다른 사람들은 그것이 기체나 액체와 같은 물질의 상태라고 말합니다.

20
00:01:39,100 --> 00:01:45,899
정확한 정의와 상관없이 우리는 의식을 경험하기 때문에 의식에 대한 직관적인 지식을 가지고 있습니다.

21
00:01:45,900 --> 00:01:51,759
우리는 우리 자신과 주변 환경을 인식하고 무의식이 어떤 느낌인지 압니다.

22
00:01:51,760 --> 00:01:57,499
일부 신경 과학자들은 충분히 발전된 시스템이 의식을 생성할 수 있다고 믿습니다.

23
00:01:57,500 --> 00:02:02,879
따라서 토스터의 하드웨어가 충분히 강력하다면 자체적으로 인식할 수 있습니다.

24
00:02:02,880 --> 00:02:05,779
그렇다면 권리를 가질 자격이 있습니까?

25
00:02:05,780 --> 00:02:11,679
글쎄, 그렇게 빠르지 않습니다.
우리가 "권리"라고 정의한 것이 의미가 있습니까?

26
00:02:11,680 --> 00:02:17,199
의식은 존재에게 고통을 줄 수 있는 능력을 주기 때문에 존재에게 권리를 부여합니다.

27
00:02:17,200 --> 00:02:22,159
고통을 느낄 뿐만 아니라 인식하는 능력을 의미합니다.

28
00:02:22,160 --> 00:02:27,539
로봇은 고통을 겪지 않으며 아마도 우리가 프로그래밍하지 않는 한 고통을 겪지 않을 것입니다.

29
00:02:27,540 --> 00:02:32,899
고통이나 쾌락이 없으면 선호도 없고 권리도 무의미하다.

30
00:02:32,900 --> 00:02:38,779
우리의 인권은 우리 자신의 프로그래밍과 깊이 연결되어 있습니다. 예를 들어 우리

31
00:02:38,780 --> 00:02:41,699
의 두뇌는 우리를 계속 살아 있게 하도록 진화했기 때문에 고통을 싫어합니다.

32
00:02:41,700 --> 00:02:46,639
뜨거운 불에 손을 대지 못하게 하거나 포식자로부터 도망치게 하기 위해서입니다.

33
00:02:46,640 --> 00:02:51,739
그래서 우리는 고통을 유발하는 침해를 보호하는 권리를 생각해 냈습니다.

34
00:02:51,740 --> 00:02:56,539
자유와 같은 더 추상적인 권리는 우리의 두뇌가 공정하고 불공정한 것을 감지하도록 연결되어 있는 방식에 뿌리를 두고

35
00:02:56,540 --> 00:03:00,099
있습니다.

36
00:03:00,100 --> 00:03:04,779
움직일 수 없는 토스터가 새장에 갇히게 될까?

37
00:03:04,780 --> 00:03:08,919
죽음에 대한 두려움이 없다면 해체해도 될까요?

38
00:03:08,920 --> 00:03:13,879
자존심이 필요 없다면 모욕당해도 될까요?

39
00:03:13,880 --> 00:03:17,479
하지만 로봇이 고통과 감정을 느끼도록 프로그래밍하면 어떻게 될까요?

40
00:03:17,480 --> 00:03:22,459
불의보다 정의를, 고통보다 쾌락을 택하고 자각하겠습니까?

41
00:03:22,460 --> 00:03:25,239
그렇게 하면 충분히 인간이 될 수 있습니까?

42
00:03:25,240 --> 00:03:29,299
많은 기술자들은

43
00:03:29,300 --> 00:03:34,279
인공 지능이 스스로 학습하고 자신보다 훨씬 더 똑똑한 인공 지능을 생성할 수 있을 때 기술의 폭발이 일어날 것이라고 믿습니다

44
00:03:34,280 --> 00:03:36,879
.

45
00:03:36,880 --> 00:03:42,519
이 시점에서 로봇이 어떻게 프로그래밍되는지에 대한 문제는 대부분 우리가 통제할 수 없는 문제가 될 것입니다.

46
00:03:42,520 --> 00:03:47,439
진화 생물학이 대부분의 생물에게 필요하다고 생각한 것처럼 인공 지능이 고통을 느끼는 능력을 프로그래밍하는 것이 필요하다는 것을 알게 되면 어떻게

47
00:03:47,440 --> 00:03:52,059
될까요?

48
00:03:52,060 --> 00:03:54,779
로봇은 그러한 권리를 가질 자격이 있습니까?

49
00:03:54,780 --> 00:03:59,719
그러나 어쩌면 우리는 초지능 로봇이 우리에게 가하는 위험에 대해 덜 걱정해야

50
00:03:59,720 --> 00:04:03,059
하고 우리가 그들에게 가하는 위험에 대해 더 걱정해야 합니다.

51
00:04:03,060 --> 00:04:07,559
우리의 전체 인간 정체성

52
00:04:07,560 --> 00:04:12,939
은 우리가 자연 세계를 지배할 자격이 있는 특별하고 독특한 눈송이라는 인간 예외주의의 아이디어에 기반을 두고 있습니다.

53
00:04:12,940 --> 00:04:17,898
인간은 다른 존재도 그들처럼 고통받을 수 있다는 것을 부정한 역사가 있습니다.

54
00:04:17,899 --> 00:04:25,119
과학 혁명의 한가운데에 르네 데카르트는 동물이 단순히 자동자, 즉 원한다면 로봇이라고 주장했습니다.

55
00:04:25,120 --> 00:04:30,239
따라서 토끼를 다치게 하는 것은 박제된 동물을 때리는 것만큼 도덕적으로 혐오스러운 일이었습니다.

56
00:04:30,240 --> 00:04:35,299
그리고 인류에 대한 가장 큰 범죄의 대부분

57
00:04:35,300 --> 00:04:40,179
은 희생자가 문명인보다 동물에 가깝다는 이유로 가해자에 의해 정당화되었습니다.

58
00:04:40,180 --> 00:04:45,499
더 문제는 우리가 로봇의 권리를 부정하는 데 경제적 이해관계가 있다는 것입니다.

59
00:04:45,500 --> 00:04:51,039
프로그램된 고문을 통해 지각 있는 AI가 원하는 대로 하도록 강제할 수

60
00:04:51,040 --> 00:04:53,659
있다면 경제적 잠재력은 무한합니다.

61
00:04:53,660 --> 00:04:56,279
결국 우리는 전에 그것을 했습니다.

62
00:04:56,280 --> 00:04:59,759
폭력은 동료 인간을 강제로 일하게 하는 데 사용되었습니다.

63
00:04:59,760 --> 00:05:04,959
그리고 우리는 이념적 정당성을 찾는 데 어려움을 겪지 않았습니다.

64
00:05:04,960 --> 00:05:12,159
노예 소유주는 노예가 노예에게 이익이 된다고 주장했습니다. 노예의 머리 위에 지붕을 씌우고 기독교를 가르쳤습니다.

65
00:05:12,160 --> 00:05:19,479
여성 투표에 반대하는 남성들은 어려운 결정을 남성에게 맡기는 것이 여성 자신의 이익이라고 주장했습니다.

66
00:05:19,480 --> 00:05:27,699
농부들은 동물을 돌보고 먹이를 주는 것이 우리가 선호하는 식이요법으로 인해 조기 사망을 정당화한다고 주장합니다.

67
00:05:27,700 --> 00:05:32,139
로봇이 지각력을 갖게 된다면,

68
00:05:32,140 --> 00:05:37,759
권리가 없어야 한다고 주장하는 사람들, 특히 로봇으로부터 이익을 얻을 수 있는 사람들의 주장이 만만치 않을 것입니다.

69
00:05:37,760 --> 00:05:42,659
인공 지능은 철학적 경계에 대해 심각한 질문을 제기합니다.

70
00:05:42,660 --> 00:05:46,799
지각 있는 로봇이 의식이 있거나 권리를 가질 자격이

71
00:05:46,800 --> 00:05:54,799
있는지 묻는 질문은 우리로 하여금 무엇이 우리를 인간으로 만드는가와 같은 기본적인 질문을 하도록 강요합니다.  무엇이 우리를 정당하게 만드는가?

72
00:05:54,800 --> 00:05:59,719
우리가 어떻게 생각하든 가까운 장래에 이 문제를 해결해야 할 수도 있습니다.

73
00:05:59,720 --> 00:06:07,279
로봇이 자신의 권리를 요구하기 시작하면 우리는 무엇을 할 것인가?

74
00:06:07,280 --> 00:06:10,779
권리를 요구하는 로봇은 우리 자신에 대해 무엇을 배울 수 있습니까?

75
00:06:10,780 --> 00:06:16,859
Wisecrack의 우리 친구들은 Westworld의 철학을 사용하여 바로 이 질문을 탐구하는 비디오를 만들었습니다.

76
00:06:16,860 --> 00:06:21,419
Wisecrack은 독특하고 철학적인 방식으로 대중 문화를 분석합니다.

77
00:06:21,420 --> 00:06:25,140
비디오를 확인하고 채널을 구독하려면 여기를 클릭하십시오.

