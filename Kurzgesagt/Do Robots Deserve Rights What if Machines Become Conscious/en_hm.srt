1
00:00:02,160 --> 00:00:07,259
Imagine a future where your toaster anticipates what kind of toast you want.

2
00:00:07,260 --> 00:00:11,559
During the day, it scans the Internet for new and exciting types of toast.

3
00:00:11,560 --> 00:00:17,539
Maybe it asks you about your day, and wants to chat about new achievements in toast technology.

4
00:00:17,540 --> 00:00:20,159
At what level would it become a person?

5
00:00:20,160 --> 00:00:24,239
At which point will you ask yourself if your toaster has feelings?

6
00:00:24,240 --> 00:00:27,259
If it did, would unplugging it be murder?

7
00:00:27,260 --> 00:00:43,179
And would you still own it?
Will we someday be forced to give our machines rights?

8
00:00:43,180 --> 00:00:45,599
AI is already all around you.

9
00:00:45,600 --> 00:00:48,379
It makes sure discounters are stocked with enough snacks,

10
00:00:48,380 --> 00:00:55,399
it serves you up just the right Internet ad, and you may have even read a new story written entirely by a machine.

11
00:00:55,400 --> 00:01:01,179
Right now we look at chat bots like Siri and laugh at their primitive simulated emotions,

12
00:01:01,180 --> 00:01:05,199
but it's likely that we will have to deal with beings that make it hard to draw the line

13
00:01:05,200 --> 00:01:08,719
between real and simulated humanity.

14
00:01:08,720 --> 00:01:12,539
Are there any machines in existence that deserve rights?

15
00:01:12,540 --> 00:01:18,459
Most likely, not yet.
But if they come, we are not prepared for it.

16
00:01:18,460 --> 00:01:23,859
Much of the philosophy of rights is ill-equipped to deal with the case of Artificial Intelligence.

17
00:01:23,860 --> 00:01:29,859
Most claims for right, with a human or animal, are centered around the question of consciousness.

18
00:01:29,860 --> 00:01:33,159
Unfortunately, nobody knows what consciousness is.

19
00:01:33,160 --> 00:01:39,099
Some think that it's immaterial, others say it's a state of matter, like gas or liquid.

20
00:01:39,100 --> 00:01:45,899
Regardless of the precise definition, we have an intuitive knowledge of consciousness because we experience it.

21
00:01:45,900 --> 00:01:51,759
We are aware of ourselves and our surroundings, and know what unconsciousness feels like.

22
00:01:51,760 --> 00:01:57,499
Some neuroscientists believe that any sufficiently advanced system can generate consciousness.

23
00:01:57,500 --> 00:02:02,879
So, if your toaster's hardware was powerful enough, it may become self-aware.

24
00:02:02,880 --> 00:02:05,779
If it does, would it deserve rights?

25
00:02:05,780 --> 00:02:11,679
Well, not so fast.
Would what we define as "rights" make sense to it?

26
00:02:11,680 --> 00:02:17,199
Consciousness entitles beings to have rights because it gives a being the ability to suffer.

27
00:02:17,200 --> 00:02:22,159
It means the ability to not only feel pain, but to be aware of it.

28
00:02:22,160 --> 00:02:27,539
Robots don't suffer, and they probably won't unless we programmed them to.

29
00:02:27,540 --> 00:02:32,899
Without pain or pleasure, there's no preference, and rights are meaningless.

30
00:02:32,900 --> 00:02:38,779
Our human rights are deeply tied to our own programming, for example we dislike pain

31
00:02:38,780 --> 00:02:41,699
because our brains evolved to keep us alive.

32
00:02:41,700 --> 00:02:46,639
To stop us from touching a hot fire, or to make us run away from predators.

33
00:02:46,640 --> 00:02:51,739
So we came up with rights that protect us from infringements that cause us pain.

34
00:02:51,740 --> 00:02:56,539
Even more abstract rights like freedom are rooted in the way our brains are wired

35
00:02:56,540 --> 00:03:00,099
to detect what is fair and unfair.

36
00:03:00,100 --> 00:03:04,779
Would a toaster that is unable to move, mind being locked in a cage?

37
00:03:04,780 --> 00:03:08,919
Would it mind being dismantled, if it had no fear of death?

38
00:03:08,920 --> 00:03:13,879
Would it mind being insulted, if it had no need for self-esteem?

39
00:03:13,880 --> 00:03:17,479
But what if we programmed the robot to feel pain and emotions?

40
00:03:17,480 --> 00:03:22,459
To prefer justice over injustice, pleasure over pain and be aware of it?

41
00:03:22,460 --> 00:03:25,239
Would that make them sufficiently human?

42
00:03:25,240 --> 00:03:29,299
Many technologists believe that an explosion in technology would occur,

43
00:03:29,300 --> 00:03:34,279
when Artificial Intelligence can learn and create their own Artificial Intelligences,

44
00:03:34,280 --> 00:03:36,879
even smarter than themselves.

45
00:03:36,880 --> 00:03:42,519
At this point, the question of how our robots are programmed will be largely out of our control.

46
00:03:42,520 --> 00:03:47,439
What if an Artificial Intelligence found it necessary to program the ability to feel pain,

47
00:03:47,440 --> 00:03:52,059
just as evolutionary biology found it necessary in most living creatures?

48
00:03:52,060 --> 00:03:54,779
Do robots deserve those rights?

49
00:03:54,780 --> 00:03:59,719
But maybe we should be less worried about the risk that super-intelligent robots pose to us,

50
00:03:59,720 --> 00:04:03,059
and more worried about the danger we pose to them.

51
00:04:03,060 --> 00:04:07,559
Our whole human identity is based on the idea of human exceptionalism,

52
00:04:07,560 --> 00:04:12,939
that we are special unique snowflakes, entitled to dominate the natural world.

53
00:04:12,940 --> 00:04:17,898
Humans have a history of denying that other beings are capable of suffering as they do.

54
00:04:17,899 --> 00:04:25,119
In the midst of the Scientific Revolution, René Descartes argued animals were mere automata―robots if you will.

55
00:04:25,120 --> 00:04:30,239
As such, injuring a rabbit was about as morally repugnant as punching a stuffed animal.

56
00:04:30,240 --> 00:04:35,299
And many of the greatest crimes against humanity were justified by their perpetrators

57
00:04:35,300 --> 00:04:40,179
on the grounds that the victims were more animal than civilized human.

58
00:04:40,180 --> 00:04:45,499
Even more problematic is that we have an economic interest in denying robot rights.

59
00:04:45,500 --> 00:04:51,039
If can coerce a sentient AI―possibly through programmed torture―into doing as we please,

60
00:04:51,040 --> 00:04:53,659
the economic potential is unlimited.

61
00:04:53,660 --> 00:04:56,279
We've done it before, after all.

62
00:04:56,280 --> 00:04:59,759
Violence has been used to force our fellow humans into working.

63
00:04:59,760 --> 00:05:04,959
And we've never had trouble coming up with ideological justifications.

64
00:05:04,960 --> 00:05:12,159
Slave owners argued that slavery benefited the slaves: it put a roof over their head and taught them Christianity.

65
00:05:12,160 --> 00:05:19,479
Men who were against women voting argued that it was in women's own interest to leave the hard decisions to men.

66
00:05:19,480 --> 00:05:27,699
Farmers argue that looking after animals and feeding them justifies their early death for our dietary preferences.

67
00:05:27,700 --> 00:05:32,139
If robots become sentient, there will be no shortage of arguments for those who say

68
00:05:32,140 --> 00:05:37,759
that they should remain without rights, especially from those who stand to profit from it.

69
00:05:37,760 --> 00:05:42,659
Artificial Intelligence raises serious questions about philosophical boundaries.

70
00:05:42,660 --> 00:05:46,799
What we may ask if sentient robots are conscious or deserving of rights,

71
00:05:46,800 --> 00:05:54,799
it forces us to pose basic questions like, what makes us human? What makes us deserving of rights?

72
00:05:54,800 --> 00:05:59,719
Regardless of what we think, the question might need to be resolved in the near future.

73
00:05:59,720 --> 00:06:07,279
What are we going to do if robots start demanding their own rights?

74
00:06:07,280 --> 00:06:10,779
What can robots demanding rights teach us about ourselves?

75
00:06:10,780 --> 00:06:16,859
Our friends at Wisecrack made a video exploring this very question using the philosophy of Westworld.

76
00:06:16,860 --> 00:06:21,419
Wisecrack dissects pop culture in a unique and philosophical way.

77
00:06:21,420 --> 00:06:25,140
Click here to check out the video and subscribe to their channel.

