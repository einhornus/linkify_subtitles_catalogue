1
00:00:02,160 --> 00:00:07,259
あなたのトースターがあなたが望むトーストの種類を予測する未来を想像してみてください。

2
00:00:07,260 --> 00:00:11,559
日中は、インターネットをスキャンして、新しくてエキサイティングな種類のトーストを探します。

3
00:00:11,560 --> 00:00:17,539
多分それはあなたにあなたの一日について尋ね、トースト技術の新しい成果についてチャットしたいと思っています。

4
00:00:17,540 --> 00:00:20,159
どのレベルで人になりますか？

5
00:00:20,160 --> 00:00:24,239
どの時点で、トースターに感情があるかどうかを自問しますか？

6
00:00:24,240 --> 00:00:27,259
もしそうなら、それを抜くことは殺人でしょうか？

7
00:00:27,260 --> 00:00:43,179
そして、あなたはまだそれを所有しますか？
いつか私たちは自分のマシンに権利を与えることを余儀なくされるのでしょうか？

8
00:00:43,180 --> 00:00:45,599
AIはすでにあなたの周りにあります。

9
00:00:45,600 --> 00:00:48,379
ディスカウンターに十分なスナックが揃っていることを確認し

10
00:00:48,380 --> 00:00:55,399
、適切なインターネット広告を表示します。また、完全に機械で書かれた新しいストーリーを読んだこともあります。

11
00:00:55,400 --> 00:01:01,179
今、私たちはSiriのようなチャットボットを見て、彼らの原始的なシミュレートされた感情を笑っ

12
00:01:01,180 --> 00:01:05,199
ていますが、実際の人類とシミュレートされた人類の間に線を引くのを難しくしている存在に対処しなければならない可能

13
00:01:05,200 --> 00:01:08,719
性があります。

14
00:01:08,720 --> 00:01:12,539
権利に値するマシンが存在しますか？

15
00:01:12,540 --> 00:01:18,459
ほとんどの場合、まだです。
しかし、彼らが来たとしても、私たちはその準備ができていません。

16
00:01:18,460 --> 00:01:23,859
権利の哲学の多くは、人工知能の事例に対処するための設備が整っていません。

17
00:01:23,860 --> 00:01:29,859
人間または動物に関する権利の主張のほとんどは、意識の問題に集中しています。

18
00:01:29,860 --> 00:01:33,159
残念ながら、誰も意識が何であるかを知りません。

19
00:01:33,160 --> 00:01:39,099
重要ではないと考える人もいれば、気体や液体などの物質の状態だと言う人もいます。

20
00:01:39,100 --> 00:01:45,899
正確な定義に関係なく、私たちはそれを経験するので、意識の直感的な知識を持っています。

21
00:01:45,900 --> 00:01:51,759
私たちは自分自身と周囲を認識し、無意識がどのように感じられるかを知っています。

22
00:01:51,760 --> 00:01:57,499
一部の神経科学者は、十分に進んだシステムであれば意識を生み出すことができると信じています。

23
00:01:57,500 --> 00:02:02,879
したがって、トースターのハードウェアが十分に強力である場合、それは自己認識になる可能性があります。

24
00:02:02,880 --> 00:02:05,779
もしそうなら、それは権利に値するでしょうか？

25
00:02:05,780 --> 00:02:11,679
まあ、それほど速くはありません。
私たちが「権利」と定義するものはそれに意味がありますか？

26
00:02:11,680 --> 00:02:17,199
意識は、存在に苦しむ能力を与えるので、存在に権利を持つ権利を与えます。

27
00:02:17,200 --> 00:02:22,159
それは、痛みを感じるだけでなく、それに気づく能力を意味します。

28
00:02:22,160 --> 00:02:27,539
ロボットは苦しむことはなく、私たちがプログラムしない限り、おそらく苦しむことはありません。

29
00:02:27,540 --> 00:02:32,899
苦痛や喜びがなければ、好みはなく、権利は無意味です。

30
00:02:32,900 --> 00:02:38,779
私たちの人権は私たち自身のプログラミングと深く結びついています。たとえば

31
00:02:38,780 --> 00:02:41,699
、私たちの脳は私たちを生き続けるために進化したので、私たちは痛みを嫌います。

32
00:02:41,700 --> 00:02:46,639
私たちが熱い火に触れないようにするため、または私たちを捕食者から逃げさせるため。

33
00:02:46,640 --> 00:02:51,739
そこで、私たちは痛みを引き起こす侵害から私たちを守る権利を思いつきました。

34
00:02:51,740 --> 00:02:56,539
自由のようなさらに抽象的な権利は、私たちの脳

35
00:02:56,540 --> 00:03:00,099
が公正で不公正なものを検出するために配線されている方法に根ざしています。

36
00:03:00,100 --> 00:03:04,779
動かせないトースターは、檻の中に閉じ込められていませんか？

37
00:03:04,780 --> 00:03:08,919
死の恐れがなければ、解体してもいいですか？

38
00:03:08,920 --> 00:03:13,879
自尊心の必要がなければ、侮辱されてもいいですか？

39
00:03:13,880 --> 00:03:17,479
しかし、痛みや感情を感じるようにロボットをプログラムした場合はどうなるでしょうか。

40
00:03:17,480 --> 00:03:22,459
不当よりも正義を好み、痛みよりも喜びを好み、それに気づきますか？

41
00:03:22,460 --> 00:03:25,239
それは彼らを十分に人間的にするでしょうか？

42
00:03:25,240 --> 00:03:29,299
多くの技術者は、

43
00:03:29,300 --> 00:03:34,279
人工知能が自分たちよりも賢く自分たちの人工知能を学び、作成できるようになると、技術の爆発的増加が起こると信じて

44
00:03:34,280 --> 00:03:36,879
います。

45
00:03:36,880 --> 00:03:42,519
この時点で、私たちのロボットがどのようにプログラムされているかという問題は、ほとんど私たちの制御の及ばないものになります。

46
00:03:42,520 --> 00:03:47,439
進化生物学がほとんどの生き物で必要だと思ったように、人工知能が痛みを感じる能力をプログラムする必要があると思っ

47
00:03:47,440 --> 00:03:52,059
たらどうしますか？

48
00:03:52,060 --> 00:03:54,779
ロボットはそれらの権利に値しますか？

49
00:03:54,780 --> 00:03:59,719
しかし、超インテリジェントロボットが私たちにもたらすリスクについてはあまり心配せず、私たちがロボットにもたらす危険性についてはもっと心配する必要があるかもしれませ

50
00:03:59,720 --> 00:04:03,059
ん。

51
00:04:03,060 --> 00:04:07,559
私たちの人間のアイデンティティ全体は

52
00:04:07,560 --> 00:04:12,939
、私たちが自然界を支配する権利を与えられた特別なユニークな雪片であるという人間の例外主義の考えに基づいています。

53
00:04:12,940 --> 00:04:17,898
人間には、他の存在が彼らと同じように苦しむことができることを否定した歴史があります。

54
00:04:17,899 --> 00:04:25,119
科学革命の真っ只中で、ルネデカルトは、動物は単なるオートマトン、つまりロボットであると主張しました。

55
00:04:25,120 --> 00:04:30,239
このように、ウサギを傷つけることは、ぬいぐるみを殴るのと同じくらい道徳的に嫌悪感を持っていました。

56
00:04:30,240 --> 00:04:35,299
そして、人道に対する最大の犯罪の多くは、

57
00:04:35,300 --> 00:04:40,179
犠牲者が文明化された人間よりも動物であるという理由で、彼らの加害者によって正当化されました。

58
00:04:40,180 --> 00:04:45,499
さらに問題なのは、ロボットの権利を否定することに経済的関心があることです。

59
00:04:45,500 --> 00:04:51,039
知覚力のあるAIを（おそらくプログラムされた拷問を通じて）私たちが望むように強制することができれば

60
00:04:51,040 --> 00:04:53,659
、経済的可能性は無限大です。

61
00:04:53,660 --> 00:04:56,279
結局のところ、私たちは前にそれをしました。

62
00:04:56,280 --> 00:04:59,759
暴力は、私たちの仲間の人間を強制的に働かせるために使用されてきました。

63
00:04:59,760 --> 00:05:04,959
そして、私たちはイデオロギー的な正当化を思い付くのに苦労したことはありません。

64
00:05:04,960 --> 00:05:12,159
奴隷所有者は奴隷制が奴隷に利益をもたらしたと主張しました：それは彼らの頭の上に屋根を置き、彼らにキリスト教を教えました。

65
00:05:12,160 --> 00:05:19,479
女性の投票に反対した男性は、難しい決断を男性に任せることは女性自身の利益であると主張した。

66
00:05:19,480 --> 00:05:27,699
農民は、動物の世話をし、それらに餌を与えることは、私たちの食事の好みのために彼らの早期の死を正当化すると主張します。

67
00:05:27,700 --> 00:05:32,139
ロボットが感覚的になれば、

68
00:05:32,140 --> 00:05:37,759
権利なしに留まるべきだと言う人々、特にそれから利益を得る立場にある人々にとって、議論が不足することはありません。

69
00:05:37,760 --> 00:05:42,659
人工知能は、哲学的境界について深刻な問題を提起します。

70
00:05:42,660 --> 00:05:46,799
感性のあるロボットが意識しているのか、権利に値するのかを尋ねると

71
00:05:46,800 --> 00:05:54,799
、人間になる理由などの基本的な質問をする必要があります。 何が私たちに権利に値するのか？

72
00:05:54,800 --> 00:05:59,719
私たちの考えに関係なく、問題は近い将来解決される必要があるかもしれません。

73
00:05:59,720 --> 00:06:07,279
ロボットが自分の権利を要求し始めたらどうしますか？

74
00:06:07,280 --> 00:06:10,779
権利を要求するロボットは私たち自身について何を教えてくれますか？

75
00:06:10,780 --> 00:06:16,859
Wisecrackの友人たちは、Westworldの哲学を使用して、まさにこの質問を探求するビデオを作成しました。

76
00:06:16,860 --> 00:06:21,419
Wisecrackは、ユニークで哲学的な方法でポップカルチャーを分析します。

77
00:06:21,420 --> 00:06:25,140
ここをクリックしてビデオをチェックし、彼らのチャンネルに登録してください。

