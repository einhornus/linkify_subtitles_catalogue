1
00:00:02,160 --> 00:00:07,259
토스터기가 여러분이 원하는 토스트를 예상하는 미래를 상상해보십시오.

2
00:00:07,260 --> 00:00:11,559
토스터기는 하루 종일 새롭고 흥미로운 유형의 토스트를 인터넷에서 검색합니다.

3
00:00:11,560 --> 00:00:17,539
어쩌면 여러분의 하루에 대해 묻고, 토스트 기술의 새로운 업적에 대해 이야기하고 싶어할지도 모릅니다.

4
00:00:17,540 --> 00:00:20,159
어느 선에서 이 토스터기는 사람이 될까요?

5
00:00:20,160 --> 00:00:24,239
어느 시점에서 토스터기가 감정을 가졌다는 것을 알게될까요?

6
00:00:24,240 --> 00:00:27,259
그렇다면 토스터기의 전원을 뽑는 것은, 살인과 다름없는 것일까요?

7
00:00:27,260 --> 00:00:29,479
우리가 계속 그들의 소유권을 주장할 수 있을까요?

8
00:00:29,480 --> 00:00:43,179
언젠가는 우리가 기계에게 "권리" 를 줄 수 밖에 없는 날이 올까요?

9
00:00:43,180 --> 00:00:45,599
인공지능은 이미 여러분의 곁에 와 있습니다.

10
00:00:45,600 --> 00:00:48,379
인공지능은 대형 할인점의 간식 재고를 관리할 뿐 아니라,

11
00:00:48,380 --> 00:00:50,639
적절한 인터넷 광고를 제공하기도 하고,

12
00:00:50,640 --> 00:00:55,399
심지어 여러분이 읽는 기사들 중 일부는 처음부터 끝까지 기계에 의해 작성되어 있습니다.

13
00:00:55,400 --> 00:01:01,179
우리는 지금 Siri와 같은 채팅봇을 보고 원시적인 시뮬레이션된 감정을 비웃고 있지만

14
00:01:01,180 --> 00:01:05,199
곧 실제와 시뮬레이션된 인간성 사이의 경계선을 긋기가

15
00:01:05,200 --> 00:01:08,719
어려운 존재들에 대처해야 할 것입니다.

16
00:01:08,720 --> 00:01:12,539
존재하는 기계중에 권리를 받을 만한 기계가 있을까요?

17
00:01:12,540 --> 00:01:14,619
아마 아직은 없을 겁니다.

18
00:01:14,620 --> 00:01:18,159
하지만 만약 그런 존재가 나타나더라도, 우리는 그에 대한 준비가 전혀 되어 있지 않을 것입니다.

19
00:01:18,160 --> 00:01:23,859
권리 철학의 대부분은 인공지능의 경우를 다루는데 적합하지 않습니다.

20
00:01:23,860 --> 00:01:29,859
인간과 동물에 대한 대부분의 권리 주장은 의식에 대한 질문이 중심이 됩니다.

21
00:01:29,860 --> 00:01:33,159
불행하게도 아무도 의식이 뭔지 모릅니다.

22
00:01:33,160 --> 00:01:39,099
어떤 사람들은 의식이 물질이 아니라고 생각하고, 다른 사람들은 가스나 액체같은 상태의 물질이라고 말합니다.

23
00:01:39,100 --> 00:01:45,899
정확한 정의와는 상관없이 의식을 경험하고 있기 때문에 우리는 의식에 대한 직관적인 지식을 가집니다.

24
00:01:45,900 --> 00:01:51,759
우리는 자신과 주변을 인지하고 있으며 무의식이 어떤 느낌인지 알고 있습니다.

25
00:01:51,760 --> 00:01:57,499
일부 신경 과학자들은 충분히 발전된 시스템이 의식을 생성 할 수 있다고 믿습니다.

26
00:01:57,500 --> 00:02:02,799
그러니 만약 토스터기의 하드웨어가 충분히 강력하다면 자의식을 가질 수 있습니다.

27
00:02:02,800 --> 00:02:05,779
만약 그렇다면, 토스터기가 권리를 받을 자격이 있을까요?

28
00:02:05,780 --> 00:02:11,679
글쎄요, 너무 이릅니다. 우리가 "권리"로 정의하는 것이 토스터기에게 이해가 될까요?

29
00:02:11,680 --> 00:02:17,199
의식은 고통받는 능력을 가진 존재이기 때문에 존재할 권리를 가집니다.

30
00:02:17,200 --> 00:02:22,159
이는 통증을 느낄뿐만 아니라 그것을 인지 할 수있는 능력을 의미합니다.

31
00:02:22,160 --> 00:02:27,539
로봇은 고통을 겪지 않으며, 우리가 프로그래밍하지 않은 이상은 그렇지 않을 것입니다.

32
00:02:27,540 --> 00:02:32,899
고통이나 즐거움이 없으면 선호하는 것도 없고 권리도 의미가 없습니다.

33
00:02:32,900 --> 00:02:38,779
우리의 인권은 우리 자신의 프로그래밍에 깊게 묶여 있습니다. 예를 들어 고통을 싫어한다던지요.

34
00:02:38,780 --> 00:02:41,699
우리의 두뇌가 우리를 살아있게하기 위해 진화했기 때문이죠.

35
00:02:41,700 --> 00:02:46,639
뜨거운 불에 손을 대지 못하게 하거나 우리를 육식 동물로부터 도망가게합니다.

36
00:02:46,640 --> 00:02:51,739
그래서 우리는 고통을 유발하는 침해 행위로부터 우리를 보호할 수 있는 권리를 생각해냈습니다.

37
00:02:51,740 --> 00:02:54,799
자유처럼 좀 더 추상적인 권리는

38
00:02:54,800 --> 00:02:59,939
우리의 두뇌가 공정하고 불공정한 것을 식별하는 능력에 뿌리를 두고 있습니다.

39
00:02:59,940 --> 00:03:04,779
움직일 수 없는 토스터가 철창안에 갖혀 있는걸 꺼릴까요?

40
00:03:04,780 --> 00:03:08,919
죽음에 대한 두려움이 없는데 해체되는걸 꺼릴까요?

41
00:03:08,920 --> 00:03:13,879
자존심이 필요없는데 모욕감을 느낄까요?

42
00:03:13,880 --> 00:03:17,479
하지만 고통과 감정을 느끼도록 로봇을 프로그래밍한다면 어떨까요?

43
00:03:17,480 --> 00:03:22,459
불의보다는 정의, 고통보다는 쾌락을 선호하고, 그것에 대해 인지한다면?

44
00:03:22,460 --> 00:03:25,239
토스터기들을 충분히 인간적으로 만들까요?

45
00:03:25,240 --> 00:03:29,299
많은 기술자들은 인공지능이 배울 수 있고

46
00:03:29,300 --> 00:03:34,279
자기 자신보다 똑똑한 인공지능을 만들 수 있을 때

47
00:03:34,280 --> 00:03:35,759
기술의 폭발이 일어날 것이라고 믿습니다.

48
00:03:35,760 --> 00:03:36,879
* 눈동자로 들어가시오! *
기술의 폭발이 일어날 것이라고 믿습니다.

49
00:03:36,880 --> 00:03:42,519
이 시점에서 우리의 로봇이 어떻게 프로그래밍되는지에 대한 질문은 대부분 우리가 통제 할 수 없을 것입니다.

50
00:03:42,520 --> 00:03:47,439
인공지능이 진화 생물학이 대부분의 생명체에 필요하다고 느끼는 것처럼

51
00:03:47,440 --> 00:03:52,059
고통을 느낄 수 있는 능력을 프로그래밍할 필요가 있다는 것을 발견했다면 어떨까요?

52
00:03:52,060 --> 00:03:54,779
* 삶은 고통이요, 고통이 곧 삶이니라 *
이제는 로봇이 권리를 부여받을 자격이 있을까요?

53
00:03:54,780 --> 00:03:59,719
하지만 우리는 초지능형 로봇이 우리에게 주는 위험성에 대해 걱정할 필요는 없고

54
00:03:59,720 --> 00:04:03,059
우리가 그들에게 줄 위험성에 대해 걱정해봐야합니다.

55
00:04:03,060 --> 00:04:07,559
우리의 전체적인 인간 정체성은 인간 예외주의의 개념을 기반으로 하는데

56
00:04:07,560 --> 00:04:12,939
이는 우리가 굉장히 특별한 모양이 눈송이 같은 것이라, 자연 세계를 지배할 권리를 부여받았다고 믿는 것입니다.

57
00:04:12,940 --> 00:04:17,898
인간은 다른 존재들이 고통을 느낄 수 있다는 사실을 부인하던 역사가 있습니다.

58
00:04:17,899 --> 00:04:25,119
과학 혁명 시기에, 르네 데카르트는 동물은 단지 오토마타, 즉 로봇일 뿐이라고 주장했습니다.

59
00:04:25,120 --> 00:04:30,239
이런 주장대로라면, 토끼를 다치게 하는 것은 토끼 인형을 때리는 것과 별반 다르지 않은 수준의 부도덕에 지나지 않습니다.

60
00:04:30,240 --> 00:04:33,299
그리고 인류에 대한 가장 큰 범죄의 대부분은

61
00:04:33,300 --> 00:04:40,179
피해자들이 문명화된 인간보다는 동물에 가깝다는 식의 논리로 가해자들에 의해 정당화되어 온 바가 있습니다.

62
00:04:40,180 --> 00:04:45,499
더 큰 문제는 우리가 로봇 권리를 부정함으로써 경제적 이익을 얻을 수 있다는 것입니다.

63
00:04:45,500 --> 00:04:51,039
지각력이 있는 인공지능을 (아마도 프로그래밍 된 고문을 통해) 우리가 원하는 일을 하도록 강요할 수 있다면

64
00:04:51,040 --> 00:04:53,659
경제적 잠재력은 무한합니다.

65
00:04:53,660 --> 00:04:56,279
사실 우리가 이미 저질러 왔던 일이기도 하죠.

66
00:04:56,280 --> 00:04:59,739
폭력은 우리의 동료인 인간들을 강제로 일하게 하는 데 사용되었습니다.

67
00:04:59,740 --> 00:05:02,679
그리고 우리는 이를 이념적으로 정당화시키는 데 큰 어려움이 없었습니다.

68
00:05:02,680 --> 00:05:05,279
"신께서 황금을 원하신다!"
그리고 우리는 이를 이념적으로 정당화시키는 데 큰 어려움이 없었습니다.

69
00:05:05,280 --> 00:05:12,159
노예 주인들은 노예에게 혜택을 주었다고 주장했습니다. 지붕이 있는 집을 지어주고 기독교를 가르쳤다는 것입니다.

70
00:05:12,160 --> 00:05:19,319
여성 참정권에 반대하는 남성들은 어려운 결정을 남성에게 맡겨 두는 것이 여성들에게는 이익이라고 주장했습니다.

71
00:05:19,320 --> 00:05:27,339
농부들은 동물들을 돌보고 먹이를 주었으니 우리가 먹고 싶은 음식을 공급하기 위해 그들을 도살하는 것은 정당하다고 말합니다.

72
00:05:27,340 --> 00:05:31,339
로봇에게 지각력이 생긴다 한들, 변명거리는 넘쳐날 겁니다.

73
00:05:31,340 --> 00:05:35,079
* 그만둬라 인간! *
로봇에게 권리가 필요없다고 말하는 사람들에게는, 특히 거기서 이익을 얻는 사람들에게는 말이죠.

74
00:05:35,080 --> 00:05:37,579
* 얘들은 일하는거 좋아해요. *
로봇에게 권리가 필요없다고 말하는 사람들에게는, 특히 거기서 이익을 얻는 사람들에게는 말이죠.

75
00:05:37,580 --> 00:05:42,659
인공지능은 철학적 경계에 관한 심각한 질문을 제기할 것입니다.

76
00:05:42,660 --> 00:05:46,739
우리가 궁금한 것은 지각력있는 로봇이 자의식이 있거나 권리를 가진다면,

77
00:05:46,740 --> 00:05:54,119
그것은 무엇이 우리를 인간으로 만들고 권리를 받게 하는지와 같은 근본적인 질문을 강요합니다.

78
00:05:54,120 --> 00:05:59,719
우리가 생각하는 것에 관계없이, 질문은 가까운 미래에 해결 되야 할 것입니다.

79
00:05:59,720 --> 00:06:07,279
로봇들이 자신의 권리를 요구하기 시작하면 우리는 어떻게 행동 할까요?

80
00:06:07,280 --> 00:06:10,779
권리를 요구하는 로봇들이 우리에 대해 무엇을 가르쳐 줄 수 있을까요?

81
00:06:10,780 --> 00:06:16,859
Wisecrack의 우리 친구들은 드라마 "웨스트월드"의 철학을 사용하여 이 질문을 탐구하는 비디오를 만들었습니다

82
00:06:16,860 --> 00:06:21,419
Wisecrack은 독특하고 철학적인 방식으로 대중 문화를 분석합니다.

83
00:06:21,420 --> 00:06:25,140
동영상을 확인하고 채널을 구독하려면 여기를 클릭하세요.

