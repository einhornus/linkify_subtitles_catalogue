1
00:00:02,000 --> 00:00:07,399
Stell dir eine Zukunft vor, in der dein Toaster vorausahnt, wie du deinen Toast möchtest.

2
00:00:07,400 --> 00:00:11,439
Tagsüber durchsucht er das Internet nach neuen und interessanten Toasts.

3
00:00:11,440 --> 00:00:13,599
Vielleicht fragt er, wie dein Tag war

4
00:00:13,600 --> 00:00:17,399
und möchte sich über neue Erfolge in Toast-Technologie unterhalten.

5
00:00:17,400 --> 00:00:20,099
Ab wann würde er eine Person sein?

6
00:00:20,100 --> 00:00:24,099
Ab wann würdest du dich fragen, ob dein Toaster Gefühle hat?

7
00:00:24,100 --> 00:00:27,099
Wenn dem so wäre, wäre es Mord den Stecker zu ziehen?

8
00:00:27,100 --> 00:00:29,599
Und würdest du ihn immer noch besitzen?

9
00:00:29,600 --> 00:00:43,099
Wären wir irgendwann gezwungen, unseren Maschinen Rechte zu geben?

10
00:00:43,100 --> 00:00:45,499
KI (Künstliche Intelligenz) ist bereits überall um dich herum.

11
00:00:45,500 --> 00:00:48,519
Sie stellt sicher, dass Geschäfte genug auf Lager haben,

12
00:00:48,520 --> 00:00:50,699
sie schneidet Werbung im Internet auf dich zu

13
00:00:50,700 --> 00:00:55,299
und du hast vielleicht sogar schon einen Artikel gelesen, komplett von einer Maschine geschrieben.

14
00:00:55,300 --> 00:00:57,799
Wir nutzen jetzt schon Chatbots (virtuelle persönliche Assistenten) wie Siri

15
00:00:57,800 --> 00:01:01,099
und lachen über ihre primitiv simulierten Emotionen.

16
00:01:01,100 --> 00:01:05,199
Aber es ist wahrscheinlich, dass wir künftig mit Wesen umgehen müssen, die es schwer machen

17
00:01:05,200 --> 00:01:06,099
den Unterschied zwischen echter

18
00:01:06,100 --> 00:01:08,699
und simulierter Menschlichkeit zu finden.

19
00:01:08,700 --> 00:01:12,499
Gibt es bereits Maschinen, die Rechte verdienen?

20
00:01:12,500 --> 00:01:14,799
Höchstwahrscheinlich...noch nicht.

21
00:01:14,800 --> 00:01:18,299
Aber wenn sie kommen, sind wir nicht darauf vorbereitet.

22
00:01:18,300 --> 00:01:23,579
Vieles aus der Philosophie des Rechts ist schlecht ausgerüstet um sich mit dem Fall von KI auseinanderzusetzen.

23
00:01:23,580 --> 00:01:26,619
Die meisten Ansprüche auf Rechte (für Mensch oder Tier)

24
00:01:26,620 --> 00:01:29,759
drehen sich um die Frage des Bewusstseins.

25
00:01:29,760 --> 00:01:33,019
Leider weiß niemand, was "Bewusstsein" ist.

26
00:01:33,020 --> 00:01:34,839
Manche denken, es sei immateriell.

27
00:01:34,840 --> 00:01:39,079
Andere sagen, es sei ein Zustand von Materie, wie Gas oder Flüssigkeit.

28
00:01:39,080 --> 00:01:41,299
Abgesehen von der genauen Definition,

29
00:01:41,300 --> 00:01:43,819
haben wir ein intuitives Verständnis von "Bewusstsein",

30
00:01:43,820 --> 00:01:45,819
weil wir es selbst erfahren.

31
00:01:45,820 --> 00:01:48,279
Wir sind uns unserer selbst und unserer Umgebung bewusst

32
00:01:48,280 --> 00:01:51,779
und wissen, wie sich Bewusstlosigkeit anfühlt.

33
00:01:51,780 --> 00:01:55,639
Einige Neurowissenschaftler glauben, dass jedes genügend fortgeschrittene System,

34
00:01:55,640 --> 00:01:57,699
ein Bewusstsein entwickeln kann.

35
00:01:57,700 --> 00:02:00,359
Also, wenn die Hardware deines Toasters mächtig genug wäre,

36
00:02:00,360 --> 00:02:02,759
könnte er ein Bewusstsein bilden.

37
00:02:02,760 --> 00:02:05,699
Wenn es dazu kommt, würde er dann Rechte verdienen?

38
00:02:05,700 --> 00:02:07,759
Nun, nicht so schnell.

39
00:02:07,760 --> 00:02:11,799
Würde, was wir als Rechte verstehen, für ihn Sinn machen?

40
00:02:11,800 --> 00:02:17,199
Ein Bewusstsein gibt einem Wesen den Anspruch auf Rechte, weil es dem Wesen die Fähigkeit zu leiden gibt.

41
00:02:17,200 --> 00:02:20,019
Das heißt, nicht nur die Fähigkeit, Schmerz zu empfinden,

42
00:02:20,020 --> 00:02:22,119
sondern auch sich diesem bewusst zu sein.

43
00:02:22,120 --> 00:02:23,819
Roboter leiden nicht.

44
00:02:23,820 --> 00:02:27,559
Und sie werden es wohl nie, sofern wir sie nicht dafür programmieren.

45
00:02:27,560 --> 00:02:32,839
Ohne Schmerz und Freude wird nichts bevorzugt und Rechte werden bedeutungslos.

46
00:02:32,840 --> 00:02:37,259
Unsere menschlichen Rechte sind stark verbunden mit unserer eigenen Programmierung.

47
00:02:37,260 --> 00:02:41,719
Zum Bespiel meiden wir Schmerz, weil sich unser Gehirn entwickelt hat, uns am Leben zu erhalten,

48
00:02:41,720 --> 00:02:44,019
uns davon abzuhalten, ein heißes Feuer zu berühren,

49
00:02:44,020 --> 00:02:46,439
oder uns von Raubtieren weglaufen zu lassen.

50
00:02:46,440 --> 00:02:51,659
Also haben wir Rechte entwickelt, die uns vor schmerzlichen Erfahrungen bewahren.

51
00:02:51,660 --> 00:02:59,979
Selbst abstraktere Rechte (wie Freiheit) wurzeln darin, wie unser Gehirn feststellt, was fair und unfair ist.

52
00:02:59,980 --> 00:03:04,839
Würde ein bewegungsunfähiger Toaster es übel nehmen, in einen Käfig gesperrt zu sein?

53
00:03:04,840 --> 00:03:08,899
Würde er es übel nehmen, auseinander genommen zu werden, wenn er keine Angst vor dem Tod kennt?

54
00:03:08,900 --> 00:03:13,639
Würde er Beleidigungen übel nehmen, wenn er keinen Nutzen für Selbstachtung hätte.

55
00:03:13,640 --> 00:03:17,519
Aber was, wenn wir einen Roboter programmierten, Schmerzen und Gefühle zu empfinden,

56
00:03:17,520 --> 00:03:19,879
Recht über Unrecht zu stellen,

57
00:03:19,880 --> 00:03:21,079
Freude über Schmerzen,

58
00:03:21,080 --> 00:03:22,499
und sich dessen bewusst zu sein.

59
00:03:22,500 --> 00:03:24,999
Würde ihn das ausreichend menschlich machen?

60
00:03:25,000 --> 00:03:29,359
Viele Technologen glauben, dass es eine Explosion in Technologie geben wird,

61
00:03:29,360 --> 00:03:34,119
wenn KI lernfähig wird und ihre eigene KI's entwickeln kann,

62
00:03:34,120 --> 00:03:36,799
die sogar schlauer als sie selbst sind.

63
00:03:36,800 --> 00:03:42,519
An dem Punkt wird die Frage, wie Roboter progammiert werden, kaum noch von uns kontrolliert.

64
00:03:42,520 --> 00:03:47,359
Was, wenn eine KI es für notwendig hält, Schmerzempfinden zu programmieren,

65
00:03:47,360 --> 00:03:52,059
genauso, wie die Evolution es für die meisten Lebewesen notwendig ansah.

66
00:03:52,060 --> 00:03:55,479
Verdienen Roboter diese Rechte?

67
00:03:55,480 --> 00:03:59,739
Aber vielleicht sollten wir uns weniger um das Risiko von super-intelligenten Robotern für uns sorgen

68
00:03:59,740 --> 00:04:03,099
und uns mehr darum sorgen, welche Gefahr wir für sie darstellen.

69
00:04:03,100 --> 00:04:07,519
Unsere gesamte Menschliche Identität ist geprägt von der Idee der Menschlichen Sonderstellung,

70
00:04:07,520 --> 00:04:12,899
dass wir besondere, einzigartige Schneeflöckchen sind, bestimmt die natürliche Welt zu beherrschen.

71
00:04:12,900 --> 00:04:17,679
Menschen haben eine Vorgeschichte, anderen Lebewesen die gleiche Leidensfähigkeit abzusprechen.

72
00:04:17,680 --> 00:04:19,979
Inmitten der Wissenschaftlichen Revolution,

73
00:04:19,980 --> 00:04:23,059
argumentierte René Descartes, dass Tiere bloße Automaten seien,

74
00:04:23,060 --> 00:04:24,899
Roboter, wenn du so möchtest.

75
00:04:24,900 --> 00:04:30,319
So war einen Hasen zu verletzen genauso wider die Moral, wie ein Stofftier zu schlagen.

76
00:04:30,320 --> 00:04:33,159
Und viele der schlimmsten Verbrechen gegen die Menschlichkeit

77
00:04:33,160 --> 00:04:35,359
waren für ihre Täter gerechtfertigt

78
00:04:35,360 --> 00:04:40,099
auf der Basis, dass ihre Opfer mehr Tier als zivilisierte Menschen seien.

79
00:04:40,100 --> 00:04:45,199
Noch problematischer ist, dass wir ein wirtschaftliches Interesse daran haben, Robotern Rechte zu verwehren.

80
00:04:45,200 --> 00:04:49,559
Wenn wir eine empfindungsfähige KI zwingen können (evtl. durch programmierte Folter),

81
00:04:49,560 --> 00:04:51,039
das zu tun, was wir wollen,

82
00:04:51,040 --> 00:04:53,999
wäre das wirtschafltiche Potential unbegrenzt.

83
00:04:54,000 --> 00:04:56,139
Immerhin haben wir das schon früher getan.

84
00:04:56,140 --> 00:04:59,659
Gewalt wurde genutzt um unsere Mitmenschen zum Arbeiten zu zwingen.

85
00:04:59,660 --> 00:05:04,799
Und wir hatten noch nie Probleme, uns ideologische Rechtfertigungen auszudenken.

86
00:05:04,800 --> 00:05:08,659
Sklavenbesitzer behaupteten, dass Sklaverei den Sklaven nütze.

87
00:05:08,660 --> 00:05:12,019
Sie gaben ihnen ein Dach über dem Kopf und lehrten sie Christentum.

88
00:05:12,020 --> 00:05:14,079
Männer, die gegen das Frauenwahlrecht waren,

89
00:05:14,080 --> 00:05:19,419
behaupteten, dass es im besten Interesse der Frauen wäre, die schweren Entscheidungen Männern zu überlassen.

90
00:05:19,420 --> 00:05:22,399
Bauern behaupteten, dass sich um Tiere zu kümmern und sie zu füttern,

91
00:05:22,400 --> 00:05:27,619
ihren vorzeitigen Tod für unsere Nahrungsvorliebe rechtfertige.

92
00:05:27,620 --> 00:05:29,599
Wenn Roboter empfindungsfähig werden,

93
00:05:29,600 --> 00:05:33,959
wird es genug Leute geben, die fordern, dass sie ohne Rechte bleiben sollen.

94
00:05:33,960 --> 00:05:37,619
Besonders unter denjenigen, die davon profitieren werden.

95
00:05:37,620 --> 00:05:42,619
KI wirft ernsthafte Fragen auf über philosophische Grenzen.

96
00:05:42,620 --> 00:05:46,799
Während wir uns fragen mögen, ob empfindungsfähige Roboter ein Bewusstsein haben oder Rechte verdienen,

97
00:05:46,800 --> 00:05:49,439
sind wir gezwungen grundlegende Fragen zu stellen, wie

98
00:05:49,440 --> 00:05:51,139
Was macht uns menschlich?

99
00:05:51,140 --> 00:05:54,659
Warum verdienen wir Rechte?

100
00:05:54,660 --> 00:05:59,639
Ungeachet dessen, was wir denken, müssen wir diese Frage vielleicht in der nahen Zukunft beantworten.

101
00:05:59,640 --> 00:06:07,219
Was werden wir tun, wenn Roboter beginnen ihre Rechte einzufordern?

102
00:06:07,220 --> 00:06:10,639
Was können wir aus Robotern, die nach Rechten verlangen, über uns selbst lernen.

103
00:06:10,640 --> 00:06:14,199
Unsere Freunde bei Wisecrack haben ein Video genau über diese Frage gemacht,

104
00:06:14,200 --> 00:06:16,879
mit Hilfe der Philosophie aus Westworld.

105
00:06:16,880 --> 00:06:21,339
Wisecrack untersucht Popkultur in einer einzigarten und philosphischen Weise.

106
00:06:21,340 --> 00:06:24,240
Klick hier um ihr Video zu sehen und ihren Kanal zu abonnieren.

