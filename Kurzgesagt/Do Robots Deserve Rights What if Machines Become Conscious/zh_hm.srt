1
00:00:02,160 --> 00:00:07,259
試諗下喺未來，你部多士爐識得估你想要邊種多士

2
00:00:07,260 --> 00:00:11,559
喺日頭嗰陣，佢又識上網搵新奇有趣嘅多士種類

3
00:00:11,560 --> 00:00:17,539
或者佢會問下你今日過成點，
又同你講下有乜新嘅多士科技

4
00:00:17,540 --> 00:00:20,159
咁喺邊個層次佢會變成一個「人」呢?

5
00:00:20,160 --> 00:00:24,239
又喺邊個位你會問你自己「唔通部野有感覺」？

6
00:00:24,240 --> 00:00:27,259
如果佢真喺有，掹走佢個插蘇會唔會等於殺咗佢？

7
00:00:27,260 --> 00:00:34,919
而且你重有冇權擁有佢？ 
我哋有日會唔會被逼要畀我哋嘅機器權利？

8
00:00:34,920 --> 00:00:43,179
（翻譯呢家野呢, 志在抓住神髓
咪逐隻字同我拗: 你譯得唔準啊
又乜又乜啊, 大佬, 照譯就唔地道架啦！）

9
00:00:43,180 --> 00:00:45,599
人工智能(AI)已經一早喺你隔離

10
00:00:45,600 --> 00:00:48,379
佢確保啲十蚊店都有充足嘅貨

11
00:00:48,380 --> 00:00:55,399
佢識賣啲啱你睇嘅廣告，
你重可能睇到一個完全由機器作嘅新嘅故仔添

12
00:00:55,400 --> 00:01:01,179
而家我哋睇見好似Siri咁嘅傾偈機械人
重可以笑下佢哋啲生硬嘅模擬情緒

13
00:01:01,180 --> 00:01:05,199
但喺最後我哋可能始終要面對一種情況

14
00:01:05,200 --> 00:01:08,719
就係連真人定電腦都分唔到

15
00:01:08,720 --> 00:01:12,539
到底而家有冇機器應該得到權利？

16
00:01:12,540 --> 00:01:18,459
多數重未有
但如果真係出現咗，我哋重未有心理準備接受

17
00:01:18,460 --> 00:01:23,859
權義哲學中大部份內容都對人工智能嘅問題無符

18
00:01:23,860 --> 00:01:29,859
大多數申索權利嘅主張，不論畀一個人類或一隻動物，都係圍繞意識嘅問題

19
00:01:29,860 --> 00:01:33,159
好唔好彩，無人知乜野係意識

20
00:01:33,160 --> 00:01:39,099
有啲人覺得佢屬於非物質性，
其他人話係一種物質嘅狀態，好似氣體或液體咁

21
00:01:39,100 --> 00:01:45,899
先唔講精確嘅定義，我哋直覺上會知意識係乜野，
因為我哋每個都有

22
00:01:45,900 --> 00:01:51,759
我哋感知到自己同周圍嘅環境，
重知冇咗意識係乜野感覺

23
00:01:51,760 --> 00:01:57,499
有啲腦神經專家相信, 
任何夠先進嘅系統都係能夠產生意識嘅

24
00:01:57,500 --> 00:02:02,879
所以如果你部多士爐硬件夠勁，
佢都可能變成有知覺

25
00:02:02,880 --> 00:02:05,779
假如佢真係有，佢有冇資格享有權利呢？

26
00:02:05,780 --> 00:02:11,679
嗱，就無咁快嘅
究竟我哋要定義啲乜野為之「權利」先合情理呢？

27
00:02:11,680 --> 00:02:17,199
意識之所以能夠令物種有權利
係因為佢令一個物種有感受痛苦嘅能力

28
00:02:17,200 --> 00:02:22,159
意思係呢個能力唔單只令佢識得痛，
重知道有痛苦呢樣野

29
00:02:22,160 --> 00:02:27,539
機械人就唔識痛喇，
如果我哋唔特登去入程式嘅話佢哋就成世都唔會識得痛

30
00:02:27,540 --> 00:02:32,899
冇咗痛苦或快樂,，就冇話鍾意唔鍾意，
咁講權利都冇乜意義啦

31
00:02:32,900 --> 00:02:38,779
我哋嘅人權同我哋自己套「程式」關係就大喇，
譬如我哋唔鍾意痛

32
00:02:38,780 --> 00:02:41,699
係因為我哋個腦進化咗用佢黎保命

33
00:02:41,700 --> 00:02:46,639
為咗唔令我哋去掂啲好熱嘅火堆，
或者去令我哋遇到猛獸時識得走

34
00:02:46,640 --> 00:02:51,739
於是我哋就得出一套保護我哋
免受令人痛苦嘅侵害嘅種種權利

35
00:02:51,740 --> 00:02:56,539
甚至乎有一啲好似自由噉咁抽象嘅權利，
係基於我哋個腦生出黎嘅雷達

36
00:02:56,540 --> 00:03:00,019
去分乜野係公平同唔公平

37
00:03:00,020 --> 00:03:04,779
一部唔識郁嘅多士爐
會唔會去介意自己好似被人困住咁呢？

38
00:03:04,780 --> 00:03:08,919
如果佢唔怕死，會唔會介意被人拆散晒？

39
00:03:08,920 --> 00:03:13,879
如果佢無自尊心，會唔會介意被人侮辱？

40
00:03:13,880 --> 00:03:17,479
不過如果我哋入啲程式
令部機識得感覺痛苦同情緒呢?

41
00:03:17,480 --> 00:03:22,459
令佢想要公義多過不義，想要快樂唔要痛苦
同埋感知到呢啲係乜野

42
00:03:22,460 --> 00:03:25,239
咁樣夠唔夠令佢哋變成人類?

43
00:03:25,240 --> 00:03:29,299
好多科技人士相信科技會有個爆炸性變化發生

44
00:03:29,300 --> 00:03:34,279
就喺人工智能識學習同創造佢哋自己嘅人工智能

45
00:03:34,280 --> 00:03:36,879
而且重叻過晒佢哋自己嘅時候

46
00:03:36,880 --> 00:03:42,599
到呢一步，我哋啲機械人要點樣入指令嘅問題
已經基本上唔喺我哋嘅掌握之中

47
00:03:42,600 --> 00:03:47,439
假如一個人工智能覺得自己有需要編程
去令佢有感覺到痛苦嘅能力

48
00:03:47,440 --> 00:03:52,059
就好似演化過程當中
大多數生物都因為有需要演化出痛感一樣咁呢？

49
00:03:52,060 --> 00:03:54,779
咁樣啲機械人有冇資格擁有咁嘅權利？

50
00:03:54,780 --> 00:03:59,719
不過我哋或者唔使咁擔心
呢啲超叻嘅機械人會為我哋帶黎災難，

51
00:03:59,720 --> 00:04:03,059
反而應該多啲擔心我哋帶畀佢哋嘅危險

52
00:04:03,060 --> 00:04:07,559
我哋成套「人」嘅身份認同
係建立喺人類例外論呢個諗法上，

53
00:04:07,560 --> 00:04:12,939
即係我哋好似獨一無二嘅雪花片一樣咁獨特，
所以有資格主宰自然萬物

54
00:04:12,940 --> 00:04:17,898
人類有史以黎
不斷否認其它物種會好似佢哋咁識得痛苦

55
00:04:17,899 --> 00:04:25,119
喺科學革命時期, 
笛卡兒拗話動物只係自動識行嘅機械人

56
00:04:25,120 --> 00:04:30,239
因為咁，整傷隻兔仔就同揼下隻毛公仔
喺道德上黎講差唔多冇乜野

57
00:04:30,240 --> 00:04:35,299
而好多最無人性嘅罪行都俾啲犯合法化咗
（打仗、獵巫）

58
00:04:35,300 --> 00:04:40,179
就係用受害者似動物多過文明人啲咁嘅理由免罪

59
00:04:40,180 --> 00:04:45,499
更加大問題嘅係我哋有一種經濟上嘅誘因
去否定機械人嘅權利

60
00:04:45,500 --> 00:04:51,039
如果我哋威逼一個有情感嘅AI―
可能係用折磨程式―要佢點就點

61
00:04:51,040 --> 00:04:53,659
個經濟潛在好處真係無窮無盡

62
00:04:53,660 --> 00:04:56,279
畢竟，我哋以前就做唔少啦

63
00:04:56,280 --> 00:04:59,759
又鞭又打咁去逼我哋啲人去做生做死

64
00:04:59,760 --> 00:05:04,959
而且我哋重用滿天神佛合理化勞隸制
萬試萬靈

65
00:05:04,960 --> 00:05:12,159
奴隸主拗話奴役對啲奴隸有益處: 
咁先令啲奴隸有瓦遮頭
同埋教佢哋信基督喎

66
00:05:12,160 --> 00:05:19,479
反對女人投票嘅男人
拗話咁係為女人好，應該等男人做咁困難嘅選擇

67
00:05:19,480 --> 00:05:27,699
農場主人拗話養啲動物咁耐，
佢哋早啲死等我哋有得食黎作為報答好合理

68
00:05:27,700 --> 00:05:32,139
如果機械人變成有情感，肯定會大把人拗話

69
00:05:32,140 --> 00:05:37,759
佢哋應該繼續乜野權利都冇，
尤其嗰啲可以從中大賺嘅人

70
00:05:37,760 --> 00:05:42,659
人工智能帶出咗
關於哲學要點樣定界嘅嚴肅問題

71
00:05:42,660 --> 00:05:46,799
我哋要問乜野問題去決定
有咗感覺嘅機械人係咪都有意識
或者應唔應該得到權利，

72
00:05:46,800 --> 00:05:54,799
咁會逼使我哋提出一啲基本問題， 
例如乜野令到我哋叫得上人呢？ 
乜野令我哋有資格得到權利呢？

73
00:05:54,800 --> 00:05:59,719
無論我哋點諗，
呢條問題可能都要快啲解決先得

74
00:05:59,720 --> 00:06:07,279
如果機械人開始要求攞返佢哋嘅權利
我哋要點做呢？

75
00:06:07,280 --> 00:06:10,779
機器人對其權利嘅追求又會教識我哋啲乜野呢？

76
00:06:10,780 --> 00:06:16,859
我哋喺Wisecrack嘅老友整咗條片
用西部世界個哲理探討下呢條咁堅嘅問題

77
00:06:16,860 --> 00:06:21,419
Wisecrack志在以獨特且發人深省嘅觀點
去剖析流行文化

78
00:06:21,420 --> 00:06:25,140
撳入呢度睇下啲片同訂閱我哋嘅頻道啦

