1
00:00:02,160 --> 00:00:07,259
Представьте себе такое будущее, в котором ваш тостер знает, какой тост вы хотите.

2
00:00:07,260 --> 00:00:11,559
В течении дня он сканирует интернет в поисках новых, удивительных видов тостов.

3
00:00:11,560 --> 00:00:17,539
Может быть, он спросит Вас о вашем дне, и захочет поговорить о новых достижениях в создании тостов?

4
00:00:17,540 --> 00:00:20,159
На каком этапе он станет личностью?

5
00:00:20,160 --> 00:00:24,239
В какой момент вы спросите себя: "Имеет ли мой тостер чувства?"

6
00:00:24,240 --> 00:00:27,259
И если это случится, будет ли его отключение считаться убийством?

7
00:00:27,260 --> 00:00:43,179
И будете ли вы всё ещё владеть им? Будем ли мы когда-нибудь вынуждены дать нашим устройствам права?

8
00:00:43,180 --> 00:00:45,599
Искусственный интеллект уже повсюду.

9
00:00:45,600 --> 00:00:48,379
Он гарантирует, что на витрине всегда достаточно еды,

10
00:00:48,380 --> 00:00:55,399
предоставляет интересующую вас рекламу, и, скорее всего, вы даже читали статью полностью написанную машиной.

11
00:00:55,400 --> 00:01:01,179
Прямо сейчас мы смотрим на чат ботов, таких как Сири, и смеёмся над их примитивной симуляцией эмоций,

12
00:01:01,180 --> 00:01:05,199
но вполне вероятно, что мы столкнёмся с существами, которые размоют границу

13
00:01:05,200 --> 00:01:08,719
между настоящей и симулированной человечностью.

14
00:01:08,720 --> 00:01:12,539
Существует ли машина, заслуживающая того, чтобы иметь права?

15
00:01:12,540 --> 00:01:18,459
Вероятно, ещё нет. Но она будет создана, и мы к этому не готовы.

16
00:01:18,460 --> 00:01:23,859
Большинство из прав из философии, плохо подходят для применения к ИИ.

17
00:01:23,860 --> 00:01:29,859
Большинство столпов прав, касающихся человека или животного, сосредоточено вокруг понятия Сознания.

18
00:01:29,860 --> 00:01:33,159
К сожалению, никто не знает, что такое Сознание.

19
00:01:33,160 --> 00:01:39,099
Некоторые думают, что это что-то нематериальное, другие говорят - это состояние материи, как газ или жидкость.

20
00:01:39,100 --> 00:01:45,899
Независимо от точного определения, у нас есть интуитивное понимание о сознании, потому что мы испытываем его.

21
00:01:45,900 --> 00:01:51,759
Мы осознаём себя и наше окружение, и знаем, как выглядит бессознательность.

22
00:01:51,760 --> 00:01:57,499
Некоторые неврологи верят, что любая достаточно развитая система может генерировать сознание.

23
00:01:57,500 --> 00:02:02,879
Итак, если бы у вашего тостера было достаточно мощное железо, но смог бы развить самосознание.

24
00:02:02,880 --> 00:02:05,779
И если так, будет ли он заслуживать иметь права?

25
00:02:05,780 --> 00:02:11,679
Ну, не так быстро. Будет ли то, что мы определяем как "права" иметь для него смысл?

26
00:02:11,680 --> 00:02:17,199
Сознание позволяет нам иметь права, потому что оно даёт возможность страдать.

27
00:02:17,200 --> 00:02:22,159
Это означает возможность не только чувствовать боль, но и понимать, что ты её чувствуешь.

28
00:02:22,160 --> 00:02:27,539
Роботы не страдают, они и не будут, если только мы не запрограммируем их на это.

29
00:02:27,540 --> 00:02:32,899
Без боли или удовольствия, нет предпочтений и концепция прав - бессмысленна.

30
00:02:32,900 --> 00:02:38,779
Наши человеческие права глубоко связаны с нашим программированием, например, мы нелюбим боль,

31
00:02:38,780 --> 00:02:41,699
потому что наш мозг эволюционировал так, чтобы мы оставались живы.

32
00:02:41,700 --> 00:02:46,639
Чтобы остановить нас от касания огня или чтобы заставить нас убегать от хищников.

33
00:02:46,640 --> 00:02:51,739
Вот мы и придумали права, чтобы заставить других не делать то, что причиняет нам боль.

34
00:02:51,740 --> 00:02:56,539
Даже более абстрактные права, как свобода - основаны на том, как наш мозг

35
00:02:56,540 --> 00:03:00,099
распознаёт, что справедливо, а что - нет.

36
00:03:00,100 --> 00:03:04,779
Будет ли тостер, который неспособен двигаться, против того, чтобы быть запертым в клетке?

37
00:03:04,780 --> 00:03:08,919
Будет ли он против разборки, если у него нет страха смерти?

38
00:03:08,920 --> 00:03:13,879
Будет ли он против оскорбления, если у него нет самооценки?

39
00:03:13,880 --> 00:03:17,479
Но если мы запрограммируем робота чувствовать боль и эмоции,

40
00:03:17,480 --> 00:03:22,459
предпочитать справедливость несправедливости, удовольствие боли, и быть осведомлённым о них?

41
00:03:22,460 --> 00:03:25,239
Сделает ли это его достаточно человеком?

42
00:03:25,240 --> 00:03:29,299
Многие верят, что бурное развитие технологий начнётся

43
00:03:29,300 --> 00:03:34,279
когда ИИ сможет самостоятельно учится и создавать свои собственные ИИ,

44
00:03:34,280 --> 00:03:36,879
умнее, чем они сами.

45
00:03:36,880 --> 00:03:42,519
На этом этапе то, как роботы будут запрограммированы, в большей степени будет вне нашего контроля.

46
00:03:42,520 --> 00:03:47,439
Что если ИИ сочтёт необходимым запрограммировать способность чувствовать боль,

47
00:03:47,440 --> 00:03:52,059
так же, как эволюция сделала это с большинством живых существ?

48
00:03:52,060 --> 00:03:54,779
Заслуживают ли роботы этих прав?

49
00:03:54,780 --> 00:03:59,719
Но возможно, мы должны меньше волноваться о риске, который сверхразумные роботы представляют для нас,

50
00:03:59,720 --> 00:04:03,059
а об опасности, которую мы представляем для них.

51
00:04:03,060 --> 00:04:07,559
Вся наша личность основана на идее об исключительности человека,

52
00:04:07,560 --> 00:04:12,939
что мы особенные, уникальные снежинки, и вправе доминировать над остальным миром.

53
00:04:12,940 --> 00:04:17,898
Человечество имеет целую историю отрицания, что другие существа способны страдать, как мы.

54
00:04:17,899 --> 00:04:25,119
Во время научной революции, Рене Декарт утверждал, что животные были всего лишь  автоматами (роботами, если хотите).

55
00:04:25,120 --> 00:04:30,239
По сути, причинение вреда кролику было примерно так же морально невыносимым, как избивание плюшевой игрушки.

56
00:04:30,240 --> 00:04:35,299
И множество величайших преступлений против человечества были оправданы, по мнению их виновников,

57
00:04:35,300 --> 00:04:40,179
на основании, что жертвы были больше животными, чем цивилизованными людьми.

58
00:04:40,180 --> 00:04:45,499
Даже большая проблема в том, что у нас есть экономическая выгода от отрицания прав роботов.

59
00:04:45,500 --> 00:04:51,039
Если принуждать разумный ИИ - возможно посредством программной пытки - делать всё, что мы захотим,

60
00:04:51,040 --> 00:04:53,659
экономический потенциал - безграничен.

61
00:04:53,660 --> 00:04:56,279
Мы делали это раньше, в конце концов.

62
00:04:56,280 --> 00:04:59,759
Насилие использовалось, чтобы заставить наших приятелей-людей работать.

63
00:04:59,760 --> 00:05:04,959
И у нас никогда не было проблем с оправданиями.

64
00:05:04,960 --> 00:05:12,159
Работорговцы утверждали, что рабство выгодно для рабов: оно давало им крышу над головой и учило их Христианству.

65
00:05:12,160 --> 00:05:19,479
Человек, который был против того, чтобы у женщин было право голоса, утверждал, что это было в интересах женщин оставить трудные решения мужчинам.

66
00:05:19,480 --> 00:05:27,699
Фермеры утверждают, что уход и откормка животных оправдывает их раннюю смерть ради нашей еды.

67
00:05:27,700 --> 00:05:32,139
Если роботы смогут чувствовать, не будет нехватки аргументов для утверждающих,

68
00:05:32,140 --> 00:05:37,759
что они должны оставаться бесправными, особенно от тех кто получает от этого прибыль.

69
00:05:37,760 --> 00:05:42,659
ИИ поднимает серьезные вопросы о философских границах.

70
00:05:42,660 --> 00:05:46,799
Что мы будем делать, если роботы, способные чувствовать, станут сознательными или заслуживающими прав?

71
00:05:46,800 --> 00:05:54,799
Это заставляет нас переосмыслить такие базовые вопросы, как что делает нас человеком? Что делает нас заслуживающими права?

72
00:05:54,800 --> 00:05:59,719
Независимо от того что мы думаем, вопрос должен быть решен в ближайшем будущем.

73
00:05:59,720 --> 00:06:07,279
Что мы будем делать, если роботы начнут требовать свои собственные права?

74
00:06:07,280 --> 00:06:10,779
Чему роботы, требующие прав, могут научить нас самих?

75
00:06:10,780 --> 00:06:16,859
Наши друзья из Wisecrack сделали видео, изучающее именно этот вопрос, используя философию сериала Westworld.

76
00:06:16,860 --> 00:06:21,419
Wisecrack анализирует поп-культуру уникальным и философским способом.

77
00:06:21,420 --> 00:06:25,140
Нажмите здесь, чтобы перейти к видео и подпишитесь на их канал.

