1
00:00:02,160 --> 00:00:07,259
食べたいトーストの種類を、あなたのトースターが予想する、そんな未来を想像してみよう。

2
00:00:07,260 --> 00:00:11,559
そのトースターは一日中、新しくて刺激的なトーストを求めてインターネットで探します。

3
00:00:11,560 --> 00:00:17,539
あなたの一日について尋ねたり、トースト技術の新しい進展について話したいと思うかもしれません。

4
00:00:17,540 --> 00:00:20,159
ではいったい、どのレベルになれば人間と同じになるのでしょうか？？

5
00:00:20,160 --> 00:00:24,239
そのトースターに感情があるかもしれないと感じ始めるのは、どんなタイミングでしょう？

6
00:00:24,240 --> 00:00:27,259
その場合、電源を切ってしまうことは殺すことになるのでしょうか？

7
00:00:27,260 --> 00:00:43,179
感情を持ってもあなたは所有を続けますか？
いずれ私たちは機械に権利を与えざる
を得なくなる日が来るのでしょうか？？

8
00:00:43,180 --> 00:00:45,599
人工知能はすでにあなたの身の回りにあります。

9
00:00:45,600 --> 00:00:48,379
人工知能はディスカウントショップが
十分な軽食をストックできるよう手配し、

10
00:00:48,380 --> 00:00:55,399
人工知能は個々に適したネット広告を提供するし、
あなたが読んだ記事の中には一から十まで機械によって書かれたものがあったかもしれません。

11
00:00:55,400 --> 00:01:01,179
今は私たちがSiriのようなチャットボットを見て
それが演じる人格が不完全なのを笑っている段階です。

12
00:01:01,180 --> 00:01:05,199
ですが、作られた人格と本物の人格の
境界が曖昧になった場合の

13
00:01:05,200 --> 00:01:08,719
対処が必要になることも十分に考えられます

14
00:01:08,720 --> 00:01:12,539
現時点で権利を与えるに値する機械はあるのでしょうか？

15
00:01:12,540 --> 00:01:18,459
おそらく、今のところはないでしょう。
しかしそれが存在したとすれば、
私たちの準備が足りていないのも事実です。

16
00:01:18,460 --> 00:01:23,859
哲学における権利の定義では人工知能に対処することはできません。

17
00:01:23,860 --> 00:01:29,859
人間または動物に権利があるという主張の多くは、
意識の有無を前提としています。

18
00:01:29,860 --> 00:01:33,159
しかし残念ながら、意識とは何かを知る人はどこにもいません。

19
00:01:33,160 --> 00:01:39,099
ある人はそれが物質的なものではないと考えていますし、
またある人は気体や液体のような物質的なものだと主張しています。

20
00:01:39,100 --> 00:01:45,899
正確な定義がなんであれ、私たちは意識について直感的に知っています。意識を持つという経験がありますから。

21
00:01:45,900 --> 00:01:51,759
私たちは自分自身とその周りについてを認識しているし、
意識がない状態がどんな感じかも知っています。

22
00:01:51,760 --> 00:01:57,499
一部の神経科学者は、高度なシステムであれば
意識をつくることができると考えています。

23
00:01:57,500 --> 00:02:02,879
そう考えたとすれば、もしもあなたのトースターのハードウェアが十分強力だったなら、自我を持つかもしれません

24
00:02:02,880 --> 00:02:05,779
そのとき、そのトースターに権を与える必要があるのでしょうか？

25
00:02:05,780 --> 00:02:11,679
少し結論を急ぎすぎましたね。
ではこの問題を考えるときに、権利をどのように考えたらよいのでしょう？

26
00:02:11,680 --> 00:02:17,199
意識を持つものに権利は与えられます。
なぜなら意識を持つものは、苦しむ能力がもつからです

27
00:02:17,200 --> 00:02:22,159
これは苦痛を感じる能力だけでなく、その苦痛を認識できることも含みます

28
00:02:22,160 --> 00:02:27,539
ロボットは苦しむことはないし、
我々がそうプログラムしない限りはずっとそうでしょう

29
00:02:27,540 --> 00:02:32,899
痛みや喜びがなければ、好みもなく、権利は必要ありません

30
00:02:32,900 --> 00:02:38,779
人権は、私たちのからだのプログラムに深く関係しています
たとえば私たちは痛みを嫌います

31
00:02:38,780 --> 00:02:41,699
それは、私たちが熱い火に触れないように、
また捕食者から逃げるように

32
00:02:41,700 --> 00:02:46,639
脳が私たちを生きながらえさせるよう進化したからです

33
00:02:46,640 --> 00:02:51,739
だから私たちは苦痛をもたらすものから自分を守るために、
「権利」を掲げるようになったのです。

34
00:02:51,740 --> 00:02:56,539
自由権のようなさらに抽象的な権利も、
何が公平で何が不公平かを

35
00:02:56,540 --> 00:03:00,099
感じ取る仕組みを脳が持っているから存在するのです。

36
00:03:00,100 --> 00:03:04,779
そもそも移動することが出来ないトースターが、
檻に閉じ込められていることが嫌だと感じるでしょうか？

37
00:03:04,780 --> 00:03:08,919
死への恐怖が無いとすれば、
分解されることを気にするでしょうか？

38
00:03:08,920 --> 00:03:13,879
自尊心が無いとすれば、
侮辱を受けても気にするでしょうか？

39
00:03:13,880 --> 00:03:17,479
しかし一方で、痛みや感情を感じるようにロボットを
プログラムした場合はどうなるでしょう？

40
00:03:17,480 --> 00:03:22,459
不正よりも正義を好むように、苦痛よりも喜びを好むよう、そしてそれを意識するようにプログラムしたら？

41
00:03:22,460 --> 00:03:25,239
これは彼らを十分に人間たらしめるでしょうか？

42
00:03:25,240 --> 00:03:29,299
多くの技術者は、人工知能が新しい人工知能について

43
00:03:29,300 --> 00:03:34,279
学習し、自身よりも優秀な人工知能を創造できるようになったとき、

44
00:03:34,280 --> 00:03:36,879
技術の爆発が起こるだろうと信じています

45
00:03:36,880 --> 00:03:42,519
この時点で、ロボットがどのようにプログラムされて
いるかは、ほとんど人間の手に負えないでしょう

46
00:03:42,520 --> 00:03:47,439
痛みを感じる能力はほぼすべての生物にとって必要だと進化生物学が明らかにしたことと同じように、

47
00:03:47,440 --> 00:03:52,059
痛みをプログラムする必要性を
人工知能が見出したとしたら？

48
00:03:52,060 --> 00:03:54,779
ロボットは権利をもつに値するでしょうか？

49
00:03:54,780 --> 00:03:59,719
ですが今は極めて賢いロボットが私たちに
もたらすリスクについてはあまり心配せず

50
00:03:59,720 --> 00:04:03,059
私たちが彼らにもたらすリスクを心配すべきなのかもしれません

51
00:04:03,060 --> 00:04:07,559
人類のアイデンティティは、
私たちは特別にユニークな雪の結晶であり、

52
00:04:07,560 --> 00:04:12,939
自然界を統べる権利をもつ例外であるという考えに基づいています

53
00:04:12,940 --> 00:04:17,898
歴史的に人類は、他の存在が人類同様に苦痛を
感じられることを否定してきました。

54
00:04:17,899 --> 00:04:25,119
科学革命の真っ只中の時期に、ルネ・デカルトは、動物が
単なる機械人形（ロボットと呼びたければどうぞ）であると主張しました

55
00:04:25,120 --> 00:04:30,239
ウサギを傷つけることの非道徳性はぬいぐるみをパンチすることと同レベルというわけです。

56
00:04:30,240 --> 00:04:35,299
そして人類に対する最大級の罪の多くは
加害者が、

57
00:04:35,300 --> 00:04:40,179
「被害者は文明化された人類ではなく
動物に近い」として正当化されてきました

58
00:04:40,180 --> 00:04:45,499
さらに問題なのは、我々がロボットの権利を
否定することで、経済的にメリットがあることです。

59
00:04:45,500 --> 00:04:51,039
意識を持つ人工知能に我々への奉仕を強制出来るとしたら(苦痛をプログラムすることによるかもしれない）

60
00:04:51,040 --> 00:04:53,659
利益を生み出す可能性は大きいでしょう

61
00:04:53,660 --> 00:04:56,279
それは我々が過去にもやったことでもあります。

62
00:04:56,280 --> 00:04:59,759
人々に労働を強制するために暴力が用いられました

63
00:04:59,760 --> 00:05:04,959
そして正当化に苦労したこともなかったのです
＜フキダシ＞神は金が必要だとおっしゃっている

64
00:05:04,960 --> 00:05:12,159
奴隷の主たちは奴隷制度は奴隷にも
益があると主張しました。彼らは屋根の下に住めるし
キリスト教を教えてもらえるのだと。

65
00:05:12,160 --> 00:05:19,479
女性の投票権に反対していた男たちは、女性は本当は
難しい判断を男に任せたのだろうと主張しました。

66
00:05:19,480 --> 00:05:27,699
農家は、人の食の好みで動物を若いうちに殺しますが、
餌を与え、面倒を見ることで正当化できると主張しています

67
00:05:27,700 --> 00:05:32,139
ロボットが自我を持った場合、彼らは権利を持たない
ままでいるべきだという主張には事欠かないでしょう

68
00:05:32,140 --> 00:05:37,759
そのことで利益を得る人からは特に

69
00:05:37,760 --> 00:05:42,659
人工知能は、哲学の境界に対して
重大な問題を提起しています

70
00:05:42,660 --> 00:05:46,799
感覚を持つロボットに自我はあるのか、
また権利を持つに値するのか

71
00:05:46,800 --> 00:05:54,799
また、「私たちは何をもって人間なのか？」
「私たちは何を根拠に権利を有しているのか？」
という根源的な問いを投げかけてきます

72
00:05:54,800 --> 00:05:59,719
私たちがどのように考えるかにかかわらず、この質問を近い将来に解決する必要があるかもしれません

73
00:05:59,720 --> 00:06:07,279
ロボットが自分の権利を要求し始めたらどうしますか？

74
00:06:07,280 --> 00:06:10,779
ロボットが権利要求してくることで、
私たちは何に気づかされるのでしょうか？

75
00:06:10,780 --> 00:06:16,859
Wisecrackに務める我々の友人は西洋哲学を駆使して、この疑問を追求する動画を作りました

76
00:06:16,860 --> 00:06:21,419
Wisecrackはポップカルチャーを
ユニークかつ哲学的な方法で解剖します。

77
00:06:21,420 --> 00:06:25,140
ここをクリックすれば彼らの動画を見て、
チャンネル登録をすることができます

