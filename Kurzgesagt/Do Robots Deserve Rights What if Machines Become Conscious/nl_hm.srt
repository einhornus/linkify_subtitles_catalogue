1
00:00:00,000 --> 00:00:04,048
Stel je een toekomst voor waarin je broodrooster

2
00:00:04,049 --> 00:00:06,419
voorspelt wat voor 'n soort toast je wilt

3
00:00:06,420 --> 00:00:08,129
In de loop van de dag

4
00:00:08,130 --> 00:00:09,659
speurt hij het internet af op zoek naar nieuwe en

5
00:00:09,660 --> 00:00:12,479
interessante types toast, misschien vraagt

6
00:00:12,480 --> 00:00:14,189
hij je hoe je dag was en wil hij graag babbelen

7
00:00:14,190 --> 00:00:15,899
over nieuwe ontwikkelingen in toast

8
00:00:15,900 --> 00:00:18,538
technologie. Wanneer word het een

9
00:00:18,539 --> 00:00:21,389
een persoon en wanneer vraag je je af

10
00:00:21,390 --> 00:00:24,299
of je toaster gevoelens heeft? Als

11
00:00:24,300 --> 00:00:26,969
hij gevoelens zou  hebben, zou de stekker eruit trekken moord zijn?

12
00:00:26,970 --> 00:00:29,848
En zou jij de toaster nog bezitten? Zullen we

13
00:00:29,849 --> 00:00:31,919
ooit gedwongen worden onze apparaten

14
00:00:31,920 --> 00:00:43,139
rechten te geven?

15
00:00:43,140 --> 00:00:45,559
Kunstmatige intelligentie is al overal.

16
00:00:45,560 --> 00:00:47,959
Het zorgt ervoor dat er genoeg snacks beschikbaar zijn in winkels.

17
00:00:47,960 --> 00:00:50,199
Het geeft je de juiste reclame op het internet

18
00:00:50,200 --> 00:00:51,839
en misschien heb je zelfs een

19
00:00:51,840 --> 00:00:54,639
nieuwsartikel gelezen die geschreven is door een robot

20
00:00:54,640 --> 00:00:57,569
Nu kijken we naar chatbots zoals Siri

21
00:00:57,570 --> 00:00:59,698
en lachen we om hun primitieve gesimuleerde

22
00:00:59,699 --> 00:01:02,339
emoties, maar het is waarschijnlijk dat we

23
00:01:02,340 --> 00:01:04,018
in de toekomst moeten omgaan met wezens die het

24
00:01:04,019 --> 00:01:06,209
lastig maken een grens te trekken tussen echte en

25
00:01:06,210 --> 00:01:08,039
gesimuleerde menselijkheid

26
00:01:08,040 --> 00:01:10,829
zijn er machines die

27
00:01:10,830 --> 00:01:11,959
rechten verdienen?

28
00:01:11,960 --> 00:01:15,919
Hoogst waarschijnlijk nog niet, maar als ze komen

29
00:01:15,920 --> 00:01:18,959
zijn we er nog niet op voorbereid. Veel van de

30
00:01:18,960 --> 00:01:20,908
rechtsfilosofie beschikt niet over de juiste middelen om

31
00:01:20,909 --> 00:01:22,529
een uitspraak te kunnen doen over kunstmatige

32
00:01:22,530 --> 00:01:25,228
intelligentie. De meeste onderbouwingen voor

33
00:01:25,229 --> 00:01:27,239
mensen- of dierenrechten  zijn gecentreerd rond

34
00:01:27,240 --> 00:01:29,519
de vraag van bewustzijn.

35
00:01:29,520 --> 00:01:31,499
Jammer genoeg kan nog niemand

36
00:01:31,500 --> 00:01:33,859
'bewustzijn' definiëren. Sommige denken dat

37
00:01:33,860 --> 00:01:36,079
het immaterieel is, andere zeggen dat het een

38
00:01:36,080 --> 00:01:38,749
massa heeft, zoals gas of vloeistof.

39
00:01:38,750 --> 00:01:41,389
Ondank het ontbreken van een definitie hebben we

40
00:01:41,390 --> 00:01:42,979
intuïtieve kennis

41
00:01:42,980 --> 00:01:45,879
wat 'het bewustzijn' is, omdat we het ervaren.

42
00:01:45,880 --> 00:01:47,379
We zijn bewust van onzelf en

43
00:01:47,380 --> 00:01:48,999
onze omgeving and weten hoe

44
00:01:49,000 --> 00:01:51,819
bewusteloosheid voelt.

45
00:01:51,820 --> 00:01:55,419
Sommige neurowetenschappers geloven dat elk voldoende geavanceerd systeem

46
00:01:55,420 --> 00:01:57,259
bewustzijn kan opwekken.

47
00:01:57,260 --> 00:02:00,319
Dus als je toasters hardware sterk genoeg is,

48
00:02:00,320 --> 00:02:02,719
kan hij misschien bewust worden van zichzelf,

49
00:02:02,720 --> 00:02:05,919
en als het dat doet, zou hij rechten verdienen?

50
00:02:05,920 --> 00:02:07,059
Nou, niet zo snel!

51
00:02:07,060 --> 00:02:09,418
Is wat wij als 'rechten' zien,

52
00:02:09,419 --> 00:02:11,499
wel logisch voor ze?

53
00:02:11,500 --> 00:02:14,279
Zelfbewust zijn zorgt voor wezens hun rechten,

54
00:02:14,280 --> 00:02:17,139
omdat het een wezen het vermogen geeft om te kunnen lijden.

55
00:02:17,140 --> 00:02:21,399
Het betekent niet alleen dat hij pijn kan voelen, maar ook dat hij er bewust van is.

56
00:02:21,400 --> 00:02:23,539
Robots lijden niet

57
00:02:23,540 --> 00:02:27,279
en dat zal ook niet gebeuren, tenzij we ze zo programmeren.

58
00:02:27,280 --> 00:02:29,359
Zonder pijn of plezier

59
00:02:29,360 --> 00:02:32,719
is er geen voorkeur en daardoor worden rechten nutteloos.

60
00:02:32,720 --> 00:02:37,179
Onze mensenrechten zijn sterk verbonden met onze eigen programmering.

61
00:02:37,180 --> 00:02:41,219
Bijvoorbeeld: we houden niet van pijn, omdat ons brein is geëvolueerd om ons in leven te houden.

62
00:02:41,220 --> 00:02:43,859
Om ons te weerhouden een heet vuur aan te raken

63
00:02:43,860 --> 00:02:46,239
of om ons te dwingen te vluchten voor roofdieren.

64
00:02:46,240 --> 00:02:51,399
Daarom hebben wij rechten ontwikkeld om ons beschermen tegen  inbreuken die ons pijn bezorgen.

65
00:02:51,400 --> 00:02:58,879
Zelfs meer abstracte rechten, zoals 'Vrijheid', zijn ingeprent in ons brein om te beoordelen wat wel en niet eerlijk is.

66
00:02:58,880 --> 00:03:01,839
Zou een broodrooster die niet kan bewegen,

67
00:03:01,840 --> 00:03:04,319
het erg vinden dat hij in een kooi gevangen zit?

68
00:03:04,320 --> 00:03:08,159
Vindt hij het erg als hij uit elkaar gehaald wordt, als hij geen angst voor de dood heeft?

69
00:03:08,160 --> 00:03:13,479
Vindt hij het erg om beledigd te worden als het geen zelfvertrouwen nodig heeft?

70
00:03:13,480 --> 00:03:17,239
Maar wat als wij een robot programmeren die pijn en gevoelens heeft?

71
00:03:17,240 --> 00:03:19,759
Dat het rechtvaardigheid boven onrechtvaardigheid kiest;

72
00:03:19,760 --> 00:03:22,419
plezier boven pijn en zich hier bewust van is?

73
00:03:22,420 --> 00:03:25,079
Zou dat menselijk genoeg zijn?

74
00:03:25,080 --> 00:03:27,979
Veel technologen geloven dat er een explosie van technologie

75
00:03:27,980 --> 00:03:28,859
zal plaatsvinden

76
00:03:28,860 --> 00:03:30,979
wanneer Artificial Intellegence (AI) kan leren

77
00:03:30,980 --> 00:03:36,639
en hun eigen Artificial Intellegence (AI) kan maken, die nog slimmer is dan zij.

78
00:03:36,640 --> 00:03:39,459
Vanaf dat punt zal de vraag hoe robots zijn geprogrammeerd

79
00:03:39,460 --> 00:03:42,459
voor een groot deel uit de onze controle zijn.

80
00:03:42,460 --> 00:03:44,319
Wat als een Artificial Intellegence (AI)

81
00:03:44,320 --> 00:03:47,179
het nodig zou vinden om de vaardigheid van pijn te programmeren,

82
00:03:47,180 --> 00:03:51,799
net zoals evolutionaire biologie het nodig vond in de meeste levende wezens,

83
00:03:51,800 --> 00:03:55,419
verdienen robots dan rechten?

84
00:03:55,420 --> 00:03:59,699
Maar misschien moeten we minder bezorgd zijn over de risico's die super intelligente robots ons voorleggen,

85
00:03:59,700 --> 00:04:03,219
en meer bezorgd zijn over de gevaren die wij hen voorleggen.

86
00:04:03,220 --> 00:04:07,319
Onze hele menselijke identiteit is gebaseerd op menselijke exceptionaliteit.

87
00:04:07,320 --> 00:04:09,499
Dat wij speciaal, uniek en bijzonder zijn,

88
00:04:09,500 --> 00:04:12,759
voorbestemd om de hele natuurlijke wereld te domineren.

89
00:04:12,760 --> 00:04:17,578
Mensen hebben een geschiedenis van ontkennen dat andere wezens net zo kunnen lijden als zij.

90
00:04:17,579 --> 00:04:21,319
in het midden van de wetenschappelijke revolutie, beweerde René Descartes dat

91
00:04:21,320 --> 00:04:24,679
dieren een soort van automatische robots waren.

92
00:04:24,680 --> 00:04:29,799
Dus het verwonden van een konijn was net zo niet erg als het slaan van een knuffel.

93
00:04:29,800 --> 00:04:34,979
En veel van de grootste misdaden tegen de menselijkheid zijn begaan door daders

94
00:04:34,980 --> 00:04:39,779
die hun slachtoffers meer als dier dan als beschaafd mens zagen.

95
00:04:39,780 --> 00:04:45,359
Wat nog problematischer is, is dat we een economisch belang hebben bij het ontkennen van robot-rechten.

96
00:04:45,360 --> 00:04:48,999
Als we een bewuste AI-misschien door middel van geprogrammeerde marteling kunnen dwingen

97
00:04:49,000 --> 00:04:51,159
om te doen wat wij willen,

98
00:04:51,160 --> 00:04:53,659
zijn de economische mogelijkheden oneindig.

99
00:04:53,660 --> 00:04:56,179
We hebben het immers al eerder gedaan.

100
00:04:56,180 --> 00:04:59,639
Geweld is gebruikt om onze medemens te dwingen te werken.

101
00:04:59,640 --> 00:05:04,559
En we hebben nooit problemen gehad met het verzinnen van ideologische verantwoordingen.

102
00:05:04,560 --> 00:05:08,619
Slavenbezitters beweerde dat slavernij de slaven bevoordeelde.

103
00:05:08,620 --> 00:05:11,959
Ze gaven ze een dak boven hun hoofd en leerde hen over het christendom.

104
00:05:11,960 --> 00:05:19,039
Mannen, die tegen vrouwenstemrecht waren, beweerde dat vrouwen zelf de moeilijke keuzes aan mannen wilden overlaten.

105
00:05:19,040 --> 00:05:27,299
Boeren beweerde dat op de dieren letten en ze voeden hun vroege dood voor onze dieetvoorkeuren  rechtvaardigt.

106
00:05:27,300 --> 00:05:32,079
Als robots dingen gaan voelen, zal er geen tekort zijn aan argumenten voor degenen die zeggen dat

107
00:05:32,080 --> 00:05:37,579
zij zonder rechten moeten blijven, vooral voor degenen die hier profijt van hebben.

108
00:05:37,580 --> 00:05:42,399
Artificial Intellegence (AI) zorgt voor serieuze vragen over filosofische barrières.

109
00:05:42,400 --> 00:05:46,959
We kunnen ons afvragen of robots met gevoelens bewust zijn, of dat ze rechten verdienen.

110
00:05:46,960 --> 00:05:50,999
Het forceert ons om simpele vragen te stellen zoals: wat maakt ons menselijk?

111
00:05:51,000 --> 00:05:54,419
Wat maakt dat wij onze rechten verdienen?

112
00:05:54,420 --> 00:05:59,079
ongeacht van wat we vinden, de vraag moet misschien opgelost worden in de nabije toekomst.

113
00:05:59,080 --> 00:06:06,739
Wat gaan we doen als robots hun eigen rechten beginnen te eisen?

114
00:06:06,740 --> 00:06:10,619
Wat kan robots die rechten eisen ons leren over onszelf?

115
00:06:10,620 --> 00:06:14,319
Onze vrienden van Wisecrack hebben een video over deze specifieke vraag gemaakt

116
00:06:14,320 --> 00:06:16,439
en daarbij hebben ze gebruik gemaakt van de filosofie van Westworld.

117
00:06:16,440 --> 00:06:21,179
Wisecrack ontleedt popcultuur op een unieke en filosofische manier.

118
00:06:21,180 --> 00:06:24,720
Klik hier om hun video te bekijken en om te abonneren op hun kanaal!

