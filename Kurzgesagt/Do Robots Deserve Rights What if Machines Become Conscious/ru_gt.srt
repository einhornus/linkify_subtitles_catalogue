1
00:00:02,160 --> 00:00:07,259
Представьте себе будущее, в котором ваш тостер предугадывает, какой тост вы хотите.

2
00:00:07,260 --> 00:00:11,559
В течение дня он сканирует Интернет в поисках новых интересных видов тостов.

3
00:00:11,560 --> 00:00:17,539
Может быть, он спрашивает, как прошел ваш день, и хочет поговорить о новых достижениях в технологии тостов.

4
00:00:17,540 --> 00:00:20,159
На каком уровне он стал бы личностью?

5
00:00:20,160 --> 00:00:24,239
В какой момент вы спросите себя, есть ли у вашего тостера чувства?

6
00:00:24,240 --> 00:00:27,259
Если бы это было так, было бы его отключение убийством?

7
00:00:27,260 --> 00:00:43,179
И вы бы по-прежнему владели им?
Нас когда-нибудь заставят дать права нашим машинам?

8
00:00:43,180 --> 00:00:45,599
ИИ уже вокруг вас.

9
00:00:45,600 --> 00:00:48,379
Он следит за тем, чтобы дискаунтеры были снабжены достаточным количеством закусок,

10
00:00:48,380 --> 00:00:55,399
он предлагает вам только нужную интернет-рекламу, и вы, возможно, даже читали новый рассказ, полностью написанный машиной.

11
00:00:55,400 --> 00:01:01,179
Прямо сейчас мы смотрим на чат-ботов, таких как Siri, и смеемся над их примитивными симулированными эмоциями,

12
00:01:01,180 --> 00:01:05,199
но вполне вероятно, что нам придется иметь дело с существами, из-за которых трудно провести грань

13
00:01:05,200 --> 00:01:08,719
между реальным и симулированным человечеством.

14
00:01:08,720 --> 00:01:12,539
Существуют ли какие-либо машины, которые заслуживают прав?

15
00:01:12,540 --> 00:01:18,459
Скорее всего, еще нет.
Но если они придут, мы к этому не готовы.

16
00:01:18,460 --> 00:01:23,859
Большая часть философии прав плохо приспособлена для работы с искусственным интеллектом.

17
00:01:23,860 --> 00:01:29,859
Большинство притязаний на право человека или животного сосредоточено вокруг вопроса о сознании.

18
00:01:29,860 --> 00:01:33,159
К сожалению, никто не знает, что такое сознание.

19
00:01:33,160 --> 00:01:39,099
Некоторые думают, что это нематериально, другие говорят, что это состояние материи, подобное газу или жидкости.

20
00:01:39,100 --> 00:01:45,899
Независимо от точного определения, у нас есть интуитивное знание сознания, потому что мы переживаем его.

21
00:01:45,900 --> 00:01:51,759
Мы осознаем себя и свое окружение и знаем, что такое бессознательное.

22
00:01:51,760 --> 00:01:57,499
Некоторые нейробиологи считают, что любая достаточно продвинутая система может генерировать сознание.

23
00:01:57,500 --> 00:02:02,879
Итак, если аппаратное обеспечение вашего тостера достаточно мощное, оно может стать самоосознающим.

24
00:02:02,880 --> 00:02:05,779
Если это так, будет ли это заслуживает прав?

25
00:02:05,780 --> 00:02:11,679
Ну не так быстро.
Будет ли смысл в том, что мы определяем как «права»?

26
00:02:11,680 --> 00:02:17,199
Сознание наделяет существа правами, потому что оно дает существом возможность страдать.

27
00:02:17,200 --> 00:02:22,159
Это означает способность не только чувствовать боль, но и осознавать ее.

28
00:02:22,160 --> 00:02:27,539
Роботы не страдают и, вероятно, не будут, если мы не запрограммируем их на это.

29
00:02:27,540 --> 00:02:32,899
Без боли и удовольствия нет предпочтений, а права бессмысленны.

30
00:02:32,900 --> 00:02:38,779
Наши права человека тесно связаны с нашим собственным программированием, например, мы не любим боль,

31
00:02:38,780 --> 00:02:41,699
потому что наш мозг эволюционировал, чтобы поддерживать нашу жизнь.

32
00:02:41,700 --> 00:02:46,639
Чтобы помешать нам прикоснуться к горячему огню или заставить нас убегать от хищников.

33
00:02:46,640 --> 00:02:51,739
Вот мы и придумали права, которые защищают нас от нарушений, причиняющих нам боль.

34
00:02:51,740 --> 00:02:56,539
Даже более абстрактные права, такие как свобода, основаны на том, как наш мозг устроен,

35
00:02:56,540 --> 00:03:00,099
чтобы определять, что справедливо, а что несправедливо.

36
00:03:00,100 --> 00:03:04,779
Будет ли тостер, который не может двигаться, возражать против того, чтобы его заперли в клетке?

37
00:03:04,780 --> 00:03:08,919
Было бы оно против того, чтобы его разобрали, если бы оно не боялось смерти?

38
00:03:08,920 --> 00:03:13,879
Было бы оно против того, чтобы его оскорбляли, если бы оно не нуждалось в самоуважении?

39
00:03:13,880 --> 00:03:17,479
Но что, если мы запрограммируем робота чувствовать боль и эмоции?

40
00:03:17,480 --> 00:03:22,459
Предпочесть справедливость несправедливости, удовольствие боли и осознавать это?

41
00:03:22,460 --> 00:03:25,239
Сделает ли это их достаточно человечными?

42
00:03:25,240 --> 00:03:29,299
Многие технологи считают, что произойдёт взрыв технологий,

43
00:03:29,300 --> 00:03:34,279
когда Искусственный Интеллект сможет обучаться и создавать собственные Искусственные Интеллекты,

44
00:03:34,280 --> 00:03:36,879
даже более умные, чем они сами.

45
00:03:36,880 --> 00:03:42,519
На данный момент вопрос о том, как запрограммированы наши роботы, будет в значительной степени вне нашего контроля.

46
00:03:42,520 --> 00:03:47,439
Что, если искусственный интеллект сочтет необходимым запрограммировать способность чувствовать боль,

47
00:03:47,440 --> 00:03:52,059
точно так же, как эволюционная биология сочла это необходимым для большинства живых существ?

48
00:03:52,060 --> 00:03:54,779
Заслуживают ли роботы этих прав?

49
00:03:54,780 --> 00:03:59,719
Но, возможно, нам следует меньше беспокоиться о риске, который представляют для нас сверхразумные роботы,

50
00:03:59,720 --> 00:04:03,059
и больше беспокоиться об опасности, которую мы представляем для них.

51
00:04:03,060 --> 00:04:07,559
Вся наша человеческая идентичность основана на идее человеческой исключительности,

52
00:04:07,560 --> 00:04:12,939
что мы особые уникальные снежинки, имеющие право господствовать над миром природы.

53
00:04:12,940 --> 00:04:17,898
У людей есть история отрицания того, что другие существа способны страдать так же, как они.

54
00:04:17,899 --> 00:04:25,119
В разгар научной революции Рене Декарт утверждал, что животные были просто автоматами — роботами, если хотите.

55
00:04:25,120 --> 00:04:30,239
Таким образом, ранить кролика было примерно так же отвратительно с моральной точки зрения, как ударить мягкую игрушку.

56
00:04:30,240 --> 00:04:35,299
И многие из величайших преступлений против человечества оправдывались их виновниками

57
00:04:35,300 --> 00:04:40,179
на том основании, что жертвами были скорее животные, чем цивилизованные люди.

58
00:04:40,180 --> 00:04:45,499
Еще более проблематичным является то, что у нас есть экономический интерес в отказе от прав роботов.

59
00:04:45,500 --> 00:04:51,039
Если можно заставить разумный ИИ — возможно, с помощью запрограммированных пыток — делать то, что нам нравится

60
00:04:51,040 --> 00:04:53,659
, экономический потенциал неограничен.

61
00:04:53,660 --> 00:04:56,279
В конце концов, мы делали это раньше.

62
00:04:56,280 --> 00:04:59,759
Насилие использовалось, чтобы заставить наших собратьев работать.

63
00:04:59,760 --> 00:05:04,959
И у нас никогда не было проблем с идеологическими оправданиями.

64
00:05:04,960 --> 00:05:12,159
Рабовладельцы утверждали, что рабство идет на пользу рабам: дает им крышу над головой и учит их христианству.

65
00:05:12,160 --> 00:05:19,479
Мужчины, которые были против голосования женщин, утверждали, что в интересах женщин оставить принятие трудных решений мужчинам.

66
00:05:19,480 --> 00:05:27,699
Фермеры утверждают, что уход за животными и их кормление оправдывают их раннюю смерть нашими диетическими предпочтениями.

67
00:05:27,700 --> 00:05:32,139
Если роботы станут разумными, не будет недостатка в аргументах у тех, кто говорит,

68
00:05:32,140 --> 00:05:37,759
что они должны оставаться бесправными, особенно у тех, кто на этом наживается.

69
00:05:37,760 --> 00:05:42,659
Искусственный интеллект поднимает серьезные вопросы о философских границах.

70
00:05:42,660 --> 00:05:46,799
Что мы можем спросить, если разумные роботы сознательны или заслуживают прав,

71
00:05:46,800 --> 00:05:54,799
это заставляет нас ставить основные вопросы, например, что делает нас людьми?  Что делает нас достойными прав?

72
00:05:54,800 --> 00:05:59,719
Независимо от того, что мы думаем, этот вопрос, возможно, придется решить в ближайшем будущем.

73
00:05:59,720 --> 00:06:07,279
Что мы будем делать, если роботы начнут требовать свои права?

74
00:06:07,280 --> 00:06:10,779
Что роботы, требующие прав, могут рассказать нам о нас самих?

75
00:06:10,780 --> 00:06:16,859
Наши друзья из Wisecrack сняли видео, в котором исследуют этот вопрос, используя философию Westworld.

76
00:06:16,860 --> 00:06:21,419
Wisecrack анализирует поп-культуру уникальным и философским способом.

77
00:06:21,420 --> 00:06:25,140
Нажмите здесь, чтобы посмотреть видео и подписаться на их канал.

