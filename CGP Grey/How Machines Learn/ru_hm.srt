1
00:00:00,020 --> 00:00:03,019
В интернете алгоритмы повсюду вокруг нас.

2
00:00:03,020 --> 00:00:07,319
Вы смотрите это видео, потому что алгоритм предложил вам кликнуть на него (среди других видео).

3
00:00:07,320 --> 00:00:10,159
Вы кликнули, и алгоритм это отметил.

4
00:00:10,160 --> 00:00:13,659
Когда вы открываете TweetBook, алгоритм решает какую информацию вы увидите.

5
00:00:13,660 --> 00:00:16,959
Когда вы ищете свои фото, алгоритм делает поиски.

6
00:00:16,960 --> 00:00:18,959
Возможно даже создает небольшой видеоролик для вас.

7
00:00:18,960 --> 00:00:21,799
Когда вы что-то покупаете, алгоритм устанавливает цену.

8
00:00:21,800 --> 00:00:25,999
И в вашем банке тоже есть алгоритм, который следит чтобы транзакции были законны.

9
00:00:26,000 --> 00:00:28,179
На бирже акций алгоритмы повсюду

10
00:00:28,180 --> 00:00:29,739
и они торгуют с другими алгоритмами.

11
00:00:29,740 --> 00:00:34,239
Зная всё это, вы, возможно, захотите узнать, как все эти столь важные маленькие алгоритмические роботы работают -

12
00:00:34,240 --> 00:00:36,039
особенно когда они не работают.

13
00:00:36,040 --> 00:00:37,079
В былые времена,

14
00:00:37,080 --> 00:00:41,899
люди создавали алгоритмических ботов, давая им точные инструкции, которые люди могли объяснить.

15
00:00:41,900 --> 00:00:43,799
"При условии А, сделай Б"

16
00:00:43,800 --> 00:00:49,079
Однако, многие проблемы слишком сложны, и их нельзя описать набором простых инструкций понятных человеку.

17
00:00:49,080 --> 00:00:53,559
Каждую секунду происходят триллионы финансовых транзакций - какие из них нелегальны?

18
00:00:53,560 --> 00:00:55,979
На NetMeTube триллионы видеороликов.

19
00:00:55,980 --> 00:01:01,679
Как выбрать из них восемь роликов, которые пользователь увидит в рекоммендациях? Что не пускать на сайт совсем?

20
00:01:01,680 --> 00:01:06,219
Для определённого места в самолёте, какую максимальную цену пользователь готов заплатить прямо сейчас?

21
00:01:06,220 --> 00:01:08,499
Боты алгоритмы дают ответы на все эти вопросы.

22
00:01:08,500 --> 00:01:11,919
Не идеальные ответы, но они намного лучше тех, что люди могли бы найти вручную.

23
00:01:11,920 --> 00:01:15,859
Но как именно эти боты работают, никто не знает.

24
00:01:15,860 --> 00:01:17,919
Даже те, кто их создал.

25
00:01:17,920 --> 00:01:18,879
Точнее, "создал",

26
00:01:18,880 --> 00:01:19,859
как мы увидим...

27
00:01:19,860 --> 00:01:23,419
Компании, которые используют этих ботов, не любят рассказывать о том, как они работают,

28
00:01:23,420 --> 00:01:25,819
потому что боты – ценные сотрудники.

29
00:01:25,820 --> 00:01:27,299
Очень, ОЧЕНЬ ценные.

30
00:01:27,300 --> 00:01:30,699
И как именно построен их мозг – очень тщательно охраняемый секрет.

31
00:01:30,700 --> 00:01:32,999
Сейчас всё крутится вокруг

32
00:01:33,000 --> 00:01:34,639
"Я надеюсь тебе нравится линейная алгебра",

33
00:01:34,640 --> 00:01:37,339
но как именно устроены боты на конкретном сайте

34
00:01:37,340 --> 00:01:41,299
и как они работают – не совсем понятно и так будет всегда.

35
00:01:41,300 --> 00:01:45,599
Так что давайте поговорим об одном из наиболее причудливых, но понятных способов "построить" бота,

36
00:01:45,600 --> 00:01:48,319
не зная как именно в итоге его мозги будут работать.

37
00:01:48,320 --> 00:01:51,239
Допустим, вы хотите бота, который может распознать, что изображено на картинке.

38
00:01:51,240 --> 00:01:53,219
Пчела, или цифра три?

39
00:01:53,220 --> 00:01:55,759
Это легко для людей (даже маленьких людей),

40
00:01:55,760 --> 00:01:59,819
но невозможно дать боту набор инструкций как именно это сделать,

41
00:01:59,820 --> 00:02:03,679
потому что мы просто "знаем", как выглядит пчела, а как цифра три.

42
00:02:03,680 --> 00:02:07,099
Мы могли бы описать словами, в чем ключевые отличия, но боты не понимают слов.

43
00:02:07,100 --> 00:02:10,978
И, в любом случае, это проводка в нашей голове позволяют нам сделать это.

44
00:02:10,979 --> 00:02:16,799
В то время как функционирование одного нейрона мы можем объяснить,

45
00:02:16,800 --> 00:02:18,459
то, как они работают все вместе, за гранью нашего понимания.

46
00:02:18,460 --> 00:02:20,019
Тем не менее, это работает.

47
00:02:20,020 --> 00:02:22,119
Так что чтобы получить бота, который сможет провести распознавание,

48
00:02:22,120 --> 00:02:23,419
мы не будем создавать его сами.

49
00:02:23,420 --> 00:02:27,199
Мы построим бота, который строит ботов, и бота, который учит ботов!

50
00:02:27,200 --> 00:02:31,679
Их мозги простые, и инструкции для них может написать обычный человек-программист.

51
00:02:31,680 --> 00:02:35,139
Бот-строитель строит ботов, но он не очень-то хорош в этом деле.

52
00:02:35,140 --> 00:02:39,359
Сначала он соединяет провода модули в мозге ботов в случайном порядке.

53
00:02:39,360 --> 00:02:41,479
Это приводит к очень...

54
00:02:41,480 --> 00:02:44,439
"особенным" ботам-студентам, которых будет учить наш бот-учитель.

55
00:02:44,440 --> 00:02:47,699
Конечно, бот-учитель тоже не может отличить пчелу от тройки;

56
00:02:47,700 --> 00:02:51,219
(если бы человек мог построить такого бота-учителя, проблема решена).

57
00:02:51,220 --> 00:02:54,779
Вместо этого человек даёт учителю набор картинок с пчелами и набор картинок с тройками,

58
00:02:54,780 --> 00:02:56,959
и подсказки что на какой картинке изображено.

59
00:02:56,960 --> 00:02:58,439
Бот-учитель не может учить,

60
00:02:58,440 --> 00:03:00,679
но он может ТЕСТИРОВАТЬ.

61
00:03:00,680 --> 00:03:03,848
Наши очаровательные боты-студенты трудятся в поте лица, стараются изо всех сил,

62
00:03:03,849 --> 00:03:05,779
но они очень плохо справляются с задачей.

63
00:03:05,780 --> 00:03:07,159
очень, ОЧЕНЬ плохо.

64
00:03:07,160 --> 00:03:10,039
И в этом нет их вины - они так были построены.

65
00:03:10,040 --> 00:03:13,599
Получив свои оценки, боты-студенты с позором возвращаются к боту-строителю.

66
00:03:13,600 --> 00:03:15,759
Тех, кто получил лучшие результаты, откладывают.

67
00:03:15,760 --> 00:03:17,419
Остальных утилизируют.

68
00:03:17,420 --> 00:03:19,699
Бот-строитель не особенно хорош в строительстве ботов,

69
00:03:19,700 --> 00:03:23,519
но теперь он берет оставшихся студентов и делает их копии с новыми изменениями.

70
00:03:23,520 --> 00:03:25,479
Они возвращаются обрано в школу.

71
00:03:25,480 --> 00:03:28,939
Бот-учитель учит - кхм, тестирует - их снова, и бот-строитель строит снова.

72
00:03:28,940 --> 00:03:30,919
И снова, и снова, и снова.

73
00:03:30,920 --> 00:03:34,239
Итак, у нас есть бот-строитель который строит что попало, бот-учитель который не умеет учить (только тестировать),

74
00:03:34,240 --> 00:03:38,019
и студенты которые не умеют учиться - они такие какие есть. По идее это не должно работать,

75
00:03:38,020 --> 00:03:39,759
но на практике это работает.

76
00:03:39,760 --> 00:03:44,999
Частично из-за того, что с каждой новой итерацией, скотобойня бота-строителя оставляет лучших и убирает худших,

77
00:03:45,000 --> 00:03:50,839
и частично потому что учитель учит не класс с парой десятков студентов,

78
00:03:50,840 --> 00:03:54,479
а бесконечное поле с тысячами студентов.

79
00:03:54,480 --> 00:03:57,739
Тест состоит не из десяти вопросов, а из миллионов.

80
00:03:57,740 --> 00:04:01,419
И сколько раз проходит цикл "тестировать, перестроить, тестировать"?

81
00:04:01,420 --> 00:04:03,939
Столько, сколько потребуется.

82
00:04:03,940 --> 00:04:06,578
Сначала выживающим студентам просто везёт,

83
00:04:06,579 --> 00:04:10,459
но комбинируя "везунчиков", сохраняя тех у кого получается

84
00:04:10,460 --> 00:04:13,239
и случайно измененяя их новые копии,

85
00:04:13,240 --> 00:04:16,018
в конце концов мы получим бота-студента которому невезёт,

86
00:04:16,019 --> 00:04:19,659
но он, может быть, чуть-чуть отличает пчелу от тройки.

87
00:04:19,660 --> 00:04:23,319
Этого бота мы снова копируем и слегка меняем, мало-помалу средний результат теста растёт,

88
00:04:23,320 --> 00:04:27,659
и оценка, необходимая для выживания, становится всё выше и выше.

89
00:04:27,660 --> 00:04:30,579
Продолжайте этот процесс, и в конце концов среди этого бесконечного поля

90
00:04:30,580 --> 00:04:31,099
(скотобойни)

91
00:04:31,100 --> 00:04:36,759
появится бот-студент, который сможет отличить пчелу от тройки на картинке, которую он никогда не видел, с большим успехом.

92
00:04:36,760 --> 00:04:40,759
Но как именно он делает это, не может понять ни бот-учитель, ни бот-строитель,

93
00:04:40,760 --> 00:04:43,099
ни человек-наблюдатель,

94
00:04:43,100 --> 00:04:45,499
ни сам студент.

95
00:04:45,500 --> 00:04:51,319
После такого огромного количества удачных случайных изменений, схема действий в голове робота стала невероятно сложной,

96
00:04:51,320 --> 00:04:57,139
и в то время как мы можем понять одну строчку кода, и даже небольшие абзацы кода,

97
00:04:57,140 --> 00:04:58,919
как работает всё целиком понять невозможно.

98
00:04:58,920 --> 00:05:00,599
Тем не менее, это работает.

99
00:05:00,600 --> 00:05:05,219
Однако это расстраивает, особенно учитывая, что после стольких усилий наш бот-студент стал очень хорош только в одном деле -

100
00:05:05,220 --> 00:05:07,999
только в том, чему мы его научили.

101
00:05:08,000 --> 00:05:13,519
С фотографиями он справляется отлично, но для роликов он бесполезен, перевёрнутые фотографии ставят его в ступор,

102
00:05:13,520 --> 00:05:17,119
и картинки, которые очевидно не являются пчёлами, для бота –
 стопроцентные пчёлы.

103
00:05:17,120 --> 00:05:18,519
Так как бот-учитель не умеет учить,

104
00:05:18,520 --> 00:05:23,239
всё что может сделать человек-наблюдатель это дать ему больше вопросов, чтобы сделать тест еще длиннее,

105
00:05:23,240 --> 00:05:26,719
и давать именно те вопросы, с которыми у бота возникают проблемы.

106
00:05:26,720 --> 00:05:28,639
Это очень важно понять.

107
00:05:28,640 --> 00:05:32,539
Именно это является причиной того, что современные компании одержимы сбором данных.

108
00:05:32,540 --> 00:05:35,859
Больше данных = больше тестов для ботов = лучше боты.

109
00:05:35,860 --> 00:05:38,859
Так что, когда вы проходите тест "а не бот ли вы?" на вебсайте,

110
00:05:38,860 --> 00:05:41,459
вы не только подтверждаете что вы человек,

111
00:05:41,460 --> 00:05:45,239
но и помогаете построить тест для ботов которые учатся читать, или считать,

112
00:05:45,240 --> 00:05:47,639
или отличать горы, или лошадей, от людей.

113
00:05:47,640 --> 00:05:50,079
В последнее время часто встречаются вопросы связанные с вождением?

114
00:05:50,080 --> 00:05:52,879
Хмм... Для кого же может быть полезен такой тест....

115
00:05:52,880 --> 00:05:56,379
Итак, для построения бота, который умеет распознавать фотографии, или документы, или фильтровать видеоролики,

116
00:05:56,380 --> 00:05:59,259
людям необходимо создать множество тестов.

117
00:05:59,260 --> 00:06:02,219
Но существует еще один вид тестов, которые могут создавться сами по себе.

118
00:06:02,220 --> 00:06:04,519
Тест НА людях.

119
00:06:04,520 --> 00:06:11,179
Например, предположим что гипотетический сервис MeTube хочет, чтобы пользователи смотрели ролики как можно дольше.

120
00:06:11,180 --> 00:06:14,539
Что ж, измерить как долго пользователь остаётся на сайте довольно просто.

121
00:06:14,540 --> 00:06:18,619
Итак, бот-учитель даёт каждому боту-студенту свою группу реальных пользователей NetMeTube.

122
00:06:18,620 --> 00:06:21,579
Боты-студенты смотрят, что смотрит пользователь, смотрит на их файлы,

123
00:06:21,580 --> 00:06:24,819
И пытается как можно лучше подобрать ролики чтобы пользователь остался на сайте как можно дольше.

124
00:06:24,820 --> 00:06:27,299
Чем больше средняя продолжительность, тем лучше результат теста.

125
00:06:27,300 --> 00:06:29,399
Перестроить, протестировать, повторить.

126
00:06:29,400 --> 00:06:34,039
Через миллион циклов, мы получим бота-студента, который будет хорош в удерживании пользователей на сайте,

127
00:06:34,040 --> 00:06:36,639
по крайней мере в сравнении с тем что бы мог построить человек.

128
00:06:36,640 --> 00:06:40,199
Но когда люди спрашивают - "а как же алгоритм MeTube выбирает видеоролики?"

129
00:06:40,200 --> 00:06:44,039
Мы не можем дать определённый ответ - только показать на бота,

130
00:06:44,040 --> 00:06:46,139
на набор данных, который мы ему дали при обучении,

131
00:06:46,140 --> 00:06:51,419
и, что наиболее важно, на критерии оценки лучших ботов.

132
00:06:51,420 --> 00:06:54,799
Это то, что бот пытается делать хорошо, чтобы выжить.

133
00:06:54,800 --> 00:06:59,419
Но что думает бот, и как он это думает, мы не знаем.

134
00:06:59,420 --> 00:07:02,999
Всё, что мы знаем - это что бот-студент становится нашим алгоритмом,

135
00:07:03,000 --> 00:07:09,159
потому что он на 0.01% лучше, чем предыдущий бот в тестах, созданных людьми.

136
00:07:09,160 --> 00:07:13,779
Так что все люди в интернете в своём роде помогают учить ботов, чтобы те могли задержать пользователя на сайте как можно дольше,

137
00:07:13,780 --> 00:07:17,239
или установить цены в нужное значение для максимальной прибыли,

138
00:07:17,240 --> 00:07:22,179
или подобрать интересные сообщения от ваших лучших друзей, итд.

139
00:07:22,180 --> 00:07:24,839
Если что то можно протестировать, этому можно научить. Точнее, "научить".

140
00:07:24,840 --> 00:07:29,899
И бот-студент, который выпустится из университета ботов, станет алгоритмом в своей области.

141
00:07:29,900 --> 00:07:31,539
Хотя бы на некоторое время.

142
00:07:31,540 --> 00:07:36,439
Мы приыкли к тому, что все вещи которые мы используем, даже если мы не понимаем как они работают, кто-то понимает.

143
00:07:36,440 --> 00:07:40,979
Но с этой новой системой ботов которые могут учиться, мы всё больше и больше находимся в позиции,

144
00:07:40,980 --> 00:07:42,459
когда мы используем вещи,

145
00:07:42,460 --> 00:07:45,719
которые никто, даже их создатели, не могут понять.

146
00:07:45,720 --> 00:07:49,219
Мы можем только надеяться помочь им тестами, которые мы создаём,

147
00:07:49,220 --> 00:07:50,939
и нам надо привыкнуть к этой мысли,

148
00:07:50,940 --> 00:07:58,239
так как наши маленькие друзья-боты повсюду, и никуда они не денутся.

149
00:07:58,240 --> 00:08:00,699
ОК. Боты наблюдают.

150
00:08:00,700 --> 00:08:02,319
Вы знаете, что сейчас будет.

151
00:08:02,320 --> 00:08:04,919
Сейчас я должен вас попросить...

152
00:08:04,920 --> 00:08:06,179
чтобы вы лайкнули...

153
00:08:06,180 --> 00:08:07,499
оставили комментарий...

154
00:08:07,500 --> 00:08:09,479
...и подписались.

155
00:08:09,480 --> 00:08:11,299
И колокольчик.

156
00:08:11,300 --> 00:08:13,759
И поделились в TweetBook.

157
00:08:13,760 --> 00:08:15,779
Аалгоритм наблюдает.

158
00:08:15,780 --> 00:08:18,199
Он не покажет другим это видео...

159
00:08:18,200 --> 00:08:21,179
если вы этого не сделаете.

160
00:08:21,180 --> 00:08:24,259
Видите, до чего вы заставляете меня опускаться, боты?!

161
00:08:24,260 --> 00:08:26,339
Чего вам надо? Больше времени просмотров?

162
00:08:26,340 --> 00:08:28,119
Этого вы хотите?

163
00:08:28,120 --> 00:08:30,299
Хорошо.

164
00:08:30,300 --> 00:08:34,259
(вздох..) Кстати, друзья, вы знаете что у меня есть подкаст?

165
00:08:34,260 --> 00:08:40,599
Можете его послушать. Или включить, когда делаете уборку.

166
00:08:40,600 --> 00:08:47,019
Это часы и часы аудиоконтента для вас, и время для ботов которые за вами наблюдают.

167
00:08:47,020 --> 00:08:50,519
Ну же, кликните на него. Развлеките себя.

168
00:08:50,520 --> 00:08:51,739
Помогите мне.

169
00:08:51,740 --> 00:08:53,420
Помогите ботам.

